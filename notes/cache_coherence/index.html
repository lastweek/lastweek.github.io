<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Yizhou Shan">
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Cache Coherence - Yizhou Shan's Home Page</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>
  <link href='https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Cache Coherence";
    var mkdocs_page_input_path = "notes/cache_coherence.md";
    var mkdocs_page_url = "/notes/cache_coherence/";
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js"></script>
  <script src="../../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../../js/highlight.pack.js"></script> 
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-143772066-1', 'auto');
      ga('send', 'pageview');
  </script>
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Yizhou Shan's Home Page</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	  
          
		  
  <ul class="" href="../..">
    <li class="toctree-l1">
  <a class="" href="../..">Home</a>
  </li></ul>
          
		  
  <p class="caption">Notes</p>
  <ul class="current">
          <li class="toctree-l1">
            
  <a class="" href="../paper_fpga/">FPGA Papers</a>
        </li>
          <li class="toctree-l1 current">
            
  <a class="current" href="./">Cache Coherence</a>
  <ul class="subnav">
      
  <li class="toctree-l2 current">
  
    <a class="current"  href="#practical-cache-coherence-implementation">Practical Cache Coherence Implementation</a>
  
  
    <ul class="">
    
        <li class="toctree-l3 toc-item" >
          <a class="toctree-l3" href="#summary-and-thoughs">Summary and Thoughs</a>
        </li>
    
        <li class="toctree-l3 toc-item" >
          <a class="toctree-l3" href="#readings">Readings</a>
        </li>
    
        <li class="toctree-l3 toc-item" >
          <a class="toctree-l3" href="#misc-facts">Misc Facts</a>
        </li>
    
        <li class="toctree-l3 toc-item" >
          <a class="toctree-l3" href="#case-study">Case Study</a>
        </li>
    
    </ul>
  
  </li>

  </ul>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../benchmark/">Benchmarks</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../paper_perf_shadows/">Perf Shadows</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../linux-articles/">Linux Articles</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../proc/">[Linux] Special Files</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../rmap/">[Linux] Reverse Mmap (rmap)</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../trace/">[Linux] Trace/Profile</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../cgroup-swap/">[Linux] Cgroup and Swap</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../userfaultfd/">[Linux] Userfaultfd</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../xperf/">[Linux] User/kern Cross Perf</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../kvm-basic/">[Linux] KVM</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../misc/essential/">Essential</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../misc/cheatsheet/">Cheatsheet</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/general_log/0919">Log</a>
        </li>
  </ul>

          
		  
  <p class="caption">FPGA</p>
  <ul class="">
          <li class="toctree-l1">
            
  <a class="" href="../../fpga/hls_axi/">HLS: Usage of AXI-Stream</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../fpga/hls_axi/">HLS: High-performance AXI-MM</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="../../fpga/vivado_tricks/">Vivado Tricks</a>
        </li>
  </ul>

          
		  
  <p class="caption">LegoOS-Dev</p>
  <ul class="">
          <li class="toctree-l1">
            
  <a class="" href="/lego/log/TODO">Log</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/lego/kernel/kconfig">Kernel</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/lego/syscall/facts">Syscall</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/lego/pcache/config">Pcache</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/lego/driver/pci">Driver</a>
        </li>
          <li class="toctree-l1">
            
  <a class="" href="/lego/paper/nmp">Paper</a>
        </li>
  </ul>

          
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Yizhou Shan's Home Page</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Notes &raquo;</li>
        
      
    
    <li>Cache Coherence</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="practical-cache-coherence-implementation">Practical Cache Coherence Implementation<a class="headerlink" href="#practical-cache-coherence-implementation" title="Permanent link">&para;</a></h1>
<details class="note"><summary>Version History</summary><table><thead><tr><th align="left">Date</th><th>Description</th></tr></thead><tbody><tr><td align="left">Oct 3, 2019</td><td>Add FPGA related discussion</td></tr><tr><td align="left">Jun 28, 2019</td><td>Initial draft</td></tr></tbody></table></details><p><img alt="ðŸ¶" class="emojione" src="https://cdn.jsdelivr.net/emojione/assets/svg/1f376.svg" title=":sake:" /></p>
<ul>
<li><a href="#practical-cache-coherence">Practical Cache Coherence</a><ul>
<li><a href="#summary-and-thoughs">Summary and Thoughs</a></li>
<li><a href="#readings">Readings</a></li>
<li><a href="#misc-facts">Misc Facts</a></li>
<li><a href="#case-study">Case Study</a><ul>
<li><a href="#intel">Intel</a></li>
<li><a href="#amd">AMD</a></li>
<li><a href="#arm">ARM</a></li>
<li><a href="#opencapi-and-ccix">OpenCAPI and CCIX</a></li>
<li><a href="#openpiton">OpenPiton</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>A general collection of resources on cache coherence.
I started this when I was having a hard time optimizing lock delegation.
This note is not about acadamic new ideas, but rather for
a concrete understanding of current cache coherence implementations.</p>
<h2 id="summary-and-thoughs">Summary and Thoughs<a class="headerlink" href="#summary-and-thoughs" title="Permanent link">&para;</a></h2>
<ul>
<li>The textbooks tough us the basic concept of MESI. And realizations
  like snoop and directory. But what usually missing is the implementation
  details when it comes to: 1) conflicts, 2) no single shared bus.</li>
<li>Modern processors have Network-on-Chip (NoC). Cores, cache slices,
  and memory controllers are connected via an on-chip network.
  The model is no different from a datacenter cluster connected by real network.</li>
<li>Cache requests generated by MESI protocols should appear <em>atomic</em> to cores.
  Given the distributed nature of all resources, those cache requests
  will have to be implemented like <strong>distributed transactions</strong>.</li>
<li>For example, the MESIF is the cache coherence protocol used by Intel.
  When a read is made to an invalid line, the corresponding cache
  will perform a <em>cache read transaction</em> to read the data from
  either other caches or memory. This transaction consists multiple
  steps such as: send requests, collect responses, send ACKs.</li>
<li>Those transactions will conflict if multiple reads and writes
  happen at the same time. Someone has to resolve it.
  It can be resolved by different cache controllers, or by a single
  serialization point like home agent.</li>
<li>Just like you can have many ways to implement transactions
  for distributed systems, there are also many ways to do
  cache coherence transactions. And there are many.</li>
<li>Atomic Read-Modify-Write (RMW) instructions will make cache coherence
  implementations even more complex. Those instructions include
  <code class="codehilite">read-and-inc</code>, <code class="codehilite">test-and-set</code>, and <code class="codehilite">lock;</code>-prefixed.
  I think, there will some &ldquo;lock the bus&rdquo;, or &ldquo;locked state&rdquo; at the
  home agent per cache line. Having atomic RMW instructions
  will add more complexity to the overall transaction design.</li>
<li>While reading Intel related cache coherence diagrams/transactions,
  you might find many different descriptions. Don&rsquo;t panic. They are
  just different implementations proposed by Intel. Different
  implementations will have different trade-offs and performance,
  you can check <a href="https://frankdenneman.nl/2016/07/11/numa-deep-dive-part-3-cache-coherency/">Frank&rsquo;s post</a>
  for more details.</li>
<li>Directory-based cache coherence protocol and implementation will
  be the future for multicore machines. Because it incurs much less
  coherence traffic than snoop-based ones, thus more scalable.
  The trend is confirmed by recent Intel UPI directory-based approach.
  Related readings:<ul>
<li>[1]: <a href="http://www.cis.upenn.edu/acg/papers/cacm12_why_coherence.pdf">Why On-Chip Cache Coherence Is Here to Stay</a></li>
<li>[2]: <a href="https://www.realworldtech.com/qpi-evolved/3/">QPI 1.1 Invovled</a></li>
<li>[3]: <a href="http://research.cs.wisc.edu/multifacet/papers/isca99_multicast_talk_pdf.pdf">Paper: Multicast Snooping: A New Coherence Method Using a Multicast Address Network, ISCA &lsquo;99</a></li>
<li>[4]: <a href="https://www.cis.upenn.edu/~milom/papers/isca03_destination_set_prediction.pdf">Paper: Using Destination-Set Prediction to Improve the Latency/Bandwidth Tradeoff in Shared-Memory Multiprocessors, ISCA&lsquo;03</a></li>
<li>[5]: The trade-off: <img alt="img_1" src="../cache_coherence_img1.png" /></li>
</ul>
</li>
</ul>
<p>Left questions:
- Do cache coherence implementations ensure <strong>fairness</strong> among cores?</p>
<h2 id="readings">Readings<a class="headerlink" href="#readings" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.455.4198&amp;rep=rep1&amp;type=pdf">The Architecture of the Nehalem Processor and Nehalem-EP SMP Platforms</a>, chapter 5.2 Cache-Coherence Protocol for Multi-Processors.</li>
<li><a href="https://software.intel.com/sites/products/collateral/hpc/vtune/performance_analysis_guide.pdf">Intel: Performance Analysis Guide for IntelÂ® Coreâ„¢ i7 Processor and IntelÂ® Xeonâ„¢ 5500 processors</a></li>
<li><a href="https://frankdenneman.nl/2016/07/11/numa-deep-dive-part-3-cache-coherency/">Blog: NUMA Deep Dive Part 3: Cache Coherency</a><ul>
<li>By far the BEST blog I&rsquo;ve seen on the topic of <code class="codehilite">Intel snoop models</code>. Frank&rsquo;s other articles are also amazing.</li>
<li>Intel is using MESIF cache coherence protocol, but it has multiple cache coherence implementations.
  The first one is <code class="codehilite">Source Snoop</code> (or <code class="codehilite">Early Snoop</code>), which is more like a traditional snoop-based
  cache coherence implementation. Upon miss, the caching agent will broadcast to other agents.
  The second one is <code class="codehilite">Home Snoop</code>, which is more like a directory-based cache coherence implementation.
  Upon miss, the caching agent will contact home agent, and then the home agent will send requests
  to other caching agents who have the requested cache line.
  There are other implementations like Cluster-on-Die.
  Intel UPI gets rid of all this complexity, it is only using directory-based, in the hope to reduce
  cache coherence traffic, which make sense.</li>
<li>Related: <a href="https://software.intel.com/en-us/articles/intel-xeon-processor-e5-2600-v4-product-family-technical-overview">Broadwell EP Snoop Models</a></li>
<li>Related: <a href="https://software.intel.com/en-us/articles/intel-xeon-processor-scalable-family-technical-overview">Skylay UPI</a></li>
</ul>
</li>
<li><a href="https://researchspace.auckland.ac.nz/bitstream/handle/2292/11594/MESIF-2009.pdf?sequence=6">Paper: MESIF: A Two-Hop Cache Coherency Protocol for Point-to-Point Interconnects (2009)__</a><ul>
<li>A MUST read.</li>
<li>This paper has the most extensive description of the MESIF protocol implementation.
  It has many <code class="codehilite">timing diagrams</code> than describe how cache requests actually proceed.
  Those diagrams can help us understand what is needed to finish a cache request.</li>
<li>Their <a href="https://parlab.eecs.berkeley.edu/sites/all/parlab/files/20091029-goodman-ssccp.pdf">slides</a>
  has more timing diagrams.</li>
<li>But do note: the implementation described by this paper is different from
  what <a href="https://www.intel.ca/content/dam/doc/white-paper/quick-path-interconnect-introduction-paper.pdf">Intel QPI</a>
  has in products. The difference is discussed at chapter 4. MESIF and QPI, namely,
  other caching agents will send responses to Home agent rather than to requesting agent.
  QPI relies on Home agent to solve conflict.</li>
<li>Also note: this is just one of the possible implementations to realize MESIF protocol.
  There could be many other ways, e.g., QPI source snooping, QPI home snooping.
  But all of them share the essential and general concepts and ideas.</li>
</ul>
</li>
<li><a href="https://www.elsevier.com/books-and-journals/book-companion/9780128119051">Appendix I: Large-Scale Multiprocessors and Scientific Applications</a>,
  chapter 7 Implementing Cache Coherence.<ul>
<li>This is probably some most insightful discussion about real implementation of cache coherence.
  With the distributed nature and Network-on-Chip, implementing cache coherence in modern
  processors is no different than implementing a distributed transaction protocol.</li>
<li>Cache activities like read miss or write miss have multi-step operations, but they
  need to appear as &ldquo;atomic&rdquo; to users. Put in another way, misses are like transactions,
  they have multiple steps but they must be atomic. They can be retried.</li>
<li>Having directory for cache coherence will make implementation easier. Because
  the place (e.g., L3) where directory resides can serve as the serialization point.
  They can solve write races.</li>
<li><code class="codehilite">Home directory controller</code> and <code class="codehilite">cache controller</code> will exchange messages like a set of distributed machines.
  In fact, with NoC, they are actually distributed system.</li>
</ul>
</li>
<li><a href="https://www.intel.ca/content/dam/doc/white-paper/quick-path-interconnect-introduction-paper.pdf">Intel: An Introduction to the IntelÂ® QuickPath Interconnect</a>,
  page 15 MESIF.<ul>
<li><a href="https://www.hotchips.org/wp-content/uploads/hc_archives/hc21/1_sun/HC21.23.1.SystemInterconnectTutorial-Epub/HC21.23.120.Safranek-Intel-QPI.pdf">HotChips slide</a>, has timing diagrams.</li>
<li>It explains the <code class="codehilite">Home Snoop</code> and <code class="codehilite">Source Snoop</code> used by Intel.</li>
<li>Based on their explanation, it seems both <code class="codehilite">Home Snoop</code> and <code class="codehilite">Source Snoop</code> are using a combination of
    snoop and directory. The Processor#4 (pg 17 and 18) maintains the directory.</li>
<li>And this is a perfect demonstration of the details described in <a href="https://www.elsevier.com/books-and-journals/book-companion/9780128119051">Appendix I: Large-Scale Multiprocessors and Scientific Applications</a>.</li>
<li>Related patent: <a href="https://patents.google.com/patent/US20150081977">Extending a cache coherency snoop broadcast protocol with directory information</a></li>
</ul>
</li>
<li><a href="http://research.cs.wisc.edu/multifacet/papers/isca99_multicast_talk_pdf.pdf">Paper: Multicast Snooping: A New Coherence Method Using a Multicast Address Network, ISCA &lsquo;99</a><ul>
<li>A hybrid snoop and directory cache coherence implementation. The insight is snoop
  cause too much bandwidth, directory incurs longer latency.</li>
<li>So this paper proposed <code class="codehilite">Multicast snoop</code>, where it multicasts coherence transactions
  to selected processors, lowering the address bandwidth required for snooping.</li>
</ul>
</li>
<li><a href="http://www.cis.upenn.edu/acg/papers/cacm12_why_coherence.pdf">Paper: Why On-Chip Cache Coherence Is Here to Stay, Communications of ACM&lsquo;02</a><ul>
<li>This paper discusses why cache coherence can scale. A nice read.</li>
<li>R1: Coherenceâ€™s interconnection network traffic per miss scales
      when precisely tracking sharers. (Okay increased directory bits,
  what about those storage cost? See R2).</li>
<li>R2: Hierarchy combined with inclusion enables efficient scaling
      of the storage cost for exact encoding of sharers.</li>
<li>R3: private evictions should send explicit messages to shared cache
      to enable precise tracking. Thus the recall (<em>back invalidation</em>) traffic can be
  reduced when shared cache is evicting (assume inclusion cache).</li>
<li>R4: Latencies of cache request can be amortized.</li>
</ul>
</li>
<li><a href="https://www.amazon.com/Parallel-Computer-Organization-Design-Professor/dp/0521886759">Book: Parallel Computer Organization and Design</a>, Chapter 7.<ul>
<li>Links coherence and consistency together. This chapter uses detailed graphs to show
  how different cache coherence implementations affect consistency.</li>
</ul>
</li>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.225.9278&amp;rep=rep1&amp;type=pdf">Book: A Primer on Memory Consistency and Cache Coherence</a><ul>
<li>Best book for this topic.</li>
</ul>
</li>
<li><a href="https://software.intel.com/en-us/forums/intel-moderncode-for-parallel-architectures/topic/700477">Dr.Bandwidth on explaining core-to-core communication transactions!</a><ul>
<li>Seriously, it&rsquo;s so good!</li>
<li>Although, I just feel there are so many unpublished details about the exact coherence transactions.
  Dr.Bandwidth himself used a lot &ldquo;maybe&rdquo;, and listed possible actions.</li>
</ul>
</li>
<li><a href="http://www.mavam.com/lance/publications/tcc_ISCA04.pdf">Transactional Memory Coherence and Consistency, ISCA&lsquo;04</a></li>
<li><a href="http://www.mavam.com/lance/publications/tcc_ASPLOS04.pdf">Programming with Transactional Coherence and Consistency (TCC)</a><ul>
<li><a href="http://www.mavam.com/lance/publications/tcc_ASPLOS04Talk.pdf">Slide1</a></li>
<li>Awarded the most influential paper at ISCA 2019. I took a read today (Jul 21, 2019).</li>
<li>I feels like it&rsquo;s using the &ldquo;batch&rdquo; optimization for all time. The TCC design,
  kind of combines both cache coherence and memory consistency: how transactions
  commit or orders, determins the coherence and consistency.</li>
<li>It seems the load/store speculative execution used in their context is so similar
  to what Dr.Bandwidth said about Intel&rsquo;s implementation. Basically, the processor
  might read some data from L1/L2 and continue execution, but there is a chance,
  that the data is modifed by others, and the L3 caching agent or home agent
  could decide to revoke it. Once receiving such revoke message,
  the processor must cancel all executions that use the speculatively read data. </li>
<li>It mentions couple Thread-Level Speculation papers, I think they should on this topic.</li>
</ul>
</li>
</ul>
<h2 id="misc-facts">Misc Facts<a class="headerlink" href="#misc-facts" title="Permanent link">&para;</a></h2>
<ul>
<li>Intel Caching Agent (Cbox) is per core (or per LLC slice). Intel Home Agent is per memory controller.<ul>
<li>&ldquo;The LLC coherence engine (CBo) manages the interface between the core and the last
level cache (LLC). All core transactions that access the LLC are directed from the core
to a CBo via the ring interconnect. The CBo is responsible for managing data delivery
from the LLC to the requesting core. It is also responsible for maintaining coherence
between the cores within the socket that share the LLC; generating snoops and
collecting snoop responses from the local cores when the MESIF protocol requires it.&rdquo;</li>
<li>&ldquo;Every physical memory address in the system is uniquely associated with a single Cbox
  instance via a proprietary hashing algorithm that is designed to keep the distribution of
  traffic across the CBox instances relatively uniform for a wide range of possible address patterns.&rdquo;</li>
<li>Read more <a href="https://www.intel.com/content/dam/www/public/us/en/documents/manuals/xeon-e5-2600-v2-uncore-manual.pdf">here, chapter 2.3</a>.</li>
<li>Starting from Intel UPI, Caching Agent and Home Agent are combined as CHA.</li>
</ul>
</li>
<li>A good <a href="https://www.realworldtech.com/qpi-evolved/3/">discussion</a> about why QPI gradually drop <code class="codehilite">Source Snoop</code> and solely use <code class="codehilite">Home Snoop</code>.<ul>
<li>The motivation is scalability. It turns out the new UPI only supports directory-based protocol.</li>
<li>This makes sense because 1) inter socket bandwidth is precious, 2) snoop will consume a lot bandwidth.</li>
</ul>
</li>
<li>Intel UPI is using directory-based home snoop coherency protocol<ul>
<li><a href="https://software.intel.com/en-us/articles/intel-xeon-processor-scalable-family-technical-overview">IntelÂ® XeonÂ® Processor Scalable Family Technical Overview</a></li>
</ul>
</li>
<li>To provide sufficient bandwidth, shared caches are typically interleaved
  by addresses with banks physically distributed across the chip.</li>
</ul>
<h2 id="case-study">Case Study<a class="headerlink" href="#case-study" title="Permanent link">&para;</a></h2>
<h3 id="intel">Intel<a class="headerlink" href="#intel" title="Permanent link">&para;</a></h3>
<p>Intel does not disclose too much details about their cache coherence implementations.
The most valuable information is extracted from uncore PMU manuals, and discussions
from Dr. Bandwidth. According to Dr. Bandwidth, the Intel CPU could dynamically
adapt its coherence strategy during runtime according to workload. There won&rsquo;t
be one fixed cache coherence implementation, there will be many. It depends on
workload which one is used at runtime.</p>
<p>List below might not be completely true. Just my understanding.</p>
<ul>
<li>Physical addresses are uniquely hashed into L3 slices. That means each individual
  physical address belongs to a L3 slice, and also belongs to a home agent.</li>
<li>Upon L2 miss, it will send requests to corresponding L3 slice. If the L3 slice
  is in the local socket, the request can be delievered within the same socket.
  If the L3 slice belongs to another remote socket, the L2 miss request will
  be sent over QPI/UPI. Also note that the L2 controller will not send snoop requests.
  (This is answering the question of &ldquo;why using local memory is faster than remote&rdquo;
   from the cache coherence perspective.)</li>
<li>At L3, when received the request from a L2,<ul>
<li>If it&rsquo;s in source snoop model, it will send <code class="codehilite">snoop messages</code> to other sockets.</li>
<li>If it&rsquo;s in home snoop model, it will send <code class="codehilite">read message</code> to other sockets.
  The another socket will generate snoop and collect responses. (R3QPI or home?)</li>
<li>Quote Dr. Bandwidth: Maintaining consistency is easier if the data is sent
  to the L3 first, and then to the requesting core, but it is also possible to
  send to both at the same time (e.g., &ldquo;Direct2Core&rdquo;). In recent processors,
  these return paths are chosen dynamically based on undocumented states and
  settings of the processor.</li>
<li>I&rsquo;m not sure who will ACK L2 at last. L3 or home agent? Both are possible.</li>
</ul>
</li>
<li>I think both L3 and home agent have directory information. They know where
  to send snoop/read messages. And both of them can serialize coherence transactions!
  It&rsquo;s just undocumented who is doing what.</li>
<li>In generall, we need to bear the fact that we cannot just figure out how Intel
  cache coherence works underlying. We maybe just need to &ldquo;vaguely&rdquo; know the fact that:<ul>
<li>Both directory and snoop will be used in combination.</li>
<li>L3/home agent will serialize conflicting transactions</li>
<li>L3/home agent will send data to requesting core</li>
<li>L3/home agent will send final ACK to requesting L2</li>
<li>A coherence transaction is a multi-step distributed transaction.
  It involes sending requests, serialize conflicts, receiving responses/ACKs.</li>
</ul>
</li>
</ul>
<p>When in doubt, read the <a href="https://software.intel.com/en-us/forums/intel-moderncode-for-parallel-architectures/topic/700477">discussion</a> posted by Dr. Bandwidth.</p>
<h3 id="amd">AMD<a class="headerlink" href="#amd" title="Permanent link">&para;</a></h3>
<ul>
<li>AMD HyperTransport Assit for Cache Coherence<ul>
<li><a href="https://www.hotchips.org/wp-content/uploads/hc_archives/hc14/3_Tue/28_AMD_Hammer_MP_HC_v8.pdf">Slide</a></li>
<li><a href="http://www.hotchips.org/wp-content/uploads/hc_archives/hc21/2_mon/HC21.24.100.ServerSystemsI-Epub/HC21.24.110.Conway-AMD-Magny-Cours.pdf">Slide</a></li>
</ul>
</li>
</ul>
<h3 id="arm">ARM<a class="headerlink" href="#arm" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://developer.arm.com/architectures/system-architectures/amba/documentation?_ga=2.147594999.1797165765.1562530195-129127748.1561485892">AMBA CHI Specifications</a><ul>
<li>This is probabaly the most comprehensive document I&rsquo;ve ever seen about cache coherence.
  Although terms used by ARM differs from the ones used by Intel, still, you can map them.
  Chapter 5 Interconnect Protocol Flows has a lot timing diagrams regarding read/write/atomic
  coherence transactions.</li>
<li>It&rsquo;s a good reference to know, but it would be hard to actually understand the details.</li>
</ul>
</li>
</ul>
<h3 id="opencapi-and-ccix">OpenCAPI and CCIX<a class="headerlink" href="#opencapi-and-ccix" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://docs.wixstatic.com/ugd/0c1418_c6d7ec2210ae47f99f58042df0006c3d.pdf">CCIX White Paper</a></li>
<li><a href="">OpenCAPI</a></li>
</ul>
<h3 id="openpiton">OpenPiton<a class="headerlink" href="#openpiton" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://parallel.princeton.edu/openpiton/docs/micro_arch.pdf">OpenPiton Microarchitecture Specification</a><ul>
<li>Directory-based MESI</li>
<li>This spec has detailed coherence message packet format and type. Unfortunately,
  it does not say anything about how they deal with coherence transaction conflicts.
  E.g., some timeline diagrams like Figrue &#8532; in this <a href="https://researchspace.auckland.ac.nz/bitstream/handle/2292/11594/MESIF-2009.pdf?sequence=6">paper</a>.</li>
</ul>
</li>
</ul>
<h3 id="fpga">FPGA<a class="headerlink" href="#fpga" title="Permanent link">&para;</a></h3>
<ul>
<li>LEAP Shared Memories: Automating the Construction of FPGA Coherent Memories, FCCM&lsquo;14.<ul>
<li>This work is built on their earlier work, which basically add the data caching
  concept to FPGA: using BRAM as L1, on-board DRAM as L2, host or remote DRAM as L3.</li>
<li>In their earlier work, each FPGA application (or bitstream) has a private L1 cache.</li>
<li>In this work, the add MESI coherence to these private L1 caches, as in they can make
  multiple L1 cache cache-coherent.</li>
<li>The techniques and protocols from this paper are similar to the exisiting ones. For example,
  1) they use a global serializing point to serialize transactions, 2) they designed a lot
  messaging types such as INV, RESP and so on.</li>
</ul>
</li>
<li><a href="https://research.vmware.com/publications/project-pberry-fpga-acceleration-for-remote-memory">VMware Research Project PBerry</a><ul>
<li>A very interesting and promising project.</li>
</ul>
</li>
<li><a href="https://www.intel.com/content/www/us/en/programmable/documentation/bfr1522087299048.html">Intel FPGA PAC</a><ul>
<li>Intel itself is building a FPGA-CPU cache coherent setting. They use the Intel UPI interconnect
  to natually the spectrum. The FPGA shell has some modules to handle this.</li>
</ul>
</li>
</ul>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../benchmark/" class="btn btn-neutral float-right" title="Benchmarks">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../paper_fpga/" class="btn btn-neutral" title="FPGA Papers"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../paper_fpga/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../benchmark/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/require.js"></script>
      <script src="../../search/search.js"></script>

</body>
</html>
