{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Hello! I\u2019m Yizhou, I\u2019m a Research Scientist at Huawei Cloud . I earned my PhD from University of California San Diego under the supervision of Prof. Yiying Zhang . Contact: y1shan AT eng DOT ucsd DOT edu . You can find my CV here . Blogging Latest Jul 2022 CXL Apr 2022 MLIR Mar 2022 Resource Disaggregation Spectrum Feb 2022 Distributed Transactions Dec 2021 Notes on Modern Data Center Networking Hot Oct 2019 FPGA Bitstream Explained May 2020 On DPDK and RDMA Related Software Jan 2020 Modern Virtualization Dec 2020 Dynamic Linking Jun 2019 Practical Cache Coherence Dec 2020 Architecture and more! Research [ Oct 2022 ] HoPP accepted to HPCA\u201823. [ Sep 2022 ] I will serve as a ATC\u201823 PC. [ Jun 2022 ] A vision paper accepted to APSys\u201822 [ Jun 2022 ] Serve as EuroSys\u201823 PC [ Jun 2022 ] Serve as SoCC\u201822 PC [ Mar 2022 ] Serve as APSys\u201822 PC [ Mar 2022 ] Serve as ChinaSys\u201822 PC [ Mar 2022 ] Defended. The full defense slide is here . [ Oct 2021 ] Serve as EuroSys\u201822 Shadow PC [ Sep 2021 ] We made our SuperNIC paper public. [ Sep 2021 ] Serve as SOSP\u201821 Artifact Evaluation PC [ Aug 2021 ] We made our Clio paper public. [ Jun 2021 ] Start my final internship at Microsoft Research, working on Security + System. [ Jun 2021 ] I proposed my thesis and became a Ph.D candidate. [ Jan 2021 ] The DPM work is accepted to present at NVMW\u201821 [ Jan 2021 ] This summer, I\u2019m going to do my last internship at MSR Redmond on cloud confidential computing . [ Dec 2020 ] Invited to join the 2021 JSys Student Editorial Board [ Oct 2020 ] Serve as EuroSys\u201821 Shadow PC [ Sep 2020 ] Serve as OSDI\u201820 Artifact Evaluation PC [ Sep 2020 ] Serve as ASPLOS\u201821 External Reviewer. First major conference review! [ Apr 2020 ] Disaggregated Persistent Memory accepted to ATC\u201820 [ Feb 2020 ] Talk about FPGA OS [ Sep 2019 ] Moved to UCSD. [ May 2019 ] Intern at VMware Research , with Marcos K. Aguilera [ Apr 2019 ] Storm accpeted to SYSTOR\u201819 . Awarded Best Paper. [ Jan 2019 ] Short paper on Disaggregated Persistent Memory accpeted to NVMW\u201819 [ Jul 2018 ] LegoOS accepted to OSDI\u201818 . Awarded Best Paper. [ May 2018 ] Intern at VMware Research , with Stanko Novakovic . Research \u00b6 My main research interests span distributed systems, data center networking, OS, hardware (FPGA), disaggregated memory/storage systems, and their intersections. Disaggregated Data Center Fully Disaggregated Data Center, APSys\u201822 LegoOS, OSDI\u201818 Disaggregated Memory HoPP, HPCA\u201823 - Hardware-augmented Prefetching for Disaggregated Memory Clio, ASPLOS\u201822 - An FPGA-based disaggregated memory device Clover, ATC\u201820 - Pure one-sided KVS on disaggregated PM Storm, SYSTOR\u201819 - Highly-efficient KVS on disaggregated memory Hotpot, SoCC\u201817 - Transactional distributed PM over RDMA Networking Design SuperNIC, arXiv\u201821 - An FPGA-based Programmable Multi-Host NIC Clio, ASPLOS\u201822 - Rethinking RDMA NIC, congestion control Publications \u00b6 HoPP: Hardware-Software Co-Designed Page Prefetching for Disaggregated Memory Haifeng Li, Ke Liu, Ting Liang, Zuojun Li, Tianyue Lu, Hui Yuan, Yinben Xia, Yungang Bao, Mingyu Chen, Yizhou Shan HPCA 2023 To Appear Towards a Fully Disaggregated and Programmable Data Center Yizhou Shan , Will Lin, Zhiyuan Guo, Yiying Zhang APSys 2022 [Paper] Distributing and Disaggregating Hardware Resources in Data Centers Yizhou Shan UCSD Dissertation 2022 A New Networking Device Designed for Disaggregation (under submission) Yizhou Shan , Will Lin, Ryan Kosta, Arvind Krishnamurthy, Yiying Zhang [Preprint] [Code] Clio: A Hardware-Software Co-Designed Disaggregated Memory System Yizhou Shan , Zhiyuan Guo (co-first authors), Xuhao Luo, Yutong Huang, Yiying Zhang ASPLOS 2022 [Paper] [Code] [Slide] Disaggregating Persistent Memory and Controlling Them Remotely: An Exploration of Passive Disaggregated Key-Value Stores Shin-Yeh Tsai, Yizhou Shan , Yiying Zhang ATC 2020 [Paper] [Code] [Slide] [Short-Talk] [Full-Talk] [Keynote] Storm: a fast transactional dataplane for remote data structures Stanko Novakovic, Yizhou Shan , Aasheesh Kolli, Michael Cui, Yiying Zhang, Haggai Eran, Liran Liss, Michael Wei, Dan Tsafrir, Marcos Aguilera SYSTOR 2019 (Best Paper Award) [Paper] [Slide] [Talk] LegoOS: A Disseminated, Distributed OS for Hardware Resource Disaggregation Yizhou Shan , Yutong Huang, Yilun Chen, Yiying Zhang OSDI 2018 (Best Paper Award) [Paper] [Code] [Slide] [Keynote-iCloud] [Talk] Distributed Shared Persistent Memory Yizhou Shan , Shin-Yeh Tsai, Yiying Zhang SoCC 2017 [Paper] [Code] [Slide] [Poster] Workshops \u00b6 Disaggregating Persistent Memory and Controlling Them Remotely: An Exploration of Passive Disaggregated Key-Value Stores Shin-Yeh Tsai, Yizhou Shan , Yiying Zhang 12 th Annual Non-Volatile Memories Workshop ( NVMW 2021 ) [Paper] Challenges in Building and Deploying Disaggregated Persistent Memory Yizhou Shan , Yutong Huang, Yiying Zhang 10 th Annual Non-Volatile Memories Workshop ( NVMW 2019 ) [Paper] Disaggregating Memory with Software-Managed Virtual Cache Yizhou Shan , Yiying Zhang 2018 Workshop on Warehouse-scale Memory Systems ( WAMS 2018 ) (co-located with ASPLOS \u201818) [Paper] Distributed Shared Persistent Memory Yizhou Shan , Shin-Yeh Tsai, Yiying Zhang 9 th Annual Non-Volatile Memories Workshop ( NVMW 2018 ) [Paper] Disaggregated Operating System Yiying Zhang, Yizhou Shan , Sumukh Hallymysore 17 th International Workshop on High Performance Transaction Systems ( HPTS 2017 ) [Paper] Professional Services \u00b6 Program Committee SoCC (2022) EuroSys (2023, 2022 shadow, 2021 shadow) ASPLOS (2021 external) Journal Journal of Systems Research: 2021 - Current ACM Transactions on Architecture and Code Optimization (TACO): 2021 ACM Transactions on Storage (TOS): 2020 IEEE/ACM Transactions on Networking: 2020 Artifact Evaluation SOSP (2021) OSDI (2020) Social \u00b6 Google Scholar Github Twitter LinkedIn Goodreads","title":"Home"},{"location":"#research","text":"My main research interests span distributed systems, data center networking, OS, hardware (FPGA), disaggregated memory/storage systems, and their intersections. Disaggregated Data Center Fully Disaggregated Data Center, APSys\u201822 LegoOS, OSDI\u201818 Disaggregated Memory HoPP, HPCA\u201823 - Hardware-augmented Prefetching for Disaggregated Memory Clio, ASPLOS\u201822 - An FPGA-based disaggregated memory device Clover, ATC\u201820 - Pure one-sided KVS on disaggregated PM Storm, SYSTOR\u201819 - Highly-efficient KVS on disaggregated memory Hotpot, SoCC\u201817 - Transactional distributed PM over RDMA Networking Design SuperNIC, arXiv\u201821 - An FPGA-based Programmable Multi-Host NIC Clio, ASPLOS\u201822 - Rethinking RDMA NIC, congestion control","title":"Research"},{"location":"#publications","text":"HoPP: Hardware-Software Co-Designed Page Prefetching for Disaggregated Memory Haifeng Li, Ke Liu, Ting Liang, Zuojun Li, Tianyue Lu, Hui Yuan, Yinben Xia, Yungang Bao, Mingyu Chen, Yizhou Shan HPCA 2023 To Appear Towards a Fully Disaggregated and Programmable Data Center Yizhou Shan , Will Lin, Zhiyuan Guo, Yiying Zhang APSys 2022 [Paper] Distributing and Disaggregating Hardware Resources in Data Centers Yizhou Shan UCSD Dissertation 2022 A New Networking Device Designed for Disaggregation (under submission) Yizhou Shan , Will Lin, Ryan Kosta, Arvind Krishnamurthy, Yiying Zhang [Preprint] [Code] Clio: A Hardware-Software Co-Designed Disaggregated Memory System Yizhou Shan , Zhiyuan Guo (co-first authors), Xuhao Luo, Yutong Huang, Yiying Zhang ASPLOS 2022 [Paper] [Code] [Slide] Disaggregating Persistent Memory and Controlling Them Remotely: An Exploration of Passive Disaggregated Key-Value Stores Shin-Yeh Tsai, Yizhou Shan , Yiying Zhang ATC 2020 [Paper] [Code] [Slide] [Short-Talk] [Full-Talk] [Keynote] Storm: a fast transactional dataplane for remote data structures Stanko Novakovic, Yizhou Shan , Aasheesh Kolli, Michael Cui, Yiying Zhang, Haggai Eran, Liran Liss, Michael Wei, Dan Tsafrir, Marcos Aguilera SYSTOR 2019 (Best Paper Award) [Paper] [Slide] [Talk] LegoOS: A Disseminated, Distributed OS for Hardware Resource Disaggregation Yizhou Shan , Yutong Huang, Yilun Chen, Yiying Zhang OSDI 2018 (Best Paper Award) [Paper] [Code] [Slide] [Keynote-iCloud] [Talk] Distributed Shared Persistent Memory Yizhou Shan , Shin-Yeh Tsai, Yiying Zhang SoCC 2017 [Paper] [Code] [Slide] [Poster]","title":"Publications"},{"location":"#workshops","text":"Disaggregating Persistent Memory and Controlling Them Remotely: An Exploration of Passive Disaggregated Key-Value Stores Shin-Yeh Tsai, Yizhou Shan , Yiying Zhang 12 th Annual Non-Volatile Memories Workshop ( NVMW 2021 ) [Paper] Challenges in Building and Deploying Disaggregated Persistent Memory Yizhou Shan , Yutong Huang, Yiying Zhang 10 th Annual Non-Volatile Memories Workshop ( NVMW 2019 ) [Paper] Disaggregating Memory with Software-Managed Virtual Cache Yizhou Shan , Yiying Zhang 2018 Workshop on Warehouse-scale Memory Systems ( WAMS 2018 ) (co-located with ASPLOS \u201818) [Paper] Distributed Shared Persistent Memory Yizhou Shan , Shin-Yeh Tsai, Yiying Zhang 9 th Annual Non-Volatile Memories Workshop ( NVMW 2018 ) [Paper] Disaggregated Operating System Yiying Zhang, Yizhou Shan , Sumukh Hallymysore 17 th International Workshop on High Performance Transaction Systems ( HPTS 2017 ) [Paper]","title":"Workshops"},{"location":"#professional-services","text":"Program Committee SoCC (2022) EuroSys (2023, 2022 shadow, 2021 shadow) ASPLOS (2021 external) Journal Journal of Systems Research: 2021 - Current ACM Transactions on Architecture and Code Optimization (TACO): 2021 ACM Transactions on Storage (TOS): 2020 IEEE/ACM Transactions on Networking: 2020 Artifact Evaluation SOSP (2021) OSDI (2020)","title":"Professional Services"},{"location":"#social","text":"Google Scholar Github Twitter LinkedIn Goodreads","title":"Social"},{"location":"vmware-intern/","text":"Intel Xeon 6138p, integrated FPGA (check it out!) retpoline (perf impact?) Intel Total Memory Encryption. Multi-Key Total Memory Encryption (MKTME). RDMA + NVM: An interesting topic. There are a lot interesting stuff to think about. I discussed this with Sanidhya today, he shared some very valuable findings: RDMA write: when does it mark a persistent point? RDMA write followed by a RDMA read, is kind of implicit memory barrier imposed by memory controller.","title":"Vmware intern"},{"location":"blog/20200404-on-read-once/","text":"On READ_ONCE and Compiler Opts \u00b6 Version History Date Description Apr 13, 2020 Initial Version I decide to write this blog after I once again got tricked by GCC optimizations. I was designing a simple single-producer-single-consumer ring buffer. Since there is a small time gap between slot-being-allocated and slot-being-usable (i.e., data filled), the producer will set a non-atomic flag once the data is filled thus usable. The consumer, running on a seperate CPU, will repeatly checking the usable flag after it has grabbed the slot. Simple, right? Yet I ran into a lot random stuck during testing. I didn\u2019t even check the ring buffer design as I was so confident. There was no timeout checking either. After some digging, I realized I missed using READ_ONCE when consumer thread is polling for the usable flag. Yeah, once again, gcc -O2 tricked me: it will optmize away repeated memory accesses if it thinks the accessed variable/data is thread-local. For instance, the following code snippet shows how gcc -O2 removes the memory access part. Without -O2, a simple assembly loop is generated. With -O2, gcc generates a deadlock itself. Original C Assembly Assembly ( gcc - S ) ( gcc - S - O2 ) int x ; | | | . L2 : | . L2 : /* Spin until x becomes true */ | movl x ( % rip ), % eax | jmp . L2 void wait_for_x ( void ) | cmpl $1 , % eax | { | je . L2 | while ( x == 1 ) | | ; | | } | | Why this is happening? Because gcc thinks vairable x is thread-local and will not be accessed by multiple threads at the same time. Thus gcc thinks the above while (x == 1) ; check will never break, so generating an assembly deadlock jmp loop. Why does this matter? Assume x is a shared variable. In the following code snippet, there are two threads, A and B. Thread A wait until B change x to 1. If we compile with -O2, thread A will deadlock. And this was my bug above. int x ; /* a global shared variable*/ Thread A Thread B /* Spin until x becomes true */ | /* Set x at some point */ void wait_for_x ( void ) | x = 1 ; { | while ( x == 1 ) | ; | } | The common approach, is to add volatile modifier, to explicitly express the concurrency issue. But volatile is considered harmful by linux kernel, and I agree with it. I generally use READ_ONCE , WRITE_ONCE , ACCESS_ONCE macros. They \u201ctell\u201d gcc that the particualr variable is a shared global variable, thus for each time a C statment is running, the variable should be accessed once and exactly once. The fix for above case is: while (READ_ONCE(x == 1)) ; . I will not go into details about why and how those macros are implemented. For more information, refers to source code , ktsan wiki . Hope you enjoyed this simple bug-documentation blog.","title":"On Read Once and Compiler Optimization"},{"location":"blog/20200404-on-read-once/#on-read_once-and-compiler-opts","text":"Version History Date Description Apr 13, 2020 Initial Version I decide to write this blog after I once again got tricked by GCC optimizations. I was designing a simple single-producer-single-consumer ring buffer. Since there is a small time gap between slot-being-allocated and slot-being-usable (i.e., data filled), the producer will set a non-atomic flag once the data is filled thus usable. The consumer, running on a seperate CPU, will repeatly checking the usable flag after it has grabbed the slot. Simple, right? Yet I ran into a lot random stuck during testing. I didn\u2019t even check the ring buffer design as I was so confident. There was no timeout checking either. After some digging, I realized I missed using READ_ONCE when consumer thread is polling for the usable flag. Yeah, once again, gcc -O2 tricked me: it will optmize away repeated memory accesses if it thinks the accessed variable/data is thread-local. For instance, the following code snippet shows how gcc -O2 removes the memory access part. Without -O2, a simple assembly loop is generated. With -O2, gcc generates a deadlock itself. Original C Assembly Assembly ( gcc - S ) ( gcc - S - O2 ) int x ; | | | . L2 : | . L2 : /* Spin until x becomes true */ | movl x ( % rip ), % eax | jmp . L2 void wait_for_x ( void ) | cmpl $1 , % eax | { | je . L2 | while ( x == 1 ) | | ; | | } | | Why this is happening? Because gcc thinks vairable x is thread-local and will not be accessed by multiple threads at the same time. Thus gcc thinks the above while (x == 1) ; check will never break, so generating an assembly deadlock jmp loop. Why does this matter? Assume x is a shared variable. In the following code snippet, there are two threads, A and B. Thread A wait until B change x to 1. If we compile with -O2, thread A will deadlock. And this was my bug above. int x ; /* a global shared variable*/ Thread A Thread B /* Spin until x becomes true */ | /* Set x at some point */ void wait_for_x ( void ) | x = 1 ; { | while ( x == 1 ) | ; | } | The common approach, is to add volatile modifier, to explicitly express the concurrency issue. But volatile is considered harmful by linux kernel, and I agree with it. I generally use READ_ONCE , WRITE_ONCE , ACCESS_ONCE macros. They \u201ctell\u201d gcc that the particualr variable is a shared global variable, thus for each time a C statment is running, the variable should be accessed once and exactly once. The fix for above case is: while (READ_ONCE(x == 1)) ; . I will not go into details about why and how those macros are implemented. For more information, refers to source code , ktsan wiki . Hope you enjoyed this simple bug-documentation blog.","title":"On READ_ONCE and Compiler Opts"},{"location":"clio/story/","text":"The Research Story Behind the Clio Project \u00b6 Version History Date Description Nov 15, 2021 Draft The Clio paper has recently been accepted to ASPLOS\u201822. We are all very excited about it and have a strong feeling on its final acceptance. This paper is just special to many of us in different ways. The whole thing started in late 2018 and it took so many different turns. Anyways, let me share the story bebind it. The Beginning: Build a Disaggregated Memory Device (Oct 2018) \u00b6 The First Failure (May 2019) \u00b6 A New Start and a Spin-Off (Sep 2019) \u00b6 The Second Failure: The FPGA OS (Dec 2019) \u00b6 Clio\u2019s Submissions \u00b6 Final Words \u00b6 Future Work \u00b6 Acknowledgements \u00b6","title":"The Research Story Behind the Clio Project"},{"location":"clio/story/#the-research-story-behind-the-clio-project","text":"Version History Date Description Nov 15, 2021 Draft The Clio paper has recently been accepted to ASPLOS\u201822. We are all very excited about it and have a strong feeling on its final acceptance. This paper is just special to many of us in different ways. The whole thing started in late 2018 and it took so many different turns. Anyways, let me share the story bebind it.","title":"The Research Story Behind the Clio Project"},{"location":"clio/story/#the-beginning-build-a-disaggregated-memory-device-oct-2018","text":"","title":"The Beginning: Build a Disaggregated Memory Device (Oct 2018)"},{"location":"clio/story/#the-first-failure-may-2019","text":"","title":"The First Failure (May 2019)"},{"location":"clio/story/#a-new-start-and-a-spin-off-sep-2019","text":"","title":"A New Start and a Spin-Off (Sep 2019)"},{"location":"clio/story/#the-second-failure-the-fpga-os-dec-2019","text":"","title":"The Second Failure: The FPGA OS (Dec 2019)"},{"location":"clio/story/#clios-submissions","text":"","title":"Clio's Submissions"},{"location":"clio/story/#final-words","text":"","title":"Final Words"},{"location":"clio/story/#future-work","text":"","title":"Future Work"},{"location":"clio/story/#acknowledgements","text":"","title":"Acknowledgements"},{"location":"ctf/basic/","text":"checksec rename in assembly pwn cyclic De Brujin Sequence ROP Shell code \u00b6 Avoid NULL byte (\\x00) is bad. No hard coded addresses: use indirect references, e.g., short jumps and near calls. First portion of payload can be a bunch of NOPs, IP will slide into the real shellcode http://shell-storm.org/ encrypt shellcode \u00b6","title":"Basic"},{"location":"ctf/basic/#shell-code","text":"Avoid NULL byte (\\x00) is bad. No hard coded addresses: use indirect references, e.g., short jumps and near calls. First portion of payload can be a bunch of NOPs, IP will slide into the real shellcode http://shell-storm.org/","title":"Shell code"},{"location":"ctf/basic/#encrypt-shellcode","text":"","title":"encrypt shellcode"},{"location":"financial/economics/","text":"TODO","title":"Economics"},{"location":"financial/economics_behavior/","text":"TODO","title":"Economics behavior"},{"location":"financial/stock/","text":"Stock \u00b6 Anyone reading this should take it with a grain of salt. I\u2019m just documenting a few useful things to understand the stocks. But being able to reason the data does not give one the power to predict market, it only makes one feel more comfortable making choices (well, maybe). Resources \u00b6 This GamestonkTermial page lists a lot useful sources. Indicators \u00b6 Important Trade what you see, not what you think. Avoid confirmation bias. TODO: 1. Catagorize by purposes. 2. also think about when to which ones. 3. what each indicator can tell you. Moving Average (MA) Simple Moving Average (SMA) Exponential Moving Average (EMA) RSI MACD Stoch Bias ATR Options \u00b6 Options Playbook Option Profit Calculator Understanding NOPE Option is risky. Start with money you are okay losing. Option contract has value. It is a different market. It goes up or down more dramatically than the normal stock price: several parameters (e.g., IV, greeks) will amplify the change. One thing I realize after playing with options is that some people do not really wait until Expiry Day to close the position. They might sell the option contract before the expiry date, which might produce more profit (also loss more) than just exercising the options. It takes a seller and a buyer to complete a transction. For some low liquid stock/option, you might not be able to find a buyer. You must pay attention to this if you are betting able to re-sell the options. Market maker (MM) will sell whatever ridiculous options. But they will in turn use option/stock to hedge, which in turn create some volality in the stock market. Unusual Whales \u00b6 Some useful tips: Whales come and go, they gamble as well. Look for high VOL/OI ratio (maybe larger than 5?) The bid/ask spread should be small. Smaller the better. It also means more volumn. Pay attention to IV. Many people suggest IV < 100% Pay attention to the strike price and date. I haven\u2019t fully grasp the core idea. Yet to learn. Mon/Fri close/mornings options somehow have higher average max return. Before futures open, here's something neat. Take a look at this chart, it shows the average max return from 2020 and breaks it down to time and week day, and the option type from the whale. You can see that Friday after 12pm EST, Monday Morning, and Monday close have the ... pic.twitter.com/QRSIstpqsx \u2014 unusual_whales (@unusual_whales) January 10, 2021 Whale Winner and Loser MEGA Report Read more tactics here: https://unusualwhales.com/spears . Tools \u00b6 I\u2019m mostly using TradingView, half an hour is enough to learn the basics. I highly recommend it if you also know a bit programming. It allows you to express things in Python. I sometimes check https://unusualwhales.com/ for unusual options, which maybe potential insider tradings. I also use https://finviz.com/ . Behavior Economics \u00b6 This topic is really interesting. I may able to document more later.","title":"Stock"},{"location":"financial/stock/#stock","text":"Anyone reading this should take it with a grain of salt. I\u2019m just documenting a few useful things to understand the stocks. But being able to reason the data does not give one the power to predict market, it only makes one feel more comfortable making choices (well, maybe).","title":"Stock"},{"location":"financial/stock/#resources","text":"This GamestonkTermial page lists a lot useful sources.","title":"Resources"},{"location":"financial/stock/#indicators","text":"Important Trade what you see, not what you think. Avoid confirmation bias. TODO: 1. Catagorize by purposes. 2. also think about when to which ones. 3. what each indicator can tell you. Moving Average (MA) Simple Moving Average (SMA) Exponential Moving Average (EMA) RSI MACD Stoch Bias ATR","title":"Indicators"},{"location":"financial/stock/#options","text":"Options Playbook Option Profit Calculator Understanding NOPE Option is risky. Start with money you are okay losing. Option contract has value. It is a different market. It goes up or down more dramatically than the normal stock price: several parameters (e.g., IV, greeks) will amplify the change. One thing I realize after playing with options is that some people do not really wait until Expiry Day to close the position. They might sell the option contract before the expiry date, which might produce more profit (also loss more) than just exercising the options. It takes a seller and a buyer to complete a transction. For some low liquid stock/option, you might not be able to find a buyer. You must pay attention to this if you are betting able to re-sell the options. Market maker (MM) will sell whatever ridiculous options. But they will in turn use option/stock to hedge, which in turn create some volality in the stock market.","title":"Options"},{"location":"financial/stock/#unusual-whales","text":"Some useful tips: Whales come and go, they gamble as well. Look for high VOL/OI ratio (maybe larger than 5?) The bid/ask spread should be small. Smaller the better. It also means more volumn. Pay attention to IV. Many people suggest IV < 100% Pay attention to the strike price and date. I haven\u2019t fully grasp the core idea. Yet to learn. Mon/Fri close/mornings options somehow have higher average max return. Before futures open, here's something neat. Take a look at this chart, it shows the average max return from 2020 and breaks it down to time and week day, and the option type from the whale. You can see that Friday after 12pm EST, Monday Morning, and Monday close have the ... pic.twitter.com/QRSIstpqsx \u2014 unusual_whales (@unusual_whales) January 10, 2021 Whale Winner and Loser MEGA Report Read more tactics here: https://unusualwhales.com/spears .","title":"Unusual Whales"},{"location":"financial/stock/#tools","text":"I\u2019m mostly using TradingView, half an hour is enough to learn the basics. I highly recommend it if you also know a bit programming. It allows you to express things in Python. I sometimes check https://unusualwhales.com/ for unusual options, which maybe potential insider tradings. I also use https://finviz.com/ .","title":"Tools"},{"location":"financial/stock/#behavior-economics","text":"This topic is really interesting. I may able to document more later.","title":"Behavior Economics"},{"location":"fpga/bitstream/","text":"FPGA Bitstream Explained \u00b6 Version History Date Description Sep 18, 2020 add github link and usenix paper Dec 20, 2019 Update Oct 24, 2019 Created The proof-of-concept code to decode Xilinx bitstream is here: https://github.com/lastweek/fpga_decode_bitstream . USENIX Security 2020 has a paper on decrypting Xilinx bitstream. They find a vulnerability in the 7-series chip and in turn able to decrypt a fully encrypted bitstream. WHAT A HACK! Introduction \u00b6 An FPGA bitstream can configure an FPGA. A bitstream includes the description of the hardware logic, routing, and initial values for both registers and on-chip memory (e.g., LUT). The common believe is that a bitstream has vendor-specific format thus cannot be reversed or understood. This is partially true. A bitstream file is more than the bits to configure an FPGA, it also has certain human-readable fields to describe those bits. In fact, it has an assembly-like instruction set to describe the FPGA configuration process. This note is trying to walk through this. At a high-level, a bitstream file is similar to an executable program. Analogous to the ELF format, a bistream has its own format to describe the contents. Note, the file format is publicly documented 1 . Thus, you can analyze the contents of a bitstream file, meaning you can understand the steps taken to configure the FPGA. The un-documented part is the bits mapping : the format of the configuration bits, especially how the bitstream bits map to specific on-chip LUTs, wires etc. Think this way: given some assembly instructions, you can simply understand that, say some assembly instructions are doing Addition on certain registers, however, the instructions do not specify which registers they operate on. As a normal FPGA user, you mostly do not need to understand neither of these. You only need to understand this if you are planning to do bitstream readback , preemption scheduling , or similar stuff. After reading this note, I hope you could understand that a bitstream file is just a sequence of instructions and data. Nothing fancy. The FPGA chip usually has a simple state machine module to accept and parse the bitstream, then configure the chip (ICAP in Xilinx). As we mentioned earlier, the bistream file format is partially public, the mapping between the bitstream configuration bits and the actual physical resource is undocumented. Bistream Related Files \u00b6 In a normal flow, Vivado only generates a simple .bit file. When you click \u201cProgram Device\u201d, Vivado will use this file to configure your FPGA. In addition to generating this file, Vivado is capable of generating a bunch other files. You can find a complete coverage in this link . We give a high level summary here. Most of the files have the same content and have similar file size. For instance, the difference between a .rbt and a .bit is that the former one is in ASCII format while the latter is in binary format, but they have the same contents. As for a .bit and a .bin file, the latter does not have some ASCII headers at the beginning of the file. .ll , the logical link file, is very interesting. It tells you the mapping between user logic and the actual bit offset in the bistream file data section. This file can be used to aid preemption scheduling. However, note that, this file only documents a very small part of the mapping. To the best of my knowledge, I think only the registers, on-chip memory are documented, but the routing information is missing. Thus, this file can help reserve engineer bitstream data section to some extend, but not full of it. Prjxray is an open source project working on cracking everything on 7-series FPGA. Details \u00b6 We use .rbt and .bit to demonstrate the file format. Note that they are essentially the same thing, except the former in human-readable ASCII format. The target board is VCU118, the one used by many cloud vendors. The following snippt is the first few lines of the .rpt file. The first few lines are human-readable ASCII contents describing some general information about the bitstream. Starting from line 8 is the actual bitstream file contents. Note that the .bin file starts directly from line 8, no general header info is attached. The interesting part is the 1s and 0s. Unless otherwise noted, when we refer to bitstream format, we focus on the 1s and 0s only and omit any general ASICC information headers. Xilinx ASCII Bitstream Created by Bitstream 2018.3 SW Build 2405991 on Thu Dec 6 23:36:41 MST 2018 Design name: base_mb_wrapper;UserID=0XFFFFFFFF;Version=2018.3 Architecture: virtexuplus Part: xcvu9p-flga2104-2L-e Date: Wed Nov 20 04:13:05 2019 Bits: 641272864 11111111111111111111111111111111 11111111111111111111111111111111 11111111111111111111111111111111 ... Note that each line has 32 bits, thus 4 bytes. In Xilinx bistream format, each four bytes is a packet (analogous to CPU instruction). Each packet has certain format, it could be a special header packet , or a normal data packet . The header packet follows a simple assembly-like instruction set to dictate the configuration process. The bitstream file is a sequence of these four bytes packets. Why it sounds so complicated, a sequence of instructions?! I think the short answer is that configuraing FPGA is not an easy task, and any wrong doings may permanently harm the chip. Natually, the designer would have a on-chip state machine to control the configuration process, not only to control the whole process but also to ensure safety. Each Xilinx FPGA has an on-chip configuration packet processor . All configuration methods such as JTAG, SelectMAP, ICAP merge into this final narrow bridge to carry out the configuration. The configuration packet processor has many internal registers (similar to x86 RAX, CRn, MSR registers). The bitstream usually interact with one of the registers at a time to do one thing. For a more detailed explanation, check out this blog , and UG570 chapter 9. To this end, a bitstream consits of three parts: 1) Header packets to prepare the configuration process. 2) The actual configuration bits in a contiguous sequence of data packets. AN write to the FDRI register marks the beginning of this section. The length of this section is described by the packet following the FDRI header packet. 3) Header packets to clean up the configuration process. The actual configuration bits are the ones determine the FPGA functionality. Note that if you are using an SSI Xilinx device like VCU118, the bitstream format is a bit more complicated. Basically, each die has the above three parts. If an chip has N dies, it will have N above triplet. I have complained about this is not well documented here and here . I wrote a simple C program to parse the .rbt file and associate a human-reable syntax with each line. I didn\u2019t have a complete coverage of the header packet format. The following snippt shows a parsed .rbt file with header removed. Here, 0xffffffff has no effect, like a NOP. 0x000000bb and 0x11220044 are special bus detect words. 0xaa995566 is another special work marking the synchronization status. The last few lines mark the beginning of the configuration bits section. Parsed from base_mb_wrapper.rbt ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff 000000bb Bus Width Sync 11220044 Bus Width Detect ffffffff ffffffff aa995566 SYNC 20000000 20000000 30022001 Write to regs 17 00000000 30020001 Write to regs 16 00000000 30008001 Write to CMD 00000000 20000000 30008001 Write to CMD 00000007 20000000 20000000 30002001 Write to FAR 00000000 30026001 Write to regs 19 00000000 30012001 Write to regs 9 38003fe5 Write to regs 1 3001c001 Write to regs 14 00400000 30018001 Write to IDCODE 04b31093 IDCODE=4b31093 30008001 Write to CMD 00000009 20000000 3000c001 Write to regs 6 00000001 3000a001 Write to regs 5 00000101 3000c001 Write to regs 6 00000000 30030001 Write to regs 24 00000000 20000000 20000000 20000000 20000000 20000000 20000000 20000000 20000000 30002001 Write to FAR 00000000 30008001 Write to CMD 00000001 20000000 30004000 Write to FDRI 5065eadc <- The length of configuration bits, follows a certain format 00000000 <- The first 4 bytes of the configuration bits! Thank you for reading. Hope you enjoyed this post. References \u00b6 Xilinx UG570 Xilinx bitstream files Another blog on Xilinx Bitstream Internals Source code to annotate bitstream","title":"Bitstream Explained"},{"location":"fpga/bitstream/#fpga-bitstream-explained","text":"Version History Date Description Sep 18, 2020 add github link and usenix paper Dec 20, 2019 Update Oct 24, 2019 Created The proof-of-concept code to decode Xilinx bitstream is here: https://github.com/lastweek/fpga_decode_bitstream . USENIX Security 2020 has a paper on decrypting Xilinx bitstream. They find a vulnerability in the 7-series chip and in turn able to decrypt a fully encrypted bitstream. WHAT A HACK!","title":"FPGA Bitstream Explained"},{"location":"fpga/bitstream/#introduction","text":"An FPGA bitstream can configure an FPGA. A bitstream includes the description of the hardware logic, routing, and initial values for both registers and on-chip memory (e.g., LUT). The common believe is that a bitstream has vendor-specific format thus cannot be reversed or understood. This is partially true. A bitstream file is more than the bits to configure an FPGA, it also has certain human-readable fields to describe those bits. In fact, it has an assembly-like instruction set to describe the FPGA configuration process. This note is trying to walk through this. At a high-level, a bitstream file is similar to an executable program. Analogous to the ELF format, a bistream has its own format to describe the contents. Note, the file format is publicly documented 1 . Thus, you can analyze the contents of a bitstream file, meaning you can understand the steps taken to configure the FPGA. The un-documented part is the bits mapping : the format of the configuration bits, especially how the bitstream bits map to specific on-chip LUTs, wires etc. Think this way: given some assembly instructions, you can simply understand that, say some assembly instructions are doing Addition on certain registers, however, the instructions do not specify which registers they operate on. As a normal FPGA user, you mostly do not need to understand neither of these. You only need to understand this if you are planning to do bitstream readback , preemption scheduling , or similar stuff. After reading this note, I hope you could understand that a bitstream file is just a sequence of instructions and data. Nothing fancy. The FPGA chip usually has a simple state machine module to accept and parse the bitstream, then configure the chip (ICAP in Xilinx). As we mentioned earlier, the bistream file format is partially public, the mapping between the bitstream configuration bits and the actual physical resource is undocumented.","title":"Introduction"},{"location":"fpga/bitstream/#bistream-related-files","text":"In a normal flow, Vivado only generates a simple .bit file. When you click \u201cProgram Device\u201d, Vivado will use this file to configure your FPGA. In addition to generating this file, Vivado is capable of generating a bunch other files. You can find a complete coverage in this link . We give a high level summary here. Most of the files have the same content and have similar file size. For instance, the difference between a .rbt and a .bit is that the former one is in ASCII format while the latter is in binary format, but they have the same contents. As for a .bit and a .bin file, the latter does not have some ASCII headers at the beginning of the file. .ll , the logical link file, is very interesting. It tells you the mapping between user logic and the actual bit offset in the bistream file data section. This file can be used to aid preemption scheduling. However, note that, this file only documents a very small part of the mapping. To the best of my knowledge, I think only the registers, on-chip memory are documented, but the routing information is missing. Thus, this file can help reserve engineer bitstream data section to some extend, but not full of it. Prjxray is an open source project working on cracking everything on 7-series FPGA.","title":"Bistream Related Files"},{"location":"fpga/bitstream/#details","text":"We use .rbt and .bit to demonstrate the file format. Note that they are essentially the same thing, except the former in human-readable ASCII format. The target board is VCU118, the one used by many cloud vendors. The following snippt is the first few lines of the .rpt file. The first few lines are human-readable ASCII contents describing some general information about the bitstream. Starting from line 8 is the actual bitstream file contents. Note that the .bin file starts directly from line 8, no general header info is attached. The interesting part is the 1s and 0s. Unless otherwise noted, when we refer to bitstream format, we focus on the 1s and 0s only and omit any general ASICC information headers. Xilinx ASCII Bitstream Created by Bitstream 2018.3 SW Build 2405991 on Thu Dec 6 23:36:41 MST 2018 Design name: base_mb_wrapper;UserID=0XFFFFFFFF;Version=2018.3 Architecture: virtexuplus Part: xcvu9p-flga2104-2L-e Date: Wed Nov 20 04:13:05 2019 Bits: 641272864 11111111111111111111111111111111 11111111111111111111111111111111 11111111111111111111111111111111 ... Note that each line has 32 bits, thus 4 bytes. In Xilinx bistream format, each four bytes is a packet (analogous to CPU instruction). Each packet has certain format, it could be a special header packet , or a normal data packet . The header packet follows a simple assembly-like instruction set to dictate the configuration process. The bitstream file is a sequence of these four bytes packets. Why it sounds so complicated, a sequence of instructions?! I think the short answer is that configuraing FPGA is not an easy task, and any wrong doings may permanently harm the chip. Natually, the designer would have a on-chip state machine to control the configuration process, not only to control the whole process but also to ensure safety. Each Xilinx FPGA has an on-chip configuration packet processor . All configuration methods such as JTAG, SelectMAP, ICAP merge into this final narrow bridge to carry out the configuration. The configuration packet processor has many internal registers (similar to x86 RAX, CRn, MSR registers). The bitstream usually interact with one of the registers at a time to do one thing. For a more detailed explanation, check out this blog , and UG570 chapter 9. To this end, a bitstream consits of three parts: 1) Header packets to prepare the configuration process. 2) The actual configuration bits in a contiguous sequence of data packets. AN write to the FDRI register marks the beginning of this section. The length of this section is described by the packet following the FDRI header packet. 3) Header packets to clean up the configuration process. The actual configuration bits are the ones determine the FPGA functionality. Note that if you are using an SSI Xilinx device like VCU118, the bitstream format is a bit more complicated. Basically, each die has the above three parts. If an chip has N dies, it will have N above triplet. I have complained about this is not well documented here and here . I wrote a simple C program to parse the .rbt file and associate a human-reable syntax with each line. I didn\u2019t have a complete coverage of the header packet format. The following snippt shows a parsed .rbt file with header removed. Here, 0xffffffff has no effect, like a NOP. 0x000000bb and 0x11220044 are special bus detect words. 0xaa995566 is another special work marking the synchronization status. The last few lines mark the beginning of the configuration bits section. Parsed from base_mb_wrapper.rbt ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff 000000bb Bus Width Sync 11220044 Bus Width Detect ffffffff ffffffff aa995566 SYNC 20000000 20000000 30022001 Write to regs 17 00000000 30020001 Write to regs 16 00000000 30008001 Write to CMD 00000000 20000000 30008001 Write to CMD 00000007 20000000 20000000 30002001 Write to FAR 00000000 30026001 Write to regs 19 00000000 30012001 Write to regs 9 38003fe5 Write to regs 1 3001c001 Write to regs 14 00400000 30018001 Write to IDCODE 04b31093 IDCODE=4b31093 30008001 Write to CMD 00000009 20000000 3000c001 Write to regs 6 00000001 3000a001 Write to regs 5 00000101 3000c001 Write to regs 6 00000000 30030001 Write to regs 24 00000000 20000000 20000000 20000000 20000000 20000000 20000000 20000000 20000000 30002001 Write to FAR 00000000 30008001 Write to CMD 00000001 20000000 30004000 Write to FDRI 5065eadc <- The length of configuration bits, follows a certain format 00000000 <- The first 4 bytes of the configuration bits! Thank you for reading. Hope you enjoyed this post.","title":"Details"},{"location":"fpga/bitstream/#references","text":"Xilinx UG570 Xilinx bitstream files Another blog on Xilinx Bitstream Internals Source code to annotate bitstream","title":"References"},{"location":"fpga/hls_axi/","text":"High-performance AXI-MM in HLS \u00b6 My personal experience: the native AXI-MM in HLS is horrible. It fails to generate efficient code. The best practice I found is the use an external Datamover. In HLS, all memory access is made via AXI-Stream. Using AXI-Stream means we can wait the result asynchronously, hence we can deal with long memory access in a more informed manner. Usually using AXI-Stream and Datamover delivers code with II=1.","title":"High-performance AXI-MM in HLS"},{"location":"fpga/hls_axi/#high-performance-axi-mm-in-hls","text":"My personal experience: the native AXI-MM in HLS is horrible. It fails to generate efficient code. The best practice I found is the use an external Datamover. In HLS, all memory access is made via AXI-Stream. Using AXI-Stream means we can wait the result asynchronously, hence we can deal with long memory access in a more informed manner. Usually using AXI-Stream and Datamover delivers code with II=1.","title":"High-performance AXI-MM in HLS"},{"location":"fpga/hls_axis/","text":"AXI-Stream Usage in HLS \u00b6 How you should ultilize the AXI-Stream in HLS code to best describe your system.","title":"AXI-Stream Usage in HLS"},{"location":"fpga/hls_axis/#axi-stream-usage-in-hls","text":"How you should ultilize the AXI-Stream in HLS code to best describe your system.","title":"AXI-Stream Usage in HLS"},{"location":"fpga/language/","text":"On-High-Level-Languages-For-FPGA-Design \u00b6 Version History Date Description May 31, 2020 Initial With FPGA getting popular among system folks, it\u2019s crucial to pick up the right language for the project. Most folks will not use Verilog/VHDL directly, but use higher level languages like Xilinx HLS, Chisel, SpinalHDL etc. All my dicussions and opinions are based on my own limited experience with FPGA (since Oct 2018), it does not reflect any others\u2019 opinions. In short: for folks new to FPGA and want to start a medium- or large- sized network-oriented academic projects, I would recommend avoid using Xilinx HLS, but use SpinalHDL/Chisel or others instead. Of course, you still need to know a bit bout Verilog/VHDL and all the tools (e.g., Vivado) for the final project packaging. I started using HLS from 2018 Oct. I\u2019ve writtin more than 20K HLS code, including but not limited to RDMA-like modules, partial-reconfiguration ICAP3 controller. I pick it because it is C-like and expressive when first using it. However, along the way, me and my labmates have had a lot issues with HLS, some due to compiler, some are still non-explainable. My own opinions about HLS. The good part: HLS is easy to pick up and write. Its semantic is similar to C. Good for prototying small project. HLS has several useful AXI-Stream interfaces. HLS has many options allowing us control FPGA resource usage. The bad part: HLS is not designed around streaming interface, which is a crutial part for network oriented projects. It\u2019s dataflow primitive is very restrictive, hard to construct a system with clear flow. Compiler. Some code pattern generate undefined behaviours, even though totally correct in turns of logic. Ugh, we have had so much trouble for this part, and this is the most annoying part. Hard to control BRAM access, i.e., avoid false-dependency and track consistency. Hard to express bits related ops. HLS has range operators, but really hard to write, a lot macros flying around. Streaming interface is a bit fragile, we found a lot random stucks during runtime due to buffer issue. For code to be really useful, you have to write in a switch-case state machine way. There is no difference with a verilog one, but with more complexity, especially for large-scale projects. Simulation framework is not easy to use, a lot restritions too. We had a lot trouble with HLS. Not until recently, one of my labmate picked up SpinalHDL, and we found it amazing. I\u2019m not personally writing SpinalHDL code, but I felt it is super expressive and match hardware primitive, physically and mentally. Personally, I would use scala-based ones over HLS for my future projects.","title":"Languages"},{"location":"fpga/language/#on-high-level-languages-for-fpga-design","text":"Version History Date Description May 31, 2020 Initial With FPGA getting popular among system folks, it\u2019s crucial to pick up the right language for the project. Most folks will not use Verilog/VHDL directly, but use higher level languages like Xilinx HLS, Chisel, SpinalHDL etc. All my dicussions and opinions are based on my own limited experience with FPGA (since Oct 2018), it does not reflect any others\u2019 opinions. In short: for folks new to FPGA and want to start a medium- or large- sized network-oriented academic projects, I would recommend avoid using Xilinx HLS, but use SpinalHDL/Chisel or others instead. Of course, you still need to know a bit bout Verilog/VHDL and all the tools (e.g., Vivado) for the final project packaging. I started using HLS from 2018 Oct. I\u2019ve writtin more than 20K HLS code, including but not limited to RDMA-like modules, partial-reconfiguration ICAP3 controller. I pick it because it is C-like and expressive when first using it. However, along the way, me and my labmates have had a lot issues with HLS, some due to compiler, some are still non-explainable. My own opinions about HLS. The good part: HLS is easy to pick up and write. Its semantic is similar to C. Good for prototying small project. HLS has several useful AXI-Stream interfaces. HLS has many options allowing us control FPGA resource usage. The bad part: HLS is not designed around streaming interface, which is a crutial part for network oriented projects. It\u2019s dataflow primitive is very restrictive, hard to construct a system with clear flow. Compiler. Some code pattern generate undefined behaviours, even though totally correct in turns of logic. Ugh, we have had so much trouble for this part, and this is the most annoying part. Hard to control BRAM access, i.e., avoid false-dependency and track consistency. Hard to express bits related ops. HLS has range operators, but really hard to write, a lot macros flying around. Streaming interface is a bit fragile, we found a lot random stucks during runtime due to buffer issue. For code to be really useful, you have to write in a switch-case state machine way. There is no difference with a verilog one, but with more complexity, especially for large-scale projects. Simulation framework is not easy to use, a lot restritions too. We had a lot trouble with HLS. Not until recently, one of my labmate picked up SpinalHDL, and we found it amazing. I\u2019m not personally writing SpinalHDL code, but I felt it is super expressive and match hardware primitive, physically and mentally. Personally, I would use scala-based ones over HLS for my future projects.","title":"On-High-Level-Languages-For-FPGA-Design"},{"location":"fpga/misc/","text":"Misc \u00b6 If we want to do relocation, we need to be careful: - identical areas in terms of shape, resource distribution within - proxy logic (i.e., partition pins) location within the PR partition - the wire between proxy logic and static region. - I think this might cause timing issue? The lock_design in Vivado is to ensure the routing between static region and all the PR partitions remain the same. Proxy Logic and Bus Macro - S1: Relocation of reconfigurable modules on Xilinx FPGA - S2: A Highly Flexible Reconfigurable System on a Xilinx FPGA Expansion of CONTAIN_ROUTING Area","title":"Misc"},{"location":"fpga/misc/#misc","text":"If we want to do relocation, we need to be careful: - identical areas in terms of shape, resource distribution within - proxy logic (i.e., partition pins) location within the PR partition - the wire between proxy logic and static region. - I think this might cause timing issue? The lock_design in Vivado is to ensure the routing between static region and all the PR partitions remain the same. Proxy Logic and Bus Macro - S1: Relocation of reconfigurable modules on Xilinx FPGA - S2: A Highly Flexible Reconfigurable System on a Xilinx FPGA Expansion of CONTAIN_ROUTING Area","title":"Misc"},{"location":"fpga/pr/","text":"Morphous (Dynamic-sized) Partial Reconfiguration \u00b6 Version History Date Description Feb 6, 2020 Created Traditional partital reconfiguration (PR) is limited to using fix-sized PR regions. With one particular static bitstream, users are restricted to only have few pre-defined PR regions. If you wish to extend the PR region size, a whole chip reprogram is needed to burn a new static bitstream. This practice is suggested by FPGA vendors, and there are reasons behind it. However, during our experiment, we found that it is possible to have dynamic-sized PR regions with one static design. The mechanism is quite straightforward with some simple hacks. I will use a MicroBlaze-based design to demonstrate the approach with a VCU118 board. Stay tuned.","title":"Partial Reconfiguration"},{"location":"fpga/pr/#morphous-dynamic-sized-partial-reconfiguration","text":"Version History Date Description Feb 6, 2020 Created Traditional partital reconfiguration (PR) is limited to using fix-sized PR regions. With one particular static bitstream, users are restricted to only have few pre-defined PR regions. If you wish to extend the PR region size, a whole chip reprogram is needed to burn a new static bitstream. This practice is suggested by FPGA vendors, and there are reasons behind it. However, during our experiment, we found that it is possible to have dynamic-sized PR regions with one static design. The mechanism is quite straightforward with some simple hacks. I will use a MicroBlaze-based design to demonstrate the approach with a VCU118 board. Stay tuned.","title":"Morphous (Dynamic-sized) Partial Reconfiguration"},{"location":"fpga/scratch/","text":"Scratch Commands \u00b6 get_property LOC [get_cells count_out_OBUF[3]_inst] get_property ROUTE $net This returns a list of *nodes*. We can also see this in the GUI. % get_property ROUTE [get_nets inst_count/count_out[0]] Manually lock a route: set_property FIXED_ROUTE [get_property ROUTE [get_nets inst_count/count_out[0]]] [get_nets inst_count/count_out[0]]","title":"Scratch Commands"},{"location":"fpga/scratch/#scratch-commands","text":"get_property LOC [get_cells count_out_OBUF[3]_inst] get_property ROUTE $net This returns a list of *nodes*. We can also see this in the GUI. % get_property ROUTE [get_nets inst_count/count_out[0]] Manually lock a route: set_property FIXED_ROUTE [get_property ROUTE [get_nets inst_count/count_out[0]]] [get_nets inst_count/count_out[0]]","title":"Scratch Commands"},{"location":"fpga/setup_hold/","text":"Setup and Hold Time \u00b6 This is a few pages from the Digital Design and Computer Architecture book. It is well written and has explained the setup/hold feature so well. Link: http://lastweek.io/pubs/setup_hold.pdf","title":"Setup and Hold Time"},{"location":"fpga/setup_hold/#setup-and-hold-time","text":"This is a few pages from the Digital Design and Computer Architecture book. It is well written and has explained the setup/hold feature so well. Link: http://lastweek.io/pubs/setup_hold.pdf","title":"Setup and Hold Time"},{"location":"fpga/vivado/","text":"Vivado Practice \u00b6 Version History Date Description Nov 5, 2019 More stuff Nov 4, 2019 Add UG903 Oct 31, 2019 Happy Halloween Sep 20, 2019 Created Cheatsheet \u00b6 Partition Pins \u00b6 The partition pins are inserted by Vivado at the boundary of a PR region. PartPin is short for Partition Pins. PPLOC is short for Partpin LOC. Get the list of partition pins: get_pplocs - pins [ get_pins - hier * ] Partition pin (seems) map to a NODE: % report_property [ get_pplocs - pins [ get_pins XXX ]] % report_property [ get_pplocs - pins [ get_pins inst_count / count_out [ 0 ]]] INFO : [ Vivado 12 - 4841 ] Found PartPin: INT_X17Y790 / NN1_E_BEG3 Property Type Read-only Value BASE_CLOCK_REGION string true X0Y13 CLASS string true node Pblocks \u00b6 Semantic of EXCLUDE_PLACEMENT \u00b6 The document describe this as: Pblock property that prevents the placement of any logic not belonging to the Pblock inside the defined Pblock range. During my own simple experiment, I found that even Vivado will not place other logics into the Pblock, the routes of static region can still go across pblock. Semantic of CONTAIN_ROUTING \u00b6 References: UG909 and UG905. The contained routing requirement of RP Pblocks for UltraScale and UltraScale+ devices has been relaxed to allow for improved routing and timing results. Instead of routing being confined strictly to the resources owned by the Pblock, the routing footprint is expanded. Note that this option is enabled by default. When this option is enabled, 1) not all interface ports receive a partition pin, 2) the RP will use routing resources outside its confined area. This is annonying in some way. If this option is disabled, the implications are: 1) each interface port (per bit) receivces a partition pin, 2) RP will only resources confined to its pblocks, 3) the generated PR bitstream will be smaller, 4) hd_visual/ will not be generated. However, this option does not prevent routings from the static region from crossing RPs. This command is useful when you want to do some hacking about Partition Pins. Actually, you can also do this via GUI. set_param hd.routingContainmentAreaExpansion false But you wouldn\u2019t believe that: Static routing is still allowed to use resources inside of the Pblock. The implication is also obvious: all PR bitstreams and even blank bitstream will also have the static routing, if their targeted Pblocks happen to have static routing in the first place. This is also why we will need the static bitstream as the base to do PR bitstream generation. Clear RM and Lock Down Static \u00b6 These commands clear out the Reconfigurable Module logics from the whole design and then lock down the static region and static routing. (Reference: UG947) update_design - cell XXX - black_box lock_design - level routing Routing \u00b6 Get the routing of a net \u00b6 set net [ get_nets XXX ] get_property ROUTE $net Lock the routing of a net \u00b6 We need to lock both the net and the connected cells. Reference is UG903. Following commands lock a route of a net. This net is already routed. You could run one by one. After execution, the route will become dashed (means locked). Replace the net name with your interested one. set net [ get_nets inst_count/count_out [ 0 ]] get_property ROUTE $net set_property FIXED_ROUTE [ get_property ROUTE $net ] $net set_property is_bel_fixed 1 [ get_cells XXX ] set_property is_loc_fixed 1 [ get_cells XXX ] Manual routing \u00b6 A great GUI-based manual routing tutorial can be found at UG986 Lab 3 . The last step of manual routing, of course is to lock down the LOC and set FIXED_ROUTE . But how can we manually route an unrouted net? The difficulty is that we need to manually find out all the connection nodes/tiles etc.. This applies to LOC placement as well. Read-the-docs \u00b6 Basic UG912 Vivado Properties Reference Guide Excellent resource on explaining cell, net, pin, port, and so on. Differentiate Netlist Objects and Device Resource Objects . Netlist Objects pin : A pin is a point of logical connectivity on a primitive or hierarchical cell. A pin allows the contents of a cell to be abstracted away, and the logic simplified for ease-of-use. A pin is attached to a cell and can be connected to pins on other cells by a net. get_pins -of [get_cells XXX] . get_pins XXX port : A port is a special type of hierarchical pin, providing an external connection point at the top-level of a hierarchical design, or an internal connection point in a hierarchical cell or block module to connect the internal logic to the pins on the hierarchical cell. cell : A cell is an instance of a netlist logic object, which can either be a leaf-cell or a hierarchical cell. A leaf-cell is a primitive, or a primitive macro, with no further logic detail in the netlist. A hierarchical cell is a module or block that contains one or more additional levels of logic, and eventually concludes at leaf-cells. .. cells have PINs which are connected to NETs to define the external netlist\u2026 The CELL can be placed onto a BEL object in the case of basic logic such as flops, LUTs, and MUXes; or can be placed onto a SITE object in the case of larger logic cells such as BRAMs and DSPs. net : A net is a set of interconnected pins, ports, and wires. Every wire has a net name, which identifies it. Two or more wires can have the same net name. All wires sharing a common net name are part of a single NET, and all pins or ports connected to these wires are electrically connected. .. In the design netlist, a NET can be connected to the PIN of a CELL, or to a PORT. .. As the design is mapped onto the target Xilinx FPGA, the NET is mapped to routing resources such as WIREs, NODEs, and PIPs on the device, and is connected to BELs through BEL_PINs, and to SITEs through SITE_PINs. pblock : A Pblock is a collection of cells, and one or more rectangular areas or regions that specify the device resources contained by the Pblock. Pblocks are used during floorplanning placement to group related logic and assign it to a region of the target device. Example create_pblock Pblock_usbEngine add_cells_to_pblock [get_pblocks Pblock_usbEngine] [get_cells -quiet [listusbEngine1]] resize_pblock [get_pblocks Pblock_usbEngine] -add {SLICE_X8Y105:SLICE_X23Y149} resize_pblock [get_pblocks Pblock_usbEngine] -add {DSP48_X0Y42:DSP48_X1Y59} resize_pblock [get_pblocks Pblock_usbEngine] -add {RAMB18_X0Y42:RAMB18_X1Y59} resize_pblock [get_pblocks Pblock_usbEngine] -add {RAMB36_X0Y21:RAMB36_X1Y29} Device Resource Objects BEL : 1) leaf-level cells from the netlist design can be mapped onto bels on the target part 2) Bels are grouped in sites. 3) Each bel has bel_pins that map to pins on the cells. 4) get_bels -of [get_cells XX] , get_bels -of [get_nets XX] , and so on. BEL_PIN : 1) a pin or connection point on a BEL object. 2) BEL_PIN is a device object, associated with netlist objects such as the PIN on a CELL, which is the connection point for the NET. 3) get_bel_pins -of_objects [get_pins -of [get_cells XXX]] TILE SITE NODE WIRE PIP CONTAIN_ROUTING : The CONTAIN_ROUTING property restricts the routing of signals contained within a Pblock to use routing resources within the area defined by the Pblock. This prevents signals inside the Pblock from being routed outside the Pblock, and increases the reusability of the design. This is useful when you are trying to do advanced PR hacks. UG835 Vivado TCL Reference Guide aka. Vivado TCL Man Page. Read this with the above UG912. UG894 Vivado Using TCL scripting Get you started with Vivado TCL UG903 Using Constraints About Xilinx XDC files. You will need to understand UG912 first. Physical Constraints DONT_TOUCH . Prevent netlist optimizations. 1) prevent a net from being optimized away. 2) Prevent merging of manually replicated logic. Placement constraints Routing constraints Book: Practical Programming in Tcl and Tk Partial Reconfiguration Related UG909 Partial Reconfiguration Partition Pins Interface points called partition pins are automatically created within the Pblock ranges defined for the Reconfigurable Partition. These virtual I/O are established within interconnect tiles as the anchor points that remain consistent from one module to the next. In UltraScale or UltraScale+ designs, not all interface ports receive a partition pin . With the routing expansion feature, as explained in Expansion of CONTAIN_ROUTING Area, some interface nets are completely contained within the expanded region. When this happens, no partition pin is inserted; the entire net, including the source and all loads, is contained within the area captured by the partial bit file. Rather than pick an unnecessary intermediate point for the route, the entire net is rerouted, giving the Vivado tools the flexibility to pick an optimal solution. Exmaple set_property HD.PARTPIN_LOCS INT_R_X4Y153 [get_ports ] set_property HD.PARTPIN_RANGE SLICE_X4Y153:SLICE_X5Y157 [get_ports ] set_property HD.PARTPIN_RANGE {SLICE_Xx0Yx0:SLICE_Xx1Yy1 SLICE_XxNYyN:SLICE_XxMYyM} [get_pins /*] These pins can be manually relocated and locked. UG905 Hierarchical Design Add the CONTAIN_ROUTING property to all OOC Pblocks. Without this property, lock_design cannot lock the routing of an imported module because it cannot be guaranteed that there are no routing conflicts Some IPs \u00b6 UG947 has the sample code for the PR Controller IP It does not support simulation. Thus we can not probe any ICAP related signals. Ultrascale+ SEM does not have any useful ICAP usage signals in Simulation. xapp1230 has some TCL scripts to perform JTAG readback.","title":"Vivado Notes"},{"location":"fpga/vivado/#vivado-practice","text":"Version History Date Description Nov 5, 2019 More stuff Nov 4, 2019 Add UG903 Oct 31, 2019 Happy Halloween Sep 20, 2019 Created","title":"Vivado Practice"},{"location":"fpga/vivado/#cheatsheet","text":"","title":"Cheatsheet"},{"location":"fpga/vivado/#partition-pins","text":"The partition pins are inserted by Vivado at the boundary of a PR region. PartPin is short for Partition Pins. PPLOC is short for Partpin LOC. Get the list of partition pins: get_pplocs - pins [ get_pins - hier * ] Partition pin (seems) map to a NODE: % report_property [ get_pplocs - pins [ get_pins XXX ]] % report_property [ get_pplocs - pins [ get_pins inst_count / count_out [ 0 ]]] INFO : [ Vivado 12 - 4841 ] Found PartPin: INT_X17Y790 / NN1_E_BEG3 Property Type Read-only Value BASE_CLOCK_REGION string true X0Y13 CLASS string true node","title":"Partition Pins"},{"location":"fpga/vivado/#pblocks","text":"","title":"Pblocks"},{"location":"fpga/vivado/#semantic-of-exclude_placement","text":"The document describe this as: Pblock property that prevents the placement of any logic not belonging to the Pblock inside the defined Pblock range. During my own simple experiment, I found that even Vivado will not place other logics into the Pblock, the routes of static region can still go across pblock.","title":"Semantic of EXCLUDE_PLACEMENT"},{"location":"fpga/vivado/#semantic-of-contain_routing","text":"References: UG909 and UG905. The contained routing requirement of RP Pblocks for UltraScale and UltraScale+ devices has been relaxed to allow for improved routing and timing results. Instead of routing being confined strictly to the resources owned by the Pblock, the routing footprint is expanded. Note that this option is enabled by default. When this option is enabled, 1) not all interface ports receive a partition pin, 2) the RP will use routing resources outside its confined area. This is annonying in some way. If this option is disabled, the implications are: 1) each interface port (per bit) receivces a partition pin, 2) RP will only resources confined to its pblocks, 3) the generated PR bitstream will be smaller, 4) hd_visual/ will not be generated. However, this option does not prevent routings from the static region from crossing RPs. This command is useful when you want to do some hacking about Partition Pins. Actually, you can also do this via GUI. set_param hd.routingContainmentAreaExpansion false But you wouldn\u2019t believe that: Static routing is still allowed to use resources inside of the Pblock. The implication is also obvious: all PR bitstreams and even blank bitstream will also have the static routing, if their targeted Pblocks happen to have static routing in the first place. This is also why we will need the static bitstream as the base to do PR bitstream generation.","title":"Semantic of CONTAIN_ROUTING"},{"location":"fpga/vivado/#clear-rm-and-lock-down-static","text":"These commands clear out the Reconfigurable Module logics from the whole design and then lock down the static region and static routing. (Reference: UG947) update_design - cell XXX - black_box lock_design - level routing","title":"Clear RM and Lock Down Static"},{"location":"fpga/vivado/#routing","text":"","title":"Routing"},{"location":"fpga/vivado/#get-the-routing-of-a-net","text":"set net [ get_nets XXX ] get_property ROUTE $net","title":"Get the routing of a net"},{"location":"fpga/vivado/#lock-the-routing-of-a-net","text":"We need to lock both the net and the connected cells. Reference is UG903. Following commands lock a route of a net. This net is already routed. You could run one by one. After execution, the route will become dashed (means locked). Replace the net name with your interested one. set net [ get_nets inst_count/count_out [ 0 ]] get_property ROUTE $net set_property FIXED_ROUTE [ get_property ROUTE $net ] $net set_property is_bel_fixed 1 [ get_cells XXX ] set_property is_loc_fixed 1 [ get_cells XXX ]","title":"Lock the routing of a net"},{"location":"fpga/vivado/#manual-routing","text":"A great GUI-based manual routing tutorial can be found at UG986 Lab 3 . The last step of manual routing, of course is to lock down the LOC and set FIXED_ROUTE . But how can we manually route an unrouted net? The difficulty is that we need to manually find out all the connection nodes/tiles etc.. This applies to LOC placement as well.","title":"Manual routing"},{"location":"fpga/vivado/#read-the-docs","text":"Basic UG912 Vivado Properties Reference Guide Excellent resource on explaining cell, net, pin, port, and so on. Differentiate Netlist Objects and Device Resource Objects . Netlist Objects pin : A pin is a point of logical connectivity on a primitive or hierarchical cell. A pin allows the contents of a cell to be abstracted away, and the logic simplified for ease-of-use. A pin is attached to a cell and can be connected to pins on other cells by a net. get_pins -of [get_cells XXX] . get_pins XXX port : A port is a special type of hierarchical pin, providing an external connection point at the top-level of a hierarchical design, or an internal connection point in a hierarchical cell or block module to connect the internal logic to the pins on the hierarchical cell. cell : A cell is an instance of a netlist logic object, which can either be a leaf-cell or a hierarchical cell. A leaf-cell is a primitive, or a primitive macro, with no further logic detail in the netlist. A hierarchical cell is a module or block that contains one or more additional levels of logic, and eventually concludes at leaf-cells. .. cells have PINs which are connected to NETs to define the external netlist\u2026 The CELL can be placed onto a BEL object in the case of basic logic such as flops, LUTs, and MUXes; or can be placed onto a SITE object in the case of larger logic cells such as BRAMs and DSPs. net : A net is a set of interconnected pins, ports, and wires. Every wire has a net name, which identifies it. Two or more wires can have the same net name. All wires sharing a common net name are part of a single NET, and all pins or ports connected to these wires are electrically connected. .. In the design netlist, a NET can be connected to the PIN of a CELL, or to a PORT. .. As the design is mapped onto the target Xilinx FPGA, the NET is mapped to routing resources such as WIREs, NODEs, and PIPs on the device, and is connected to BELs through BEL_PINs, and to SITEs through SITE_PINs. pblock : A Pblock is a collection of cells, and one or more rectangular areas or regions that specify the device resources contained by the Pblock. Pblocks are used during floorplanning placement to group related logic and assign it to a region of the target device. Example create_pblock Pblock_usbEngine add_cells_to_pblock [get_pblocks Pblock_usbEngine] [get_cells -quiet [listusbEngine1]] resize_pblock [get_pblocks Pblock_usbEngine] -add {SLICE_X8Y105:SLICE_X23Y149} resize_pblock [get_pblocks Pblock_usbEngine] -add {DSP48_X0Y42:DSP48_X1Y59} resize_pblock [get_pblocks Pblock_usbEngine] -add {RAMB18_X0Y42:RAMB18_X1Y59} resize_pblock [get_pblocks Pblock_usbEngine] -add {RAMB36_X0Y21:RAMB36_X1Y29} Device Resource Objects BEL : 1) leaf-level cells from the netlist design can be mapped onto bels on the target part 2) Bels are grouped in sites. 3) Each bel has bel_pins that map to pins on the cells. 4) get_bels -of [get_cells XX] , get_bels -of [get_nets XX] , and so on. BEL_PIN : 1) a pin or connection point on a BEL object. 2) BEL_PIN is a device object, associated with netlist objects such as the PIN on a CELL, which is the connection point for the NET. 3) get_bel_pins -of_objects [get_pins -of [get_cells XXX]] TILE SITE NODE WIRE PIP CONTAIN_ROUTING : The CONTAIN_ROUTING property restricts the routing of signals contained within a Pblock to use routing resources within the area defined by the Pblock. This prevents signals inside the Pblock from being routed outside the Pblock, and increases the reusability of the design. This is useful when you are trying to do advanced PR hacks. UG835 Vivado TCL Reference Guide aka. Vivado TCL Man Page. Read this with the above UG912. UG894 Vivado Using TCL scripting Get you started with Vivado TCL UG903 Using Constraints About Xilinx XDC files. You will need to understand UG912 first. Physical Constraints DONT_TOUCH . Prevent netlist optimizations. 1) prevent a net from being optimized away. 2) Prevent merging of manually replicated logic. Placement constraints Routing constraints Book: Practical Programming in Tcl and Tk Partial Reconfiguration Related UG909 Partial Reconfiguration Partition Pins Interface points called partition pins are automatically created within the Pblock ranges defined for the Reconfigurable Partition. These virtual I/O are established within interconnect tiles as the anchor points that remain consistent from one module to the next. In UltraScale or UltraScale+ designs, not all interface ports receive a partition pin . With the routing expansion feature, as explained in Expansion of CONTAIN_ROUTING Area, some interface nets are completely contained within the expanded region. When this happens, no partition pin is inserted; the entire net, including the source and all loads, is contained within the area captured by the partial bit file. Rather than pick an unnecessary intermediate point for the route, the entire net is rerouted, giving the Vivado tools the flexibility to pick an optimal solution. Exmaple set_property HD.PARTPIN_LOCS INT_R_X4Y153 [get_ports ] set_property HD.PARTPIN_RANGE SLICE_X4Y153:SLICE_X5Y157 [get_ports ] set_property HD.PARTPIN_RANGE {SLICE_Xx0Yx0:SLICE_Xx1Yy1 SLICE_XxNYyN:SLICE_XxMYyM} [get_pins /*] These pins can be manually relocated and locked. UG905 Hierarchical Design Add the CONTAIN_ROUTING property to all OOC Pblocks. Without this property, lock_design cannot lock the routing of an imported module because it cannot be guaranteed that there are no routing conflicts","title":"Read-the-docs"},{"location":"fpga/vivado/#some-ips","text":"UG947 has the sample code for the PR Controller IP It does not support simulation. Thus we can not probe any ICAP related signals. Ultrascale+ SEM does not have any useful ICAP usage signals in Simulation. xapp1230 has some TCL scripts to perform JTAG readback.","title":"Some IPs"},{"location":"general_log/0719/","text":"Jul 2019 \u00b6 0727 Sat \u00b6 bug fixed, we need to do the \u201cprep_new_page\u201d before return the page back into our lists. Obviously, pages in our lists are in \u201callocated\u201d state. Okay. Eval perf also. Looks like the direct invocation of cb_alloc_zero_page is not good.. Although the perf stat show that using pgadvance help to reduce the handlemmfault overhead by 15%, the actual runtime is the same.. weird. 0726 Friday \u00b6 Stuck at the BUG: bad mm counter and print_bad_pte . Issues identified: looks like I must use pcp lists? 0725 \u00b6 HA. I leaned about perf lock , which requies a kernel with CONFIG_LOCKDEP and CONFIG_LOCK_STAT . Not sure exactly how these options work, but they should insert some code inside each lock acquire and release. Anyway, with perf lock , we are able to know what specific locks are hot. This is fantastic. Note that normal perf record -e 'cycles:k' can tell use how much time is spent on spin_lock , but it does not say how much time each specific lock uses. Cool. Ah, side note, make nconfig is really powerful!! Even though I\u2019ve been playing with Linux for many years, I haven\u2019t actually played with linux config manually. Tried once. Our spinlock for pgadvance list shouldn\u2019t be the issue. Now disable it and reboot. 254 pg 252 nopg 37.140 0724 \u00b6 Bagel Day. First replot the figrue, adding an avg/95P/99P figure. Very long tails. Yeah! Then tune page advance. The key is to find a not busy CPU. I\u2019m first trying Round-Robin . Try TF Cifar. First run without pgadvance, see how the first 100 step performs in different runs. They seem to be very stable. 1 ) step = 100 ( 167 .432 sec ) 2 ) step = 100 ( 168 .021 sec ) step = 200 ( 167 .467 sec ) 3 ) step = 100 ( 167 .903 sec ) DAMN. Forgot to turn off huge page. Now use perf to make sure do_anonymous_page got enough cycles.. 22/23 down, no pgadvance, 163, 161, 161 22/23 down, no pgadvance, no perf, 159 0723 \u00b6 11:59pm End of day. Learned how to plot Violin. Very long tail, and does not scale well even with PCP opt! 9pm I\u2019m using my own benchmark to measure buddy allocator. I\u2019m testing order-0 alloc performance. Something weird happen during test. The 16 th line is very costly. And after that, suddenly the perf improves nealy 50%. I\u2019m reporting CPU cycles, CPU frequency change shouldn\u2019t matter, right? Linux has Per-CPU Pages (pcp), which is intended to optimize 0-order allocation. In my test case, each CPU keep 7 free pages. The patten is reflected in the measurement. Note that, the refill is sync. \"\"\" (latency in CPU cycles. 2.4GHz Xeon E5 v3) \"\"\" ... [ 1043.789257] idx=11956 order=0 latency=3128 [ 1043.789257] idx=11957 order=0 latency=376 [ 1043.789258] idx=11958 order=0 latency=376 [ 1043.789258] idx=11959 order=0 latency=368 [ 1043.789258] idx=11960 order=0 latency=376 [ 1043.789259] idx=11961 order=0 latency=400 [ 1043.789259] idx=11962 order=0 latency=384 [ 1043.789260] idx=11963 order=0 latency=3080 [ 1043.789260] idx=11964 order=0 latency=408 [ 1043.789260] idx=11965 order=0 latency=400 [ 1043.789261] idx=11966 order=0 latency=392 [ 1043.789261] idx=11967 order=0 latency=360 [ 1043.789262] idx=11968 order=0 latency=360 [ 1043.789262] idx=11969 order=0 latency=376 [ 1043.789262] idx=11970 order=0 latency=2992 [ 1043.789263] idx=11971 order=0 latency=29930 [ 1043.789263] idx=11972 order=0 latency=171 [ 1043.789264] idx=11973 order=0 latency=156 [ 1043.789264] idx=11974 order=0 latency=177 [ 1043.789264] idx=11975 order=0 latency=174 [ 1043.789265] idx=11976 order=0 latency=174 [ 1043.789265] idx=11977 order=0 latency=1419 [ 1043.789265] idx=11978 order=0 latency=156 [ 1043.789266] idx=11979 order=0 latency=174 [ 1043.789266] idx=11980 order=0 latency=171 [ 1043.789267] idx=11981 order=0 latency=171 [ 1043.789267] idx=11982 order=0 latency=171 [ 1043.789267] idx=11983 order=0 latency=156 [ 1043.789268] idx=11984 order=0 latency=1362 [ 1043.789268] idx=11985 order=0 latency=174 [ 1043.789269] idx=11986 order=0 latency=168 [ 1043.789269] idx=11987 order=0 latency=156 [ 1043.789269] idx=11988 order=0 latency=168 [ 1043.789270] idx=11989 order=0 latency=174 [ 1043.789270] idx=11990 order=0 latency=171 [ 1043.789270] idx=11991 order=0 latency=1266 ...","title":"Jul 2019"},{"location":"general_log/0719/#jul-2019","text":"","title":"Jul 2019"},{"location":"general_log/0719/#0727-sat","text":"bug fixed, we need to do the \u201cprep_new_page\u201d before return the page back into our lists. Obviously, pages in our lists are in \u201callocated\u201d state. Okay. Eval perf also. Looks like the direct invocation of cb_alloc_zero_page is not good.. Although the perf stat show that using pgadvance help to reduce the handlemmfault overhead by 15%, the actual runtime is the same.. weird.","title":"0727 Sat"},{"location":"general_log/0719/#0726-friday","text":"Stuck at the BUG: bad mm counter and print_bad_pte . Issues identified: looks like I must use pcp lists?","title":"0726 Friday"},{"location":"general_log/0719/#0725","text":"HA. I leaned about perf lock , which requies a kernel with CONFIG_LOCKDEP and CONFIG_LOCK_STAT . Not sure exactly how these options work, but they should insert some code inside each lock acquire and release. Anyway, with perf lock , we are able to know what specific locks are hot. This is fantastic. Note that normal perf record -e 'cycles:k' can tell use how much time is spent on spin_lock , but it does not say how much time each specific lock uses. Cool. Ah, side note, make nconfig is really powerful!! Even though I\u2019ve been playing with Linux for many years, I haven\u2019t actually played with linux config manually. Tried once. Our spinlock for pgadvance list shouldn\u2019t be the issue. Now disable it and reboot. 254 pg 252 nopg 37.140","title":"0725"},{"location":"general_log/0719/#0724","text":"Bagel Day. First replot the figrue, adding an avg/95P/99P figure. Very long tails. Yeah! Then tune page advance. The key is to find a not busy CPU. I\u2019m first trying Round-Robin . Try TF Cifar. First run without pgadvance, see how the first 100 step performs in different runs. They seem to be very stable. 1 ) step = 100 ( 167 .432 sec ) 2 ) step = 100 ( 168 .021 sec ) step = 200 ( 167 .467 sec ) 3 ) step = 100 ( 167 .903 sec ) DAMN. Forgot to turn off huge page. Now use perf to make sure do_anonymous_page got enough cycles.. 22/23 down, no pgadvance, 163, 161, 161 22/23 down, no pgadvance, no perf, 159","title":"0724"},{"location":"general_log/0719/#0723","text":"11:59pm End of day. Learned how to plot Violin. Very long tail, and does not scale well even with PCP opt! 9pm I\u2019m using my own benchmark to measure buddy allocator. I\u2019m testing order-0 alloc performance. Something weird happen during test. The 16 th line is very costly. And after that, suddenly the perf improves nealy 50%. I\u2019m reporting CPU cycles, CPU frequency change shouldn\u2019t matter, right? Linux has Per-CPU Pages (pcp), which is intended to optimize 0-order allocation. In my test case, each CPU keep 7 free pages. The patten is reflected in the measurement. Note that, the refill is sync. \"\"\" (latency in CPU cycles. 2.4GHz Xeon E5 v3) \"\"\" ... [ 1043.789257] idx=11956 order=0 latency=3128 [ 1043.789257] idx=11957 order=0 latency=376 [ 1043.789258] idx=11958 order=0 latency=376 [ 1043.789258] idx=11959 order=0 latency=368 [ 1043.789258] idx=11960 order=0 latency=376 [ 1043.789259] idx=11961 order=0 latency=400 [ 1043.789259] idx=11962 order=0 latency=384 [ 1043.789260] idx=11963 order=0 latency=3080 [ 1043.789260] idx=11964 order=0 latency=408 [ 1043.789260] idx=11965 order=0 latency=400 [ 1043.789261] idx=11966 order=0 latency=392 [ 1043.789261] idx=11967 order=0 latency=360 [ 1043.789262] idx=11968 order=0 latency=360 [ 1043.789262] idx=11969 order=0 latency=376 [ 1043.789262] idx=11970 order=0 latency=2992 [ 1043.789263] idx=11971 order=0 latency=29930 [ 1043.789263] idx=11972 order=0 latency=171 [ 1043.789264] idx=11973 order=0 latency=156 [ 1043.789264] idx=11974 order=0 latency=177 [ 1043.789264] idx=11975 order=0 latency=174 [ 1043.789265] idx=11976 order=0 latency=174 [ 1043.789265] idx=11977 order=0 latency=1419 [ 1043.789265] idx=11978 order=0 latency=156 [ 1043.789266] idx=11979 order=0 latency=174 [ 1043.789266] idx=11980 order=0 latency=171 [ 1043.789267] idx=11981 order=0 latency=171 [ 1043.789267] idx=11982 order=0 latency=171 [ 1043.789267] idx=11983 order=0 latency=156 [ 1043.789268] idx=11984 order=0 latency=1362 [ 1043.789268] idx=11985 order=0 latency=174 [ 1043.789269] idx=11986 order=0 latency=168 [ 1043.789269] idx=11987 order=0 latency=156 [ 1043.789269] idx=11988 order=0 latency=168 [ 1043.789270] idx=11989 order=0 latency=174 [ 1043.789270] idx=11990 order=0 latency=171 [ 1043.789270] idx=11991 order=0 latency=1266 ...","title":"0723"},{"location":"general_log/0819/","text":"Aug 2019 \u00b6 Aug 14 \u00b6 Back to sweet WL. Helping out for asplos submission. I was trying to run Octopus. Its cmake report that MPI_C is missing, so I run yum install openmpi-devel . However, this failed due to some broken dependency on rdma-core and others. It seems these packages have been updated by mlx-ofed.. what a mess.","title":"Aug 2019"},{"location":"general_log/0819/#aug-2019","text":"","title":"Aug 2019"},{"location":"general_log/0819/#aug-14","text":"Back to sweet WL. Helping out for asplos submission. I was trying to run Octopus. Its cmake report that MPI_C is missing, so I run yum install openmpi-devel . However, this failed due to some broken dependency on rdma-core and others. It seems these packages have been updated by mlx-ofed.. what a mess.","title":"Aug 14"},{"location":"general_log/0919/","text":"Sep 2019 \u00b6 Log range 0920 - 0930. 9/26/19 \u00b6 Check out PR today. create_pblock 9/25/19 \u00b6 Singularity and Helios 1 2 3 - I 've been reading Singularity today. It has many insights on extension and isolation. Something we might be interested: 1) application has a manifest. We may want to have a similar one for each FPGA app. 2) Seal OS architecture, where the OS or app remain invariant after install. This is the nature of FPGA.. - Also , I think it 's important to figure out a way to do IP sharing. The same thing is also beneficial for PR. - Scheduling : preemptive or non - preemptive .. Thoughts after reading Singularity papers - The contract-based channel is promising - The manifest-based program approach is also promising. Similarly, the AmoghOS has some Resource Vector associated with each FPGA application. I think it\u2019s valid and beneficial to attach such a spec with FPGA applications. I think I need to think more on the applications. Cannot wait till its too late! If an app is too big to fit into a FPGA, can we do \u201cbitstream\u201d swap? - App need to conform to some sort of model (e.g., msg-based) - Fast PR - Must be slow from app\u2019s point, but a solution., 0923 Monday \u00b6 Continue working on FPGA stuff. Let\u2019s focus on writing possible design ideas. I should also read some related work. 0921 Weekends \u00b6 Spent some time reading ATC papers, came across quite some interesting ones. Distributed actor runtime I came across actors many times recently. Like the iPipe, ST-Accel. There are some open-source frameworks. Erlang and akka. It\u2019s model that I should consider in the future SSD Related Alibaba has a study paper about SSD reliability in their datacenters. Amy Tai has an interesting paper, they enable distributed storage systems to run on high error rate SSDs. Traditionally, if an SSD has a high error rate, it will impact local file system perf thus higher level system perf. Their idea is neat: utilize the remote replicas to recover local SSD errors! Thus they could use those SSDs! File system on SSD study. Paper from Toronto. I haven\u2019t read it yet. 0920 Fri \u00b6 Well.. I should continue on this. We moved to UCSD recently. Everything is setup except desktop and server stuff. Started using F1 recently. Porting our code from VCU108 to VCU118. The migration between boards and between different vivado versions is a REAL headache. (VCU108 -> VCU118 && 2018.2 -> 2018.3) So for those TCL scripts generated by vivado, i found it will use hardcoded IP version. Upgrading vivado means possibly updated IP versions, thus broken TCL scripts. I\u2019ve found a way to workaround. But if the IP interface changed, it has to be modified manually. Many things left on the table - Merge LegoOS code - Think about and finish design doc - Tons of papers to read Life wise: sea is nearby, although UCSD gym sucks, it has jiu jitsu courses. Let\u2019s do the work. Try make PCIe work first. Checking out xtp444, the VCU118 PCIe reference design. Okay. Finished patching the XDC file, basically went through the example designs and check couple design docs, same old shit. Synthesis can pass. Implementation failed because Disk is full (?!). Anyway, next step is: - Resize Disk size - Run implementation, check it can pass - Run simulation, functionality check of RDM!","title":"Sep 2019"},{"location":"general_log/0919/#sep-2019","text":"Log range 0920 - 0930.","title":"Sep 2019"},{"location":"general_log/0919/#92619","text":"Check out PR today. create_pblock","title":"9/26/19"},{"location":"general_log/0919/#92519","text":"Singularity and Helios 1 2 3 - I 've been reading Singularity today. It has many insights on extension and isolation. Something we might be interested: 1) application has a manifest. We may want to have a similar one for each FPGA app. 2) Seal OS architecture, where the OS or app remain invariant after install. This is the nature of FPGA.. - Also , I think it 's important to figure out a way to do IP sharing. The same thing is also beneficial for PR. - Scheduling : preemptive or non - preemptive .. Thoughts after reading Singularity papers - The contract-based channel is promising - The manifest-based program approach is also promising. Similarly, the AmoghOS has some Resource Vector associated with each FPGA application. I think it\u2019s valid and beneficial to attach such a spec with FPGA applications. I think I need to think more on the applications. Cannot wait till its too late! If an app is too big to fit into a FPGA, can we do \u201cbitstream\u201d swap? - App need to conform to some sort of model (e.g., msg-based) - Fast PR - Must be slow from app\u2019s point, but a solution.,","title":"9/25/19"},{"location":"general_log/0919/#0923-monday","text":"Continue working on FPGA stuff. Let\u2019s focus on writing possible design ideas. I should also read some related work.","title":"0923 Monday"},{"location":"general_log/0919/#0921-weekends","text":"Spent some time reading ATC papers, came across quite some interesting ones. Distributed actor runtime I came across actors many times recently. Like the iPipe, ST-Accel. There are some open-source frameworks. Erlang and akka. It\u2019s model that I should consider in the future SSD Related Alibaba has a study paper about SSD reliability in their datacenters. Amy Tai has an interesting paper, they enable distributed storage systems to run on high error rate SSDs. Traditionally, if an SSD has a high error rate, it will impact local file system perf thus higher level system perf. Their idea is neat: utilize the remote replicas to recover local SSD errors! Thus they could use those SSDs! File system on SSD study. Paper from Toronto. I haven\u2019t read it yet.","title":"0921 Weekends"},{"location":"general_log/0919/#0920-fri","text":"Well.. I should continue on this. We moved to UCSD recently. Everything is setup except desktop and server stuff. Started using F1 recently. Porting our code from VCU108 to VCU118. The migration between boards and between different vivado versions is a REAL headache. (VCU108 -> VCU118 && 2018.2 -> 2018.3) So for those TCL scripts generated by vivado, i found it will use hardcoded IP version. Upgrading vivado means possibly updated IP versions, thus broken TCL scripts. I\u2019ve found a way to workaround. But if the IP interface changed, it has to be modified manually. Many things left on the table - Merge LegoOS code - Think about and finish design doc - Tons of papers to read Life wise: sea is nearby, although UCSD gym sucks, it has jiu jitsu courses. Let\u2019s do the work. Try make PCIe work first. Checking out xtp444, the VCU118 PCIe reference design. Okay. Finished patching the XDC file, basically went through the example designs and check couple design docs, same old shit. Synthesis can pass. Implementation failed because Disk is full (?!). Anyway, next step is: - Resize Disk size - Run implementation, check it can pass - Run simulation, functionality check of RDM!","title":"0920 Fri"},{"location":"general_log/1019/","text":"Oct 2019 \u00b6 Writing a research journal here has its advantages: simple and version-control. But I\u2019m moving to Google Docs.","title":"Oct 2019"},{"location":"general_log/1019/#oct-2019","text":"Writing a research journal here has its advantages: simple and version-control. But I\u2019m moving to Google Docs.","title":"Oct 2019"},{"location":"howto/qemu-iommu/","text":"How to add an IOMMU device in QEMU? \u00b6 Version History Date Description Aug 2, 2021 Initial TL;DR This blog explains how QEMU simulate IOMMU device and how you can add one of your own. We will take a brief read of Intel IOMMU, ARM SMMU, and Virtio-IOMMU. Finally we will add a new one to RISC-V virt machine mode. The plan is to write this doc at the end of Sep 2021.","title":"How to add an IOMMU device in QEMU?"},{"location":"howto/qemu-iommu/#how-to-add-an-iommu-device-in-qemu","text":"Version History Date Description Aug 2, 2021 Initial TL;DR This blog explains how QEMU simulate IOMMU device and how you can add one of your own. We will take a brief read of Intel IOMMU, ARM SMMU, and Virtio-IOMMU. Finally we will add a new one to RISC-V virt machine mode. The plan is to write this doc at the end of Sep 2021.","title":"How to add an IOMMU device in QEMU?"},{"location":"lego/driver/ib/","text":"Infiniband Subsystem \u00b6 Current Status \u00b6 Lego\u2019s IB stack is ported based on linux-3.11.1 . We ported: ib_core mlx4_ib mlx4_core Lego does not support uverbs. At the time of writing, Lego IB stack has only been tested on Mellanox Technologies MT27500 Family [ConnectX-3] . Random summary \u00b6 The stack is SUPER complex, a lot data structures and pointers fly all over. Good thing is the whole stack is layered clearly. Top down ib_core \u00b6 IB core code is in driver/infiniband/core , which exposes the major IB API to both user and kernel applications. Inside, it has two parts. The first part is function callback, that call back to underlying device-specific functions. The second part is the management stack, including communication manager (cm), management datagram (mad), and so on. In IB, each port\u2019s QP0 and QP1 are reserved for management purpose. They will receive/send MAD from/to subnet manager, who typically runs on switch. All the IB management stuff is carried out by exchanging MAD. There are several key data structures: ib_client, ib_device, and mad_agent. MAD, CM, and some others are ib_client, which means they use IB device, and will be called back whenever a device has been added. mad_agent is something that will be called back whenever a device received a MAD message from switch (see ib_mad_completion_handler() ). A lot layers, huh? ib_mad_completion_handler() : we changed the behavior of it. we use busy polling instead of interrupt. Originally, it will be invoked by mlx4_core/eq.c mlx4_ib and mlx4_core \u00b6 mlx4_core is actually the Ethernet driver for Mellanox NIC device (drivers/net/ethernet/mellanox/hw/mlx4), which do the actual dirty work of talking with device. On the other hand, mlx4_ib is the glue code between ib_core and mlx4_core, who do the translation. A lot IB verbs are ultimately translated into fw.c __mlx4_cmd() , which actually send commands to device and get the result. There are two ways of getting result: 1) polling: after writing to device memory the command, the same thread keep polling. 2) sleep and wait for interrupt. By default, the interrupt way is used (obviously). But, at the time of writing (Aug 20, 2018), we don\u2019t really have a working IRQ subsystem, so we use polling instead. I\u2019m still a little concerned that without interrupt handler, we might lose some events and the NIC may behavave incorrectly if interrupts are not handled. Init Sequence \u00b6 Init PCI subsystem, build data structures Core IB layer register ib_client mlx4_init() : register PCI driver, provide a callback __mlx4_init_one() : initialize the hardware itself, register interrupt handler. mlx4_ib_init() : allocate a ib_device, and register, which will callback through all ib_client registered at step 1. \u2013 Yizhou Shan Created: Aug 20, 2018 Last Updated: Aug 20, 2018","title":"Infiniband"},{"location":"lego/driver/ib/#infiniband-subsystem","text":"","title":"Infiniband Subsystem"},{"location":"lego/driver/ib/#current-status","text":"Lego\u2019s IB stack is ported based on linux-3.11.1 . We ported: ib_core mlx4_ib mlx4_core Lego does not support uverbs. At the time of writing, Lego IB stack has only been tested on Mellanox Technologies MT27500 Family [ConnectX-3] .","title":"Current Status"},{"location":"lego/driver/ib/#random-summary","text":"The stack is SUPER complex, a lot data structures and pointers fly all over. Good thing is the whole stack is layered clearly. Top down","title":"Random summary"},{"location":"lego/driver/ib/#ib_core","text":"IB core code is in driver/infiniband/core , which exposes the major IB API to both user and kernel applications. Inside, it has two parts. The first part is function callback, that call back to underlying device-specific functions. The second part is the management stack, including communication manager (cm), management datagram (mad), and so on. In IB, each port\u2019s QP0 and QP1 are reserved for management purpose. They will receive/send MAD from/to subnet manager, who typically runs on switch. All the IB management stuff is carried out by exchanging MAD. There are several key data structures: ib_client, ib_device, and mad_agent. MAD, CM, and some others are ib_client, which means they use IB device, and will be called back whenever a device has been added. mad_agent is something that will be called back whenever a device received a MAD message from switch (see ib_mad_completion_handler() ). A lot layers, huh? ib_mad_completion_handler() : we changed the behavior of it. we use busy polling instead of interrupt. Originally, it will be invoked by mlx4_core/eq.c","title":"ib_core"},{"location":"lego/driver/ib/#mlx4_ib-and-mlx4_core","text":"mlx4_core is actually the Ethernet driver for Mellanox NIC device (drivers/net/ethernet/mellanox/hw/mlx4), which do the actual dirty work of talking with device. On the other hand, mlx4_ib is the glue code between ib_core and mlx4_core, who do the translation. A lot IB verbs are ultimately translated into fw.c __mlx4_cmd() , which actually send commands to device and get the result. There are two ways of getting result: 1) polling: after writing to device memory the command, the same thread keep polling. 2) sleep and wait for interrupt. By default, the interrupt way is used (obviously). But, at the time of writing (Aug 20, 2018), we don\u2019t really have a working IRQ subsystem, so we use polling instead. I\u2019m still a little concerned that without interrupt handler, we might lose some events and the NIC may behavave incorrectly if interrupts are not handled.","title":"mlx4_ib and mlx4_core"},{"location":"lego/driver/ib/#init-sequence","text":"Init PCI subsystem, build data structures Core IB layer register ib_client mlx4_init() : register PCI driver, provide a callback __mlx4_init_one() : initialize the hardware itself, register interrupt handler. mlx4_ib_init() : allocate a ib_device, and register, which will callback through all ib_client registered at step 1. \u2013 Yizhou Shan Created: Aug 20, 2018 Last Updated: Aug 20, 2018","title":"Init Sequence"},{"location":"lego/driver/pci/","text":"PCI Subsystem \u00b6 What we have ported so far \u00b6 PCI data structures such as pci_dev , pci_bus , and so on. Mechanism to scan bus and build data structures during boot. Performed by pci_scan_root_bus() , and most code is in driver/pci/probe.c Unfinished business \u00b6 Ways to go through all PCI device. pci_init_capabilities() : for each PCI device pci_fixup_device() : a lot quicks, maybe not useful pcie_aspm_init_link_state() : PCIe link state pci_iov_bus_range : all SR-IOV support \u2013 Yizhou Shan Created: July 5, 2018 Last Updated: July 5, 2018","title":"PCI"},{"location":"lego/driver/pci/#pci-subsystem","text":"","title":"PCI Subsystem"},{"location":"lego/driver/pci/#what-we-have-ported-so-far","text":"PCI data structures such as pci_dev , pci_bus , and so on. Mechanism to scan bus and build data structures during boot. Performed by pci_scan_root_bus() , and most code is in driver/pci/probe.c","title":"What we have ported so far"},{"location":"lego/driver/pci/#unfinished-business","text":"Ways to go through all PCI device. pci_init_capabilities() : for each PCI device pci_fixup_device() : a lot quicks, maybe not useful pcie_aspm_init_link_state() : PCIe link state pci_iov_bus_range : all SR-IOV support \u2013 Yizhou Shan Created: July 5, 2018 Last Updated: July 5, 2018","title":"Unfinished business"},{"location":"lego/kernel/boot/","text":"Notes on GRUB2 and Boot Sequence \u00b6 Version History Date Description Mar 31, 2020 Copied from https://github.com/lastweek/source-grub2 . About GRUB2 \u00b6 GRUB2: https://www.gnu.org/software/grub/manual/grub/grub.html#Introduction Source code: https://github.com/lastweek/source-grub2 linux v.s. linux16 \u00b6 An interesting thing is that there are two ways to load an kernel image in grub.cfg , either linux vmlinuz-3.10.0 or linux16 vmlinuz-3.10.0 . They have different effects, but not sure what are those differences. I remember only the linux16 one works for me, but not remembering why either. At least on CentOS 7, it\u2019s all linux16. The linux16 and initrd16 in grub-core/loader/i386/pc/linux.c : GRUB_MOD_INIT ( linux16 ) { cmd_linux = grub_register_command ( \"linux16\" , grub_cmd_linux , 0 , N_ ( \"Load Linux.\" )); cmd_initrd = grub_register_command ( \"initrd16\" , grub_cmd_initrd , 0 , N_ ( \"Load initrd.\" )); my_mod = mod ; } The linux and initrd in grub-core/loader/i386/linux.c : static grub_command_t cmd_linux , cmd_initrd ; GRUB_MOD_INIT ( linux ) { cmd_linux = grub_register_command ( \"linux\" , grub_cmd_linux , 0 , N_ ( \"Load Linux.\" )); cmd_initrd = grub_register_command ( \"initrd\" , grub_cmd_initrd , 0 , N_ ( \"Load initrd.\" )); my_mod = mod ; } Boot Protocol and Sequence \u00b6 This was written for https://github.com/lastweek/source-grub2 . I just copied it here. Linux (x86) has a boot protocol, described by https://www.kernel.org/doc/html/latest/x86/boot.html . Essentially, it is a contiguous memory region, just like a big C struct : some fields are filled by kernel duing compile time ( arch/x86/boot/tools/build.c and some in code), some fields are filled by GRUB2 during boot time to tell kernel some important addresses, e.g., kernel parameters, ramdisk locations etc. GRUB2 code follows the protocol, and you can partially tell from the grub_cmd_linux() function. Last time I working on this was late 2016, I truly spent a lot investigating how GRUB and linux boot works. I will try to document a bit, if my memory serves: In the Linux kernel, file arch/x86/boot/header.S is the first file got run after GRUB2. This file is a bit complicated but not hard to understand! It has 3 parts. For the first part, it detects if it was loaded by a bootloader, if not, just by printing an error message and reboot. It the kernel was loaded by a bootloader like GRUB2, the first part will never execute. The bootload will directly jump to the second part. This is part of the boot protocol. For the second part, it lists all the fields described by the boot protocol. And finally the third part is real-mode instructions that got run after the GRUB2 jumo. The starting function is called start_of_setup , which will do some stack checking, and then jump to C code in arch/x86/boot/main.c . arch/x86/boot/main.c runs on real-mode, it will do some setup and jump to protected-mode (32-bit). It is running after BIOS but before the actual Linux kernel. Thus this piece of code must rely on BIOS to do stuff, which makes it very unique. The major task of the setup code is to prepare the struct boot_params , which has all the boot information, some of them were extracted from the header.S . The struct boot_params will be passed down and used by many kernel subsystems later on. The final jump happens in arch/x86/boot/pmjump.S # # Jump to protected-mode kernel, 0x100000 # which is the compressed/head_$(BITS).o # jmp *% eax Then, we are in arch/x86/boot/compressed/head_64.S . Above pmjump jumps to startup_32 , it will enable paging, tweak GDT table etc, setup pagetable, and transition to 64-bit entry point startup_64 . And finally, we are in 64-bit. The final jump will go to arch/x86/kernel/head_64.S . We are close! Now we are in arch/x86/kernel/head_64.S . We are in 64-bit. But some further setup is needed. This part is really low-level and engaging. I would never know I how managed to understand and port all this shit. It setup a lot GDT, IDT stuff, and some pgfault handlers. It turns out those early pgfault handlers are NECESSARY and I remember they played an very interesting role! Finally, this assembly will jump to arch/x86/kernel/head64.c , the C code! I guess an interesting part is secondary_startup_64 . This code is actually run by non-booting CPUs, or secondary CPUs. After the major boot CPU is up and running (already within start_kernel() ), I believe its the smp_init() that will send IPI wakeup interrupts to all present secondary CPUs. The secondary CPUs will start from real-mode, obviously. Then they will transition from 16bit to 32bit, from 32bit to 64bit. That code is in arch/x86/realmode/rm/trampoline.S ! arch/x86/realmode is interesting. It uses piggyback technique. All the real-mode and 32bit code are in arch/x86/realmode/rm/* , a special linker script is used to construct the code in a specific way! Think about mix 16bit, 32bit, 64bit code together, nasty! Hooray, C world. We are in arch/x86/kernel/head64.c . The starting function is x86_64_start_kernel ! And the end is the start_kernel , the one in init/main.c . In all, there are a lot jumps after GRUB2 load the kernel, and its a long road before we can reach start_kernel() . It probably should not be this complex, but the x86 architecture really makes it worse. Happy hacking!","title":"GRUB2 and Boot"},{"location":"lego/kernel/boot/#notes-on-grub2-and-boot-sequence","text":"Version History Date Description Mar 31, 2020 Copied from https://github.com/lastweek/source-grub2 .","title":"Notes on GRUB2 and Boot Sequence"},{"location":"lego/kernel/boot/#about-grub2","text":"GRUB2: https://www.gnu.org/software/grub/manual/grub/grub.html#Introduction Source code: https://github.com/lastweek/source-grub2","title":"About GRUB2"},{"location":"lego/kernel/boot/#linux-vs-linux16","text":"An interesting thing is that there are two ways to load an kernel image in grub.cfg , either linux vmlinuz-3.10.0 or linux16 vmlinuz-3.10.0 . They have different effects, but not sure what are those differences. I remember only the linux16 one works for me, but not remembering why either. At least on CentOS 7, it\u2019s all linux16. The linux16 and initrd16 in grub-core/loader/i386/pc/linux.c : GRUB_MOD_INIT ( linux16 ) { cmd_linux = grub_register_command ( \"linux16\" , grub_cmd_linux , 0 , N_ ( \"Load Linux.\" )); cmd_initrd = grub_register_command ( \"initrd16\" , grub_cmd_initrd , 0 , N_ ( \"Load initrd.\" )); my_mod = mod ; } The linux and initrd in grub-core/loader/i386/linux.c : static grub_command_t cmd_linux , cmd_initrd ; GRUB_MOD_INIT ( linux ) { cmd_linux = grub_register_command ( \"linux\" , grub_cmd_linux , 0 , N_ ( \"Load Linux.\" )); cmd_initrd = grub_register_command ( \"initrd\" , grub_cmd_initrd , 0 , N_ ( \"Load initrd.\" )); my_mod = mod ; }","title":"linux v.s. linux16"},{"location":"lego/kernel/boot/#boot-protocol-and-sequence","text":"This was written for https://github.com/lastweek/source-grub2 . I just copied it here. Linux (x86) has a boot protocol, described by https://www.kernel.org/doc/html/latest/x86/boot.html . Essentially, it is a contiguous memory region, just like a big C struct : some fields are filled by kernel duing compile time ( arch/x86/boot/tools/build.c and some in code), some fields are filled by GRUB2 during boot time to tell kernel some important addresses, e.g., kernel parameters, ramdisk locations etc. GRUB2 code follows the protocol, and you can partially tell from the grub_cmd_linux() function. Last time I working on this was late 2016, I truly spent a lot investigating how GRUB and linux boot works. I will try to document a bit, if my memory serves: In the Linux kernel, file arch/x86/boot/header.S is the first file got run after GRUB2. This file is a bit complicated but not hard to understand! It has 3 parts. For the first part, it detects if it was loaded by a bootloader, if not, just by printing an error message and reboot. It the kernel was loaded by a bootloader like GRUB2, the first part will never execute. The bootload will directly jump to the second part. This is part of the boot protocol. For the second part, it lists all the fields described by the boot protocol. And finally the third part is real-mode instructions that got run after the GRUB2 jumo. The starting function is called start_of_setup , which will do some stack checking, and then jump to C code in arch/x86/boot/main.c . arch/x86/boot/main.c runs on real-mode, it will do some setup and jump to protected-mode (32-bit). It is running after BIOS but before the actual Linux kernel. Thus this piece of code must rely on BIOS to do stuff, which makes it very unique. The major task of the setup code is to prepare the struct boot_params , which has all the boot information, some of them were extracted from the header.S . The struct boot_params will be passed down and used by many kernel subsystems later on. The final jump happens in arch/x86/boot/pmjump.S # # Jump to protected-mode kernel, 0x100000 # which is the compressed/head_$(BITS).o # jmp *% eax Then, we are in arch/x86/boot/compressed/head_64.S . Above pmjump jumps to startup_32 , it will enable paging, tweak GDT table etc, setup pagetable, and transition to 64-bit entry point startup_64 . And finally, we are in 64-bit. The final jump will go to arch/x86/kernel/head_64.S . We are close! Now we are in arch/x86/kernel/head_64.S . We are in 64-bit. But some further setup is needed. This part is really low-level and engaging. I would never know I how managed to understand and port all this shit. It setup a lot GDT, IDT stuff, and some pgfault handlers. It turns out those early pgfault handlers are NECESSARY and I remember they played an very interesting role! Finally, this assembly will jump to arch/x86/kernel/head64.c , the C code! I guess an interesting part is secondary_startup_64 . This code is actually run by non-booting CPUs, or secondary CPUs. After the major boot CPU is up and running (already within start_kernel() ), I believe its the smp_init() that will send IPI wakeup interrupts to all present secondary CPUs. The secondary CPUs will start from real-mode, obviously. Then they will transition from 16bit to 32bit, from 32bit to 64bit. That code is in arch/x86/realmode/rm/trampoline.S ! arch/x86/realmode is interesting. It uses piggyback technique. All the real-mode and 32bit code are in arch/x86/realmode/rm/* , a special linker script is used to construct the code in a specific way! Think about mix 16bit, 32bit, 64bit code together, nasty! Hooray, C world. We are in arch/x86/kernel/head64.c . The starting function is x86_64_start_kernel ! And the end is the start_kernel , the one in init/main.c . In all, there are a lot jumps after GRUB2 load the kernel, and its a long road before we can reach start_kernel() . It probably should not be this complex, but the x86 architecture really makes it worse. Happy hacking!","title":"Boot Protocol and Sequence"},{"location":"lego/kernel/debug/","text":"Debug Facility in Lego \u00b6 Lego provides several handy debug helpers to ease our coding pain. We category them by layers, namely 1) Core Kernel , the lowest level of Lego, which is shared by all managers. 2) Processor Manager , which controls processor components. 3) Memory Manager , which controls memory components. Core Kernel \u00b6 void dump_pte ( pte_t * ptep , const char * reason ); void dump_page ( struct page * page , const char * reason ); These two helpers will dump a given pte entry or a page. Use this function if you are developing core related to physical memory allocation or pcache. void ptdump_walk_pgd_level ( pgd_t * pgd ); This debug helper will dump the whole pgtable ranges. Contiguous page table entries that share the same property will be merged together and will be printed once. Use this function if you are developing code related to user page tables. void show_state_filter ( unsigned long state_filter , bool print_rq ); void sched_show_task ( struct task_struct * p ); void sysrq_sched_debug_show ( void ); This set of functions are debug helpers for local scheduler. They will print all the tasks running in the system, and detailed information about percpu runqueue . Use this set of functions if you are developing code related to scheduler. Processor Manager \u00b6 void dump_pcache_meta ( struct pcache_meta * pcm , const char * reason ); void dump_pcache_victim ( struct pcache_victim_meta * victim , const char * reason ); void dump_pcache_rmap ( struct pcache_rmap * rmap , const char * reason ); void dump_pcache_line ( struct pcache_meta * pcm , const char * reason ); These functions dump a given pcache line, a victim line, or a given reserve mapping. The last one will print the pcache line content, which generates a lot messages, you are warned. Use these functions if you are developing pcache or victim cache code. Memory Manager \u00b6 void dump_lego_mm ( const struct lego_mm_struct * mm ); void dump_vma ( const struct vm_area_struct * vma ); These two functions are used to dump the virtual address space of a process. Use these functions if you developing process VM related things.","title":"Debug"},{"location":"lego/kernel/debug/#debug-facility-in-lego","text":"Lego provides several handy debug helpers to ease our coding pain. We category them by layers, namely 1) Core Kernel , the lowest level of Lego, which is shared by all managers. 2) Processor Manager , which controls processor components. 3) Memory Manager , which controls memory components.","title":"Debug Facility in Lego"},{"location":"lego/kernel/debug/#core-kernel","text":"void dump_pte ( pte_t * ptep , const char * reason ); void dump_page ( struct page * page , const char * reason ); These two helpers will dump a given pte entry or a page. Use this function if you are developing core related to physical memory allocation or pcache. void ptdump_walk_pgd_level ( pgd_t * pgd ); This debug helper will dump the whole pgtable ranges. Contiguous page table entries that share the same property will be merged together and will be printed once. Use this function if you are developing code related to user page tables. void show_state_filter ( unsigned long state_filter , bool print_rq ); void sched_show_task ( struct task_struct * p ); void sysrq_sched_debug_show ( void ); This set of functions are debug helpers for local scheduler. They will print all the tasks running in the system, and detailed information about percpu runqueue . Use this set of functions if you are developing code related to scheduler.","title":"Core Kernel"},{"location":"lego/kernel/debug/#processor-manager","text":"void dump_pcache_meta ( struct pcache_meta * pcm , const char * reason ); void dump_pcache_victim ( struct pcache_victim_meta * victim , const char * reason ); void dump_pcache_rmap ( struct pcache_rmap * rmap , const char * reason ); void dump_pcache_line ( struct pcache_meta * pcm , const char * reason ); These functions dump a given pcache line, a victim line, or a given reserve mapping. The last one will print the pcache line content, which generates a lot messages, you are warned. Use these functions if you are developing pcache or victim cache code.","title":"Processor Manager"},{"location":"lego/kernel/debug/#memory-manager","text":"void dump_lego_mm ( const struct lego_mm_struct * mm ); void dump_vma ( const struct vm_area_struct * vma ); These two functions are used to dump the virtual address space of a process. Use these functions if you developing process VM related things.","title":"Memory Manager"},{"location":"lego/kernel/fpu/","text":"x86 Floating Point Unit \u00b6 This is not a document about the FPU technology, this is just a simple note on FPU code and my debugging lesson. FPU is heavily used by user level code. You may not use it directly, but glibc library is using it a lot, e.g. the strcmp function. x86 FPU is really another complex thing designed by Intel. Of course its performance is good and widely used, but the legacy compatible feature? Hmm. I would say, without Ingo Molnar\u2019s x86 FPU code rewrite , there is no way for me to easily understand it. The current x86 FPU code is well-written. Even though I don\u2019t quite understand what and why the code is, but I enjoy reading it. The naming convention, the code organization, the file organization, the header files, it is a nice piece of art. Anyway, Lego ported this low-level FPU code from Linux without any change. The porting is painful because it requires a lot other related features. And it also deals with compatible syscalls a little bit. Below I will just briefly list other subsystems that are using FPU, and talk about my thoughts. Boot \u00b6 FPU detection and init happen during early boot. You should know the struct fpu is a dynamically-sized structure. The size of it depends on what features the underlying CPU support. Since struct fpu is part of task_struct , that implies task_struct is dynamically-sized too. Apparently, cpu_init() will also callback to init its local FPU. Context Switch \u00b6 FPU consists a lot registers, and each thread has its own FPU context. However, CPU will not save the FPU registers for us, it is software\u2019s duty to save and restore FPU context properly. FPU context is saved in struct fpu . Thus whenever we switch task, we also need to switch FPU context: __visible struct task_struct * __switch_to ( struct task_struct * prev_p , struct task_struct * next_p ) { .. fpu_switch = switch_fpu_prepare ( prev_fpu , next_fpu , cpu ); .. switch_fpu_finish ( next_fpu , fpu_switch ); .. } SYSCALL \u00b6 fork() and clone(): When a new thread or process is created, the FPU context is copied from the calling thread. execve(): When execve() is called, the FPU context will be cleared. exit(): When a thread exit,, FPU will do cleanup based on if eagerfpu or lazyfpu is used. Exceptions \u00b6 Like the device not available exception, which may be triggered if lazyfpu is used. Also, do_simd_exception and do_coprocessor_error , which are some math related exceptions. Signal \u00b6 Kernel needs to setup a sigframe for user level signal handlers. sigframe is a contiguous stack memory consists the general purpose registers and FPU registers. So signal handling part will also call back to FPU to setup and copy the FPU registers to sigframe in stack. Thoughts \u00b6 I\u2019ve been debugging this FPU introduced bugs for over a month. And during this month, I\u2019m always not sure if it is FPU\u2019s bug, or some other code that corrupts memory. So I\u2019m lazy to re-port FPU again. But after rule out every other possibilities, I turned back to FPU. At first I did not port all FPU code, cause I don\u2019t think I need all of it. One stupid thing is I forgot to turn on DEBUG_FPU, which should help me in the first place. I kind of lost myself in various engineering work during this debugging. I really need some big context switch in the middle to fresh my mind. Anyway, glad it is all done today (Feb 23), and I\u2019m able to move to next stage. Compatibility is a heavy thing to carry. But it is also a nice thing for marketing. No one can deny the success of Intel on its backward compatibility. Bad for programmers. \u2013 Yizhou Shan Created: Feb 22, 2018 Last Updated: Feb 23, 2018","title":"x86 FPU"},{"location":"lego/kernel/fpu/#x86-floating-point-unit","text":"This is not a document about the FPU technology, this is just a simple note on FPU code and my debugging lesson. FPU is heavily used by user level code. You may not use it directly, but glibc library is using it a lot, e.g. the strcmp function. x86 FPU is really another complex thing designed by Intel. Of course its performance is good and widely used, but the legacy compatible feature? Hmm. I would say, without Ingo Molnar\u2019s x86 FPU code rewrite , there is no way for me to easily understand it. The current x86 FPU code is well-written. Even though I don\u2019t quite understand what and why the code is, but I enjoy reading it. The naming convention, the code organization, the file organization, the header files, it is a nice piece of art. Anyway, Lego ported this low-level FPU code from Linux without any change. The porting is painful because it requires a lot other related features. And it also deals with compatible syscalls a little bit. Below I will just briefly list other subsystems that are using FPU, and talk about my thoughts.","title":"x86 Floating Point Unit"},{"location":"lego/kernel/fpu/#boot","text":"FPU detection and init happen during early boot. You should know the struct fpu is a dynamically-sized structure. The size of it depends on what features the underlying CPU support. Since struct fpu is part of task_struct , that implies task_struct is dynamically-sized too. Apparently, cpu_init() will also callback to init its local FPU.","title":"Boot"},{"location":"lego/kernel/fpu/#context-switch","text":"FPU consists a lot registers, and each thread has its own FPU context. However, CPU will not save the FPU registers for us, it is software\u2019s duty to save and restore FPU context properly. FPU context is saved in struct fpu . Thus whenever we switch task, we also need to switch FPU context: __visible struct task_struct * __switch_to ( struct task_struct * prev_p , struct task_struct * next_p ) { .. fpu_switch = switch_fpu_prepare ( prev_fpu , next_fpu , cpu ); .. switch_fpu_finish ( next_fpu , fpu_switch ); .. }","title":"Context Switch"},{"location":"lego/kernel/fpu/#syscall","text":"fork() and clone(): When a new thread or process is created, the FPU context is copied from the calling thread. execve(): When execve() is called, the FPU context will be cleared. exit(): When a thread exit,, FPU will do cleanup based on if eagerfpu or lazyfpu is used.","title":"SYSCALL"},{"location":"lego/kernel/fpu/#exceptions","text":"Like the device not available exception, which may be triggered if lazyfpu is used. Also, do_simd_exception and do_coprocessor_error , which are some math related exceptions.","title":"Exceptions"},{"location":"lego/kernel/fpu/#signal","text":"Kernel needs to setup a sigframe for user level signal handlers. sigframe is a contiguous stack memory consists the general purpose registers and FPU registers. So signal handling part will also call back to FPU to setup and copy the FPU registers to sigframe in stack.","title":"Signal"},{"location":"lego/kernel/fpu/#thoughts","text":"I\u2019ve been debugging this FPU introduced bugs for over a month. And during this month, I\u2019m always not sure if it is FPU\u2019s bug, or some other code that corrupts memory. So I\u2019m lazy to re-port FPU again. But after rule out every other possibilities, I turned back to FPU. At first I did not port all FPU code, cause I don\u2019t think I need all of it. One stupid thing is I forgot to turn on DEBUG_FPU, which should help me in the first place. I kind of lost myself in various engineering work during this debugging. I really need some big context switch in the middle to fresh my mind. Anyway, glad it is all done today (Feb 23), and I\u2019m able to move to next stage. Compatibility is a heavy thing to carry. But it is also a nice thing for marketing. No one can deny the success of Intel on its backward compatibility. Bad for programmers. \u2013 Yizhou Shan Created: Feb 22, 2018 Last Updated: Feb 23, 2018","title":"Thoughts"},{"location":"lego/kernel/grub/","text":"Use GRUB2 to boot Lego \u00b6 Last Updated: 02/02/2018 This document explains: 1) how Lego itself is written to pretend as a Linux kernel, 2) how to boot Lego kernel with GRUB2, 3) GRUB2 configurations specific to Lego. How Lego pretend as a Linux kernel \u00b6 asdsad How to config GRUB2 for Lego \u00b6 asdsa","title":"GRUB"},{"location":"lego/kernel/grub/#use-grub2-to-boot-lego","text":"Last Updated: 02/02/2018 This document explains: 1) how Lego itself is written to pretend as a Linux kernel, 2) how to boot Lego kernel with GRUB2, 3) GRUB2 configurations specific to Lego.","title":"Use GRUB2 to boot Lego"},{"location":"lego/kernel/grub/#how-lego-pretend-as-a-linux-kernel","text":"asdsad","title":"How Lego pretend as a Linux kernel"},{"location":"lego/kernel/grub/#how-to-config-grub2-for-lego","text":"asdsa","title":"How to config GRUB2 for Lego"},{"location":"lego/kernel/irq/","text":"IRQ \u00b6 IRQ is majorly ported based on linux-4.4 . The decision of porting of whole IRQ stack from linux was made at early stage of Lego, when I\u2019m not so familiar with this stuff. This technique decision has pros and cons. The whole thing is made complicated by having IRQ domain. IRQ domain is introduced to address the multiple interrupt controller issue. And in x86, we kind of have mutiple as well: IO-APIC, REMAP, LAPIC. Although we are not supporting IRQ remap now. Init \u00b6 The first part of initialization is trap_init() at early setup_arch() . The second major entry point is irq_init() at start_kernel() . This irq_init() is actually a combination of linux\u2019s: early_irq_init() : 1) setup irq_desc[] array, and then call arch_early_irq_init() , which will register two IRQ domains (x86_vector_domain, msi_domain). init_IRQ() : is actually a callback to low-level x86 interrupt setup. It mainly setup the desc\u2019s data/chip etc, and register all different handlers. In Lego, you will be able to find all the functionalitis are moved into arch_irq_init() . And, to this point, we have a complete setup. The third (and last) entry point is smp_prepare_cpus() : smp_prepare_cpus() -> apic_bsp_setup() -> setup_local_APIC() -> setup_IO_APIC() -> x86_init.timers.setup_percpu_clockev() IRQ Domain \u00b6 We should have at least 2 or 3 IRQ domains: x86_vector x86_msi x86_ioapic-N (each ioapic has one) The first two guys are created during arch_irq_init() . While the latter ioapic ones are created during setup_IO_APIC() . All of them are allocated eventually by __irq_domain_add() , and linked at LIST_HEAD(irq_domain_list) . So.... Lego or Linux maintains its own IRQ numbers, starting from 0 to NR_IRQs. However, this IRQ number MAY not have a identical mapping to hardware\u2019s own IRQ number (let us call it hwirq). Given this, we want to know the mapping between IRQ and hwirq. That\u2019s the purpose of having linear_revmap and revmap_tree within each domain, it is used to translate hwirq to IRQ. Why two different data structures? linear_revmap is fairly simple, an array, which is indexed by hwirq. However, the hwirq maybe very large, we don\u2019t want to waste memory, that\u2019s how we want to use trees. These two can be used together. If we fail to insert into linear_revmap , we insert into tree. During search time, we need to look up both. By default, x86_vector and x86_msi use radix tree only. x86_ioapic-N uses a mix of linear and radix tree. To dump all IRQ domains, call dump_irq_domain_list() , which give you something like this: [ 118.308544 ] name mapped linear - max direct - max devtree - node [ 118.316114 ] x86_ioapic -2 24 24 0 [ 118.322707 ] x86_ioapic -1 24 24 0 [ 118.329299 ] x86_ioapic -0 24 24 0 [ 118.335893 ] x86_msi 25 0 0 [ 118.342486 ] * x86_vector 40 0 0 [ 118.349078 ] irq hwirq chip name chip data active type domain [ 118.358775 ] 1 0x00001 IO - APIC 0xffff88107fcae000 LINEAR x86_ioapic -0 [ 118.368858 ] 3 0x00003 IO - APIC 0xffff88107fc8f000 LINEAR x86_ioapic -0 [ 118.378940 ] 4 0x00004 IO - APIC 0xffff88107fc6e000 LINEAR x86_ioapic -0 [ 118.389025 ] 5 0x00005 IO - APIC 0xffff88107fc6f000 LINEAR x86_ioapic -0 [ 118.399109 ] 6 0x00006 IO - APIC 0xffff88107fc4e000 LINEAR x86_ioapic -0 [ 118.409192 ] 7 0x00007 IO - APIC 0xffff88107fc4f000 LINEAR x86_ioapic -0 [ 118.419276 ] 8 0x00008 IO - APIC 0xffff88107fc2e000 LINEAR x86_ioapic -0 [ 118.429358 ] 9 0x00009 IO - APIC 0xffff88107fc2f000 LINEAR x86_ioapic -0 [ 118.439442 ] 10 0x0000a IO - APIC 0xffff88107fc0e000 LINEAR x86_ioapic -0 [ 118.449525 ] 11 0x0000b IO - APIC 0xffff88107fc0f000 LINEAR x86_ioapic -0 [ 118.459609 ] 12 0x0000c IO - APIC 0xffff88107fff0000 LINEAR x86_ioapic -0 [ 118.469692 ] 13 0x0000d IO - APIC 0xffff88107fff1000 LINEAR x86_ioapic -0 [ 118.479776 ] 14 0x0000e IO - APIC 0xffff88107fff2000 LINEAR x86_ioapic -0 [ 118.489860 ] 15 0x0000f IO - APIC 0xffff88107fff3000 LINEAR x86_ioapic -0 [ 118.499943 ] 24 0x300000 PCI - MSI ( null ) * RADIX x86_msi [ 118.509833 ] 25 0x300001 PCI - MSI ( null ) * RADIX x86_msi [ 118.519722 ] 26 0x300002 PCI - MSI ( null ) * RADIX x86_msi [ 118.529612 ] 27 0x300003 PCI - MSI ( null ) * RADIX x86_msi [ 118.539501 ] 28 0x300004 PCI - MSI ( null ) RADIX x86_msi Aug 20, 2018 \u00b6 Well, I\u2019ve ported the IRQ stuff at early days of Lego. At that time, I mainly ported the low-level APIC, IO-APIC, and ACPI stuff, along with the upper layer irqchip, irqdesc stuff. These days, I was verifying our IB code and tried to add back mlx4en\u2019s interrupt handler, somehow, there is no interrupt after request_irq() . Two possible reasons: 1) I missed something during PCI setup, 2) underlying APIC and IO-APIC need more work. \u2013 Last Updated: Aug 28, 2018","title":"IRQ"},{"location":"lego/kernel/irq/#irq","text":"IRQ is majorly ported based on linux-4.4 . The decision of porting of whole IRQ stack from linux was made at early stage of Lego, when I\u2019m not so familiar with this stuff. This technique decision has pros and cons. The whole thing is made complicated by having IRQ domain. IRQ domain is introduced to address the multiple interrupt controller issue. And in x86, we kind of have mutiple as well: IO-APIC, REMAP, LAPIC. Although we are not supporting IRQ remap now.","title":"IRQ"},{"location":"lego/kernel/irq/#init","text":"The first part of initialization is trap_init() at early setup_arch() . The second major entry point is irq_init() at start_kernel() . This irq_init() is actually a combination of linux\u2019s: early_irq_init() : 1) setup irq_desc[] array, and then call arch_early_irq_init() , which will register two IRQ domains (x86_vector_domain, msi_domain). init_IRQ() : is actually a callback to low-level x86 interrupt setup. It mainly setup the desc\u2019s data/chip etc, and register all different handlers. In Lego, you will be able to find all the functionalitis are moved into arch_irq_init() . And, to this point, we have a complete setup. The third (and last) entry point is smp_prepare_cpus() : smp_prepare_cpus() -> apic_bsp_setup() -> setup_local_APIC() -> setup_IO_APIC() -> x86_init.timers.setup_percpu_clockev()","title":"Init"},{"location":"lego/kernel/irq/#irq-domain","text":"We should have at least 2 or 3 IRQ domains: x86_vector x86_msi x86_ioapic-N (each ioapic has one) The first two guys are created during arch_irq_init() . While the latter ioapic ones are created during setup_IO_APIC() . All of them are allocated eventually by __irq_domain_add() , and linked at LIST_HEAD(irq_domain_list) . So.... Lego or Linux maintains its own IRQ numbers, starting from 0 to NR_IRQs. However, this IRQ number MAY not have a identical mapping to hardware\u2019s own IRQ number (let us call it hwirq). Given this, we want to know the mapping between IRQ and hwirq. That\u2019s the purpose of having linear_revmap and revmap_tree within each domain, it is used to translate hwirq to IRQ. Why two different data structures? linear_revmap is fairly simple, an array, which is indexed by hwirq. However, the hwirq maybe very large, we don\u2019t want to waste memory, that\u2019s how we want to use trees. These two can be used together. If we fail to insert into linear_revmap , we insert into tree. During search time, we need to look up both. By default, x86_vector and x86_msi use radix tree only. x86_ioapic-N uses a mix of linear and radix tree. To dump all IRQ domains, call dump_irq_domain_list() , which give you something like this: [ 118.308544 ] name mapped linear - max direct - max devtree - node [ 118.316114 ] x86_ioapic -2 24 24 0 [ 118.322707 ] x86_ioapic -1 24 24 0 [ 118.329299 ] x86_ioapic -0 24 24 0 [ 118.335893 ] x86_msi 25 0 0 [ 118.342486 ] * x86_vector 40 0 0 [ 118.349078 ] irq hwirq chip name chip data active type domain [ 118.358775 ] 1 0x00001 IO - APIC 0xffff88107fcae000 LINEAR x86_ioapic -0 [ 118.368858 ] 3 0x00003 IO - APIC 0xffff88107fc8f000 LINEAR x86_ioapic -0 [ 118.378940 ] 4 0x00004 IO - APIC 0xffff88107fc6e000 LINEAR x86_ioapic -0 [ 118.389025 ] 5 0x00005 IO - APIC 0xffff88107fc6f000 LINEAR x86_ioapic -0 [ 118.399109 ] 6 0x00006 IO - APIC 0xffff88107fc4e000 LINEAR x86_ioapic -0 [ 118.409192 ] 7 0x00007 IO - APIC 0xffff88107fc4f000 LINEAR x86_ioapic -0 [ 118.419276 ] 8 0x00008 IO - APIC 0xffff88107fc2e000 LINEAR x86_ioapic -0 [ 118.429358 ] 9 0x00009 IO - APIC 0xffff88107fc2f000 LINEAR x86_ioapic -0 [ 118.439442 ] 10 0x0000a IO - APIC 0xffff88107fc0e000 LINEAR x86_ioapic -0 [ 118.449525 ] 11 0x0000b IO - APIC 0xffff88107fc0f000 LINEAR x86_ioapic -0 [ 118.459609 ] 12 0x0000c IO - APIC 0xffff88107fff0000 LINEAR x86_ioapic -0 [ 118.469692 ] 13 0x0000d IO - APIC 0xffff88107fff1000 LINEAR x86_ioapic -0 [ 118.479776 ] 14 0x0000e IO - APIC 0xffff88107fff2000 LINEAR x86_ioapic -0 [ 118.489860 ] 15 0x0000f IO - APIC 0xffff88107fff3000 LINEAR x86_ioapic -0 [ 118.499943 ] 24 0x300000 PCI - MSI ( null ) * RADIX x86_msi [ 118.509833 ] 25 0x300001 PCI - MSI ( null ) * RADIX x86_msi [ 118.519722 ] 26 0x300002 PCI - MSI ( null ) * RADIX x86_msi [ 118.529612 ] 27 0x300003 PCI - MSI ( null ) * RADIX x86_msi [ 118.539501 ] 28 0x300004 PCI - MSI ( null ) RADIX x86_msi","title":"IRQ Domain"},{"location":"lego/kernel/irq/#aug-20-2018","text":"Well, I\u2019ve ported the IRQ stuff at early days of Lego. At that time, I mainly ported the low-level APIC, IO-APIC, and ACPI stuff, along with the upper layer irqchip, irqdesc stuff. These days, I was verifying our IB code and tried to add back mlx4en\u2019s interrupt handler, somehow, there is no interrupt after request_irq() . Two possible reasons: 1) I missed something during PCI setup, 2) underlying APIC and IO-APIC need more work. \u2013 Last Updated: Aug 28, 2018","title":"Aug 20, 2018"},{"location":"lego/kernel/kconfig/","text":"Lego Kconfig \u00b6 Network \u00b6 Enable CONFIG_INFINIBAND Enable CONFIG_FIT Set CONFIG_FIT_INITIAL_SLEEP_TIMEOUT : boot time connection timeout Set CONFIG_FIT_NR_NODES : number of Lego nodes in this run Set CONFIG_FIT_LOCAL_ID : current node id In net/lego/fit_machine.c , modify the lego_cluster_hostnames array to match the machines you are using. Set CONFIG_DEFAULT_MEM_NODE in processor manager Set CONFIG_DEFAULT_STORAGE_NODE if you are running with storage component. Network configuration is crucial, please make sure all Lego nodes have consistent configurations. Otherwise the system may panic or fail to connect. Processor \u00b6 Enable CONFIG_COMP_PROCESSOR open .config remove line # CONFIG_COMP_PROCESSOR is not set close .config do make , you will see Configure Lego as processor component (COMP_PROCESSOR) [N/y/?] (NEW) , select Y Choose default configuration for all new config options Enable CONFIG_USE_RAMFS if you are not using storage components Memory \u00b6 Enable CONFIG_COMP_MEMORY open .config remove line # CONFIG_COMP_MEMORY is not set close .config do make , you will see Configure Lego as memory component manager (COMP_MEMORY) [N/y/?] (NEW) , select Y Choose default configuration for all new config options Enable CONFIG_USE_RAMFS if you are not using storage components Set CONFIG_RAMFS_OBJECT_FILE : points to static-linked ELF file that you want to execute. tips: you can put your test code under usr/ directory, and a simple make will compile everything under. Run without Storage Component \u00b6 To run Lego just with one processor component and one memory component, you need to: Enable CONFIG_USE_RAMFS at both sides. And in memory side, you need to set the CONFIG_RAMFS_OBJECT_FILE , which points to the ELF binary you want to test. make sure CONFIG_DEFAULT_MEM_NODE at processor component is pointing to memory component\u2019s node id. A typical code snippet and configuration would be: static const char * lego_cluster_hostnames [ CONFIG_FIT_NR_NODES ] = { [ 0 ] = \"wuklab00\" , [ 1 ] = \"wuklab01\" , }; wuklab00 Processor # # Lego Processor Component Configurations # CONFIG_COMP_PROCESSOR=y CONFIG_CHECKPOINT=y CONFIG_MEMMAP_MEMBLOCK_RESERVED=y # CONFIG_PCACHE_EVICT_RANDOM is not set # CONFIG_PCACHE_EVICT_FIFO is not set CONFIG_PCACHE_EVICT_LRU=y CONFIG_PCACHE_EVICT_GENERIC_SWEEP=y # CONFIG_PCACHE_EVICTION_WRITE_PROTECT is not set # CONFIG_PCACHE_EVICTION_PERSET_LIST is not set CONFIG_PCACHE_EVICTION_VICTIM=y CONFIG_PCACHE_EVICTION_VICTIM_NR_ENTRIES=8 CONFIG_PCACHE_PREFETCH=y # # Processor DEBUG Options # # # Lego Memory Component Configurations # # CONFIG_COMP_MEMORY is not set # # DRAM Cache Options # CONFIG_PCACHE_LINE_SIZE_SHIFT=12 CONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3 # # General Manager Config/Debug Options # CONFIG_DEFAULT_MEM_NODE=1 CONFIG_DEFAULT_STORAGE_NODE=2 CONFIG_USE_RAMFS=y # # Networking # # CONFIG_LWIP is not set CONFIG_FIT=y # CONFIG_FIT_DEBUG is not set CONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30 CONFIG_FIT_NR_NODES=2 CONFIG_FIT_LOCAL_ID=0 wuklab01 Memory # # Lego Memory Component Configurations # CONFIG_COMP_MEMORY=y # # Memory DEBUG Options # # CONFIG_MEM_PREFETCH is not set # # DRAM Cache Options # CONFIG_PCACHE_LINE_SIZE_SHIFT=12 CONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3 # # General Manager Config/Debug Options # CONFIG_DEFAULT_MEM_NODE=1 CONFIG_DEFAULT_STORAGE_NODE=2 CONFIG_USE_RAMFS=y CONFIG_RAMFS_OBJECT_FILE=\"usr/pcache_conflict.o\" # # Networking # # CONFIG_LWIP is not set CONFIG_FIT=y # CONFIG_FIT_DEBUG is not set CONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30 CONFIG_FIT_NR_NODES=2 CONFIG_FIT_LOCAL_ID=1","title":"Kconfig"},{"location":"lego/kernel/kconfig/#lego-kconfig","text":"","title":"Lego Kconfig"},{"location":"lego/kernel/kconfig/#network","text":"Enable CONFIG_INFINIBAND Enable CONFIG_FIT Set CONFIG_FIT_INITIAL_SLEEP_TIMEOUT : boot time connection timeout Set CONFIG_FIT_NR_NODES : number of Lego nodes in this run Set CONFIG_FIT_LOCAL_ID : current node id In net/lego/fit_machine.c , modify the lego_cluster_hostnames array to match the machines you are using. Set CONFIG_DEFAULT_MEM_NODE in processor manager Set CONFIG_DEFAULT_STORAGE_NODE if you are running with storage component. Network configuration is crucial, please make sure all Lego nodes have consistent configurations. Otherwise the system may panic or fail to connect.","title":"Network"},{"location":"lego/kernel/kconfig/#processor","text":"Enable CONFIG_COMP_PROCESSOR open .config remove line # CONFIG_COMP_PROCESSOR is not set close .config do make , you will see Configure Lego as processor component (COMP_PROCESSOR) [N/y/?] (NEW) , select Y Choose default configuration for all new config options Enable CONFIG_USE_RAMFS if you are not using storage components","title":"Processor"},{"location":"lego/kernel/kconfig/#memory","text":"Enable CONFIG_COMP_MEMORY open .config remove line # CONFIG_COMP_MEMORY is not set close .config do make , you will see Configure Lego as memory component manager (COMP_MEMORY) [N/y/?] (NEW) , select Y Choose default configuration for all new config options Enable CONFIG_USE_RAMFS if you are not using storage components Set CONFIG_RAMFS_OBJECT_FILE : points to static-linked ELF file that you want to execute. tips: you can put your test code under usr/ directory, and a simple make will compile everything under.","title":"Memory"},{"location":"lego/kernel/kconfig/#run-without-storage-component","text":"To run Lego just with one processor component and one memory component, you need to: Enable CONFIG_USE_RAMFS at both sides. And in memory side, you need to set the CONFIG_RAMFS_OBJECT_FILE , which points to the ELF binary you want to test. make sure CONFIG_DEFAULT_MEM_NODE at processor component is pointing to memory component\u2019s node id. A typical code snippet and configuration would be: static const char * lego_cluster_hostnames [ CONFIG_FIT_NR_NODES ] = { [ 0 ] = \"wuklab00\" , [ 1 ] = \"wuklab01\" , }; wuklab00 Processor # # Lego Processor Component Configurations # CONFIG_COMP_PROCESSOR=y CONFIG_CHECKPOINT=y CONFIG_MEMMAP_MEMBLOCK_RESERVED=y # CONFIG_PCACHE_EVICT_RANDOM is not set # CONFIG_PCACHE_EVICT_FIFO is not set CONFIG_PCACHE_EVICT_LRU=y CONFIG_PCACHE_EVICT_GENERIC_SWEEP=y # CONFIG_PCACHE_EVICTION_WRITE_PROTECT is not set # CONFIG_PCACHE_EVICTION_PERSET_LIST is not set CONFIG_PCACHE_EVICTION_VICTIM=y CONFIG_PCACHE_EVICTION_VICTIM_NR_ENTRIES=8 CONFIG_PCACHE_PREFETCH=y # # Processor DEBUG Options # # # Lego Memory Component Configurations # # CONFIG_COMP_MEMORY is not set # # DRAM Cache Options # CONFIG_PCACHE_LINE_SIZE_SHIFT=12 CONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3 # # General Manager Config/Debug Options # CONFIG_DEFAULT_MEM_NODE=1 CONFIG_DEFAULT_STORAGE_NODE=2 CONFIG_USE_RAMFS=y # # Networking # # CONFIG_LWIP is not set CONFIG_FIT=y # CONFIG_FIT_DEBUG is not set CONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30 CONFIG_FIT_NR_NODES=2 CONFIG_FIT_LOCAL_ID=0 wuklab01 Memory # # Lego Memory Component Configurations # CONFIG_COMP_MEMORY=y # # Memory DEBUG Options # # CONFIG_MEM_PREFETCH is not set # # DRAM Cache Options # CONFIG_PCACHE_LINE_SIZE_SHIFT=12 CONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3 # # General Manager Config/Debug Options # CONFIG_DEFAULT_MEM_NODE=1 CONFIG_DEFAULT_STORAGE_NODE=2 CONFIG_USE_RAMFS=y CONFIG_RAMFS_OBJECT_FILE=\"usr/pcache_conflict.o\" # # Networking # # CONFIG_LWIP is not set CONFIG_FIT=y # CONFIG_FIT_DEBUG is not set CONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30 CONFIG_FIT_NR_NODES=2 CONFIG_FIT_LOCAL_ID=1","title":"Run without Storage Component"},{"location":"lego/kernel/loader/","text":"Lego Program Loader \u00b6 This document explains the high-level workflow of Lego\u2019s program loader, and how we change the normal loader to fit the disaggregated operating system model. Background on linking and loading is recommended. Status \u00b6 Formats Supported ELF (static-linked) ELF (dynamic-linked) Overall \u00b6 In order to support different executable formats, Lego has a virtual loader layer above all specific formats, which is quite similar to virtual file system . In Lego, execve() is divided into two parts: 1) syscall hook at processor side, 2) real loader at memory side. Combined together, they provide the same semantic of execve() as described in Linux man page. Also for the code, we divide the Linux implementation into parts. But our emulation model introduces several interesting workarounds. Lego\u2019s Loader \u00b6 Lego basically divide the Linux loader into two parts, one in memory manager and other in processor manager. Most dirty work is done by memory manager. Processor manager only needs to make sure the new execution has a fresh environment to start. Entry Point \u00b6 So the normal entry point is do_execve() . Above that, it can be invoked by syscall from user space, or from kernel space by calling do_execve() directly. There are not too many places that will call do_execve within kernel. One notable case is how kernel starts the pid 1 user program. This happens after kernel finished all initialization. The code is: static int run_init_process ( const char * init_filename ) { argv_init [ 0 ] = init_filename ; return do_execve ( init_filename , argv_init , envp_init ); } Memory Manager\u2019s Job \u00b6 Memory manager side will do most of the dirty loading work. It will parse the ELF image, create new VMAs based on ELF information. After that, it only pass start_ip and start_stack back to processor manager. Once processor manager starts running this new execution, pages will be fetched from memory component on demand. Load ld-linux \u00b6 For dynamically-linked images, kernel ELF loader needs to load the ld-linux.so as well. It will first try to map the ld-linux.so into this process\u2019s virtual address space. Furthermore, the first user instruction that will run is no longer __libc_main_start , kernel will transfer the kernel to ld-linux.so instead. Thus, for a normal user program, ld-linux.so will load all the shared libraries before running glibc. static int load_elf_binary ( struct lego_task_struct * tsk , struct lego_binprm * bprm , u64 * new_ip , u64 * new_sp , unsigned long * argv_len , unsigned long * envp_len ) { ... /* Dynamically-linked */ if ( elf_interpreter ) { unsigned long interp_map_addr = 0 ; elf_entry = load_elf_interp ( tsk , & loc -> interp_elf_ex , interpreter , & interp_map_addr , load_bias , interp_elf_phdata ); if ( ! IS_ERR (( void * ) elf_entry )) { /* * load_elf_interp() returns relocation * adjustment */ interp_load_addr = elf_entry ; elf_entry += loc -> interp_elf_ex . e_entry ; } if ( BAD_ADDR ( elf_entry )) { retval = IS_ERR (( void * ) elf_entry ) ? ( int ) elf_entry : - EINVAL ; goto out_free_dentry ; } reloc_func_desc = interp_load_addr ; put_lego_file ( interpreter ); kfree ( elf_interpreter ); } else { /* Statically-linked */ /* * e_entry is the VA to which the system first transfers control * Not the start_code! Normally, it is the <_start> function. */ elf_entry = loc -> elf_ex . e_entry ; if ( BAD_ADDR ( elf_entry )) { retval = - EINVAL ; goto out_free_dentry ; } } ... } Processor Manager\u2019s Job \u00b6 It needs to flush old execution environment, and setup the new execution environment, such as signal, FPU. Notably, processor manager need to run flush_old_exec() , and setup_new_exec() . Destroy old context: flush_old_exec() \u00b6 Zap other threads \u00b6 de_thread is used to kill other threads within the same thread group, thus make sure this process has its own signal table. Furthermore, A exec starts a new thread group with the same TGID of the previous thread group, so we probably also need to switch PID if calling thread is not a leader. Switch to new address space \u00b6 We also need to release the old mm, and allocate a new mm. The new mm only has the high address kernel mapping established. Do note that in Lego, pgtable is used to emulate the processor cache: static int exec_mmap ( void ) { struct mm_struct * new_mm ; struct mm_struct * old_mm ; struct task_struct * tsk ; new_mm = mm_alloc (); if ( ! new_mm ) return - ENOMEM ; tsk = current ; old_mm = current -> mm ; mm_release ( tsk , old_mm ); task_lock ( tsk ); tsk -> mm = new_mm ; tsk -> active_mm = new_mm ; activate_mm ( old_mm , new_mm ); task_unlock ( tsk ); if ( old_mm ) mmput ( old_mm ); return 0 ; } Clear Architecture-Specific state \u00b6 This is performed by flush_thread() , which is an architecture-specific callback. In x86, we need to clear FPU state, and reset TLS array: void flush_thread ( void ) { struct task_struct * tsk = current ; memset ( tsk -> thread . tls_array , 0 , sizeof ( tsk -> thread . tls_array )); fpu__clear ( & tsk -> thread . fpu ); } Setup new context: setup_new_exec() \u00b6 Lego\u2019s setup_new_exec() is quite different from Linux\u2019s default implementation. Lego moves several functions to memory component, like the arch_pick_mmap_layout stuff. Thus, Lego only flush the signal handlers and reset the signal stack stuff: static void setup_new_exec ( const char * filename ) { /* This is the point of no return */ current -> sas_ss_sp = current -> sas_ss_size = 0 ; set_task_comm ( current , kbasename ( filename )); flush_signal_handlers ( current , 0 ); } Change return frame in stack \u00b6 We do not return to user mode here, we simply replace the return IP of the regs frame. While the kernel thread returns, it will simply merge to syscall return path (check ret_from_fork() in entry.S for detail). /** * start_thread - Starting a new user thread * @regs: pointer to pt_regs * @new_ip: the first instruction IP of user thread * @new_sp: the new stack pointer of user thread */ void start_thread ( struct pt_regs * regs , unsigned long new_ip , unsigned long new_sp ) { loadsegment ( fs , 0 ); loadsegment ( es , 0 ); loadsegment ( ds , 0 ); load_gs_index ( 0 ); regs -> ip = new_ip ; regs -> sp = new_sp ; regs -> cs = __USER_CS ; regs -> ss = __USER_DS ; regs -> flags = X86_EFLAGS_IF ; } If calling execve() from userspace, the return frame is saved in the stack, we can simply do start_thread above, and merge to syscall return path. However, if calling execve() from a kernel thread, things changed. As you can see, all forked threads will run from ret_from_fork when it wakes for the first time. If it is a kernel thread, it jumps to line 23 , to execute the kernel function. Normally, the function should not return. If it does return, it normally has called an execve() , and return frame has been changed by start_thread() . So we jump to line 16 to let it merge to syscall return path. /* * A newly forked process directly context switches into this address. * * rax: prev task we switched from * rbx: kernel thread func (NULL for user thread) * r12: kernel thread arg */ ENTRY ( ret_from_fork ) movq %rax , %rdi call schedule_tail /* rdi: 'prev' task parameter */ testq %rbx , %rbx /* from kernel_thread? */ jnz 1 f /* kernel threads are uncommon */ 2: movq %rsp , %rdi call syscall_return_slowpath /* return with IRQs disabled */ SWAPGS /* switch to user gs.base */ jmp restore_regs_and_iret 1: /* kernel thread */ movq %r12 , %rdi call * %rbx /* * A kernel thread is allowed to return here after successfully * calling do_execve(). Exit to userspace to complete the execve() * syscall: */ movq $0 , RAX ( %rsp ) jmp 2 b END ( ret_from_fork ) This is such a typical control flow hijacking. :-) Features \u00b6 This section lists various features, or behaviors and Lego\u2019s program loader. Virtual Address Space Range \u00b6 User\u2019s virtual address falls into this range: [sysctl_mmap_min_addr, TASK_SIZE) By default, unsigned long sysctl_mmap_min_addr = PAGE_SIZE ; /* * User space process size. 47bits minus one guard page. The guard * page is necessary on Intel CPUs: if a SYSCALL instruction is at * the highest possible canonical userspace address, then that * syscall will enter the kernel with a non-canonical return * address, and SYSRET will explode dangerously. We avoid this * particular problem by preventing anything from being mapped * at the maximum canonical address. */ #define TASK_SIZE ((1UL << 47) - PAGE_SIZE) Essentially: [0x1000, 0x7ffffffff000) Pre-Populated .bss and .brk \u00b6 The heap vma created at loading time is a combination of .bss and .brk segments. Since brk usage is 0 (will it be non-zero?) at this moment, so the heap vma is essentially just .bss pages. Normally, Linux kernel does not populate pages for this vma during loading, but Lego does. It can save several page allocation cost for heap pcache miss. It is controlled by vm_brk() . int vm_brk ( struct lego_task_struct * tsk , unsigned long start , unsigned long len ) { int ret ; struct lego_mm_struct * mm = tsk -> mm ; if ( down_write_killable ( & mm -> mmap_sem )) return - EINTR ; ret = do_brk ( tsk , start , len ); up_write ( & mm -> mmap_sem ); /* Prepopulate brk pages */ if ( ! ret ) lego_mm_populate ( mm , start , len ); return ret ; } Un-Populated stack \u00b6 Stack vma is manually expanded to 32 pages + pages for argv info by loader to accommodate future usage. Only pages for argv are populated by default, the extra 32 pages are not. A typical program may need 1 page for saving argv info, plus the 32 extra, the layout will be: 7ffffffde000-7ffffffff000 rw-p 00000000 [stack] The code to expand stack is done when ELF loader tries to finalize the stack vma, by calling setup_arg_pages() : int setup_arg_pages ( struct lego_task_struct * tsk , struct lego_binprm * bprm , unsigned long stack_top , int executable_stack ) { ... /* * 32*4k (or 2*64k) pages */ stack_expand = 131072UL ; stack_size = vma -> vm_end - vma -> vm_start ; stack_base = vma -> vm_start - stack_expand ; mm -> start_stack = bprm -> p ; ret = expand_stack ( vma , stack_base ); ... } Un-Populated .text and .data \u00b6 In essence, all PT_LOAD segments of ELF image are not pre-populated. They will be fetched from storage on demand. This is the traditional on-demand paging way. If we want to reduce the overhead of code and data\u2019s on-demand paging, we can prefault them in the future. Disabled Randomized Top of Stack \u00b6 Lego currently does not randomize the stack top. The stack vma is allocated by bprm_mm_init() at early execve time. There is no randomization at the allocation time, and this applies to all exectuable formats. The end of vma is just TASK_SIZE : static int __bprm_mm_init ( struct lego_binprm * bprm ) { ... vma -> vm_end = TASK_SIZE ; ... } ( managers / memory / loader / elf . c ) Top of stack randomization happens within each specific format loader. They do this by calling back to virtual loader layer\u2019s setup_arg_pages() function, which is used to finalize the top of stack: int setup_arg_pages ( struct lego_task_struct * tsk , struct lego_binprm * bprm , unsigned long stack_top , int executable_stack ); So, to actually randomize the top of stack, you can simply do the following: static unsigned long randomize_stack_top ( unsigned long stack_top ) { unsigned long random_variable = 0 ; if (( current -> flags & PF_RANDOMIZE ) && ! ( current -> personality & ADDR_NO_RANDOMIZE )) { random_variable = get_random_long (); random_variable &= STACK_RND_MASK ; random_variable <<= PAGE_SHIFT ; } #ifdef CONFIG_STACK_GROWSUP return PAGE_ALIGN ( stack_top ) + random_variable ; #else return PAGE_ALIGN ( stack_top ) - random_variable ; #endif } static int load_elf_binary ( struct lego_task_struct * tsk , struct lego_binprm * bprm , u64 * new_ip , u64 * new_sp , unsigned long * argv_len , unsigned long * envp_len ) { ... retval = setup_arg_pages ( bprm , randomize_stack_top ( TASK_SIZE ), executable_stack ); ... } However, current Lego disables randomization by passing TASK_SIZE : static int load_elf_binary ( struct lego_task_struct * tsk , struct lego_binprm * bprm , u64 * new_ip , u64 * new_sp , unsigned long * argv_len , unsigned long * envp_len ) { ... retval = setup_arg_pages ( tsk , bprm , TASK_SIZE , executable_stack ); ... } ( managers / memory / loader / elf . c ) No vDSO \u00b6 Currently, Lego does not have vDSO support. There are not too many syscalls mapped in the vDSO, for x86-64 : clock_gettime getcpu gettimeofday time The reason to add it back is simple: if those syscalls are used a lot and hurt overall performance. Do note that when we add it back, it will be different from the common design: vDSO must be mapped at processor side, mapped in our emulated pgtable. Below is the original part where loader maps vDSO: static int load_elf_binary ( struct lego_task_struct * tsk , struct lego_binprm * bprm , u64 * new_ip , u64 * new_sp , unsigned long * argv_len , unsigned long * envp_len ) { ... #ifdef ARCH_HAS_SETUP_ADDITIONAL_PAGES /* * TODO: vdso * x86 can map vdso vma here */ #endif ... } managers / memory / loader / elf . c For lego, we should move it to processor right before start_thread() : int do_execve ( const char * filename , const char * const * argv , const char * const * envp ) { ... /* Should be here */ start_thread ( regs , new_ip , new_sp ); ... } Besides, don\u2019t forget to report the vDSO address in the aux vector: static int create_elf_tables ( struct lego_task_struct * tsk , struct lego_binprm * bprm , struct elfhdr * exec , unsigned long load_addr , unsigned long interp_load_addr , unsigned long * argv_len , unsigned long * envp_len ) { ... #ifdef ARCH_DLINFO /* * ARCH_DLINFO must come first so PPC can do its special alignment of * AUXV. * update AT_VECTOR_SIZE_ARCH if the number of NEW_AUX_ENT() in * ARCH_DLINFO changes */ ARCH_DLINFO ; #endif ... } \u2013 Yizhou Shan Created: Feb 16, 2018 Last Updated: Feb 27, 2018","title":"Program Loader"},{"location":"lego/kernel/loader/#lego-program-loader","text":"This document explains the high-level workflow of Lego\u2019s program loader, and how we change the normal loader to fit the disaggregated operating system model. Background on linking and loading is recommended.","title":"Lego Program Loader"},{"location":"lego/kernel/loader/#status","text":"Formats Supported ELF (static-linked) ELF (dynamic-linked)","title":"Status"},{"location":"lego/kernel/loader/#overall","text":"In order to support different executable formats, Lego has a virtual loader layer above all specific formats, which is quite similar to virtual file system . In Lego, execve() is divided into two parts: 1) syscall hook at processor side, 2) real loader at memory side. Combined together, they provide the same semantic of execve() as described in Linux man page. Also for the code, we divide the Linux implementation into parts. But our emulation model introduces several interesting workarounds.","title":"Overall"},{"location":"lego/kernel/loader/#legos-loader","text":"Lego basically divide the Linux loader into two parts, one in memory manager and other in processor manager. Most dirty work is done by memory manager. Processor manager only needs to make sure the new execution has a fresh environment to start.","title":"Lego's Loader"},{"location":"lego/kernel/loader/#entry-point","text":"So the normal entry point is do_execve() . Above that, it can be invoked by syscall from user space, or from kernel space by calling do_execve() directly. There are not too many places that will call do_execve within kernel. One notable case is how kernel starts the pid 1 user program. This happens after kernel finished all initialization. The code is: static int run_init_process ( const char * init_filename ) { argv_init [ 0 ] = init_filename ; return do_execve ( init_filename , argv_init , envp_init ); }","title":"Entry Point"},{"location":"lego/kernel/loader/#memory-managers-job","text":"Memory manager side will do most of the dirty loading work. It will parse the ELF image, create new VMAs based on ELF information. After that, it only pass start_ip and start_stack back to processor manager. Once processor manager starts running this new execution, pages will be fetched from memory component on demand.","title":"Memory Manager's Job"},{"location":"lego/kernel/loader/#load-ld-linux","text":"For dynamically-linked images, kernel ELF loader needs to load the ld-linux.so as well. It will first try to map the ld-linux.so into this process\u2019s virtual address space. Furthermore, the first user instruction that will run is no longer __libc_main_start , kernel will transfer the kernel to ld-linux.so instead. Thus, for a normal user program, ld-linux.so will load all the shared libraries before running glibc. static int load_elf_binary ( struct lego_task_struct * tsk , struct lego_binprm * bprm , u64 * new_ip , u64 * new_sp , unsigned long * argv_len , unsigned long * envp_len ) { ... /* Dynamically-linked */ if ( elf_interpreter ) { unsigned long interp_map_addr = 0 ; elf_entry = load_elf_interp ( tsk , & loc -> interp_elf_ex , interpreter , & interp_map_addr , load_bias , interp_elf_phdata ); if ( ! IS_ERR (( void * ) elf_entry )) { /* * load_elf_interp() returns relocation * adjustment */ interp_load_addr = elf_entry ; elf_entry += loc -> interp_elf_ex . e_entry ; } if ( BAD_ADDR ( elf_entry )) { retval = IS_ERR (( void * ) elf_entry ) ? ( int ) elf_entry : - EINVAL ; goto out_free_dentry ; } reloc_func_desc = interp_load_addr ; put_lego_file ( interpreter ); kfree ( elf_interpreter ); } else { /* Statically-linked */ /* * e_entry is the VA to which the system first transfers control * Not the start_code! Normally, it is the <_start> function. */ elf_entry = loc -> elf_ex . e_entry ; if ( BAD_ADDR ( elf_entry )) { retval = - EINVAL ; goto out_free_dentry ; } } ... }","title":"Load ld-linux"},{"location":"lego/kernel/loader/#processor-managers-job","text":"It needs to flush old execution environment, and setup the new execution environment, such as signal, FPU. Notably, processor manager need to run flush_old_exec() , and setup_new_exec() .","title":"Processor Manager's Job"},{"location":"lego/kernel/loader/#destroy-old-context-flush_old_exec","text":"","title":"Destroy old context: flush_old_exec()"},{"location":"lego/kernel/loader/#zap-other-threads","text":"de_thread is used to kill other threads within the same thread group, thus make sure this process has its own signal table. Furthermore, A exec starts a new thread group with the same TGID of the previous thread group, so we probably also need to switch PID if calling thread is not a leader.","title":"Zap other threads"},{"location":"lego/kernel/loader/#switch-to-new-address-space","text":"We also need to release the old mm, and allocate a new mm. The new mm only has the high address kernel mapping established. Do note that in Lego, pgtable is used to emulate the processor cache: static int exec_mmap ( void ) { struct mm_struct * new_mm ; struct mm_struct * old_mm ; struct task_struct * tsk ; new_mm = mm_alloc (); if ( ! new_mm ) return - ENOMEM ; tsk = current ; old_mm = current -> mm ; mm_release ( tsk , old_mm ); task_lock ( tsk ); tsk -> mm = new_mm ; tsk -> active_mm = new_mm ; activate_mm ( old_mm , new_mm ); task_unlock ( tsk ); if ( old_mm ) mmput ( old_mm ); return 0 ; }","title":"Switch to new address space"},{"location":"lego/kernel/loader/#clear-architecture-specific-state","text":"This is performed by flush_thread() , which is an architecture-specific callback. In x86, we need to clear FPU state, and reset TLS array: void flush_thread ( void ) { struct task_struct * tsk = current ; memset ( tsk -> thread . tls_array , 0 , sizeof ( tsk -> thread . tls_array )); fpu__clear ( & tsk -> thread . fpu ); }","title":"Clear Architecture-Specific state"},{"location":"lego/kernel/loader/#setup-new-context-setup_new_exec","text":"Lego\u2019s setup_new_exec() is quite different from Linux\u2019s default implementation. Lego moves several functions to memory component, like the arch_pick_mmap_layout stuff. Thus, Lego only flush the signal handlers and reset the signal stack stuff: static void setup_new_exec ( const char * filename ) { /* This is the point of no return */ current -> sas_ss_sp = current -> sas_ss_size = 0 ; set_task_comm ( current , kbasename ( filename )); flush_signal_handlers ( current , 0 ); }","title":"Setup new context: setup_new_exec()"},{"location":"lego/kernel/loader/#change-return-frame-in-stack","text":"We do not return to user mode here, we simply replace the return IP of the regs frame. While the kernel thread returns, it will simply merge to syscall return path (check ret_from_fork() in entry.S for detail). /** * start_thread - Starting a new user thread * @regs: pointer to pt_regs * @new_ip: the first instruction IP of user thread * @new_sp: the new stack pointer of user thread */ void start_thread ( struct pt_regs * regs , unsigned long new_ip , unsigned long new_sp ) { loadsegment ( fs , 0 ); loadsegment ( es , 0 ); loadsegment ( ds , 0 ); load_gs_index ( 0 ); regs -> ip = new_ip ; regs -> sp = new_sp ; regs -> cs = __USER_CS ; regs -> ss = __USER_DS ; regs -> flags = X86_EFLAGS_IF ; } If calling execve() from userspace, the return frame is saved in the stack, we can simply do start_thread above, and merge to syscall return path. However, if calling execve() from a kernel thread, things changed. As you can see, all forked threads will run from ret_from_fork when it wakes for the first time. If it is a kernel thread, it jumps to line 23 , to execute the kernel function. Normally, the function should not return. If it does return, it normally has called an execve() , and return frame has been changed by start_thread() . So we jump to line 16 to let it merge to syscall return path. /* * A newly forked process directly context switches into this address. * * rax: prev task we switched from * rbx: kernel thread func (NULL for user thread) * r12: kernel thread arg */ ENTRY ( ret_from_fork ) movq %rax , %rdi call schedule_tail /* rdi: 'prev' task parameter */ testq %rbx , %rbx /* from kernel_thread? */ jnz 1 f /* kernel threads are uncommon */ 2: movq %rsp , %rdi call syscall_return_slowpath /* return with IRQs disabled */ SWAPGS /* switch to user gs.base */ jmp restore_regs_and_iret 1: /* kernel thread */ movq %r12 , %rdi call * %rbx /* * A kernel thread is allowed to return here after successfully * calling do_execve(). Exit to userspace to complete the execve() * syscall: */ movq $0 , RAX ( %rsp ) jmp 2 b END ( ret_from_fork ) This is such a typical control flow hijacking. :-)","title":"Change return frame in stack"},{"location":"lego/kernel/loader/#features","text":"This section lists various features, or behaviors and Lego\u2019s program loader.","title":"Features"},{"location":"lego/kernel/loader/#virtual-address-space-range","text":"User\u2019s virtual address falls into this range: [sysctl_mmap_min_addr, TASK_SIZE) By default, unsigned long sysctl_mmap_min_addr = PAGE_SIZE ; /* * User space process size. 47bits minus one guard page. The guard * page is necessary on Intel CPUs: if a SYSCALL instruction is at * the highest possible canonical userspace address, then that * syscall will enter the kernel with a non-canonical return * address, and SYSRET will explode dangerously. We avoid this * particular problem by preventing anything from being mapped * at the maximum canonical address. */ #define TASK_SIZE ((1UL << 47) - PAGE_SIZE) Essentially: [0x1000, 0x7ffffffff000)","title":"Virtual Address Space Range"},{"location":"lego/kernel/loader/#pre-populated-bss-and-brk","text":"The heap vma created at loading time is a combination of .bss and .brk segments. Since brk usage is 0 (will it be non-zero?) at this moment, so the heap vma is essentially just .bss pages. Normally, Linux kernel does not populate pages for this vma during loading, but Lego does. It can save several page allocation cost for heap pcache miss. It is controlled by vm_brk() . int vm_brk ( struct lego_task_struct * tsk , unsigned long start , unsigned long len ) { int ret ; struct lego_mm_struct * mm = tsk -> mm ; if ( down_write_killable ( & mm -> mmap_sem )) return - EINTR ; ret = do_brk ( tsk , start , len ); up_write ( & mm -> mmap_sem ); /* Prepopulate brk pages */ if ( ! ret ) lego_mm_populate ( mm , start , len ); return ret ; }","title":"Pre-Populated .bss and .brk"},{"location":"lego/kernel/loader/#un-populated-stack","text":"Stack vma is manually expanded to 32 pages + pages for argv info by loader to accommodate future usage. Only pages for argv are populated by default, the extra 32 pages are not. A typical program may need 1 page for saving argv info, plus the 32 extra, the layout will be: 7ffffffde000-7ffffffff000 rw-p 00000000 [stack] The code to expand stack is done when ELF loader tries to finalize the stack vma, by calling setup_arg_pages() : int setup_arg_pages ( struct lego_task_struct * tsk , struct lego_binprm * bprm , unsigned long stack_top , int executable_stack ) { ... /* * 32*4k (or 2*64k) pages */ stack_expand = 131072UL ; stack_size = vma -> vm_end - vma -> vm_start ; stack_base = vma -> vm_start - stack_expand ; mm -> start_stack = bprm -> p ; ret = expand_stack ( vma , stack_base ); ... }","title":"Un-Populated stack"},{"location":"lego/kernel/loader/#un-populated-text-and-data","text":"In essence, all PT_LOAD segments of ELF image are not pre-populated. They will be fetched from storage on demand. This is the traditional on-demand paging way. If we want to reduce the overhead of code and data\u2019s on-demand paging, we can prefault them in the future.","title":"Un-Populated .text and .data"},{"location":"lego/kernel/loader/#disabled-randomized-top-of-stack","text":"Lego currently does not randomize the stack top. The stack vma is allocated by bprm_mm_init() at early execve time. There is no randomization at the allocation time, and this applies to all exectuable formats. The end of vma is just TASK_SIZE : static int __bprm_mm_init ( struct lego_binprm * bprm ) { ... vma -> vm_end = TASK_SIZE ; ... } ( managers / memory / loader / elf . c ) Top of stack randomization happens within each specific format loader. They do this by calling back to virtual loader layer\u2019s setup_arg_pages() function, which is used to finalize the top of stack: int setup_arg_pages ( struct lego_task_struct * tsk , struct lego_binprm * bprm , unsigned long stack_top , int executable_stack ); So, to actually randomize the top of stack, you can simply do the following: static unsigned long randomize_stack_top ( unsigned long stack_top ) { unsigned long random_variable = 0 ; if (( current -> flags & PF_RANDOMIZE ) && ! ( current -> personality & ADDR_NO_RANDOMIZE )) { random_variable = get_random_long (); random_variable &= STACK_RND_MASK ; random_variable <<= PAGE_SHIFT ; } #ifdef CONFIG_STACK_GROWSUP return PAGE_ALIGN ( stack_top ) + random_variable ; #else return PAGE_ALIGN ( stack_top ) - random_variable ; #endif } static int load_elf_binary ( struct lego_task_struct * tsk , struct lego_binprm * bprm , u64 * new_ip , u64 * new_sp , unsigned long * argv_len , unsigned long * envp_len ) { ... retval = setup_arg_pages ( bprm , randomize_stack_top ( TASK_SIZE ), executable_stack ); ... } However, current Lego disables randomization by passing TASK_SIZE : static int load_elf_binary ( struct lego_task_struct * tsk , struct lego_binprm * bprm , u64 * new_ip , u64 * new_sp , unsigned long * argv_len , unsigned long * envp_len ) { ... retval = setup_arg_pages ( tsk , bprm , TASK_SIZE , executable_stack ); ... } ( managers / memory / loader / elf . c )","title":"Disabled Randomized Top of Stack"},{"location":"lego/kernel/loader/#no-vdso","text":"Currently, Lego does not have vDSO support. There are not too many syscalls mapped in the vDSO, for x86-64 : clock_gettime getcpu gettimeofday time The reason to add it back is simple: if those syscalls are used a lot and hurt overall performance. Do note that when we add it back, it will be different from the common design: vDSO must be mapped at processor side, mapped in our emulated pgtable. Below is the original part where loader maps vDSO: static int load_elf_binary ( struct lego_task_struct * tsk , struct lego_binprm * bprm , u64 * new_ip , u64 * new_sp , unsigned long * argv_len , unsigned long * envp_len ) { ... #ifdef ARCH_HAS_SETUP_ADDITIONAL_PAGES /* * TODO: vdso * x86 can map vdso vma here */ #endif ... } managers / memory / loader / elf . c For lego, we should move it to processor right before start_thread() : int do_execve ( const char * filename , const char * const * argv , const char * const * envp ) { ... /* Should be here */ start_thread ( regs , new_ip , new_sp ); ... } Besides, don\u2019t forget to report the vDSO address in the aux vector: static int create_elf_tables ( struct lego_task_struct * tsk , struct lego_binprm * bprm , struct elfhdr * exec , unsigned long load_addr , unsigned long interp_load_addr , unsigned long * argv_len , unsigned long * envp_len ) { ... #ifdef ARCH_DLINFO /* * ARCH_DLINFO must come first so PPC can do its special alignment of * AUXV. * update AT_VECTOR_SIZE_ARCH if the number of NEW_AUX_ENT() in * ARCH_DLINFO changes */ ARCH_DLINFO ; #endif ... } \u2013 Yizhou Shan Created: Feb 16, 2018 Last Updated: Feb 27, 2018","title":"No vDSO"},{"location":"lego/kernel/net_thpool/","text":"Thread Pool Model for Handling Network Requests \u00b6 Passive : whenever a network request comes in, callback to thpool. Active : thpool keep polling if there is new network requests queued. Previously, our memory side use the Active mode to handle requests, which has very bad latency. Several days ago we changed to the Passive mode, which has a very good latency! One ib_send_reply RRT drops from ~20us to a normal ~6us for a TensorFlow run. Never thought this could make such a big difference (~3x slowdown)! Dark network! \u2013 Yizhou Shan Created: April 29, 2018 Last Updated: April 29, 2018","title":"Network Thpool"},{"location":"lego/kernel/net_thpool/#thread-pool-model-for-handling-network-requests","text":"Passive : whenever a network request comes in, callback to thpool. Active : thpool keep polling if there is new network requests queued. Previously, our memory side use the Active mode to handle requests, which has very bad latency. Several days ago we changed to the Passive mode, which has a very good latency! One ib_send_reply RRT drops from ~20us to a normal ~6us for a TensorFlow run. Never thought this could make such a big difference (~3x slowdown)! Dark network! \u2013 Yizhou Shan Created: April 29, 2018 Last Updated: April 29, 2018","title":"Thread Pool Model for Handling Network Requests"},{"location":"lego/kernel/pagefault_disable/","text":"The story of pagefault_disable/enable \u00b6 pagefault_disable() is not really disabling the whole pgfault handling code. It is used to disable only the handling of pgfault that landed from user virtual address . Please note the difference between user virtual address and user mode fault . The first means the faulting address belongs to user virtual address space, while it can come from either user mode (CPL3) or kernel mode (CPL0). The second is a fault come from user mode (CPL3). If pgfault is disabled, then do_page_fault() function will NOT try to solve the pgfault by calling into pcache , instead, it will go straight to fixup code (in no_context()). This function is not intended to be used standalone. Normally, we do 1) pagefault_disable() , 2) then use some functions that have fixup code, 3) then pagefault_enable() . (The fixup code is another magic inside kernel. We will cover it in another document.) Currently in Lego, this is only used by futex , which needs something like atomic_cmpxchg() with an user virtual address. If pgfault happens in the middle, then this will not be atomic since kernel need to do pcache operations, which further needs to through network. However, do note the difference with uaccess family functions. Most uaccess functions will not disable pgfault handling, which means pcache will be invoked. If pcache returns a SEGFAULT , pgfault code will go into fixup code. And that, my friend, is where uaccess returns -EFAULT to caller. \u2013 Yizhou Shan Feb 01, 2018","title":"Disable pgfault"},{"location":"lego/kernel/pagefault_disable/#the-story-of-pagefault_disableenable","text":"pagefault_disable() is not really disabling the whole pgfault handling code. It is used to disable only the handling of pgfault that landed from user virtual address . Please note the difference between user virtual address and user mode fault . The first means the faulting address belongs to user virtual address space, while it can come from either user mode (CPL3) or kernel mode (CPL0). The second is a fault come from user mode (CPL3). If pgfault is disabled, then do_page_fault() function will NOT try to solve the pgfault by calling into pcache , instead, it will go straight to fixup code (in no_context()). This function is not intended to be used standalone. Normally, we do 1) pagefault_disable() , 2) then use some functions that have fixup code, 3) then pagefault_enable() . (The fixup code is another magic inside kernel. We will cover it in another document.) Currently in Lego, this is only used by futex , which needs something like atomic_cmpxchg() with an user virtual address. If pgfault happens in the middle, then this will not be atomic since kernel need to do pcache operations, which further needs to through network. However, do note the difference with uaccess family functions. Most uaccess functions will not disable pgfault handling, which means pcache will be invoked. If pcache returns a SEGFAULT , pgfault code will go into fixup code. And that, my friend, is where uaccess returns -EFAULT to caller. \u2013 Yizhou Shan Feb 01, 2018","title":"The story of pagefault_disable/enable"},{"location":"lego/kernel/profile/","text":"Lego Profilers \u00b6 Lego has three runtime profilers in kernel: strace heatmap profile points Combined together, they can provide the following information. Sweet, huh? [ 1017.047366 ] Kernel strace [ 1017.050276 ] Task : 20 : 20 nr_accumulated_threads : 46 [ 1017.055837 ] % time seconds usecs / call calls errors syscall [ 1017.063213 ] ------ -------------- ----------- --------- --------- ---------------- [ 1017.071648 ] 98.16 33.839597842 1879978 18 0 sys_futex [ 1017.079406 ] 0.26 0.260143997 260144 1 0 sys_execve [ 1017.087260 ] 0.18 0.185456860 7133 26 0 sys_write [ 1017.095017 ] 0.50 0.050189546 913 55 0 sys_munmap [ 1017.102870 ] 0.25 0.025223661 255 99 0 sys_mmap [ 1017.110531 ] 0.50 0.000505134 12 45 0 sys_clone [ 1017.118288 ] 0.20 0.000202327 26 8 0 sys_read [ 1017.125947 ] 0.14 0.000144065 17 9 0 sys_open [ 1017.133608 ] 0.67 0.000067251 7 11 0 sys_brk [ 1017.141171 ] 0.30 0.000030361 7 5 0 sys_newfstat [ 1017.149219 ] 0.64 0.000006410 1 9 0 sys_close [ 1017.156976 ] 0.48 0.000004842 1 45 0 sys_madvise [ 1017.164927 ] 0.34 0.000003443 1 47 0 sys_set_robust_list [ 1017.173653 ] 0.21 0.000002137 1 52 0 sys_mprotect [ 1017.181702 ] 0.71 0.000000717 1 4 0 sys_gettimeofday [ 1017.190137 ] 0.60 0.000000608 1 3 0 sys_time [ 1017.197797 ] 0.51 0.000000513 1 2 0 sys_getrlimit [ 1017.205942 ] 0.49 0.000000498 1 2 0 sys_rt_sigprocmask [ 1017.214572 ] 0.46 0.000000469 1 4 0 sys_rt_sigaction [ 1017.223008 ] 0.45 0.000000453 1 2 0 sys_arch_prctl [ 1017.231249 ] 0.27 0.000000272 1 2 0 sys_newuname [ 1017.239298 ] 0.13 0.000000135 1 2 0 sys_set_tid_address [ 1017.248025 ] ------ -------------- ----------- --------- --------- ---------------- [ 1017.256460 ] 100.00 34.361581541 451 0 total [ 1017.263830 ] [ 1017.308295 ] [ 1017.309754 ] Kernel Heatmap ( top # 10 ) [ 1017.313731 ] Address Function NR % [ 1017.321294 ] ---------------- -------------------- ---------- --------- [ 1017.328858 ] ffffffff8101a600 cpu_idle 112082 73.11 [ 1017.336421 ] ffffffff810666f0 __schedule 19192 12.95 [ 1017.343983 ] ffffffff8104f500 mlx4_ib_poll_cq 5551 3.99 [ 1017.351546 ] ffffffff8103bf50 delay_tsc 5393 3.83 [ 1017.359110 ] ffffffff81034a10 victim_flush_async 3766 2.72 [ 1017.366673 ] ffffffff8102b220 slob_alloc . constpro 1992 1.47 [ 1017.374235 ] ffffffff810668d0 schedule 1519 0.15 [ 1017.381800 ] ffffffff810648f0 fit_send_reply_with 956 0.95 [ 1017.389362 ] ffffffff81062370 ibapi_send_reply_ti 307 0.30 [ 1017.396925 ] ffffffff8105a0d0 ib_mad_completion_h 232 0.23 [ 1017.404487 ] ---------------- -------------------- ---------- --------- [ 1017.412052 ] 151994 100.00 [ 1017.419613 ] [ 1017.421267 ] [ 1017.422911 ] Kernel Profile Points [ 1017.426594 ] status name total nr avg . ns [ 1017.436292 ] ------- -------------------- ---------------- ---------------- ---------------- [ 1017.445988 ] off flush_tlb_others 0.000153470 55 2791 [ 1017.455685 ] off pcache_cache_miss 16.147020152 274698 58781 [ 1017.465381 ] ------- -------------------- ---------------- ---------------- ----------------","title":"Profile"},{"location":"lego/kernel/profile/#lego-profilers","text":"Lego has three runtime profilers in kernel: strace heatmap profile points Combined together, they can provide the following information. Sweet, huh? [ 1017.047366 ] Kernel strace [ 1017.050276 ] Task : 20 : 20 nr_accumulated_threads : 46 [ 1017.055837 ] % time seconds usecs / call calls errors syscall [ 1017.063213 ] ------ -------------- ----------- --------- --------- ---------------- [ 1017.071648 ] 98.16 33.839597842 1879978 18 0 sys_futex [ 1017.079406 ] 0.26 0.260143997 260144 1 0 sys_execve [ 1017.087260 ] 0.18 0.185456860 7133 26 0 sys_write [ 1017.095017 ] 0.50 0.050189546 913 55 0 sys_munmap [ 1017.102870 ] 0.25 0.025223661 255 99 0 sys_mmap [ 1017.110531 ] 0.50 0.000505134 12 45 0 sys_clone [ 1017.118288 ] 0.20 0.000202327 26 8 0 sys_read [ 1017.125947 ] 0.14 0.000144065 17 9 0 sys_open [ 1017.133608 ] 0.67 0.000067251 7 11 0 sys_brk [ 1017.141171 ] 0.30 0.000030361 7 5 0 sys_newfstat [ 1017.149219 ] 0.64 0.000006410 1 9 0 sys_close [ 1017.156976 ] 0.48 0.000004842 1 45 0 sys_madvise [ 1017.164927 ] 0.34 0.000003443 1 47 0 sys_set_robust_list [ 1017.173653 ] 0.21 0.000002137 1 52 0 sys_mprotect [ 1017.181702 ] 0.71 0.000000717 1 4 0 sys_gettimeofday [ 1017.190137 ] 0.60 0.000000608 1 3 0 sys_time [ 1017.197797 ] 0.51 0.000000513 1 2 0 sys_getrlimit [ 1017.205942 ] 0.49 0.000000498 1 2 0 sys_rt_sigprocmask [ 1017.214572 ] 0.46 0.000000469 1 4 0 sys_rt_sigaction [ 1017.223008 ] 0.45 0.000000453 1 2 0 sys_arch_prctl [ 1017.231249 ] 0.27 0.000000272 1 2 0 sys_newuname [ 1017.239298 ] 0.13 0.000000135 1 2 0 sys_set_tid_address [ 1017.248025 ] ------ -------------- ----------- --------- --------- ---------------- [ 1017.256460 ] 100.00 34.361581541 451 0 total [ 1017.263830 ] [ 1017.308295 ] [ 1017.309754 ] Kernel Heatmap ( top # 10 ) [ 1017.313731 ] Address Function NR % [ 1017.321294 ] ---------------- -------------------- ---------- --------- [ 1017.328858 ] ffffffff8101a600 cpu_idle 112082 73.11 [ 1017.336421 ] ffffffff810666f0 __schedule 19192 12.95 [ 1017.343983 ] ffffffff8104f500 mlx4_ib_poll_cq 5551 3.99 [ 1017.351546 ] ffffffff8103bf50 delay_tsc 5393 3.83 [ 1017.359110 ] ffffffff81034a10 victim_flush_async 3766 2.72 [ 1017.366673 ] ffffffff8102b220 slob_alloc . constpro 1992 1.47 [ 1017.374235 ] ffffffff810668d0 schedule 1519 0.15 [ 1017.381800 ] ffffffff810648f0 fit_send_reply_with 956 0.95 [ 1017.389362 ] ffffffff81062370 ibapi_send_reply_ti 307 0.30 [ 1017.396925 ] ffffffff8105a0d0 ib_mad_completion_h 232 0.23 [ 1017.404487 ] ---------------- -------------------- ---------- --------- [ 1017.412052 ] 151994 100.00 [ 1017.419613 ] [ 1017.421267 ] [ 1017.422911 ] Kernel Profile Points [ 1017.426594 ] status name total nr avg . ns [ 1017.436292 ] ------- -------------------- ---------------- ---------------- ---------------- [ 1017.445988 ] off flush_tlb_others 0.000153470 55 2791 [ 1017.455685 ] off pcache_cache_miss 16.147020152 274698 58781 [ 1017.465381 ] ------- -------------------- ---------------- ---------------- ----------------","title":"Lego Profilers"},{"location":"lego/kernel/profile_heatmap/","text":"Lego Profile Kernel Heatmap \u00b6 To get a sense of what is the hottest function within kernel, Lego adds a counter based heatmap. It is the same with Linux\u2019s /proc/profile . Mechanism \u00b6 General idea: for each possible function/instruction byte in the kernel, we attach to a counter to it. Once we detect this function/instruction was executed, we increment its associated counter. However, fine granularity counting will need a lot extra memory, and it is not necessary to track each single instruction byte. Besides, it is hard to track down every time the function was executed. Furthermore, we only need an approximate heatmap. Thus, kernel\u2019s solutions are: Coarse granularity : maintain a counter for each 1<<prof_shift bytes. Update counter on timer interrupt tick , which is a constant stable entry. Supported Features \u00b6 Currently, we only support CPU_PROFILING , which profile on each timer interrupt tick. We could also add SCHED_PROFILING , or SLEEP_PROFILING . But we are fine with current setting. Of course, we also have a simple dump function void print_profile_heatmap_nr(int nr) , which is similar to userspace tool readprofile . Example Output \u00b6 Workload is: MT-Phoenix word count, with 1GB data. (We probably want to rule out cpu_idle() ) [ 1017.309754 ] Kernel Heatmap ( top # 10 ) [ 1017.313731 ] Address Function NR % [ 1017.321294 ] ---------------- -------------------- ---------- --------- [ 1017.328858 ] ffffffff8101a600 cpu_idle 112082 73.11 [ 1017.336421 ] ffffffff810666f0 __schedule 19192 12.95 [ 1017.343983 ] ffffffff8104f500 mlx4_ib_poll_cq 5551 3.99 [ 1017.351546 ] ffffffff8103bf50 delay_tsc 5393 3.83 [ 1017.359110 ] ffffffff81034a10 victim_flush_async 3766 2.72 [ 1017.366673 ] ffffffff8102b220 slob_alloc . constpro 1992 1.47 [ 1017.374235 ] ffffffff810668d0 schedule 1519 0.15 [ 1017.381800 ] ffffffff810648f0 fit_send_reply_with 956 0.95 [ 1017.389362 ] ffffffff81062370 ibapi_send_reply_ti 307 0.30 [ 1017.396925 ] ffffffff8105a0d0 ib_mad_completion_h 232 0.23 [ 1017.404487 ] ---------------- -------------------- ---------- --------- [ 1017.412052 ] 151994 100.00 [ 1017.419613 ] \u2013 Yizhou Shan Created: April 06, 2018 Last Updated: April 06, 2018","title":"Profile heatmap"},{"location":"lego/kernel/profile_heatmap/#lego-profile-kernel-heatmap","text":"To get a sense of what is the hottest function within kernel, Lego adds a counter based heatmap. It is the same with Linux\u2019s /proc/profile .","title":"Lego Profile Kernel Heatmap"},{"location":"lego/kernel/profile_heatmap/#mechanism","text":"General idea: for each possible function/instruction byte in the kernel, we attach to a counter to it. Once we detect this function/instruction was executed, we increment its associated counter. However, fine granularity counting will need a lot extra memory, and it is not necessary to track each single instruction byte. Besides, it is hard to track down every time the function was executed. Furthermore, we only need an approximate heatmap. Thus, kernel\u2019s solutions are: Coarse granularity : maintain a counter for each 1<<prof_shift bytes. Update counter on timer interrupt tick , which is a constant stable entry.","title":"Mechanism"},{"location":"lego/kernel/profile_heatmap/#supported-features","text":"Currently, we only support CPU_PROFILING , which profile on each timer interrupt tick. We could also add SCHED_PROFILING , or SLEEP_PROFILING . But we are fine with current setting. Of course, we also have a simple dump function void print_profile_heatmap_nr(int nr) , which is similar to userspace tool readprofile .","title":"Supported Features"},{"location":"lego/kernel/profile_heatmap/#example-output","text":"Workload is: MT-Phoenix word count, with 1GB data. (We probably want to rule out cpu_idle() ) [ 1017.309754 ] Kernel Heatmap ( top # 10 ) [ 1017.313731 ] Address Function NR % [ 1017.321294 ] ---------------- -------------------- ---------- --------- [ 1017.328858 ] ffffffff8101a600 cpu_idle 112082 73.11 [ 1017.336421 ] ffffffff810666f0 __schedule 19192 12.95 [ 1017.343983 ] ffffffff8104f500 mlx4_ib_poll_cq 5551 3.99 [ 1017.351546 ] ffffffff8103bf50 delay_tsc 5393 3.83 [ 1017.359110 ] ffffffff81034a10 victim_flush_async 3766 2.72 [ 1017.366673 ] ffffffff8102b220 slob_alloc . constpro 1992 1.47 [ 1017.374235 ] ffffffff810668d0 schedule 1519 0.15 [ 1017.381800 ] ffffffff810648f0 fit_send_reply_with 956 0.95 [ 1017.389362 ] ffffffff81062370 ibapi_send_reply_ti 307 0.30 [ 1017.396925 ] ffffffff8105a0d0 ib_mad_completion_h 232 0.23 [ 1017.404487 ] ---------------- -------------------- ---------- --------- [ 1017.412052 ] 151994 100.00 [ 1017.419613 ] \u2013 Yizhou Shan Created: April 06, 2018 Last Updated: April 06, 2018","title":"Example Output"},{"location":"lego/kernel/profile_points/","text":"Lego Profile Points \u00b6 Lego profile points facility is added to trace specific functions, or even a small piece of code. It is added in the hope that it can help to find performance bottleneck. It is added in the hope that it can reduce the redundant coding chore. Example \u00b6 To trace TLB shootdown cost. DEFINE_PROFILE_POINT ( flush_tlb_others ) void flush_tlb_others ( const struct cpumask * cpumask , struct mm_struct * mm , unsigned long start , unsigned long end ) { struct flush_tlb_info info ; PROFILE_POINT_TIME ( flush_tlb_others ) if ( end == 0 ) end = start + PAGE_SIZE ; info . flush_mm = mm ; info . flush_start = start ; info . flush_end = end ; profile_point_start ( flush_tlb_others ); smp_call_function_many ( cpumask , flush_tlb_func , & info , 1 ); profile_point_leave ( flush_tlb_others ); } Explanation: DEFINE_PROFILE_POINT() will define a local structure, that contains the profile point name, number of invoked times, and total execution time. PROFILE_POINT_TIME() will define a stack local variable, to save the starting time. profile_point_start() will save the current time in nanosecond, while profile_point_leave() will calculate the execution of this run, and update the global counters defined by DEFINE_PROFILE_POINT() . System-wide profile points will be printed together if you invoke print_profile_points() : [ 1017.422911 ] Kernel Profile Points [ 1017.426594 ] status name total nr avg . ns [ 1017.436292 ] ------- -------------------- ---------------- ---------------- ---------------- [ 1017.445988 ] off flush_tlb_others 0.000153470 55 2791 [ 1017.455685 ] off pcache_cache_miss 16.147020152 274698 58781 [ 1017.465381 ] ------- -------------------- ---------------- ---------------- ---------------- Mechanism \u00b6 Once again, the profile points are aggregated by linker script. Each profile point will be in a special section .profile.point . The linker will merge them into one section, and export the starting and ending address of this section. Part I. Annotate. #define __profile_point __section(.profile.point) #define DEFINE_PROFILE_POINT(name) \\ struct profile_point _PP_NAME(name) __profile_point = { ... ... }; Part II. Link script merge. . = ALIGN ( L1_CACHE_BYTES ); . profile . point : AT ( ADDR (. profile . point ) - LOAD_OFFSET ) { __sprofilepoint = .; * (. profile . point ) __eprofilepoint = .; } Part III. Walk through. void print_profile_points ( void ) { struct profile_point * pp ; for ( pp = __sprofilepoint ; pp < __eprofilepoint ; pp ++ ) { print_profile_point ( pp ); ... } I really love the linker script. ;-) \u2013 Yizhou Shan Created: April 06, 2018 Last Updated: April 06, 2018","title":"Profile points"},{"location":"lego/kernel/profile_points/#lego-profile-points","text":"Lego profile points facility is added to trace specific functions, or even a small piece of code. It is added in the hope that it can help to find performance bottleneck. It is added in the hope that it can reduce the redundant coding chore.","title":"Lego Profile Points"},{"location":"lego/kernel/profile_points/#example","text":"To trace TLB shootdown cost. DEFINE_PROFILE_POINT ( flush_tlb_others ) void flush_tlb_others ( const struct cpumask * cpumask , struct mm_struct * mm , unsigned long start , unsigned long end ) { struct flush_tlb_info info ; PROFILE_POINT_TIME ( flush_tlb_others ) if ( end == 0 ) end = start + PAGE_SIZE ; info . flush_mm = mm ; info . flush_start = start ; info . flush_end = end ; profile_point_start ( flush_tlb_others ); smp_call_function_many ( cpumask , flush_tlb_func , & info , 1 ); profile_point_leave ( flush_tlb_others ); } Explanation: DEFINE_PROFILE_POINT() will define a local structure, that contains the profile point name, number of invoked times, and total execution time. PROFILE_POINT_TIME() will define a stack local variable, to save the starting time. profile_point_start() will save the current time in nanosecond, while profile_point_leave() will calculate the execution of this run, and update the global counters defined by DEFINE_PROFILE_POINT() . System-wide profile points will be printed together if you invoke print_profile_points() : [ 1017.422911 ] Kernel Profile Points [ 1017.426594 ] status name total nr avg . ns [ 1017.436292 ] ------- -------------------- ---------------- ---------------- ---------------- [ 1017.445988 ] off flush_tlb_others 0.000153470 55 2791 [ 1017.455685 ] off pcache_cache_miss 16.147020152 274698 58781 [ 1017.465381 ] ------- -------------------- ---------------- ---------------- ----------------","title":"Example"},{"location":"lego/kernel/profile_points/#mechanism","text":"Once again, the profile points are aggregated by linker script. Each profile point will be in a special section .profile.point . The linker will merge them into one section, and export the starting and ending address of this section. Part I. Annotate. #define __profile_point __section(.profile.point) #define DEFINE_PROFILE_POINT(name) \\ struct profile_point _PP_NAME(name) __profile_point = { ... ... }; Part II. Link script merge. . = ALIGN ( L1_CACHE_BYTES ); . profile . point : AT ( ADDR (. profile . point ) - LOAD_OFFSET ) { __sprofilepoint = .; * (. profile . point ) __eprofilepoint = .; } Part III. Walk through. void print_profile_points ( void ) { struct profile_point * pp ; for ( pp = __sprofilepoint ; pp < __eprofilepoint ; pp ++ ) { print_profile_point ( pp ); ... } I really love the linker script. ;-) \u2013 Yizhou Shan Created: April 06, 2018 Last Updated: April 06, 2018","title":"Mechanism"},{"location":"lego/kernel/profile_strace/","text":"Lego Profile strace \u00b6 Lego has a built-in kernel-version syscall tracer, similar to strace utility in the user space. Below we will just call our Lego\u2019s syscall tracer as strace for simplicity. Design \u00b6 There are essentially three important metrics to track for each syscall number of times invoked number of times error happened total execution, or per-call latency Besides, there is another important design decision: 1) should all threads within a process share one copy of data to maintain bookkeeping, or 2) should each thread do its bookkeeping on its own set of data? Our answer is 2). For two reasons: Performance: set of counters are atomic_t , updating is performed by a locked instruction. The first solution will add huge overhead while tracing heavily multithreaded applications. Simplicity: in order to track the latency of each syscall, we need to know when it enter and when it finish. As threads come and go, it is hard to maintain such information. To make it worse, a preemptable kernel, or schedule-related syscalls will move threads around cores. Below is our simple design, where each thread has a struct strace_info , which include a set of counters for each syscall. All strace_info within a process are chained together by a doubly-linked list. When we want to look at the strace statistic numbers, we need to accumulate counters from all threads within a process, including those dead threads. We do the accumulate when the last thread of this process is going to exit. The benefit of doubly-linked strace_info is we can walk through the list starting anywhere. There is really no list head here. In fact, everyone can be the head. See how we respect equality? Besides, even if task_struct is reaped, strace_info is still there and linked. For example, assume thread_3 has a SIGSEGV, and did a zap_other_threads . And he is the last standing live thread of this process. When it is going to exit, it will accumulate all the statistic and do the necessary printing. Details \u00b6 There are essentially three hooks in core kernel: syscall : before and after sys_call_table fork/clone : create strace_info for each thread do_exit() : when group_dead(signal->live==1), accumulate Example Output \u00b6 [ 1017.047366 ] Kernel strace [ 1017.050276 ] Task : 20 : 20 nr_accumulated_threads : 46 [ 1017.055837 ] % time seconds usecs / call calls errors syscall [ 1017.063213 ] ------ -------------- ----------- --------- --------- ---------------- [ 1017.071648 ] 98.16 33.839597842 1879978 18 0 sys_futex [ 1017.079406 ] 0.26 0.260143997 260144 1 0 sys_execve [ 1017.087260 ] 0.18 0.185456860 7133 26 0 sys_write [ 1017.095017 ] 0.50 0.050189546 913 55 0 sys_munmap [ 1017.102870 ] 0.25 0.025223661 255 99 0 sys_mmap [ 1017.110531 ] 0.50 0.000505134 12 45 0 sys_clone [ 1017.118288 ] 0.20 0.000202327 26 8 0 sys_read [ 1017.125947 ] 0.14 0.000144065 17 9 0 sys_open [ 1017.133608 ] 0.67 0.000067251 7 11 0 sys_brk [ 1017.141171 ] 0.30 0.000030361 7 5 0 sys_newfstat [ 1017.149219 ] 0.64 0.000006410 1 9 0 sys_close [ 1017.156976 ] 0.48 0.000004842 1 45 0 sys_madvise [ 1017.164927 ] 0.34 0.000003443 1 47 0 sys_set_robust_list [ 1017.173653 ] 0.21 0.000002137 1 52 0 sys_mprotect [ 1017.181702 ] 0.71 0.000000717 1 4 0 sys_gettimeofday [ 1017.190137 ] 0.60 0.000000608 1 3 0 sys_time [ 1017.197797 ] 0.51 0.000000513 1 2 0 sys_getrlimit [ 1017.205942 ] 0.49 0.000000498 1 2 0 sys_rt_sigprocmask [ 1017.214572 ] 0.46 0.000000469 1 4 0 sys_rt_sigaction [ 1017.223008 ] 0.45 0.000000453 1 2 0 sys_arch_prctl [ 1017.231249 ] 0.27 0.000000272 1 2 0 sys_newuname [ 1017.239298 ] 0.13 0.000000135 1 2 0 sys_set_tid_address [ 1017.248025 ] ------ -------------- ----------- --------- --------- ---------------- [ 1017.256460 ] 100.00 34.361581541 451 0 total \u2013 Yizhou Shan Created: April 05, 2018 Last Updated: April 05, 2018","title":"strace"},{"location":"lego/kernel/profile_strace/#lego-profile-strace","text":"Lego has a built-in kernel-version syscall tracer, similar to strace utility in the user space. Below we will just call our Lego\u2019s syscall tracer as strace for simplicity.","title":"Lego Profile strace"},{"location":"lego/kernel/profile_strace/#design","text":"There are essentially three important metrics to track for each syscall number of times invoked number of times error happened total execution, or per-call latency Besides, there is another important design decision: 1) should all threads within a process share one copy of data to maintain bookkeeping, or 2) should each thread do its bookkeeping on its own set of data? Our answer is 2). For two reasons: Performance: set of counters are atomic_t , updating is performed by a locked instruction. The first solution will add huge overhead while tracing heavily multithreaded applications. Simplicity: in order to track the latency of each syscall, we need to know when it enter and when it finish. As threads come and go, it is hard to maintain such information. To make it worse, a preemptable kernel, or schedule-related syscalls will move threads around cores. Below is our simple design, where each thread has a struct strace_info , which include a set of counters for each syscall. All strace_info within a process are chained together by a doubly-linked list. When we want to look at the strace statistic numbers, we need to accumulate counters from all threads within a process, including those dead threads. We do the accumulate when the last thread of this process is going to exit. The benefit of doubly-linked strace_info is we can walk through the list starting anywhere. There is really no list head here. In fact, everyone can be the head. See how we respect equality? Besides, even if task_struct is reaped, strace_info is still there and linked. For example, assume thread_3 has a SIGSEGV, and did a zap_other_threads . And he is the last standing live thread of this process. When it is going to exit, it will accumulate all the statistic and do the necessary printing.","title":"Design"},{"location":"lego/kernel/profile_strace/#details","text":"There are essentially three hooks in core kernel: syscall : before and after sys_call_table fork/clone : create strace_info for each thread do_exit() : when group_dead(signal->live==1), accumulate","title":"Details"},{"location":"lego/kernel/profile_strace/#example-output","text":"[ 1017.047366 ] Kernel strace [ 1017.050276 ] Task : 20 : 20 nr_accumulated_threads : 46 [ 1017.055837 ] % time seconds usecs / call calls errors syscall [ 1017.063213 ] ------ -------------- ----------- --------- --------- ---------------- [ 1017.071648 ] 98.16 33.839597842 1879978 18 0 sys_futex [ 1017.079406 ] 0.26 0.260143997 260144 1 0 sys_execve [ 1017.087260 ] 0.18 0.185456860 7133 26 0 sys_write [ 1017.095017 ] 0.50 0.050189546 913 55 0 sys_munmap [ 1017.102870 ] 0.25 0.025223661 255 99 0 sys_mmap [ 1017.110531 ] 0.50 0.000505134 12 45 0 sys_clone [ 1017.118288 ] 0.20 0.000202327 26 8 0 sys_read [ 1017.125947 ] 0.14 0.000144065 17 9 0 sys_open [ 1017.133608 ] 0.67 0.000067251 7 11 0 sys_brk [ 1017.141171 ] 0.30 0.000030361 7 5 0 sys_newfstat [ 1017.149219 ] 0.64 0.000006410 1 9 0 sys_close [ 1017.156976 ] 0.48 0.000004842 1 45 0 sys_madvise [ 1017.164927 ] 0.34 0.000003443 1 47 0 sys_set_robust_list [ 1017.173653 ] 0.21 0.000002137 1 52 0 sys_mprotect [ 1017.181702 ] 0.71 0.000000717 1 4 0 sys_gettimeofday [ 1017.190137 ] 0.60 0.000000608 1 3 0 sys_time [ 1017.197797 ] 0.51 0.000000513 1 2 0 sys_getrlimit [ 1017.205942 ] 0.49 0.000000498 1 2 0 sys_rt_sigprocmask [ 1017.214572 ] 0.46 0.000000469 1 4 0 sys_rt_sigaction [ 1017.223008 ] 0.45 0.000000453 1 2 0 sys_arch_prctl [ 1017.231249 ] 0.27 0.000000272 1 2 0 sys_newuname [ 1017.239298 ] 0.13 0.000000135 1 2 0 sys_set_tid_address [ 1017.248025 ] ------ -------------- ----------- --------- --------- ---------------- [ 1017.256460 ] 100.00 34.361581541 451 0 total \u2013 Yizhou Shan Created: April 05, 2018 Last Updated: April 05, 2018","title":"Example Output"},{"location":"lego/kernel/stop_machine/","text":"The highest priority thread in kernel \u00b6 This document is about migration/N kernel threads, stop_sched schdueling class, and the interesting source file kernel/stop_machine.c . Background on kernel scheduler design is recommended. Scheduler uses the following code to pick the next runnable task: static inline struct task_struct * pick_next_task ( struct rq * rq , struct task_struct * prev ) { struct task_struct * p ; const struct sched_class * class ; again : for_each_class ( class ) { p = class -> pick_next_task ( rq , prev ); if ( p ) { if ( unlikely ( p == RETRY_TASK )) goto again ; return p ; } } BUG (); } while the class is linked together as: #define sched_class_highest (&stop_sched_class) #define for_each_class(class) \\ for ( class = sched_class_highest ; class ; class = class -> next ) Clearly, the highest priority class is stop_sched_class . Whenever this scheduling has class runnable threads, scheduler will always run them first. So what kernel threads are using this scheduling class? Well, you must have seen something like migration/0 when you do ps aux in Linux. And yes, these kernel threads are the only users. These threads are sleeping most of their lifetime, they will be invoked to do some very urgent stuff. For example, when a user thread that is currently running on CPU0 calls sched_setaffinity() to bind to CPU1, kernel is not able to do this because this user thread is currently running (runqueue can not move a running task out, it can only move queued task out). Then, scheduler has to ask migration/0 for help. Once there is a job enqueued, migration/0 will be invoked. Since it has the highest-priority, it will start execution immediately. Thus the migration from CPU0 to CPU1 is performed safely and fast. migration code is defined in kernel/stop_machine.c . They are created during early boot. They use the smpboot_register_percpu_thread to create threads. They are written in this way because Linux supports cpu hotplug. To simplify we can also create them manually through kthread_create . Since Lego does not support cpu hotplug, and this cpu_stop_init is called after SMP is initialized, so Lego has slight different initialiaztion: void __init cpu_stop_init ( void ) { unsigned int cpu ; for_each_possible_cpu ( cpu ) { struct cpu_stopper * stopper = & per_cpu ( cpu_stopper , cpu ); spin_lock_init ( & stopper -> lock ); INIT_LIST_HEAD ( & stopper -> works ); } BUG_ON ( smpboot_register_percpu_thread ( & cpu_stop_threads )); /* * smpboot_create_threads use kthread_create_on_cpu() to * create new threads. And they are parked, too. * Since we call this function after smp_init(), all CPUs * are already online, thus we need to unpark them manually. */ for_each_online_cpu ( cpu ) stop_machine_unpark ( cpu ); Internally, it also use a list to keep enqueued jobs. Once the thread is waken up, it tries to lookup this list and dequeue jobs (similar to kthread creation, kworker etc.): static void cpu_stopper_thread ( unsigned int cpu ) { struct cpu_stopper * stopper = & per_cpu ( cpu_stopper , cpu ); struct cpu_stop_work * work ; repeat : work = NULL ; spin_lock_irq ( & stopper -> lock ); if ( ! list_empty ( & stopper -> works )) { work = list_first_entry ( & stopper -> works , struct cpu_stop_work , list ); list_del_init ( & work -> list ); } spin_unlock_irq ( & stopper -> lock ); if ( work ) { ... ret = fn ( arg ); ... goto repeat ; } } It has several interesting public APIs that are quite similar to smp_call_functions , but the difference is: this set of APIs provide a guaranteed time-to-execute waiting time, because it will simply preempt anything running on CPU. int stop_one_cpu ( unsigned int cpu , cpu_stop_fn_t fn , void * arg ); int stop_cpus ( const struct cpumask * cpumask , cpu_stop_fn_t fn , void * arg ); int try_stop_cpus ( const struct cpumask * cpumask , cpu_stop_fn_t fn , void * arg ); They are used only when there are some very urgent things to do. So, please use with caution. \u2013 Yizhou Shan Created: Feb 12, 2018 Last Updated: Feb 12, 2018","title":"Stop machine"},{"location":"lego/kernel/stop_machine/#the-highest-priority-thread-in-kernel","text":"This document is about migration/N kernel threads, stop_sched schdueling class, and the interesting source file kernel/stop_machine.c . Background on kernel scheduler design is recommended. Scheduler uses the following code to pick the next runnable task: static inline struct task_struct * pick_next_task ( struct rq * rq , struct task_struct * prev ) { struct task_struct * p ; const struct sched_class * class ; again : for_each_class ( class ) { p = class -> pick_next_task ( rq , prev ); if ( p ) { if ( unlikely ( p == RETRY_TASK )) goto again ; return p ; } } BUG (); } while the class is linked together as: #define sched_class_highest (&stop_sched_class) #define for_each_class(class) \\ for ( class = sched_class_highest ; class ; class = class -> next ) Clearly, the highest priority class is stop_sched_class . Whenever this scheduling has class runnable threads, scheduler will always run them first. So what kernel threads are using this scheduling class? Well, you must have seen something like migration/0 when you do ps aux in Linux. And yes, these kernel threads are the only users. These threads are sleeping most of their lifetime, they will be invoked to do some very urgent stuff. For example, when a user thread that is currently running on CPU0 calls sched_setaffinity() to bind to CPU1, kernel is not able to do this because this user thread is currently running (runqueue can not move a running task out, it can only move queued task out). Then, scheduler has to ask migration/0 for help. Once there is a job enqueued, migration/0 will be invoked. Since it has the highest-priority, it will start execution immediately. Thus the migration from CPU0 to CPU1 is performed safely and fast. migration code is defined in kernel/stop_machine.c . They are created during early boot. They use the smpboot_register_percpu_thread to create threads. They are written in this way because Linux supports cpu hotplug. To simplify we can also create them manually through kthread_create . Since Lego does not support cpu hotplug, and this cpu_stop_init is called after SMP is initialized, so Lego has slight different initialiaztion: void __init cpu_stop_init ( void ) { unsigned int cpu ; for_each_possible_cpu ( cpu ) { struct cpu_stopper * stopper = & per_cpu ( cpu_stopper , cpu ); spin_lock_init ( & stopper -> lock ); INIT_LIST_HEAD ( & stopper -> works ); } BUG_ON ( smpboot_register_percpu_thread ( & cpu_stop_threads )); /* * smpboot_create_threads use kthread_create_on_cpu() to * create new threads. And they are parked, too. * Since we call this function after smp_init(), all CPUs * are already online, thus we need to unpark them manually. */ for_each_online_cpu ( cpu ) stop_machine_unpark ( cpu ); Internally, it also use a list to keep enqueued jobs. Once the thread is waken up, it tries to lookup this list and dequeue jobs (similar to kthread creation, kworker etc.): static void cpu_stopper_thread ( unsigned int cpu ) { struct cpu_stopper * stopper = & per_cpu ( cpu_stopper , cpu ); struct cpu_stop_work * work ; repeat : work = NULL ; spin_lock_irq ( & stopper -> lock ); if ( ! list_empty ( & stopper -> works )) { work = list_first_entry ( & stopper -> works , struct cpu_stop_work , list ); list_del_init ( & work -> list ); } spin_unlock_irq ( & stopper -> lock ); if ( work ) { ... ret = fn ( arg ); ... goto repeat ; } } It has several interesting public APIs that are quite similar to smp_call_functions , but the difference is: this set of APIs provide a guaranteed time-to-execute waiting time, because it will simply preempt anything running on CPU. int stop_one_cpu ( unsigned int cpu , cpu_stop_fn_t fn , void * arg ); int stop_cpus ( const struct cpumask * cpumask , cpu_stop_fn_t fn , void * arg ); int try_stop_cpus ( const struct cpumask * cpumask , cpu_stop_fn_t fn , void * arg ); They are used only when there are some very urgent things to do. So, please use with caution. \u2013 Yizhou Shan Created: Feb 12, 2018 Last Updated: Feb 12, 2018","title":"The highest priority thread in kernel"},{"location":"lego/kernel/tlbflush/","text":"TLB Flush \u00b6 \u2013 Yizhou Shan Created: March 01, 2018 Last Updated: March 01, 2018","title":"TLB Flush"},{"location":"lego/kernel/tlbflush/#tlb-flush","text":"\u2013 Yizhou Shan Created: March 01, 2018 Last Updated: March 01, 2018","title":"TLB Flush"},{"location":"lego/kernel/trampoline/","text":"How trampoline works in Lego \u00b6 What is trampoline code? \u00b6 Trampoline code is used by BSP to boot other secondary CPUs. At startup, BSP wakeup secondary CPUs by sending a APIC INIT command, which carry the [start_ip] where the secondary CPUs should start to run. The trampoline code is the code starting from [start_ip] . Used by the secondary CPU to jump from 16-bit realmode to 64-bit code (the first instruction of 64-bit code will be in arch/x86/kernel/head_64.S ). Where is the trampoline source code? \u00b6 The source files are all in arch/x86/realmode/ . There are two parts: 1) arch/x86/realmode/rm/trampoline.S : which is the code that will run. And it is a mix of 16-bit, 32-bit, 64-bit code (ugh..). 2) arch/x86/realmode/piggy.S : Since the trampoline code can not to linked into kernel image directly. So we have to piggyback the trampoline.bin binary code into a section, which is described by trampoline_start and trampoline_end . So the kernel can address the trampoline code via these two symbols. The compile flow is: arch/x86/realmode/rm/trmapoline.S -> CC__ arch/x86/realmode/rm/trmapoline.o -> LD arch/x86/realmode/rm/trampoline -> OBJCOPY arch/x86/realmode/rm/trampoline.bin -> This bin goes into piggy.o -> piggy.o goes into vmImage What happened at runtime? \u00b6 The setup code was loaded by GRUB below 1MB. Inside arch/x86/boot/main.c , we will save the cs() into the boot_params and pass it to kernel. In setup_arch() , we will copy the trampoline.bin code to the cs() address reported by boot_param . This means we will override setup code, which is okay. At last, we wake up the secondary CPUs inside smp_init() . Compare with Linux \u00b6 I vaguely remember how Linux implement this. The only thing I remember is that Linux use some sort of structure, which is filled by BSP and then passed, or used by secondary CPUs. The mechanism has no difference, though. Linux just has more robust debugging facilities. \u2013 Yizhou Shan Mar 3, 2017","title":"Trampoline"},{"location":"lego/kernel/trampoline/#how-trampoline-works-in-lego","text":"","title":"How trampoline works in Lego"},{"location":"lego/kernel/trampoline/#what-is-trampoline-code","text":"Trampoline code is used by BSP to boot other secondary CPUs. At startup, BSP wakeup secondary CPUs by sending a APIC INIT command, which carry the [start_ip] where the secondary CPUs should start to run. The trampoline code is the code starting from [start_ip] . Used by the secondary CPU to jump from 16-bit realmode to 64-bit code (the first instruction of 64-bit code will be in arch/x86/kernel/head_64.S ).","title":"What is trampoline code?"},{"location":"lego/kernel/trampoline/#where-is-the-trampoline-source-code","text":"The source files are all in arch/x86/realmode/ . There are two parts: 1) arch/x86/realmode/rm/trampoline.S : which is the code that will run. And it is a mix of 16-bit, 32-bit, 64-bit code (ugh..). 2) arch/x86/realmode/piggy.S : Since the trampoline code can not to linked into kernel image directly. So we have to piggyback the trampoline.bin binary code into a section, which is described by trampoline_start and trampoline_end . So the kernel can address the trampoline code via these two symbols. The compile flow is: arch/x86/realmode/rm/trmapoline.S -> CC__ arch/x86/realmode/rm/trmapoline.o -> LD arch/x86/realmode/rm/trampoline -> OBJCOPY arch/x86/realmode/rm/trampoline.bin -> This bin goes into piggy.o -> piggy.o goes into vmImage","title":"Where is the trampoline source code?"},{"location":"lego/kernel/trampoline/#what-happened-at-runtime","text":"The setup code was loaded by GRUB below 1MB. Inside arch/x86/boot/main.c , we will save the cs() into the boot_params and pass it to kernel. In setup_arch() , we will copy the trampoline.bin code to the cs() address reported by boot_param . This means we will override setup code, which is okay. At last, we wake up the secondary CPUs inside smp_init() .","title":"What happened at runtime?"},{"location":"lego/kernel/trampoline/#compare-with-linux","text":"I vaguely remember how Linux implement this. The only thing I remember is that Linux use some sort of structure, which is filled by BSP and then passed, or used by secondary CPUs. The mechanism has no difference, though. Linux just has more robust debugging facilities. \u2013 Yizhou Shan Mar 3, 2017","title":"Compare with Linux"},{"location":"lego/kernel/vDSO/","text":"vDSO and vsyscall \u00b6 We have choice but port vDSO and vsyscall for Lego, because some dynamic-linked ELF images will use these features. References: https://0xax.gitbooks.io/linux-insides/content/SysCall/syscall-3.html \u2013 Yizhou Shan Created: March 01, 2018 Last Updated: March 01, 2018","title":"vDSO"},{"location":"lego/kernel/vDSO/#vdso-and-vsyscall","text":"We have choice but port vDSO and vsyscall for Lego, because some dynamic-linked ELF images will use these features. References: https://0xax.gitbooks.io/linux-insides/content/SysCall/syscall-3.html \u2013 Yizhou Shan Created: March 01, 2018 Last Updated: March 01, 2018","title":"vDSO and vsyscall"},{"location":"lego/kernel/vfs/","text":"Processor Manager\u2019s Virtual File System \u00b6 Lego processor manager has an virtual file system layer to accommodate the famous legacy Everything is a file philosophy. But we implement this in a very dirty way. Cover later. \u2013 Yizhou Shan Created: Feb 20, 2018 Last Updated: Feb 20, 2018","title":"Virtual File System"},{"location":"lego/kernel/vfs/#processor-managers-virtual-file-system","text":"Lego processor manager has an virtual file system layer to accommodate the famous legacy Everything is a file philosophy. But we implement this in a very dirty way. Cover later. \u2013 Yizhou Shan Created: Feb 20, 2018 Last Updated: Feb 20, 2018","title":"Processor Manager's Virtual File System"},{"location":"lego/kernel/vm/","text":"Process Virtual Memory \u00b6 Limits \u00b6 Max Number of VMAs \u00b6 By default, the maximum number of VMAs is: 65530 . It is defined by the following variable: #define MAPCOUNT_ELF_CORE_MARGIN (5) #define DEFAULT_MAX_MAP_COUNT (USHRT_MAX - MAPCOUNT_ELF_CORE_MARGIN) int sysctl_max_map_count __read_mostly = DEFAULT_MAX_MAP_COUNT ; Facts \u00b6 munmap can split vma \u00b6 munmap can create a hole with an existing vma, thus divide one existing vma to two new vmas. Do note that, munmap can create hole for both anonymous vma and file-backed vma. msync() is not atomic \u00b6 During msync() , pages are being written back to disk one by one (or batched). Consider the case where few pages have been flushed back, while some other few pages are still in the memory. This premature writeback is not atomic and will be affected by failure. msync() need concurrency control \u00b6 With a multi-threaded application, does msync() provide the synchronization semantic? The answer is NO. Other threads within the same process are able to write to pages currently under msync() . This implies that application need to handle concurrency by themselves, e.g., rwlocks. \u2013 Yizhou Shan Created: Feb 19, 2018 Last Updated: Feb 19, 2018","title":"Process Virtual Memory"},{"location":"lego/kernel/vm/#process-virtual-memory","text":"","title":"Process Virtual Memory"},{"location":"lego/kernel/vm/#limits","text":"","title":"Limits"},{"location":"lego/kernel/vm/#max-number-of-vmas","text":"By default, the maximum number of VMAs is: 65530 . It is defined by the following variable: #define MAPCOUNT_ELF_CORE_MARGIN (5) #define DEFAULT_MAX_MAP_COUNT (USHRT_MAX - MAPCOUNT_ELF_CORE_MARGIN) int sysctl_max_map_count __read_mostly = DEFAULT_MAX_MAP_COUNT ;","title":"Max Number of VMAs"},{"location":"lego/kernel/vm/#facts","text":"","title":"Facts"},{"location":"lego/kernel/vm/#munmap-can-split-vma","text":"munmap can create a hole with an existing vma, thus divide one existing vma to two new vmas. Do note that, munmap can create hole for both anonymous vma and file-backed vma.","title":"munmap can split vma"},{"location":"lego/kernel/vm/#msync-is-not-atomic","text":"During msync() , pages are being written back to disk one by one (or batched). Consider the case where few pages have been flushed back, while some other few pages are still in the memory. This premature writeback is not atomic and will be affected by failure.","title":"msync() is not atomic"},{"location":"lego/kernel/vm/#msync-need-concurrency-control","text":"With a multi-threaded application, does msync() provide the synchronization semantic? The answer is NO. Other threads within the same process are able to write to pages currently under msync() . This implies that application need to handle concurrency by themselves, e.g., rwlocks. \u2013 Yizhou Shan Created: Feb 19, 2018 Last Updated: Feb 19, 2018","title":"msync() need concurrency control"},{"location":"lego/log/TODO/","text":"TODO \u00b6 Last Updated: July 18, 2018 Planned \u00b6 Try fully-associative pcache, to see how many conflict misses can be removed (got the idea from HPCA18 google search paper) kmem_cache TSC deadline mode (one-shot tick) . What is the performance comparison with periodic mode? batched TLB flush __unhash_process() : in exit, release pid etc. de_thread() : in exec, change pid etc. posix timers : used by exit(), wait() and others. Functions like posix_cpu_timers_exit_group . vDSO : if later we find applications are using gettimeofday , time , and getcpu a lot, and it truly hurt performance, then we should consider adding this in the processor side. (Check Processor Loader document for code that needs to be patched). (02/27/18) VA randomization : our loader does not add any randomization. For security reasons, we probably want to add this. VM Organization : multiple vm choice at M side, on a per-vma basis. fork: dup free pool : duplicate the free VA pool at both P and M. pcache : send each page\u2019s type back. something like PcacheAnon, PcacheFile. So the pcache_evict/do_exit routine can be optimized. mm alloc : don\u2019t use the kmalloc to get a new mm_struct. This is a hot data structure, use get_free_page instead maybe. Like task_struct. fork_dup_pcache : have real vm_flags to guide write-protect. Get vm ranges from memory to optimize the duplication. Currently, all pages will be downgraded to read-only. P side mm sem : check if we need the sem in P side. pgfault need read, fork and others need W. Even though M side also serialize this, but out ops are divided. mprotect : it is empty now. We assume applications are well-written. But does any of them rely on this COW feature? CPU_NO_HZ : disable timer for some cores, to reduce the overhead of timer interrupts. This is named CPU_NO_HZ and some similar Kconfigs. SYSCALL : compared with linux, we are always using the slow path, which pass all arguments. We should consider optimize this. OS-intensive applications may hurt. IB : reply is a sg list. Esp benefit pcache. Finished \u00b6 - vsyscall : mostly emulation-","title":"TODO"},{"location":"lego/log/TODO/#todo","text":"Last Updated: July 18, 2018","title":"TODO"},{"location":"lego/log/TODO/#planned","text":"Try fully-associative pcache, to see how many conflict misses can be removed (got the idea from HPCA18 google search paper) kmem_cache TSC deadline mode (one-shot tick) . What is the performance comparison with periodic mode? batched TLB flush __unhash_process() : in exit, release pid etc. de_thread() : in exec, change pid etc. posix timers : used by exit(), wait() and others. Functions like posix_cpu_timers_exit_group . vDSO : if later we find applications are using gettimeofday , time , and getcpu a lot, and it truly hurt performance, then we should consider adding this in the processor side. (Check Processor Loader document for code that needs to be patched). (02/27/18) VA randomization : our loader does not add any randomization. For security reasons, we probably want to add this. VM Organization : multiple vm choice at M side, on a per-vma basis. fork: dup free pool : duplicate the free VA pool at both P and M. pcache : send each page\u2019s type back. something like PcacheAnon, PcacheFile. So the pcache_evict/do_exit routine can be optimized. mm alloc : don\u2019t use the kmalloc to get a new mm_struct. This is a hot data structure, use get_free_page instead maybe. Like task_struct. fork_dup_pcache : have real vm_flags to guide write-protect. Get vm ranges from memory to optimize the duplication. Currently, all pages will be downgraded to read-only. P side mm sem : check if we need the sem in P side. pgfault need read, fork and others need W. Even though M side also serialize this, but out ops are divided. mprotect : it is empty now. We assume applications are well-written. But does any of them rely on this COW feature? CPU_NO_HZ : disable timer for some cores, to reduce the overhead of timer interrupts. This is named CPU_NO_HZ and some similar Kconfigs. SYSCALL : compared with linux, we are always using the slow path, which pass all arguments. We should consider optimize this. OS-intensive applications may hurt. IB : reply is a sg list. Esp benefit pcache.","title":"Planned"},{"location":"lego/log/TODO/#finished","text":"- vsyscall : mostly emulation-","title":"Finished"},{"location":"lego/log/log-02-2018/","text":"Feb 2018 \u00b6 02/28 Wed \u00b6 patch fork, and cow handler debug pcache, while running python hello world add vDSO, gettimeofday So, it is end of the day. After adding wp handler, I now have the whole picture of pcache activities, and the interactions between them. The reclaim, zap, move, copy, add, operations needs to be carefully synchronized. Also the refcount etc. I feel the ground rule is we need to make sure a PCM that a function is currently using, can not suddenly become invalid due to other operations. This has to be synced by: refcount, lock, flags. Oh well, mm is hard with SMP, but also fun. We are very close to have a fully working OS. I did not have time to look into the python hello world bug issue. It is a very serious one. It may also rule out some root bugs. 02/27 Tue \u00b6 Spent two days on CS527 source project, implemented a small SSHD and SSD client. And we have to inject exactly five bugs, or vulnerabilities into the systems. Lol, it is really hard to intentionally plant BUGs! Anyway, back to Lego. Since others are having a hard time compile program statically, I will try to add dynamic loader today. The interpreter: /lib64/ld-linux-x86-64.so.2 . Linux seq.c maps (no randomization): 00400000-00401000 r-xp 00000000 fd:00 18752683 /root/ys/LegoOS/usr/a.out 00600000-00601000 r--p 00000000 fd:00 18752683 /root/ys/LegoOS/usr/a.out 00601000-00602000 rw-p 00001000 fd:00 18752683 /root/ys/LegoOS/usr/a.out 00602000-00604000 rw-p 00000000 00:00 0 [heap] 7ffff7a18000-7ffff7bd0000 r-xp 00000000 fd:00 55051990 /usr/lib64/libc-2.17.so 7ffff7bd0000-7ffff7dd0000 ---p 001b8000 fd:00 55051990 /usr/lib64/libc-2.17.so 7ffff7dd0000-7ffff7dd4000 r--p 001b8000 fd:00 55051990 /usr/lib64/libc-2.17.so 7ffff7dd4000-7ffff7dd6000 rw-p 001bc000 fd:00 55051990 /usr/lib64/libc-2.17.so 7ffff7dd6000-7ffff7ddb000 rw-p 00000000 00:00 0 7ffff7ddb000-7ffff7dfc000 r-xp 00000000 fd:00 55051983 /usr/lib64/ld-2.17.so 7ffff7fde000-7ffff7fe1000 rw-p 00000000 00:00 0 7ffff7ff9000-7ffff7ffa000 rw-p 00000000 00:00 0 7ffff7ffa000-7ffff7ffc000 r-xp 00000000 00:00 0 [vdso] 7ffff7ffc000-7ffff7ffd000 r--p 00021000 fd:00 55051983 /usr/lib64/ld-2.17.so 7ffff7ffd000-7ffff7ffe000 rw-p 00022000 fd:00 55051983 /usr/lib64/ld-2.17.so 7ffff7ffe000-7ffff7fff000 rw-p 00000000 00:00 0 7ffffffde000-7ffffffff000 rw-p 00000000 00:00 0 [stack] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall] lego after loading 00400000-00401000 r-xp 00000000 /root/ys/LegoOS/usr/a.out 00600000-00602000 rw-p 00000000 /root/ys/LegoOS/usr/a.out 00602000-00604000 rw-p 00000000 [heap] 7ffff7ddb000-7ffff7dfc000 r-xp 00000000 /lib64/ld-linux-x86-64.so.2 7ffff7ffc000-7ffff7ffe000 rw-p 00021000 /lib64/ld-linux-x86-64.so.2 7ffff7ffe000-7ffff7fff000 rw-p 00000000 7ffffffde000-7ffffffff000 rw-p 00000000 [stack] [ 2066.379224] **** Finish dump final mm [ 2066.426023] handle_p2m_execve(): reply_status: OKAY, new_ip: 0x7ffff7ddc170, new_sp: 0x7fffffffede0 [ 2066.628949] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:150 vaddr:0x7ffff7ddc170 [ 2066.732034] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:150 vaddr:0x7ffff7ddc170 [ 2066.934947] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:51 vaddr:0x7fffffffedd8 [ 2067.036978] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:51 vaddr:0x7fffffffedd8 [ 2067.238842] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7ffce00 [ 2067.340880] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7ffce00 [ 2067.542747] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:51 vaddr:0x7ffff7ffd9a8 [ 2067.644774] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:51 vaddr:0x7ffff7ffd9a8 [ 2067.846640] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7ddb8e0 [ 2067.948679] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7ddb8e0 [ 2068.355424] ------------[ cut here ]------------ [ 2068.408568] WARNING: CPU: 4 PID: 31 at managers/memory/handle_pcache/fault.c:54 handle_p2m_pcache_miss+0x29d/0x380 [ 2068.532327] src_nid:0,pid:32,vaddr:0x7ffff7e0e000 [ 2068.588487] CPU: 4 PID: 31 Comm: mc-manager 4.0.0-lego-ys+ #100 [ 2068.659207] Stack: [root@wuklab13: lib64] $ ll ld-* -rwxr-xr-x 1 root root 164112 Nov 30 13:53 ld-2.17.so lrwxrwxrwx 1 root root 10 Jan 8 12:34 ld-linux-x86-64.so.2 -> ld-2.17.so [root@wuklab13: lib64] It turns out there is a bug in mmap code: forgot to increment the file ref count when a file-backed vma is created. Some put_file in loader accidentally free the ld-linux file. Bug fixed, dyloader works like a charm. 02/24 Sat \u00b6 Well. PhDs do not have weekends. Anyway, it is Saturday after all, relaxed a little bit. I was looking into the pcache issue. Also added our own kernel version strace. 02/23 Fri \u00b6 Solved FPU BUG \u00b6 current is fine. I should not compare the old implementation with the new per-cpu current. I forgot that the kernel stack is switched in the __switch_to_asm . This means in __switch_to() , we are actually using the next_p \u2018s kernel stack. So there is small time frame, where current_thread_info() points to next_p , while current_task is still prev_p . Since interrupts are disabled during context switch, we are good with this mismatch. Rule out current, the only thing left is fpu__copy warning, which happens during copy_process() . One weird thing is this function has been called multiple times before it showed a warning. System itself use this function to create a lot background threads, which are fine. Only when it was triggered by sys_clone then we have the warning: [ 3213.055639 ] CPU : 6 PID : 17 sys_clone + 0x0 / 0x30 [ 3213.056584 ] new task_struct : ffff88083e4c9838 [ 3213.057530 ] arch_dup_task_struct cpu6 dst : ffff88083e4c9838 17 word_count - seq src : ffff88083e457838 17 word_count - seq [ 3213.059536 ] TRAP do_general_protection in CPU6 , error_code : 0 current : ffff88083e457838 17 word_count - seq [ 3213.061289 ] fixup_exception pid ( 17 ) cpu ( 6 ) insn : 0xffffffff81009a21 ( fpu__copy + 0x81 / 0x260 ) fixup : 0xffffffff8105d9b2 ( __fixup_text_start + 0xc2 / 0x322 ) handler : ex_handler_default + 0x0 / 0x20 [ 3213.064114 ] ------------ [ cut here ] ------------ [ 3213.065040 ] WARNING : CPU : 6 PID : 17 at . / arch / x86 / include / asm / fpu / internal . h : 354 fpu__copy + 0xc3 / 0x260 [ 3213.066760 ] CPU : 6 PID : 17 Comm : word_count - seq 4.0.0 - lego + # 6 [ 3213.067855 ] Stack : [ 3213.068424 ] ffff88083e4c7dd0 ffffffff810124b5 ffff88083e4c9bf8 ffff88083e4c9c38 [ 3213.070133 ] ffff88083e4c9838 00007f fff7ffd700 ffff88083e4c7de0 ffffffff8101258f [ 3213.071775 ] ffff88083e4c7e08 ffffffff81009a63 ffff88083e457838 ffff88083e4c9838 [ 3213.073419 ] ffff88083e457838 ffff88083e4c7e40 ffffffff81000ebb ffff88083e457838 [ 3213.075057 ] ffff880800000011 ffff88083e457a68 00000000003 d0f00 ffff88083e457838 [ 3213.076703 ] Call Trace : [ 3213.077295 ] < TSK > [ 3213.077828 ] [ < ffffffff810124c1 > ] __warn . constprop .0 + 0x91 / 0xd0 [ 3213.078855 ] [ < ffffffff8101258f > ] warn_slowpath_null + 0xf / 0x20 [ 3213.081653 ] [ < ffffffff81009a63 > ] fpu__copy + 0xc3 / 0x260 [ 3213.082543 ] [ < ffffffff81000ebb > ] arch_dup_task_struct + 0x7b / 0x90 [ 3213.083667 ] [ < ffffffff8101d32e > ] copy_process + 0x14e / 0x10e0 [ 3213.084618 ] [ < ffffffff8103a3c6 > ] ? n_tty_write + 0x166 / 0x3c0 [ 3213.085564 ] [ < ffffffff8101e2e6 > ] do_fork + 0x26 / 0x140 [ 3213.086439 ] [ < ffffffff8101e4a0 > ] ? sys_vfork + 0x40 / 0x40 [ 3213.087333 ] [ < ffffffff8101e4a0 > ] ? sys_vfork + 0x40 / 0x40 [ 3213.088232 ] [ < ffffffff8101e4c9 > ] sys_clone + 0x29 / 0x30 [ 3213.089109 ] [ < ffffffff8100e719 > ] do_syscall_64 + 0x69 / 0xf0 [ 3213.090030 ] [ < ffffffff8100d5ec > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 3213.091078 ] < EOT > [ 3213.091580 ] --- [ end trace 0000000000000000 ] --- [ 3213.093250 ] TRAP do_general_protection in CPU7 , error_code : 0 current : ffff88083fd0f008 0 swapper / 7 [ 3213.096526 ] fixup_exception pid ( 0 ) cpu ( 7 ) insn : 0xffffffff81000c62 ( __switch_to + 0x452 / 0x630 ) fixup : 0xffffffff8105d922 ( __fixup_text_start + 0x32 / 0x322 ) handler : ex_handler_default + 0x0 / 0x20 [ 3213.101241 ] ------------ [ cut here ] ------------ [ 3213.103285 ] WARNING : CPU : 7 PID : 0 at . / arch / x86 / include / asm / fpu / internal . h : 369 __switch_to + 0x47e / 0x630 So, dig into fpu__copy() , find out why it fails at this certain point. Glad I have something to dig into. The instruction leads to GP is: ffffffff8100b0f5 : 48 0f ae 27 xsave64 ( % rdi ) which is generated by: #define XSTATE_XSAVE(st, lmask, hmask, err) \\ asm volatile(ALTERNATIVE_2(XSAVE, \\ XSAVEOPT, X86_FEATURE_XSAVEOPT, \\ XSAVES, X86_FEATURE_XSAVES) \\ \"\\n\" \\ \"xor %[err], %[err]\\n\" \\ \"3:\\n\" \\ \".pushsection .fixup,\\\"ax\\\"\\n\" \\ \"4: movl $-2, %[err]\\n\" \\ \"jmp 3b\\n\" \\ \".popsection\\n\" \\ _ASM_EXTABLE(661b, 4b) \\ : [err] \"=r\" (err) \\ : \"D\" (st), \"m\" (*st), \"a\" (lmask), \"d\" (hmask) \\ : \"memory\") static inline void copy_xregs_to_kernel ( struct xregs_state * xstate ) { u64 mask = -1 ; u32 lmask = mask ; u32 hmask = mask >> 32 ; int err ; WARN_ON ( ! alternatives_patched ); XSTATE_XSAVE ( xstate , lmask , hmask , err ); /* We should never fault when copying to a kernel buffer: */ WARN_ON_FPU ( err ); } From SDM on XSAVE : Use of a destination operand not aligned to 64-byte boundary (in either 64-bit or 32-bit modes) results in a general-protection (#GP) exception. In 64-bit mode, the upper 32 bits of RDX and RAX are ignored. %rdi is struct xregs_state *xstate in above code. Thus, check if xstate if 64-bytes aligned. Of course, it is not: [10894.999997] copy_xregs_to_kernel CPU6 xstate: ffff88083e4c8c38 Hehe. Criminal identified. But why? The xstate structure is already marked as __attribute__(aliged 64) in the code. It is the task_struct , which is NOT 0x40 aligned. But god why? Because we currently use kmalloc to allocate new task_struct, whose minimum alignment is 8 bytes . Anyway, use __alloc_pages instead. Such an deeply hidden bug. Took me almost a month to find out. IB \u00b6 Seen this during boot (at both P and M, although lego continue running correctly): [ 54017.712533 ] *** NodeID Hostname LID QPN [ 54017.770776 ] *** ------------------------------------- [ 54017.834220 ] *** 0 wuklab12 13 72 [ 54017.892462 ] *** 1 wuklab14 16 72 <--- [ 54017.955906 ] *** 2 wuklab16 20 74 [ 54018.014149 ] *** [ 54074.552844 ] *** Start establish connection ( mynodeid : 1 ) [ 54102.554407 ] ib_process_mad mad_ifc fails [ 54130.960691 ] *** recvpollcq runs on CPU2 [ 54131.070918 ] *** Successfully built QP for node 0 [ LID : 13 QPN : 72 ] [ 54131.152936 ] *** Successfully built QP for node 2 [ LID : 20 QPN : 74 ] [ 54161.228245 ] *** FIT layer ready to go ! [ 54161.272034 ] *** Another one: [ 1966.930409 ] *** [ 1966.951210 ] *** FIT_initial_timeout_s : 30 [ 1967.002168 ] *** FIT_local_id : 0 [ 1967.052087 ] *** [ 1967.072887 ] *** NodeID Hostname LID QPN [ 1967.131126 ] *** ------------------------------------- [ 1967.194567 ] *** 0 wuklab12 13 72 <--- [ 1967.258005 ] *** 1 wuklab14 16 72 [ 1967.316244 ] *** 2 wuklab16 20 74 [ 1967.374484 ] *** [ 2032.926448 ] *** Start establish connection ( mynodeid : 0 ) [ 2032.996068 ] Fail to modify qp [ 6 ] [ 2033.032572 ] Fail to do client_init_ctx [ 2033.077287 ] client_establish_conn : ctx ( null ) fail to init_interface [ 2033.164646 ] ibapi_establish_conn : ctx ( null ) fail to init_interface [ 2033.250967 ] *** [ 2035.620167 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000004 [ 2035.713763 ] IP : [ < ffffffff8105c589 > ] client_send_reply_with_rdma_write_with_imm + 0x69 / 0x3b0 [ 2035.812562 ] PGD 0 [ 2035.836482 ] Oops : 0002 [ # 1 ] SMP PROCESSOR [ 2035.884321 ] CPU : 0 PID : 1 Comm : kernel_init 4.0.0 - lego - ys + # 253 [ 2035.955041 ] RIP : 0010 : [ < ffffffff8105c589 > ] [ < ffffffff8105c589 > ] client_send_reply_with_rdma_write_with_imm + 0x69 / 0x3b0 ... [ 2037.313267 ] < TSK > [ 2037.336146 ] [ < ffffffff8105a377 > ] ibapi_send_reply_timeout + 0x57 / 0x70 [ 2037.411025 ] [ < ffffffff81033d24 > ] ? net_send_reply_timeout + 0x94 / 0x132 [ 2037.486944 ] [ < ffffffff81033d24 > ] net_send_reply_timeout + 0x94 / 0x132 pcache \u00b6 Running word_count-pthread, with 100MB dataset, finally got some reasonable bug: [ 54211.243181 ] pcache_evict_line () : pset : ffff88207f86e3c0 , for uva : 0x7ffff1b8f000 [ 54211.385654 ] pcache : ffff88207f86e3a8 mapcount : 8 refcount : 0 flags :() [ 54211.510447 ] pcache dumped because : PCACHE_BUG_ON_PCM ( ! PcacheLocked ( pcm )) [ 54212.080336 ] BUG : failure at managers / processor / pcache / evict . c : 240 / pcache_evict_line () ! [ 54212.664785 ] Kernel Panic - not syncing : BUG ! [ 54212.715742 ] CPU : 8 PID : 81 Comm : word_count - pthr 4.0.0 - lego - ys + # 252 ... [ 54213.391706 ] < TSK > [ 54213.414584 ] [ < ffffffff81024180 > ] panic + 0xc2 / 0xeb [ 54213.524818 ] [ < ffffffff8101b81c > ] ? task_tick_rt + 0x2c / 0xd0 [ 54213.589295 ] [ < ffffffff81018f75 > ] ? scheduler_tick + 0x55 / 0x60 [ 54213.655850 ] [ < ffffffff81016625 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 54213.728647 ] [ < ffffffff81006634 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 54213.801443 ] [ < ffffffff8100e22a > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 54213.879439 ] [ < ffffffff8101256d > ] ? printk + 0x11d / 0x1b0 [ 54214.103027 ] [ < ffffffff8102ecf4 > ] pcache_evict_line + 0x134 / 0x220 [ 54214.172703 ] [ < ffffffff8102c6ae > ] pcache_alloc + 0x22e / 0x2e0 [ 54214.237179 ] [ < ffffffff8102be0a > ] common_do_fill_page + 0x2a / 0x1f0 [ 54214.307895 ] [ < ffffffff8102baf0 > ] ? move_page_tables + 0x4c0 / 0x4c0 [ 54214.378612 ] [ < ffffffff8102c172 > ] pcache_handle_fault + 0x1a2 / 0x3a0 [ 54214.450367 ] [ < ffffffff8100fc02 > ] do_page_fault + 0xa2 / 0x1a0 [ 54214.514843 ] [ < ffffffff8100d85f > ] page_fault + 0x1f / 0x30 [ 54214.575161 ] [ < ffffffff81034842 > ] ? copy_user_enhanced_fast_string + 0x2 / 0x10 [ 54214.657316 ] [ < ffffffff81032368 > ] ? seq_read + 0x248 / 0x360 [ 54214.719714 ] [ < ffffffff810307af > ] sys_read + 0x3f / 0xc0 [ 54214.777949 ] [ < ffffffff81030770 > ] ? sweep_pset_lru + 0x220 / 0x220 [ 54214.846587 ] [ < ffffffff8100e619 > ] do_syscall_64 + 0x69 / 0xf0 [ 54214.910022 ] [ < ffffffff8100d4ec > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 54214.985939 ] < EOT > Another one: [ 735.393244 ] pcache_evict_line () : pset : ffff88207f86e3c0 , for uva : 0x7ffff1b8fd90 [ 735.537804 ] pcache : ffff88207f86e3a8 mapcount : 8 refcount : 0 flags :() [ 735.663642 ] pcache dumped because : PCACHE_BUG_ON_PCM ( ! PcacheLocked ( pcm )) Do note this happens after computation. This happens when phoenix create a lot threads to sort the results. Both bug happen to the same set, same user page. The pcache is clearly corrupted: mapcount:8, refcount:0, flags:(). Come back after dinner. Remember to check altenative, cause the XSAVE above should be XSAVEOPT. Make sure it does not override other memory. Also, check linker script. Do not forget to link any sections. Another several bug logs in wuklab13 and wuklab15: 022318-* . I\u2019m really tired today after fixing the FPU bug. But I\u2019m also pretty confident pcache is something I\u2019m able to debug. Even thought it is hard in SMP case. Anyway, I gonna call for the day. 02/22 Thur \u00b6 context switch fpu signal compat check, all good. make current use percpu current_task, so all code in Lego is consistent. checked entry_SYSCALL-64 again, which looks good to me. The only concern is rsp_scratch and current_top_of_stack , which are per-cpu variables. If these per-cpu is setup wrong, then we are doomed. Also check if per-cpu is all cleared up? try big syscall lock does x86 has to use different kernel stacks? Interrupt is using different stack in Linux, has to do so??? check current is correct. compare with old implementation. First of all, FPU is definitely functional for now. Since I replaced the current macro today, I add some code to check if this current matches our old implementation: static __always_inline struct task_struct *get_current(void) { return this_cpu_read_stable(current_task); } //#define current get_current() #define current \\ ({ \\ struct task_struct *old = current_thread_info()->task; \\ struct task_struct *new = get_current(); \\ \\ if (old != new) { \\ printk(\"%s:%d() cpu:%d old:%pS %d %s new:%pS %d %s\\n\", \\ __func__, __LINE__, smp_processor_id(), old, old->pid, old->comm, \\ new, new->pid, new->comm); \\ BUG(); \\ } \\ get_current(); \\ }) Combined with some FPU warning, it is now like this: [ 3273.748819 ] CPU : 5 PID : 32 sys_clone + 0x0 / 0x30 [ 3273.800808 ] alloc_task_struct_node : size : 740 ffff88107e831838 [ 3273.869451 ] arch_dup_task_struct () CPU5 current : 32 new : ffff88107e831838 old : ffff88107e827838 32 [ 3273.975533 ] ------------ [ cut here ] ------------ [ 3274.030651 ] WARNING : CPU : 5 PID : 32 at . / arch / x86 / include / asm / fpu / internal . h : 354 fpu__copy + 0xe2 / 0x310 [ 3274.140895 ] CPU : 5 PID : 32 Comm : word_count - pthr 4.0.0 - lego - ys - gdbe6dbe - dirty # 249 [ 3274.231377 ] Stack : [ 3274.255298 ] ffff88107e82fd68 ffffffff81016dbf 00000000f fffffff 0000000000000000 [ 3274.342659 ] 00000000f fffffff 0000000000000000 ffff88107e831bf8 ffff88107e831c38 [ 3274.430021 ] ffff88107e831838 000000207f e64000 ffff88107e82fd78 ffffffff810170af [ 3274.517382 ] ffff88107e82fdc0 ffffffff8100b052 0000000000000020 ffff88107e831838 [ 3274.604745 ] ffff88107e827838 ffff88107e827838 ffff88107e831838 ffff88107e827838 [ 3274.692106 ] Call Trace : [ 3274.721229 ] < TSK > [ 3274.744109 ] [ < ffffffff81016dd8 > ] __warn . constprop .0 + 0xe8 / 0x3b0 [ 3274.813790 ] [ < ffffffff810170af > ] warn_slowpath_null + 0xf / 0x20 [ 3274.881391 ] [ < ffffffff8100b052 > ] fpu__copy + 0xe2 / 0x310 [ 3274.941713 ] [ < ffffffff810012e4 > ] arch_dup_task_struct + 0x84 / 0x120 [ 3275.013475 ] [ < ffffffff81022c10 > ] copy_process + 0x160 / 0x1e60 [ 3275.078996 ] [ < ffffffff81024936 > ] do_fork + 0x26 / 0x140 [ 3275.137238 ] [ < ffffffff81024af0 > ] ? sys_vfork + 0x40 / 0x40 [ 3275.198599 ] [ < ffffffff81024af0 > ] ? sys_vfork + 0x40 / 0x40 [ 3275.259960 ] [ < ffffffff81024b19 > ] sys_clone + 0x29 / 0x30 [ 3275.319242 ] [ < ffffffff81012314 > ] do_syscall_64 + 0x84 / 0x240 [ 3275.383723 ] [ < ffffffff8101106c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 3275.459645 ] < EOT > [ 3275.482526 ] --- [ end trace 0000000000000000 ] --- [ 3275.537648 ] wake_up_new_task CPU5 task : ffff88107e831838 , dest_cpu : 6 current : 32 [ 3275.623970 ] SMP IPI : reschedule_interrupt () CPU ( 6 ) PID ( 0 ) [ 3275.739412 ] do_general_protection : 186 () cpu : 6 old : 0xffff88107e831838 33 word_count - pthr new : 0xffff88107fcaf008 0 swapper / 6 [ 3275.871493 ] ------------ [ cut here ] ------------ [ 3275.926614 ] BUG : failure at arch / x86 / kernel / traps . c : 186 / do_general_protection () ! [ 3276.015018 ] Kernel Panic - not syncing : BUG ! [ 3276.065978 ] panic : 107 () cpu : 6 old : 0xffff88107e831838 33 word_count - pthr new : 0xffff88107fcaf008 0 swapper / 6 Based on the switch code: __switch_to ( struct task_struct * prev_p , struct task_struct * next_p ) { this_cpu_write ( current_task , next_p ); /* Reload sp0 This changes current_thread_info(). */ load_sp0 ( tss , next ); } Based on log line 30, load_sp0() already happened, which means this_cpu_write(..) happened too. If this_cpu_write(..) happened, then log line 30\u2019s new should have been updated to 0xffff88107e831838 . Something wrong with percpu? 02/21 Wed \u00b6 irq_regs, old code, check signal frame, and fpu hook together Done in_interrupt() , it is empty, TODO check arch/x86/Makefile, it introduce a lot FPU flags. added more than 4K lines today. Damn FPU. Ugh go home sleep. 02/20 Tue Cloudy \u00b6 Not too many Sunny days recently. Well, continue yesterday\u2019s work. I don\u2019t think I can easily find out why so many /proc/memoinfo open happened. Instead, I\u2019m trying to enable the flush_thread in P\u2019s exec code. During the way, I found some issue related to __ARCH_HAS_SA_RESTORER in signal code. I need to check if these x86 macros are defined, but lego does not port them. Well, it turns out flush_thread does not make too much difference. Next I\u2019m going to try to disable exit_thread , which uses fpu__drop() . Hmm, disable exit_thread also does not work. 02/19 Mon Rainy \u00b6 It is another week. I can not deny I\u2019m a little tired about the bug. Tried so many possible solutions, but none of them work. Well, today I first need to test the vma changes (pgoff and anon_vma) thing. Especially the vma merge and split. This morning I fixed a bug in kernel_init process: make kernel_init able to run all possible CPUs. Because the first user process is forked from kernel_init, it is quite important that it gets the right cpu affinity: static int kernel_init ( void * unused ) { ... set_cpus_allowed_ptr ( current , cpu_possible_mask ); ... } Well, interestingly, the unmodified word_count-pthread succeed with 50MB dataset\u2026 with or without any DEBUG option! Amazing! I need to find out why the cpus_allowed becomes 0 at the beginning of kernel_init. Because init_task actually has: . cpus_allowed = CPU_MASK_ALL , . nr_cpus_allowed = NR_CPUS , Things to do next: check why the cpus_allowed changed check why word_count-pthread open /dev/../cpu so many times. Anything wrong with our copy_files , or open, close? here is an idea, to verify if FPU code is correct, run some scientific benchmarks. Okay, findings: cpus_allowd is fine, it is reset inside sched_init() , when it tries make the init_task as the idle thread. Thus it is reasonable to set cpus_allowed again at kernel_init thread. And it should NOTHING to do with the bug. about the second, check the following log: [ 11838.364543 ] STDOUT : --- [ Wordcount : Running ... ] --- [ 11838.422886 ] STDOUT : --- [ ] --- [ 11838.463445 ] SYSC_open ( cpu5 pid : 32 ) : f_name : / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count_datafiles / word_50MB . txt , flags : 0 , mode : 900 [ 11838.619460 ] SYSC_open ( cpu5 pid : 32 ) : fd : 3 [ 11838.667406 ] SYSC_open ( cpu5 pid : 32 ) : f_name : / sys / devices / system / cpu / online , flags : 80000 , mode : 0 [ 11838.773351 ] SYSC_open ( cpu5 pid : 32 ) : fd : 4 [ 11838.821239 ] seq_file : dest_uva : 00007f ffffffc8d0 , nr_chars : 5 string : [ 0-23 ] [ 11838.913791 ] SYSC_close ( cpu5 pid : 32 ) : fd : 4 [ 11838.962622 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 11840.223255 ] STDOUT : --- [ Word Count : Computation Completed 1.555581 sec ] --- [ 11840.309678 ] SYSC_open ( cpu5 pid : 32 ) : f_name : / sys / devices / system / cpu / online , flags : 80000 , mode : 0 [ 11840.415754 ] SYSC_open ( cpu5 pid : 32 ) : fd : 4 [ 11840.463593 ] seq_file : dest_uva : 00007f ffffffc8a0 , nr_chars : 5 string : [ 0-23 ] [ 11840.556147 ] SYSC_close ( cpu5 pid : 32 ) : fd : 4 [ 11840.605024 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 11840.677821 ] STDOUT : --- [ THe number of processors is 24 \u00f4 ] --- [ 11840.753769 ] SYSC_open ( cpu7 pid : 80 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11840.844212 ] SYSC_open ( cpu19 pid : 92 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11840.935728 ] SYSC_open ( cpu7 pid : 80 ) : fd : 4 [ 11840.983567 ] SYSC_open ( cpu19 pid : 92 ) : fd : 5 [ 11841.032444 ] seq_file : dest_uva : 00007f fff444c000 , nr_chars : 172 string : [ MemTotal : 115355128 kB MemFree : 115355128 kB MemAvailable : 115355128 kB DirectMap4k : 5812 kB DirectMap2M : 1861632 kB DirectMap1G : 134217728 kB ] [ 11841.305953 ] seq_file : dest_uva : 00007f fff444b000 , nr_chars : 172 string : [ MemTotal : 115355128 kB MemFree : 115355128 kB MemAvailable : 115355128 kB DirectMap4k : 5812 kB DirectMap2M : 1861632 kB DirectMap1G : 134217728 kB ] [ 11841.579460 ] SYSC_close ( cpu7 pid : 80 ) : fd : 4 [ 11841.628339 ] SYSC_close ( cpu19 pid : 92 ) : fd : 5 [ 11841.678257 ] SYSC_close () : [ 4 ] -> [ / proc / meminfo ] [ 11841.733375 ] SYSC_close () : [ 5 ] -> [ / proc / meminfo ] [ 11841.788493 ] SYSC_open ( cpu18 pid : 91 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11841.880008 ] SYSC_open ( cpu6 pid : 102 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11841.971523 ] SYSC_open ( cpu12 pid : 85 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11842.063040 ] SYSC_open ( cpu0 pid : 97 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11842.153516 ] SYSC_open ( cpu14 pid : 87 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11842.245032 ] SYSC_open ( cpu16 pid : 89 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11842.336548 ] SYSC_open ( cpu4 pid : 100 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11842.428064 ] SYSC_open ( cpu16 pid : 89 ) : fd : 9 [ 11842.476942 ] SYSC_open ( cpu4 pid : 100 ) : fd : 10 [ 11842.526860 ] seq_file : dest_uva : 00007f fff444c000 , nr_chars : 172 string : [ MemTotal : 115355128 kB MemFree : 115355128 kB MemAvailable : 115355128 kB DirectMap4k : 5812 kB DirectMap2M : 1861632 kB DirectMap1G : 134217728 kB ] [ 11842.800368 ] seq_file : dest_uva : 00007f fff444b000 , nr_chars : 172 string : [ MemTotal : 115355128 kB MemFree : 115355128 kB MemAvailable : 115355128 kB DirectMap4k : 5812 kB DirectMap2M : 1861632 kB DirectMap1G : 134217728 kB ] [ 11843.073877 ] SYSC_close ( cpu16 pid : 89 ) : fd : 9 However, in a normal Linux exeution: strace - C - o strace_2 . / word_count - pthread . / word_count_datafiles / word_50MB . txt % time seconds usecs / call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 86.41 0.052074 1736 30 futex 6.89 0.004151 67 62 munmap 2.47 0.001490 17 88 mmap 2.12 0.001278 14 93 clone 1.51 0.000912 14 64 mprotect 0.19 0.000117 7 16 write 0.15 0.000092 46 2 open $ cat strace_2 | grep open open ( \"./word_count_datafiles/word_50MB.txt\" , O_RDONLY ) = 3 open ( \"/sys/devices/system/cpu/online\" , O_RDONLY | O_CLOEXEC ) = 4 It opened the /proc/meminfo for way too many times. In the normal Linux execution, this should not happen. Is it because our meminfo is faked, so glibs is complaining? But why it does not open meminfo while running in Linux? Or does our entry assembly messed up some stuff in stack, so the return path changed? oh, about the FPU. It reminds our flush_thread function actually has an issue before. When I enabled this function during loading in P, the P will crash. Within flush_thread , there is a fpu_clear !!! So, check this tomorrow! (12:00am, need to go home) 02/18 Sun Sunny \u00b6 It is a nice day. Yesterday I\u2019ve changed one line of code in mmap code path: change anonymous vma\u2019s pgoff from some value to 0. The result is I got several succeed work-count-pthread(bind to one core) testing. However, it still fail with unmodified word-count-pthread. It brings me to inspect pgoff manipulation code and all mmap.c code. We ported everything from linux without almost zero modification. That means we ported all those useless anon_vma and pgoff code, which is used a lot by vma_merge, vma_split code. The thing is: our memory manager, our vma code do not need such anon_vma structure, and do not maintain pgoff. Thus, I\u2019m a little bit worried linux code may doing some crazy behind our back: mess vma and pages, then pcache miss gets some wrong pages Well. Lego does not use anon_vma , and pgoff should only be used by file-backed vma. So, I decided to remove anon_vma from our code, and make sure pgoff is used properly. Of course, the goal is to make vma_merge, split, copy, do the things we intended. Lesson learned. 02/17 Sat Snowy \u00b6 Fixed the bss bug. It comes from loader. We did not implement the lego_clear_user function, so some part of bss is non-zero. Bad news is word_count-pthread still fail at same fpu instruction. Have to look into memory code more. This is actually a fun debugging story. We should always add TODO or XXX or some warnings to unfinished code, no matter what. Lesson learned. 02/16 Fri Cloudy \u00b6 Yilun found a major loader bug yesterday: the .bss section variables are not 0, in the iozone benchmark. I did not encounter this issue before with simple test program. This is pretty serious. 02/15 Thur Rainy \u00b6 Today is Chinese New Year. Line 7 and 8 show the uva belong to the same page. Need to revisit get_arg_pages etc functions. [ 108.393991] handle_p2m_execve(): pid:22,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread [ 108.395255] argc[0] (len: 65): /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread [ 108.396329] argc[1] (len: 82): /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt [ 108.397530] envc[0] (len: 7): HOME=/ [ 108.398069] envc[1] (len: 11): TERM=linux [ 108.398640] __bprm_mm_init vma: ffff88083effe6b8 [ 108.399226] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffefed [ 108.399949] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffef94 Well, this is 100% fine. I wrote this loader code long time ago and need some time to pickup. So, after I read the loader code, especially the copy_strings function, I found this is okay. Because copy_strings will be invoked three times, so the faultin_page basically will be invoked at least three times. That is why it went to that pte fault handling code. Although actually I think copy_strings should not use faultin_page , instead, it should use get_user_pages , which will walk through the pgtable first, then went to handle_lego_mm_fault . 02/14 Wed Rainy \u00b6 Hmm, tried to make kmalloc behave as kzalloc, and bind all threads to one core, still gave the same old bug: 42731a: f3 0f 6f 16 movdqu (%rsi),%xmm2 [93182.657376] word_count-pthr[85] general protection ip:42731a sp:7fffe3ffed28 error:0 [93182.747959] CPU: 8 PID: 85 Comm: word_count-pthr 4.0.0-lego+ #170 [93182.820758] RIP: 0033:[<000000000042731a>] [<000000000042731a>] 0x42731a [93182.901878] RSP: 002b:00007fffe3ffed28 EFLAGS: 00010283 [93182.965317] RAX: 000000000000001f RBX: 00007ffff001b010 RCX: 0000000000000005 [93183.050596] RDX: 0000000000000000 RSI: 5345485355420045 RDI: 00007ffff294791f [93183.135876] RBP: 00007ffff294791f R08: 000000000000ffff R09: 0000000000000008 [93183.221156] R10: fffffffffffff048 R11: 00000000004acfc0 R12: 0000000000001cde [93183.306435] R13: 00000000006e4a8c R14: 0000000000001cd7 R15: 0000000000001cda [93183.391716] FS: 00007fffe3fff700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000 [93183.488434] CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [93183.557075] CR2: 00007ffff27a4000 CR3: 000000107e924000 CR4: 00000000000406a0 427377: 66 0f 6f 17 movdqa (%rdi),%xmm2 [93180.527248] word_count-pthr[93]: segfault at 0x0 ip 0000000000427377 sp 00007fffdfff6d28 error 4 [93180.630314] CPU: 8 PID: 93 Comm: word_count-pthr 4.0.0-lego+ #170 [93180.703114] RIP: 0033:[<0000000000427377>] [<0000000000427377>] 0x427377 [93180.784234] RSP: 002b:00007fffdfff6d28 EFLAGS: 00010297 [93180.847674] RAX: 0000000000000000 RBX: 000000000073c4c0 RCX: 000000000000000d [93180.932953] RDX: 000000000000ffff RSI: 00007ffff4999070 RDI: 0000000000000000 [93181.018233] RBP: 00007ffff499907d R08: 000000000000ffff R09: 0000000000000000 [93181.103513] R10: 0000000000427760 R11: 00007ffff49982c0 R12: 0000000000000118 [93181.188791] R13: 00000000006e4aac R14: 0000000000000116 R15: 0000000000000117 [93181.274072] FS: 00007fffdfff7700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000 [93181.370790] CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [93181.439430] CR2: 0000000000000000 CR3: 000000107e924000 CR4: 00000000000406a0 Tried several ways to ensure memory safety. It still failed even if I enabled all of them. So, I guess the memory safety is ensured? Still some other things? force alloc_pages to use __GFP_ZERO make kmalloc behave as kzalloc make kfree empty I also suspect munmap may free extra wrong pgtable entries. Although I\u2019ve went through all the code and checked, but in addition to the above things, I\u2019m going to: make munmap dummy (no p2m_munmap, return 0 directly) Failed. Next, I\u2019m going to: add checksum for every page transferred across network. add warning for unnormal cases Bang! I found something while running P+M: [ 115.727597 ] Memory - component manager is up and running . [ 116.691723 ] handle_p2m_fork () : nid : 0 , pid : 22 , tgid : 22 , parent_tgid : 1 [ 116.697038 ] handle_p2m_fork () : reply : 0 : OKAY [ 116.791088 ] handle_p2m_execve () : pid : 22 , argc : 2 , envc : 2 , file : / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count - pthread [ 116.792357 ] argc [ 0 ] ( len : 65 ) : / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count - pthread [ 116.793439 ] argc [ 1 ] ( len : 82 ) : / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count_datafiles / word_100MB . txt [ 116.794653 ] envc [ 0 ] ( len : 7 ) : HOME =/ [ 116.795196 ] envc [ 1 ] ( len : 11 ) : TERM = linux [ 116.795772 ] __bprm_mm_init vma : ffff88083effe6b8 [ 116.796209 ] faultin_page vma : ffff88083effe6b8 [ 116.796729 ] faultin_page vma : ffff88083effe6b8 [ 116.797150 ] handle_pte_fault vma : ffff88083effe6b8 entry : 0xffff88083e8c1067 [ 116.798044 ] pte : ffff88083e8c0ff0 pfn : 0x8083e8c1 flags :( present | writable | user | accessed | dirty | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 116.799462 ] ------------ [ cut here ] ------------ [ 116.800049 ] WARNING : CPU : 4 PID : 15 at managers / memory / vm / fault . c : 148 handle_lego_mm_fault + 0x4d8 / 0x550 [ 116.801148 ] CPU : 4 PID : 15 Comm : mc - manager 4.0.0 - lego + # 78 [ 116.801818 ] Stack : [ 116.802179 ] ffff88083e893c50 ffffffff8100e827 00007f ffffffef94 ffff88083effe6b8 [ 116.803283 ] ffff88083e894008 ffff88083e8c1067 ffff88083e893c60 ffffffff8100e91f [ 116.804387 ] ffff88083e893cf0 ffffffff8102b008 0000000000000031 ffff88083e893cf0 [ 116.805488 ] 00000000000002 96 00003f ffffe00000 ffff800000000067 ffff88083e893d50 [ 116.806590 ] ffff880000000001 ffffffff81066798 ffff88083effe6b8 ffff88083e893d50 [ 116.807691 ] Call Trace : [ 116.808087 ] < TSK > [ 116.808448 ] [ < ffffffff8100e836 > ] __warn . constprop .0 + 0xa6 / 0x100 [ 116.809126 ] [ < ffffffff8100e91f > ] warn_slowpath_null + 0xf / 0x20 [ 116.809802 ] [ < ffffffff8102b008 > ] handle_lego_mm_fault + 0x4d8 / 0x550 [ 116.810505 ] [ < ffffffff8102cfe3 > ] faultin_page + 0x43 / 0xb0 [ 116.811131 ] [ < ffffffff8102dab1 > ] copy_strings . isra .1 + 0xe1 / 0x130 [ 116.811819 ] [ < ffffffff8102dd1e > ] exec_loader + 0x21e / 0x350 [ 116.812457 ] [ < ffffffff8102680a > ] handle_p2m_execve + 0x1aa / 0x290 This is a temporary stack vma that loader created for saving argv and envp. So, this vma was created here: static int __bprm_mm_init ( struct lego_binprm * bprm ) { ... bprm -> vma = vma = kzalloc ( sizeof ( * vma ), GFP_KERNEL ); ... } And then copy_strings will call faultin_page to populate a page for a specific user virtual adddress: int faultin_page ( struct vm_area_struct * vma , unsigned long start , unsigned long flags , unsigned long * kvaddr ) { ... ret = handle_lego_mm_fault ( vma , start , flags , kvaddr ); ... } Eventually, the handle_lego_mm_fault will call handle_pte_fault : static int handle_pte_fault ( struct vm_area_struct * vma , unsigned long address , unsigned int flags , pte_t * pte , pmd_t * pmd , unsigned long * mapping_flags ) { ... if ( ! pte_present ( entry )) { ... } pr_info ( \"%s vma: %p entry: %#lx \\n \" , FUNC , vma , entry . pte ); dump_pte ( pte , NULL ); WARN_ON_ONCE ( 1 ); ... } Apparently, pte is wrong! But I don\u2019t have time today. Continue tomorrow. Hmm forgot that we are saving kernel virtual addresses in the pte. Just take a quick look at the lego_pud_alloc things, seems will have some issues. I defenitly need to check all these stuff tomorrow. I\u2019ve not touch this part for too long! 02/13 Tue Sunny \u00b6 Checking our SLOB allocator today. So I found Yutong\u2019s code is using set_page_private when slob get a new page from buddy. This private field is only intended to be used by buddy to record the order . This mixed usage will confuse buddy and create bug. Even though I removed the set_page_private ( page , 0 ) after free_page , word_count-pthread still fails. Damn. 02/12 Mon Cloudy \u00b6 Add this commit 4cb3a8b6a943c90714fd9bb5e5465ee315f0aa30 : memory: Use kzalloc instead of kmalloc in __bprm_mm_init (loader) This was an potentionl bug that was not triggered previously. It is simply because kmalloc'ed vma contains some garbage area, while later in the pgfault code, we use if (vma->vm_ops && vma->vm_ops->fault) ... to check if it is an file-backed fault. Fortunately the vma->vm_ops happens to have some leftover value. So this bug was triggered. This actually reminds me that this is a series of potential bugs! Even though before I've added things like force GFP_ZERO in all physical page allocation, I missed the kmalloc's case! The story is: I patched the stop_machine code today, and tried to run code with P+M on VM, everything works fine. However, when I tried to run the new code with P+M+S on physical machine, M crashed at a very weird point: [ 7791.998168] handle_p2m_execve(): pid:81,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread [ 7792.129312] BUG: unable to handle kernel NULL pointer dereference at 0000000000000031 [ 7792.222889] IP: [<ffffffff8102c180>] handle_lego_mm_fault+0x160/0x4b0 [ 7792.299842] PGD 0 [ 7792.323760] Oops: 0000 [#1] PREEMPT SMP MEMORY [ 7792.376794] CPU: 4 PID: 79 Comm: mc-manager 4.0.0-lego+ #29 [ 7792.443349] RIP: .. [<ffffffff8102c180>] handle_lego_mm_fault+0x160/0x4b0 ...... .... [ 7793.750506] Call Trace: [ 7793.779623] <TSK> [ 7793.802501] [<ffffffff810053f4>] ? apic_timer_interrupt+0x54/0x90 [ 7793.875295] [<ffffffff8102e469>] faultin_page+0x9/0x70 [ 7793.936649] [<ffffffff8102ef01>] copy_strings.isra.1+0xe1/0x130 [ 7794.007362] [<ffffffff8102f11e>] exec_loader+0x1ce/0x340 [ 7794.070796] [<ffffffff81027def>] handle_p2m_execve+0x12f/0x200 [ 7794.140469] [<ffffffff810274fb>] mc_manager+0x1ab/0x2b0 [ 7794.202864] [<ffffffff81027350>] ? bitmap_fill+0x33/0x33 [ 7794.266298] [<ffffffff8101c6b7>] kthread+0x107/0x130 [ 7794.325572] [<ffffffff8101c5b0>] ? __kthread_parkme+0x90/0x90 [ 7794.394205] [<ffffffff8100b462>] ret_from_fork+0x22/0x30 So faulting source code is: static int handle_pte_fault ( struct vm_area_struct * vma , unsigned long address , unsigned int flags , pte_t * pte , pmd_t * pmd ) { .... if ( vma -> vm_ops && vma -> vm_ops -> fault ) return do_linear_fault ( vma , address , flags , pte , pmd , entry ) .... Something wrong with vma ? At this loader stage, this vma is a temporaty stack vma created for saving argv and envp . So I look back into the code that created this vma: managers / memory / loader / core . c : static int __bprm_mm_init ( struct lego_binprm * bprm ) { int err ; struct vm_area_struct * vma = NULL ; struct lego_mm_struct * mm = bprm -> mm ; bprm -> vma = vma = kmalloc ( sizeof ( * vma ), GFP_KERNEL ); if ( ! vma ) return - ENOMEM ; The code after this does NOT do necessary cleanup. The vm_ops happens to have some garbage value from last user. So it is not 0, so the above vma->vm_ops is true, and it will try to read vma->vm_ops->fault . And that, my friend, is where garbage turns into crash. This presents a series of potential bugs. Ugh, memory safety ! 02/09 Fri Cloudy \u00b6 Tried to modify Phoneix code: replace realloc with malloc+mempcy . Thus the mremap syscall is avoided, but it still has general protection fault. Same with yesterday, corrupted at __strcmp_sse42 , with corrupted RSI or RDI . So I guess it is not about mremap itself at all. I will follow yesterday\u2019s checking list. 02/08 Thur Cloudy \u00b6 00000000004272d0 <__strcmp_sse42>: 4272d0: 89 f1 mov %esi,%ecx 4272d2: 89 f8 mov %edi,%eax 4272d4: 48 83 e1 3f and $0x3f,%rcx 4272d8: 48 83 e0 3f and $0x3f,%rax 4272dc: 83 f9 30 cmp $0x30,%ecx 4272df: 77 3f ja 427320 <__strcmp_sse42+0x50> 4272e1: 83 f8 30 cmp $0x30,%eax 4272e4: 77 3a ja 427320 <__strcmp_sse42+0x50> 4272e6: f3 0f 6f 0f movdqu (%rdi),%xmm1 * 4272ea: f3 0f 6f 16 movdqu (%rsi),%xmm2 4272ee: 66 0f ef c0 pxor %xmm0,%xmm0 4272f2: 66 0f 74 c1 pcmpeqb %xmm1,%xmm0 4272f6: 66 0f 74 ca pcmpeqb %xmm2,%xmm1 4272fa: 66 0f f8 c8 psubb %xmm0,%xmm1 4272fe: 66 0f d7 d1 pmovmskb %xmm1,%edx 427302: 81 ea ff ff 00 00 sub $0xffff,%edx 427308: 0f 85 42 0d 00 00 jne 428050 <__strcmp_sse42+0xd80> 42730e: 48 83 c6 10 add $0x10,%rsi 427312: 48 83 c7 10 add $0x10,%rdi 427316: 66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 42731d: 00 00 00 427320: 48 83 e6 f0 and $0xfffffffffffffff0,%rsi 427324: 48 83 e7 f0 and $0xfffffffffffffff0,%rdi 427328: ba ff ff 00 00 mov $0xffff,%edx 42732d: 45 31 c0 xor %r8d,%r8d 427330: 83 e1 0f and $0xf,%ecx 427333: 83 e0 0f and $0xf,%eax 427336: 66 0f ef c0 pxor %xmm0,%xmm0 42733a: 39 c1 cmp %eax,%ecx 42733c: 74 32 je 427370 <__strcmp_sse42+0xa0> 42733e: 77 07 ja 427347 <__strcmp_sse42+0x77> 427340: 41 89 d0 mov %edx,%r8d 427343: 91 xchg %eax,%ecx 427344: 48 87 f7 xchg %rsi,%rdi * 427347: 66 0f 6f 17 movdqa (%rdi),%xmm2 (RDI: 0000000000000000) Frustrating! What is wrong with multithread program? Because of broken FPU-switch code? of inappropriate TLB flush? of IB corrupts memory? of what? ugh? I\u2019m done with this random guess and frustrated general protection or segfault, I need to first make sure underlying kernel is 100% percent correct, this is a checking list: fpu save/restore always fail at some XMM instruction always with corrupted RDI or RSI switch_to_asm %gs and %fs switch_mm (pgd) stack frame set_arch_tls (%fs) glibc\u2019s way of using per thread data some cpu may miss tlb flush kernel entry/exit assembly current_task macro stack_stratch per-cpu data in entry.S futex clear_tid set_tid shared mm robust list interrupts vector array APIC setup IO-APIC timer interrupt cpu_init and Trampoline faked kernel version P side pgfault handling code (SMP) and M side pgfault handling (SMP) mremap, munmap check pgtable boundary In all, check SMP implications Is there any code, that is solely used to test if the underlying kernel has appropriate behaviors? Like glibc test code? How to protect kernel virtual memory? Any existing solutions in Linux? What is the implication of multiple CPU entering kernel at the same time? How can it corrupt user pages? Maybe: kernel entry code, per-cpu data in entry code, fpu code, switch_to, scheduler. Why it always fail at those FPU code i.e. the strcmp function? I failed to compile without those sse, any solution? How it hurt performance? 02/07 Wed Cloudy \u00b6 20:07 Pushed a small patch on mremap issue. Hope it will work. mremap really makes the whole thing very interesting, will be a very good research finding on combing virtual cache and operating system. Need to go gym with a friend, will be back on debugging late tonight. 9:30 Have two meetings to do today, and an security class, won\u2019t have too much time coding during daytime. 02/06 Tue Sunny \u00b6 Well. We\u2019ve ruled out both smp_call_function and workqueue yesterday with Yiying\u2019s help. But the multi-thread word-count still fails :-( Single thread word-count just finished 4GB dataset (with 8GB pcache). So what could be still wrong with multithread one???? chill check exit code (Checked) check pcache\u2019s usage of task_struct, should always use the group_leader check cpu boot code and check the switch code again I believe pinpoint the issue in multithread word-count can solve a lot issues, it must be some thread creation, removal, schedule things. How about adding a lock for ibapi, make it sequential? Sweet, I tried, finally it is a bug that we are able to debug . 22:39 Done for today. I\u2019m trying to patch move_pte and pcache_move_pte . Although in theory we defenitly need to patch it, I keep thinking the code before should not trigger any serious bus or memory corruption. Ugh. Maybe it is concurrent mremap that one of them remap from A to B, while another one remap from C to A. It is possible. But my dead brain can not think of this anymore. I\u2019m going to hit the gym and do some squats. 17:01 Criminal found: mremap() and virtual cache did the crime. Interesting, I have not seen any research paper, tech-reports, writeup, code about this, not even the OVC paper, which, by the way, I think they must consider this case. Otherwise, a mremap will simply crash its virtual cache. Many thanks went to my smoke-and-think time. 15:14 Something new came up! After adding a spinlock for ibapi, this showed up (I tried one more time after this, which does not show up). We are lucky to catch this. At least I know where to look at. Also, this is defenitly triggered by mremap . It is seems it is overlapped mremap() . One thing I did not know is which thread trigger this bug, the sweep thread? Cause mremap related pcache rmap functions do not use rmap_get_locked_pte . [ 3826.048774] normal_p2s_open(): f_name: word_100MB.txt, mode: 04400, flags: 0 [ 3827.891622] SYSC_mremap(cpu18): move: [0x7fffe5788000 - 0x7fffe5806000] -> [0x7fffe531b000 - 0x7fffe5399000] [ 3828.178643] SYSC_mremap(cpu14): move: [0x7fffe5941000 - 0x7fffe5980000] -> [0x7fffe57c7000 - 0x7fffe5806000] **** ERROR: mismatched PTE and rmap **** rmap->owner_process: word_count-pthr uva: 0x7fffe57c8000 ptep: ffff88107efe0e40, rmap->page_table: ffff88107efe0e40 **** pcache_pfn: 0x1257c8, pte_pfn: 0x125942 14:00 word_count-pthread : 100MB dataset pcache : 8GB, 8-way victim : 8 entries [ 1294.845313] STDOUT: ---[ Wordcount: Running... ]--- [ 1294.903661] STDOUT: ---[ o; ]--- [ 1294.946301] normal_p2s_open(): f_name: /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt, mode: 04400, flags: 0 [ 1295.100517] SYSC_close(): [4] -> [/sys/devices/system/cpu/online] [ 1295.594658] word_count-pthr[59] general protection ip:4272ea sp:7ffff1b8ed28 error:0 [ 1295.685236] CPU: 10 PID: 59 Comm: word_count-pthr 4.0.0-lego+ #113 [ 1295.759070] RIP: 0033:[<00000000004272ea>] [<00000000004272ea>] 0x4272ea [ 1295.840184] RSP: 002b:00007ffff1b8ed28 EFLAGS: 00010283 [ 1295.903621] RAX: 000000000000000f RBX: 00007fffe5a3d010 RCX: 0000000000000001 [ 1295.988893] RDX: 0000000000000000 RSI: 4854005942004441 RDI: 00007ffff1c1e80f [ 1296.074166] RBP: 00007ffff1c1e80f R08: 0000000000000000 R09: 0000000000000010 [ 1296.211435] R10: 0000000000427ce0 R11: 00007ffff1bbb3ba R12: 0000000000001de4 [ 1296.296711] R13: 00000000006e4a80 R14: 0000000000001d9e R15: 0000000000001dc1 [ 1296.433978] FS: 00007ffff1b8f700(0000) GS:ffff88107fca0000(0000) knlGS:0000000000000000 [ 1296.582686] CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [ 1296.963297] CR2: 00007ffff1c1e000 CR3: 000000207fd8a000 CR4: 00000000000406a0 So what is this ip:4272ea , let us objdump the binary: 0000000000425e60 <strcmp>: 425e60: 48 8d 05 69 14 00 00 lea 0x1469(%rip),%rax # 4272d0 <__strcmp_sse42> 425e67: f7 05 5f b8 2b 00 00 testl $0x100000,0x2bb85f(%rip) # 6e16d0 <_dl_x86_cpu_features+0x10> 425e6e: 00 10 00 425e71: 75 1a jne 425e8d <strcmp+0x2d> 425e73: 48 8d 05 46 b0 00 00 lea 0xb046(%rip),%rax # 430ec0 <__strcmp_ssse3> 425e7a: f7 05 4c b8 2b 00 00 testl $0x200,0x2bb84c(%rip) # 6e16d0 <_dl_x86_cpu_features+0x10> 425e81: 02 00 00 425e84: 75 07 jne 425e8d <strcmp+0x2d> 425e86: 48 8d 05 03 00 00 00 lea 0x3(%rip),%rax # 425e90 <__GI_strcmp> 425e8d: c3 retq 425e8e: 66 90 xchg %ax,%ax .. .. .. .. 00000000004272d0 <__strcmp_sse42>: 4272d0: 89 f1 mov %esi,%ecx 4272d2: 89 f8 mov %edi,%eax 4272d4: 48 83 e1 3f and $0x3f,%rcx 4272d8: 48 83 e0 3f and $0x3f,%rax 4272dc: 83 f9 30 cmp $0x30,%ecx 4272df: 77 3f ja 427320 <__strcmp_sse42+0x50> 4272e1: 83 f8 30 cmp $0x30,%eax 4272e4: 77 3a ja 427320 <__strcmp_sse42+0x50> 4272e6: f3 0f 6f 0f movdqu (%rdi),%xmm1 * 4272ea: f3 0f 6f 16 movdqu (%rsi),%xmm2 4272ee: 66 0f ef c0 pxor %xmm0,%xmm0 You can see %rsi has some garbage value RSI: 4854005942004441 . Something went wrong. Will it be our FPU? I\u2019m not quite sure. If FPU code has error, why single-thread one succeed? Why it only shows up at multithread ones? 02/05 Mon Sunny \u00b6 From yesterday\u2019s testing of Phoenix, it looks like something is wrong in smp_call_functions() . They are invoked through tlb flush , which was further invoked by mremap , or munmap . The warning from smp is: [ 1260.586696 ] WARNING : CPU : 0 PID : 73 at kernel / smp . c : 129 generic_smp_call_function_single_interrupt + 0xb8 / 0x160 [ 1260.705251 ] CPU : 0 PID : 73 Comm : word_count - pthr 4.0.0 - lego + # 99 [ 1260.777008 ] Stack : [ 1260.800927 ] ffff88207fdffef8 ffffffff8100ec67 ffff88107fc00000 ffff88107fc00000 [ 1260.888283 ] ffffffff8100d410 ffff88207fe23df0 ffff88207fdfff08 ffffffff8100ed5f [ 1260.975639 ] ffff88207fdfff38 ffffffff8100fe68 00007f ffe58c3010 0000000000000f 96 [ 1261.062995 ] 000000000000f 960 0000000000000f 95 ffff88207fdfff48 ffffffff810020dd [ 1261.150351 ] 00007f fff58869c1 ffffffff8100b2e9 0000000000000f 96 0000000000000f 95 [ 1261.237707 ] Call Trace : [ 1261.266825 ] < TSK > [ 1261.289704 ] [ < ffffffff8100ec76 > ] __warn . constprop .0 + 0xa6 / 0x100 [ 1261.359381 ] [ < ffffffff8100d410 > ] ? pgd_free + 0x90 / 0x90 [ 1261.419699 ] [ < ffffffff8100ed5f > ] warn_slowpath_null + 0xf / 0x20 [ 1261.487295 ] [ < ffffffff8100fe68 > ] generic_smp_call_function_single_interrupt + 0xb8 / 0x160 [ 1261.581931 ] [ < ffffffff810020dd > ] call_function_interrupt + 0x1d / 0x20 [ 1261.655767 ] [ < ffffffff8100b2e9 > ] smp__call_function_interrupt + 0x69 / 0x70 So I decided to look into smp.c a little bit to find out if there is something wrong (I wrote it long time ago). The warning itself is true, it means some inconsistent behavior.. I saw alloc_percpu stuff during call_function_init , hence probably I also need to check percpu code a little code cause I\u2019m not sure if I port all the functionalities. In all, today\u2019s task, check percpu and smp_call_function code. Esp, percpu code, they are crucial and very hard to relate real bugs to it. Well\u2026 things changed. I found a more serious bug: something about cpuhotplug , even though lego is not using it. cpuhotplug is a set of implict callbacks to all different subsystems who want to do some initialization work on each offline->online cpu. Let us dig into how secondary cpu boots: Trampoline .. setup 64 bit mode start_secondary () smp_callin () notify_cpu_starting () ... while ( st -> state < target ) { st -> state ++ ; cpuhp_invoke_callback ( cpu , st -> state , true , NULL ); } cpuhp_invoke_callback () See? There will be some callbacks! What are those callbacks exactly? Well, they are predefined at the kernel/cpu.c . To save the trouble of reading code, I just print what functions are executed, the log is: [ 0.118235] cpuhp_invoke_callback(): 136 CPU:0 page_writeback_cpu_online+0x0/0x20 [ 0.368478] cpuhp_invoke_callback(): 136 CPU:1 smpboot_create_threads+0x0/0x90 [ 0.370196] cpuhp_invoke_callback(): 136 CPU:1 perf_event_init_cpu+0x0/0xa0 [ 0.370403] cpuhp_invoke_callback(): 136 CPU:1 workqueue_prepare_cpu+0x0/0x80 [ 0.371112] cpuhp_invoke_callback(): 136 CPU:1 hrtimers_prepare_cpu+0x0/0x60 [ 0.371339] cpuhp_invoke_callback(): 136 CPU:1 smpcfd_prepare_cpu+0x0/0x80 [ 0.371584] cpuhp_invoke_callback(): 136 CPU:1 relay_prepare_cpu+0x0/0xe0 [ 0.371794] cpuhp_invoke_callback(): 136 CPU:1 rcutree_prepare_cpu+0x0/0x170 [ 0.372333] cpuhp_invoke_callback(): 136 CPU:1 notify_prepare+0x0/0xa0 [ 0.372744] cpuhp_invoke_callback(): 136 CPU:1 bringup_cpu+0x0/0x100 [ 0.008000] cpuhp_invoke_callback(): 136 CPU:1 sched_cpu_starting+0x0/0x60 [ 0.926124] cpuhp_invoke_callback(): 136 CPU:1 smpboot_unpark_threads+0x0/0x90 [ 0.926124] cpuhp_invoke_callback(): 136 CPU:1 perf_event_init_cpu+0x0/0xa0 [ 0.927028] cpuhp_invoke_callback(): 136 CPU:1 workqueue_online_cpu+0x0/0x2a0 [ 0.927768] cpuhp_invoke_callback(): 136 CPU:1 rcutree_online_cpu+0x0/0x70 [ 0.928045] cpuhp_invoke_callback(): 136 CPU:1 notify_online+0x0/0x20 [ 0.928256] cpuhp_invoke_callback(): 136 CPU:1 page_writeback_cpu_online+0x0/0x20 [ 0.928527] cpuhp_invoke_callback(): 136 CPU:1 sched_cpu_activate+0x0/0x190 [ 0.929084] cpuhp_invoke_callback(): 136 CPU:2 smpboot_create_threads+0x0/0x90 [ 0.930240] cpuhp_invoke_callback(): 136 CPU:2 perf_event_init_cpu+0x0/0xa0 [ 0.930434] cpuhp_invoke_callback(): 136 CPU:2 workqueue_prepare_cpu+0x0/0x80 [ 0.931070] cpuhp_invoke_callback(): 136 CPU:2 hrtimers_prepare_cpu+0x0/0x60 [ 0.931264] cpuhp_invoke_callback(): 136 CPU:2 smpcfd_prepare_cpu+0x0/0x80 [ 0.931464] cpuhp_invoke_callback(): 136 CPU:2 relay_prepare_cpu+0x0/0xe0 [ 0.931649] cpuhp_invoke_callback(): 136 CPU:2 rcutree_prepare_cpu+0x0/0x170 [ 0.932245] cpuhp_invoke_callback(): 136 CPU:2 notify_prepare+0x0/0xa0 [ 0.932475] cpuhp_invoke_callback(): 136 CPU:2 bringup_cpu+0x0/0x100 [ 0.008000] cpuhp_invoke_callback(): 136 CPU:2 sched_cpu_starting+0x0/0x60 [ 1.005023] cpuhp_invoke_callback(): 136 CPU:2 smpboot_unpark_threads+0x0/0x90 [ 1.005065] cpuhp_invoke_callback(): 136 CPU:2 perf_event_init_cpu+0x0/0xa0 [ 1.005408] cpuhp_invoke_callback(): 136 CPU:2 workqueue_online_cpu+0x0/0x2a0 [ 1.005729] cpuhp_invoke_callback(): 136 CPU:2 rcutree_online_cpu+0x0/0x70 [ 1.006029] cpuhp_invoke_callback(): 136 CPU:2 notify_online+0x0/0x20 [ 1.006206] cpuhp_invoke_callback(): 136 CPU:2 page_writeback_cpu_online+0x0/0x20 [ 1.006549] cpuhp_invoke_callback(): 136 CPU:2 sched_cpu_activate+0x0/0x190 Interesting! Currently, Lego need to add the smpboot_create_threads() , workqueue_prepare_cpu() , workqueue_prepare_cpu() , bringup_cpu() , smpboot_unpark_threads() , workqueue_online_cpu() . This hidden things is really hard to find and not easy to track during boot. Especially during boot, they should do something like for_each_online_cpu and init one by one. But I guess, after adding support of cpu hotplug, code kind of merged. Some stuff will be executed whenever a cpu has been teardown or bought up. And bang, why not use the same set of hotplug during boot, right? Well.","title":"Feb 2018"},{"location":"lego/log/log-02-2018/#feb-2018","text":"","title":"Feb 2018"},{"location":"lego/log/log-02-2018/#0228-wed","text":"patch fork, and cow handler debug pcache, while running python hello world add vDSO, gettimeofday So, it is end of the day. After adding wp handler, I now have the whole picture of pcache activities, and the interactions between them. The reclaim, zap, move, copy, add, operations needs to be carefully synchronized. Also the refcount etc. I feel the ground rule is we need to make sure a PCM that a function is currently using, can not suddenly become invalid due to other operations. This has to be synced by: refcount, lock, flags. Oh well, mm is hard with SMP, but also fun. We are very close to have a fully working OS. I did not have time to look into the python hello world bug issue. It is a very serious one. It may also rule out some root bugs.","title":"02/28 Wed"},{"location":"lego/log/log-02-2018/#0227-tue","text":"Spent two days on CS527 source project, implemented a small SSHD and SSD client. And we have to inject exactly five bugs, or vulnerabilities into the systems. Lol, it is really hard to intentionally plant BUGs! Anyway, back to Lego. Since others are having a hard time compile program statically, I will try to add dynamic loader today. The interpreter: /lib64/ld-linux-x86-64.so.2 . Linux seq.c maps (no randomization): 00400000-00401000 r-xp 00000000 fd:00 18752683 /root/ys/LegoOS/usr/a.out 00600000-00601000 r--p 00000000 fd:00 18752683 /root/ys/LegoOS/usr/a.out 00601000-00602000 rw-p 00001000 fd:00 18752683 /root/ys/LegoOS/usr/a.out 00602000-00604000 rw-p 00000000 00:00 0 [heap] 7ffff7a18000-7ffff7bd0000 r-xp 00000000 fd:00 55051990 /usr/lib64/libc-2.17.so 7ffff7bd0000-7ffff7dd0000 ---p 001b8000 fd:00 55051990 /usr/lib64/libc-2.17.so 7ffff7dd0000-7ffff7dd4000 r--p 001b8000 fd:00 55051990 /usr/lib64/libc-2.17.so 7ffff7dd4000-7ffff7dd6000 rw-p 001bc000 fd:00 55051990 /usr/lib64/libc-2.17.so 7ffff7dd6000-7ffff7ddb000 rw-p 00000000 00:00 0 7ffff7ddb000-7ffff7dfc000 r-xp 00000000 fd:00 55051983 /usr/lib64/ld-2.17.so 7ffff7fde000-7ffff7fe1000 rw-p 00000000 00:00 0 7ffff7ff9000-7ffff7ffa000 rw-p 00000000 00:00 0 7ffff7ffa000-7ffff7ffc000 r-xp 00000000 00:00 0 [vdso] 7ffff7ffc000-7ffff7ffd000 r--p 00021000 fd:00 55051983 /usr/lib64/ld-2.17.so 7ffff7ffd000-7ffff7ffe000 rw-p 00022000 fd:00 55051983 /usr/lib64/ld-2.17.so 7ffff7ffe000-7ffff7fff000 rw-p 00000000 00:00 0 7ffffffde000-7ffffffff000 rw-p 00000000 00:00 0 [stack] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall] lego after loading 00400000-00401000 r-xp 00000000 /root/ys/LegoOS/usr/a.out 00600000-00602000 rw-p 00000000 /root/ys/LegoOS/usr/a.out 00602000-00604000 rw-p 00000000 [heap] 7ffff7ddb000-7ffff7dfc000 r-xp 00000000 /lib64/ld-linux-x86-64.so.2 7ffff7ffc000-7ffff7ffe000 rw-p 00021000 /lib64/ld-linux-x86-64.so.2 7ffff7ffe000-7ffff7fff000 rw-p 00000000 7ffffffde000-7ffffffff000 rw-p 00000000 [stack] [ 2066.379224] **** Finish dump final mm [ 2066.426023] handle_p2m_execve(): reply_status: OKAY, new_ip: 0x7ffff7ddc170, new_sp: 0x7fffffffede0 [ 2066.628949] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:150 vaddr:0x7ffff7ddc170 [ 2066.732034] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:150 vaddr:0x7ffff7ddc170 [ 2066.934947] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:51 vaddr:0x7fffffffedd8 [ 2067.036978] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:51 vaddr:0x7fffffffedd8 [ 2067.238842] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7ffce00 [ 2067.340880] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7ffce00 [ 2067.542747] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:51 vaddr:0x7ffff7ffd9a8 [ 2067.644774] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:51 vaddr:0x7ffff7ffd9a8 [ 2067.846640] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7ddb8e0 [ 2067.948679] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7ddb8e0 [ 2068.355424] ------------[ cut here ]------------ [ 2068.408568] WARNING: CPU: 4 PID: 31 at managers/memory/handle_pcache/fault.c:54 handle_p2m_pcache_miss+0x29d/0x380 [ 2068.532327] src_nid:0,pid:32,vaddr:0x7ffff7e0e000 [ 2068.588487] CPU: 4 PID: 31 Comm: mc-manager 4.0.0-lego-ys+ #100 [ 2068.659207] Stack: [root@wuklab13: lib64] $ ll ld-* -rwxr-xr-x 1 root root 164112 Nov 30 13:53 ld-2.17.so lrwxrwxrwx 1 root root 10 Jan 8 12:34 ld-linux-x86-64.so.2 -> ld-2.17.so [root@wuklab13: lib64] It turns out there is a bug in mmap code: forgot to increment the file ref count when a file-backed vma is created. Some put_file in loader accidentally free the ld-linux file. Bug fixed, dyloader works like a charm.","title":"02/27 Tue"},{"location":"lego/log/log-02-2018/#0224-sat","text":"Well. PhDs do not have weekends. Anyway, it is Saturday after all, relaxed a little bit. I was looking into the pcache issue. Also added our own kernel version strace.","title":"02/24 Sat"},{"location":"lego/log/log-02-2018/#0223-fri","text":"","title":"02/23 Fri"},{"location":"lego/log/log-02-2018/#solved-fpu-bug","text":"current is fine. I should not compare the old implementation with the new per-cpu current. I forgot that the kernel stack is switched in the __switch_to_asm . This means in __switch_to() , we are actually using the next_p \u2018s kernel stack. So there is small time frame, where current_thread_info() points to next_p , while current_task is still prev_p . Since interrupts are disabled during context switch, we are good with this mismatch. Rule out current, the only thing left is fpu__copy warning, which happens during copy_process() . One weird thing is this function has been called multiple times before it showed a warning. System itself use this function to create a lot background threads, which are fine. Only when it was triggered by sys_clone then we have the warning: [ 3213.055639 ] CPU : 6 PID : 17 sys_clone + 0x0 / 0x30 [ 3213.056584 ] new task_struct : ffff88083e4c9838 [ 3213.057530 ] arch_dup_task_struct cpu6 dst : ffff88083e4c9838 17 word_count - seq src : ffff88083e457838 17 word_count - seq [ 3213.059536 ] TRAP do_general_protection in CPU6 , error_code : 0 current : ffff88083e457838 17 word_count - seq [ 3213.061289 ] fixup_exception pid ( 17 ) cpu ( 6 ) insn : 0xffffffff81009a21 ( fpu__copy + 0x81 / 0x260 ) fixup : 0xffffffff8105d9b2 ( __fixup_text_start + 0xc2 / 0x322 ) handler : ex_handler_default + 0x0 / 0x20 [ 3213.064114 ] ------------ [ cut here ] ------------ [ 3213.065040 ] WARNING : CPU : 6 PID : 17 at . / arch / x86 / include / asm / fpu / internal . h : 354 fpu__copy + 0xc3 / 0x260 [ 3213.066760 ] CPU : 6 PID : 17 Comm : word_count - seq 4.0.0 - lego + # 6 [ 3213.067855 ] Stack : [ 3213.068424 ] ffff88083e4c7dd0 ffffffff810124b5 ffff88083e4c9bf8 ffff88083e4c9c38 [ 3213.070133 ] ffff88083e4c9838 00007f fff7ffd700 ffff88083e4c7de0 ffffffff8101258f [ 3213.071775 ] ffff88083e4c7e08 ffffffff81009a63 ffff88083e457838 ffff88083e4c9838 [ 3213.073419 ] ffff88083e457838 ffff88083e4c7e40 ffffffff81000ebb ffff88083e457838 [ 3213.075057 ] ffff880800000011 ffff88083e457a68 00000000003 d0f00 ffff88083e457838 [ 3213.076703 ] Call Trace : [ 3213.077295 ] < TSK > [ 3213.077828 ] [ < ffffffff810124c1 > ] __warn . constprop .0 + 0x91 / 0xd0 [ 3213.078855 ] [ < ffffffff8101258f > ] warn_slowpath_null + 0xf / 0x20 [ 3213.081653 ] [ < ffffffff81009a63 > ] fpu__copy + 0xc3 / 0x260 [ 3213.082543 ] [ < ffffffff81000ebb > ] arch_dup_task_struct + 0x7b / 0x90 [ 3213.083667 ] [ < ffffffff8101d32e > ] copy_process + 0x14e / 0x10e0 [ 3213.084618 ] [ < ffffffff8103a3c6 > ] ? n_tty_write + 0x166 / 0x3c0 [ 3213.085564 ] [ < ffffffff8101e2e6 > ] do_fork + 0x26 / 0x140 [ 3213.086439 ] [ < ffffffff8101e4a0 > ] ? sys_vfork + 0x40 / 0x40 [ 3213.087333 ] [ < ffffffff8101e4a0 > ] ? sys_vfork + 0x40 / 0x40 [ 3213.088232 ] [ < ffffffff8101e4c9 > ] sys_clone + 0x29 / 0x30 [ 3213.089109 ] [ < ffffffff8100e719 > ] do_syscall_64 + 0x69 / 0xf0 [ 3213.090030 ] [ < ffffffff8100d5ec > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 3213.091078 ] < EOT > [ 3213.091580 ] --- [ end trace 0000000000000000 ] --- [ 3213.093250 ] TRAP do_general_protection in CPU7 , error_code : 0 current : ffff88083fd0f008 0 swapper / 7 [ 3213.096526 ] fixup_exception pid ( 0 ) cpu ( 7 ) insn : 0xffffffff81000c62 ( __switch_to + 0x452 / 0x630 ) fixup : 0xffffffff8105d922 ( __fixup_text_start + 0x32 / 0x322 ) handler : ex_handler_default + 0x0 / 0x20 [ 3213.101241 ] ------------ [ cut here ] ------------ [ 3213.103285 ] WARNING : CPU : 7 PID : 0 at . / arch / x86 / include / asm / fpu / internal . h : 369 __switch_to + 0x47e / 0x630 So, dig into fpu__copy() , find out why it fails at this certain point. Glad I have something to dig into. The instruction leads to GP is: ffffffff8100b0f5 : 48 0f ae 27 xsave64 ( % rdi ) which is generated by: #define XSTATE_XSAVE(st, lmask, hmask, err) \\ asm volatile(ALTERNATIVE_2(XSAVE, \\ XSAVEOPT, X86_FEATURE_XSAVEOPT, \\ XSAVES, X86_FEATURE_XSAVES) \\ \"\\n\" \\ \"xor %[err], %[err]\\n\" \\ \"3:\\n\" \\ \".pushsection .fixup,\\\"ax\\\"\\n\" \\ \"4: movl $-2, %[err]\\n\" \\ \"jmp 3b\\n\" \\ \".popsection\\n\" \\ _ASM_EXTABLE(661b, 4b) \\ : [err] \"=r\" (err) \\ : \"D\" (st), \"m\" (*st), \"a\" (lmask), \"d\" (hmask) \\ : \"memory\") static inline void copy_xregs_to_kernel ( struct xregs_state * xstate ) { u64 mask = -1 ; u32 lmask = mask ; u32 hmask = mask >> 32 ; int err ; WARN_ON ( ! alternatives_patched ); XSTATE_XSAVE ( xstate , lmask , hmask , err ); /* We should never fault when copying to a kernel buffer: */ WARN_ON_FPU ( err ); } From SDM on XSAVE : Use of a destination operand not aligned to 64-byte boundary (in either 64-bit or 32-bit modes) results in a general-protection (#GP) exception. In 64-bit mode, the upper 32 bits of RDX and RAX are ignored. %rdi is struct xregs_state *xstate in above code. Thus, check if xstate if 64-bytes aligned. Of course, it is not: [10894.999997] copy_xregs_to_kernel CPU6 xstate: ffff88083e4c8c38 Hehe. Criminal identified. But why? The xstate structure is already marked as __attribute__(aliged 64) in the code. It is the task_struct , which is NOT 0x40 aligned. But god why? Because we currently use kmalloc to allocate new task_struct, whose minimum alignment is 8 bytes . Anyway, use __alloc_pages instead. Such an deeply hidden bug. Took me almost a month to find out.","title":"Solved FPU BUG"},{"location":"lego/log/log-02-2018/#ib","text":"Seen this during boot (at both P and M, although lego continue running correctly): [ 54017.712533 ] *** NodeID Hostname LID QPN [ 54017.770776 ] *** ------------------------------------- [ 54017.834220 ] *** 0 wuklab12 13 72 [ 54017.892462 ] *** 1 wuklab14 16 72 <--- [ 54017.955906 ] *** 2 wuklab16 20 74 [ 54018.014149 ] *** [ 54074.552844 ] *** Start establish connection ( mynodeid : 1 ) [ 54102.554407 ] ib_process_mad mad_ifc fails [ 54130.960691 ] *** recvpollcq runs on CPU2 [ 54131.070918 ] *** Successfully built QP for node 0 [ LID : 13 QPN : 72 ] [ 54131.152936 ] *** Successfully built QP for node 2 [ LID : 20 QPN : 74 ] [ 54161.228245 ] *** FIT layer ready to go ! [ 54161.272034 ] *** Another one: [ 1966.930409 ] *** [ 1966.951210 ] *** FIT_initial_timeout_s : 30 [ 1967.002168 ] *** FIT_local_id : 0 [ 1967.052087 ] *** [ 1967.072887 ] *** NodeID Hostname LID QPN [ 1967.131126 ] *** ------------------------------------- [ 1967.194567 ] *** 0 wuklab12 13 72 <--- [ 1967.258005 ] *** 1 wuklab14 16 72 [ 1967.316244 ] *** 2 wuklab16 20 74 [ 1967.374484 ] *** [ 2032.926448 ] *** Start establish connection ( mynodeid : 0 ) [ 2032.996068 ] Fail to modify qp [ 6 ] [ 2033.032572 ] Fail to do client_init_ctx [ 2033.077287 ] client_establish_conn : ctx ( null ) fail to init_interface [ 2033.164646 ] ibapi_establish_conn : ctx ( null ) fail to init_interface [ 2033.250967 ] *** [ 2035.620167 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000004 [ 2035.713763 ] IP : [ < ffffffff8105c589 > ] client_send_reply_with_rdma_write_with_imm + 0x69 / 0x3b0 [ 2035.812562 ] PGD 0 [ 2035.836482 ] Oops : 0002 [ # 1 ] SMP PROCESSOR [ 2035.884321 ] CPU : 0 PID : 1 Comm : kernel_init 4.0.0 - lego - ys + # 253 [ 2035.955041 ] RIP : 0010 : [ < ffffffff8105c589 > ] [ < ffffffff8105c589 > ] client_send_reply_with_rdma_write_with_imm + 0x69 / 0x3b0 ... [ 2037.313267 ] < TSK > [ 2037.336146 ] [ < ffffffff8105a377 > ] ibapi_send_reply_timeout + 0x57 / 0x70 [ 2037.411025 ] [ < ffffffff81033d24 > ] ? net_send_reply_timeout + 0x94 / 0x132 [ 2037.486944 ] [ < ffffffff81033d24 > ] net_send_reply_timeout + 0x94 / 0x132","title":"IB"},{"location":"lego/log/log-02-2018/#pcache","text":"Running word_count-pthread, with 100MB dataset, finally got some reasonable bug: [ 54211.243181 ] pcache_evict_line () : pset : ffff88207f86e3c0 , for uva : 0x7ffff1b8f000 [ 54211.385654 ] pcache : ffff88207f86e3a8 mapcount : 8 refcount : 0 flags :() [ 54211.510447 ] pcache dumped because : PCACHE_BUG_ON_PCM ( ! PcacheLocked ( pcm )) [ 54212.080336 ] BUG : failure at managers / processor / pcache / evict . c : 240 / pcache_evict_line () ! [ 54212.664785 ] Kernel Panic - not syncing : BUG ! [ 54212.715742 ] CPU : 8 PID : 81 Comm : word_count - pthr 4.0.0 - lego - ys + # 252 ... [ 54213.391706 ] < TSK > [ 54213.414584 ] [ < ffffffff81024180 > ] panic + 0xc2 / 0xeb [ 54213.524818 ] [ < ffffffff8101b81c > ] ? task_tick_rt + 0x2c / 0xd0 [ 54213.589295 ] [ < ffffffff81018f75 > ] ? scheduler_tick + 0x55 / 0x60 [ 54213.655850 ] [ < ffffffff81016625 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 54213.728647 ] [ < ffffffff81006634 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 54213.801443 ] [ < ffffffff8100e22a > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 54213.879439 ] [ < ffffffff8101256d > ] ? printk + 0x11d / 0x1b0 [ 54214.103027 ] [ < ffffffff8102ecf4 > ] pcache_evict_line + 0x134 / 0x220 [ 54214.172703 ] [ < ffffffff8102c6ae > ] pcache_alloc + 0x22e / 0x2e0 [ 54214.237179 ] [ < ffffffff8102be0a > ] common_do_fill_page + 0x2a / 0x1f0 [ 54214.307895 ] [ < ffffffff8102baf0 > ] ? move_page_tables + 0x4c0 / 0x4c0 [ 54214.378612 ] [ < ffffffff8102c172 > ] pcache_handle_fault + 0x1a2 / 0x3a0 [ 54214.450367 ] [ < ffffffff8100fc02 > ] do_page_fault + 0xa2 / 0x1a0 [ 54214.514843 ] [ < ffffffff8100d85f > ] page_fault + 0x1f / 0x30 [ 54214.575161 ] [ < ffffffff81034842 > ] ? copy_user_enhanced_fast_string + 0x2 / 0x10 [ 54214.657316 ] [ < ffffffff81032368 > ] ? seq_read + 0x248 / 0x360 [ 54214.719714 ] [ < ffffffff810307af > ] sys_read + 0x3f / 0xc0 [ 54214.777949 ] [ < ffffffff81030770 > ] ? sweep_pset_lru + 0x220 / 0x220 [ 54214.846587 ] [ < ffffffff8100e619 > ] do_syscall_64 + 0x69 / 0xf0 [ 54214.910022 ] [ < ffffffff8100d4ec > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 54214.985939 ] < EOT > Another one: [ 735.393244 ] pcache_evict_line () : pset : ffff88207f86e3c0 , for uva : 0x7ffff1b8fd90 [ 735.537804 ] pcache : ffff88207f86e3a8 mapcount : 8 refcount : 0 flags :() [ 735.663642 ] pcache dumped because : PCACHE_BUG_ON_PCM ( ! PcacheLocked ( pcm )) Do note this happens after computation. This happens when phoenix create a lot threads to sort the results. Both bug happen to the same set, same user page. The pcache is clearly corrupted: mapcount:8, refcount:0, flags:(). Come back after dinner. Remember to check altenative, cause the XSAVE above should be XSAVEOPT. Make sure it does not override other memory. Also, check linker script. Do not forget to link any sections. Another several bug logs in wuklab13 and wuklab15: 022318-* . I\u2019m really tired today after fixing the FPU bug. But I\u2019m also pretty confident pcache is something I\u2019m able to debug. Even thought it is hard in SMP case. Anyway, I gonna call for the day.","title":"pcache"},{"location":"lego/log/log-02-2018/#0222-thur","text":"context switch fpu signal compat check, all good. make current use percpu current_task, so all code in Lego is consistent. checked entry_SYSCALL-64 again, which looks good to me. The only concern is rsp_scratch and current_top_of_stack , which are per-cpu variables. If these per-cpu is setup wrong, then we are doomed. Also check if per-cpu is all cleared up? try big syscall lock does x86 has to use different kernel stacks? Interrupt is using different stack in Linux, has to do so??? check current is correct. compare with old implementation. First of all, FPU is definitely functional for now. Since I replaced the current macro today, I add some code to check if this current matches our old implementation: static __always_inline struct task_struct *get_current(void) { return this_cpu_read_stable(current_task); } //#define current get_current() #define current \\ ({ \\ struct task_struct *old = current_thread_info()->task; \\ struct task_struct *new = get_current(); \\ \\ if (old != new) { \\ printk(\"%s:%d() cpu:%d old:%pS %d %s new:%pS %d %s\\n\", \\ __func__, __LINE__, smp_processor_id(), old, old->pid, old->comm, \\ new, new->pid, new->comm); \\ BUG(); \\ } \\ get_current(); \\ }) Combined with some FPU warning, it is now like this: [ 3273.748819 ] CPU : 5 PID : 32 sys_clone + 0x0 / 0x30 [ 3273.800808 ] alloc_task_struct_node : size : 740 ffff88107e831838 [ 3273.869451 ] arch_dup_task_struct () CPU5 current : 32 new : ffff88107e831838 old : ffff88107e827838 32 [ 3273.975533 ] ------------ [ cut here ] ------------ [ 3274.030651 ] WARNING : CPU : 5 PID : 32 at . / arch / x86 / include / asm / fpu / internal . h : 354 fpu__copy + 0xe2 / 0x310 [ 3274.140895 ] CPU : 5 PID : 32 Comm : word_count - pthr 4.0.0 - lego - ys - gdbe6dbe - dirty # 249 [ 3274.231377 ] Stack : [ 3274.255298 ] ffff88107e82fd68 ffffffff81016dbf 00000000f fffffff 0000000000000000 [ 3274.342659 ] 00000000f fffffff 0000000000000000 ffff88107e831bf8 ffff88107e831c38 [ 3274.430021 ] ffff88107e831838 000000207f e64000 ffff88107e82fd78 ffffffff810170af [ 3274.517382 ] ffff88107e82fdc0 ffffffff8100b052 0000000000000020 ffff88107e831838 [ 3274.604745 ] ffff88107e827838 ffff88107e827838 ffff88107e831838 ffff88107e827838 [ 3274.692106 ] Call Trace : [ 3274.721229 ] < TSK > [ 3274.744109 ] [ < ffffffff81016dd8 > ] __warn . constprop .0 + 0xe8 / 0x3b0 [ 3274.813790 ] [ < ffffffff810170af > ] warn_slowpath_null + 0xf / 0x20 [ 3274.881391 ] [ < ffffffff8100b052 > ] fpu__copy + 0xe2 / 0x310 [ 3274.941713 ] [ < ffffffff810012e4 > ] arch_dup_task_struct + 0x84 / 0x120 [ 3275.013475 ] [ < ffffffff81022c10 > ] copy_process + 0x160 / 0x1e60 [ 3275.078996 ] [ < ffffffff81024936 > ] do_fork + 0x26 / 0x140 [ 3275.137238 ] [ < ffffffff81024af0 > ] ? sys_vfork + 0x40 / 0x40 [ 3275.198599 ] [ < ffffffff81024af0 > ] ? sys_vfork + 0x40 / 0x40 [ 3275.259960 ] [ < ffffffff81024b19 > ] sys_clone + 0x29 / 0x30 [ 3275.319242 ] [ < ffffffff81012314 > ] do_syscall_64 + 0x84 / 0x240 [ 3275.383723 ] [ < ffffffff8101106c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 3275.459645 ] < EOT > [ 3275.482526 ] --- [ end trace 0000000000000000 ] --- [ 3275.537648 ] wake_up_new_task CPU5 task : ffff88107e831838 , dest_cpu : 6 current : 32 [ 3275.623970 ] SMP IPI : reschedule_interrupt () CPU ( 6 ) PID ( 0 ) [ 3275.739412 ] do_general_protection : 186 () cpu : 6 old : 0xffff88107e831838 33 word_count - pthr new : 0xffff88107fcaf008 0 swapper / 6 [ 3275.871493 ] ------------ [ cut here ] ------------ [ 3275.926614 ] BUG : failure at arch / x86 / kernel / traps . c : 186 / do_general_protection () ! [ 3276.015018 ] Kernel Panic - not syncing : BUG ! [ 3276.065978 ] panic : 107 () cpu : 6 old : 0xffff88107e831838 33 word_count - pthr new : 0xffff88107fcaf008 0 swapper / 6 Based on the switch code: __switch_to ( struct task_struct * prev_p , struct task_struct * next_p ) { this_cpu_write ( current_task , next_p ); /* Reload sp0 This changes current_thread_info(). */ load_sp0 ( tss , next ); } Based on log line 30, load_sp0() already happened, which means this_cpu_write(..) happened too. If this_cpu_write(..) happened, then log line 30\u2019s new should have been updated to 0xffff88107e831838 . Something wrong with percpu?","title":"02/22 Thur"},{"location":"lego/log/log-02-2018/#0221-wed","text":"irq_regs, old code, check signal frame, and fpu hook together Done in_interrupt() , it is empty, TODO check arch/x86/Makefile, it introduce a lot FPU flags. added more than 4K lines today. Damn FPU. Ugh go home sleep.","title":"02/21 Wed"},{"location":"lego/log/log-02-2018/#0220-tue-cloudy","text":"Not too many Sunny days recently. Well, continue yesterday\u2019s work. I don\u2019t think I can easily find out why so many /proc/memoinfo open happened. Instead, I\u2019m trying to enable the flush_thread in P\u2019s exec code. During the way, I found some issue related to __ARCH_HAS_SA_RESTORER in signal code. I need to check if these x86 macros are defined, but lego does not port them. Well, it turns out flush_thread does not make too much difference. Next I\u2019m going to try to disable exit_thread , which uses fpu__drop() . Hmm, disable exit_thread also does not work.","title":"02/20 Tue Cloudy"},{"location":"lego/log/log-02-2018/#0219-mon-rainy","text":"It is another week. I can not deny I\u2019m a little tired about the bug. Tried so many possible solutions, but none of them work. Well, today I first need to test the vma changes (pgoff and anon_vma) thing. Especially the vma merge and split. This morning I fixed a bug in kernel_init process: make kernel_init able to run all possible CPUs. Because the first user process is forked from kernel_init, it is quite important that it gets the right cpu affinity: static int kernel_init ( void * unused ) { ... set_cpus_allowed_ptr ( current , cpu_possible_mask ); ... } Well, interestingly, the unmodified word_count-pthread succeed with 50MB dataset\u2026 with or without any DEBUG option! Amazing! I need to find out why the cpus_allowed becomes 0 at the beginning of kernel_init. Because init_task actually has: . cpus_allowed = CPU_MASK_ALL , . nr_cpus_allowed = NR_CPUS , Things to do next: check why the cpus_allowed changed check why word_count-pthread open /dev/../cpu so many times. Anything wrong with our copy_files , or open, close? here is an idea, to verify if FPU code is correct, run some scientific benchmarks. Okay, findings: cpus_allowd is fine, it is reset inside sched_init() , when it tries make the init_task as the idle thread. Thus it is reasonable to set cpus_allowed again at kernel_init thread. And it should NOTHING to do with the bug. about the second, check the following log: [ 11838.364543 ] STDOUT : --- [ Wordcount : Running ... ] --- [ 11838.422886 ] STDOUT : --- [ ] --- [ 11838.463445 ] SYSC_open ( cpu5 pid : 32 ) : f_name : / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count_datafiles / word_50MB . txt , flags : 0 , mode : 900 [ 11838.619460 ] SYSC_open ( cpu5 pid : 32 ) : fd : 3 [ 11838.667406 ] SYSC_open ( cpu5 pid : 32 ) : f_name : / sys / devices / system / cpu / online , flags : 80000 , mode : 0 [ 11838.773351 ] SYSC_open ( cpu5 pid : 32 ) : fd : 4 [ 11838.821239 ] seq_file : dest_uva : 00007f ffffffc8d0 , nr_chars : 5 string : [ 0-23 ] [ 11838.913791 ] SYSC_close ( cpu5 pid : 32 ) : fd : 4 [ 11838.962622 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 11840.223255 ] STDOUT : --- [ Word Count : Computation Completed 1.555581 sec ] --- [ 11840.309678 ] SYSC_open ( cpu5 pid : 32 ) : f_name : / sys / devices / system / cpu / online , flags : 80000 , mode : 0 [ 11840.415754 ] SYSC_open ( cpu5 pid : 32 ) : fd : 4 [ 11840.463593 ] seq_file : dest_uva : 00007f ffffffc8a0 , nr_chars : 5 string : [ 0-23 ] [ 11840.556147 ] SYSC_close ( cpu5 pid : 32 ) : fd : 4 [ 11840.605024 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 11840.677821 ] STDOUT : --- [ THe number of processors is 24 \u00f4 ] --- [ 11840.753769 ] SYSC_open ( cpu7 pid : 80 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11840.844212 ] SYSC_open ( cpu19 pid : 92 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11840.935728 ] SYSC_open ( cpu7 pid : 80 ) : fd : 4 [ 11840.983567 ] SYSC_open ( cpu19 pid : 92 ) : fd : 5 [ 11841.032444 ] seq_file : dest_uva : 00007f fff444c000 , nr_chars : 172 string : [ MemTotal : 115355128 kB MemFree : 115355128 kB MemAvailable : 115355128 kB DirectMap4k : 5812 kB DirectMap2M : 1861632 kB DirectMap1G : 134217728 kB ] [ 11841.305953 ] seq_file : dest_uva : 00007f fff444b000 , nr_chars : 172 string : [ MemTotal : 115355128 kB MemFree : 115355128 kB MemAvailable : 115355128 kB DirectMap4k : 5812 kB DirectMap2M : 1861632 kB DirectMap1G : 134217728 kB ] [ 11841.579460 ] SYSC_close ( cpu7 pid : 80 ) : fd : 4 [ 11841.628339 ] SYSC_close ( cpu19 pid : 92 ) : fd : 5 [ 11841.678257 ] SYSC_close () : [ 4 ] -> [ / proc / meminfo ] [ 11841.733375 ] SYSC_close () : [ 5 ] -> [ / proc / meminfo ] [ 11841.788493 ] SYSC_open ( cpu18 pid : 91 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11841.880008 ] SYSC_open ( cpu6 pid : 102 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11841.971523 ] SYSC_open ( cpu12 pid : 85 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11842.063040 ] SYSC_open ( cpu0 pid : 97 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11842.153516 ] SYSC_open ( cpu14 pid : 87 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11842.245032 ] SYSC_open ( cpu16 pid : 89 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11842.336548 ] SYSC_open ( cpu4 pid : 100 ) : f_name : / proc / meminfo , flags : 80000 , mode : 1 b6 [ 11842.428064 ] SYSC_open ( cpu16 pid : 89 ) : fd : 9 [ 11842.476942 ] SYSC_open ( cpu4 pid : 100 ) : fd : 10 [ 11842.526860 ] seq_file : dest_uva : 00007f fff444c000 , nr_chars : 172 string : [ MemTotal : 115355128 kB MemFree : 115355128 kB MemAvailable : 115355128 kB DirectMap4k : 5812 kB DirectMap2M : 1861632 kB DirectMap1G : 134217728 kB ] [ 11842.800368 ] seq_file : dest_uva : 00007f fff444b000 , nr_chars : 172 string : [ MemTotal : 115355128 kB MemFree : 115355128 kB MemAvailable : 115355128 kB DirectMap4k : 5812 kB DirectMap2M : 1861632 kB DirectMap1G : 134217728 kB ] [ 11843.073877 ] SYSC_close ( cpu16 pid : 89 ) : fd : 9 However, in a normal Linux exeution: strace - C - o strace_2 . / word_count - pthread . / word_count_datafiles / word_50MB . txt % time seconds usecs / call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 86.41 0.052074 1736 30 futex 6.89 0.004151 67 62 munmap 2.47 0.001490 17 88 mmap 2.12 0.001278 14 93 clone 1.51 0.000912 14 64 mprotect 0.19 0.000117 7 16 write 0.15 0.000092 46 2 open $ cat strace_2 | grep open open ( \"./word_count_datafiles/word_50MB.txt\" , O_RDONLY ) = 3 open ( \"/sys/devices/system/cpu/online\" , O_RDONLY | O_CLOEXEC ) = 4 It opened the /proc/meminfo for way too many times. In the normal Linux execution, this should not happen. Is it because our meminfo is faked, so glibs is complaining? But why it does not open meminfo while running in Linux? Or does our entry assembly messed up some stuff in stack, so the return path changed? oh, about the FPU. It reminds our flush_thread function actually has an issue before. When I enabled this function during loading in P, the P will crash. Within flush_thread , there is a fpu_clear !!! So, check this tomorrow! (12:00am, need to go home)","title":"02/19 Mon Rainy"},{"location":"lego/log/log-02-2018/#0218-sun-sunny","text":"It is a nice day. Yesterday I\u2019ve changed one line of code in mmap code path: change anonymous vma\u2019s pgoff from some value to 0. The result is I got several succeed work-count-pthread(bind to one core) testing. However, it still fail with unmodified word-count-pthread. It brings me to inspect pgoff manipulation code and all mmap.c code. We ported everything from linux without almost zero modification. That means we ported all those useless anon_vma and pgoff code, which is used a lot by vma_merge, vma_split code. The thing is: our memory manager, our vma code do not need such anon_vma structure, and do not maintain pgoff. Thus, I\u2019m a little bit worried linux code may doing some crazy behind our back: mess vma and pages, then pcache miss gets some wrong pages Well. Lego does not use anon_vma , and pgoff should only be used by file-backed vma. So, I decided to remove anon_vma from our code, and make sure pgoff is used properly. Of course, the goal is to make vma_merge, split, copy, do the things we intended. Lesson learned.","title":"02/18 Sun Sunny"},{"location":"lego/log/log-02-2018/#0217-sat-snowy","text":"Fixed the bss bug. It comes from loader. We did not implement the lego_clear_user function, so some part of bss is non-zero. Bad news is word_count-pthread still fail at same fpu instruction. Have to look into memory code more. This is actually a fun debugging story. We should always add TODO or XXX or some warnings to unfinished code, no matter what. Lesson learned.","title":"02/17 Sat Snowy"},{"location":"lego/log/log-02-2018/#0216-fri-cloudy","text":"Yilun found a major loader bug yesterday: the .bss section variables are not 0, in the iozone benchmark. I did not encounter this issue before with simple test program. This is pretty serious.","title":"02/16 Fri Cloudy"},{"location":"lego/log/log-02-2018/#0215-thur-rainy","text":"Today is Chinese New Year. Line 7 and 8 show the uva belong to the same page. Need to revisit get_arg_pages etc functions. [ 108.393991] handle_p2m_execve(): pid:22,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread [ 108.395255] argc[0] (len: 65): /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread [ 108.396329] argc[1] (len: 82): /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt [ 108.397530] envc[0] (len: 7): HOME=/ [ 108.398069] envc[1] (len: 11): TERM=linux [ 108.398640] __bprm_mm_init vma: ffff88083effe6b8 [ 108.399226] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffefed [ 108.399949] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffef94 Well, this is 100% fine. I wrote this loader code long time ago and need some time to pickup. So, after I read the loader code, especially the copy_strings function, I found this is okay. Because copy_strings will be invoked three times, so the faultin_page basically will be invoked at least three times. That is why it went to that pte fault handling code. Although actually I think copy_strings should not use faultin_page , instead, it should use get_user_pages , which will walk through the pgtable first, then went to handle_lego_mm_fault .","title":"02/15 Thur Rainy"},{"location":"lego/log/log-02-2018/#0214-wed-rainy","text":"Hmm, tried to make kmalloc behave as kzalloc, and bind all threads to one core, still gave the same old bug: 42731a: f3 0f 6f 16 movdqu (%rsi),%xmm2 [93182.657376] word_count-pthr[85] general protection ip:42731a sp:7fffe3ffed28 error:0 [93182.747959] CPU: 8 PID: 85 Comm: word_count-pthr 4.0.0-lego+ #170 [93182.820758] RIP: 0033:[<000000000042731a>] [<000000000042731a>] 0x42731a [93182.901878] RSP: 002b:00007fffe3ffed28 EFLAGS: 00010283 [93182.965317] RAX: 000000000000001f RBX: 00007ffff001b010 RCX: 0000000000000005 [93183.050596] RDX: 0000000000000000 RSI: 5345485355420045 RDI: 00007ffff294791f [93183.135876] RBP: 00007ffff294791f R08: 000000000000ffff R09: 0000000000000008 [93183.221156] R10: fffffffffffff048 R11: 00000000004acfc0 R12: 0000000000001cde [93183.306435] R13: 00000000006e4a8c R14: 0000000000001cd7 R15: 0000000000001cda [93183.391716] FS: 00007fffe3fff700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000 [93183.488434] CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [93183.557075] CR2: 00007ffff27a4000 CR3: 000000107e924000 CR4: 00000000000406a0 427377: 66 0f 6f 17 movdqa (%rdi),%xmm2 [93180.527248] word_count-pthr[93]: segfault at 0x0 ip 0000000000427377 sp 00007fffdfff6d28 error 4 [93180.630314] CPU: 8 PID: 93 Comm: word_count-pthr 4.0.0-lego+ #170 [93180.703114] RIP: 0033:[<0000000000427377>] [<0000000000427377>] 0x427377 [93180.784234] RSP: 002b:00007fffdfff6d28 EFLAGS: 00010297 [93180.847674] RAX: 0000000000000000 RBX: 000000000073c4c0 RCX: 000000000000000d [93180.932953] RDX: 000000000000ffff RSI: 00007ffff4999070 RDI: 0000000000000000 [93181.018233] RBP: 00007ffff499907d R08: 000000000000ffff R09: 0000000000000000 [93181.103513] R10: 0000000000427760 R11: 00007ffff49982c0 R12: 0000000000000118 [93181.188791] R13: 00000000006e4aac R14: 0000000000000116 R15: 0000000000000117 [93181.274072] FS: 00007fffdfff7700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000 [93181.370790] CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [93181.439430] CR2: 0000000000000000 CR3: 000000107e924000 CR4: 00000000000406a0 Tried several ways to ensure memory safety. It still failed even if I enabled all of them. So, I guess the memory safety is ensured? Still some other things? force alloc_pages to use __GFP_ZERO make kmalloc behave as kzalloc make kfree empty I also suspect munmap may free extra wrong pgtable entries. Although I\u2019ve went through all the code and checked, but in addition to the above things, I\u2019m going to: make munmap dummy (no p2m_munmap, return 0 directly) Failed. Next, I\u2019m going to: add checksum for every page transferred across network. add warning for unnormal cases Bang! I found something while running P+M: [ 115.727597 ] Memory - component manager is up and running . [ 116.691723 ] handle_p2m_fork () : nid : 0 , pid : 22 , tgid : 22 , parent_tgid : 1 [ 116.697038 ] handle_p2m_fork () : reply : 0 : OKAY [ 116.791088 ] handle_p2m_execve () : pid : 22 , argc : 2 , envc : 2 , file : / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count - pthread [ 116.792357 ] argc [ 0 ] ( len : 65 ) : / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count - pthread [ 116.793439 ] argc [ 1 ] ( len : 82 ) : / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count_datafiles / word_100MB . txt [ 116.794653 ] envc [ 0 ] ( len : 7 ) : HOME =/ [ 116.795196 ] envc [ 1 ] ( len : 11 ) : TERM = linux [ 116.795772 ] __bprm_mm_init vma : ffff88083effe6b8 [ 116.796209 ] faultin_page vma : ffff88083effe6b8 [ 116.796729 ] faultin_page vma : ffff88083effe6b8 [ 116.797150 ] handle_pte_fault vma : ffff88083effe6b8 entry : 0xffff88083e8c1067 [ 116.798044 ] pte : ffff88083e8c0ff0 pfn : 0x8083e8c1 flags :( present | writable | user | accessed | dirty | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 116.799462 ] ------------ [ cut here ] ------------ [ 116.800049 ] WARNING : CPU : 4 PID : 15 at managers / memory / vm / fault . c : 148 handle_lego_mm_fault + 0x4d8 / 0x550 [ 116.801148 ] CPU : 4 PID : 15 Comm : mc - manager 4.0.0 - lego + # 78 [ 116.801818 ] Stack : [ 116.802179 ] ffff88083e893c50 ffffffff8100e827 00007f ffffffef94 ffff88083effe6b8 [ 116.803283 ] ffff88083e894008 ffff88083e8c1067 ffff88083e893c60 ffffffff8100e91f [ 116.804387 ] ffff88083e893cf0 ffffffff8102b008 0000000000000031 ffff88083e893cf0 [ 116.805488 ] 00000000000002 96 00003f ffffe00000 ffff800000000067 ffff88083e893d50 [ 116.806590 ] ffff880000000001 ffffffff81066798 ffff88083effe6b8 ffff88083e893d50 [ 116.807691 ] Call Trace : [ 116.808087 ] < TSK > [ 116.808448 ] [ < ffffffff8100e836 > ] __warn . constprop .0 + 0xa6 / 0x100 [ 116.809126 ] [ < ffffffff8100e91f > ] warn_slowpath_null + 0xf / 0x20 [ 116.809802 ] [ < ffffffff8102b008 > ] handle_lego_mm_fault + 0x4d8 / 0x550 [ 116.810505 ] [ < ffffffff8102cfe3 > ] faultin_page + 0x43 / 0xb0 [ 116.811131 ] [ < ffffffff8102dab1 > ] copy_strings . isra .1 + 0xe1 / 0x130 [ 116.811819 ] [ < ffffffff8102dd1e > ] exec_loader + 0x21e / 0x350 [ 116.812457 ] [ < ffffffff8102680a > ] handle_p2m_execve + 0x1aa / 0x290 This is a temporary stack vma that loader created for saving argv and envp. So, this vma was created here: static int __bprm_mm_init ( struct lego_binprm * bprm ) { ... bprm -> vma = vma = kzalloc ( sizeof ( * vma ), GFP_KERNEL ); ... } And then copy_strings will call faultin_page to populate a page for a specific user virtual adddress: int faultin_page ( struct vm_area_struct * vma , unsigned long start , unsigned long flags , unsigned long * kvaddr ) { ... ret = handle_lego_mm_fault ( vma , start , flags , kvaddr ); ... } Eventually, the handle_lego_mm_fault will call handle_pte_fault : static int handle_pte_fault ( struct vm_area_struct * vma , unsigned long address , unsigned int flags , pte_t * pte , pmd_t * pmd , unsigned long * mapping_flags ) { ... if ( ! pte_present ( entry )) { ... } pr_info ( \"%s vma: %p entry: %#lx \\n \" , FUNC , vma , entry . pte ); dump_pte ( pte , NULL ); WARN_ON_ONCE ( 1 ); ... } Apparently, pte is wrong! But I don\u2019t have time today. Continue tomorrow. Hmm forgot that we are saving kernel virtual addresses in the pte. Just take a quick look at the lego_pud_alloc things, seems will have some issues. I defenitly need to check all these stuff tomorrow. I\u2019ve not touch this part for too long!","title":"02/14 Wed Rainy"},{"location":"lego/log/log-02-2018/#0213-tue-sunny","text":"Checking our SLOB allocator today. So I found Yutong\u2019s code is using set_page_private when slob get a new page from buddy. This private field is only intended to be used by buddy to record the order . This mixed usage will confuse buddy and create bug. Even though I removed the set_page_private ( page , 0 ) after free_page , word_count-pthread still fails. Damn.","title":"02/13 Tue Sunny"},{"location":"lego/log/log-02-2018/#0212-mon-cloudy","text":"Add this commit 4cb3a8b6a943c90714fd9bb5e5465ee315f0aa30 : memory: Use kzalloc instead of kmalloc in __bprm_mm_init (loader) This was an potentionl bug that was not triggered previously. It is simply because kmalloc'ed vma contains some garbage area, while later in the pgfault code, we use if (vma->vm_ops && vma->vm_ops->fault) ... to check if it is an file-backed fault. Fortunately the vma->vm_ops happens to have some leftover value. So this bug was triggered. This actually reminds me that this is a series of potential bugs! Even though before I've added things like force GFP_ZERO in all physical page allocation, I missed the kmalloc's case! The story is: I patched the stop_machine code today, and tried to run code with P+M on VM, everything works fine. However, when I tried to run the new code with P+M+S on physical machine, M crashed at a very weird point: [ 7791.998168] handle_p2m_execve(): pid:81,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread [ 7792.129312] BUG: unable to handle kernel NULL pointer dereference at 0000000000000031 [ 7792.222889] IP: [<ffffffff8102c180>] handle_lego_mm_fault+0x160/0x4b0 [ 7792.299842] PGD 0 [ 7792.323760] Oops: 0000 [#1] PREEMPT SMP MEMORY [ 7792.376794] CPU: 4 PID: 79 Comm: mc-manager 4.0.0-lego+ #29 [ 7792.443349] RIP: .. [<ffffffff8102c180>] handle_lego_mm_fault+0x160/0x4b0 ...... .... [ 7793.750506] Call Trace: [ 7793.779623] <TSK> [ 7793.802501] [<ffffffff810053f4>] ? apic_timer_interrupt+0x54/0x90 [ 7793.875295] [<ffffffff8102e469>] faultin_page+0x9/0x70 [ 7793.936649] [<ffffffff8102ef01>] copy_strings.isra.1+0xe1/0x130 [ 7794.007362] [<ffffffff8102f11e>] exec_loader+0x1ce/0x340 [ 7794.070796] [<ffffffff81027def>] handle_p2m_execve+0x12f/0x200 [ 7794.140469] [<ffffffff810274fb>] mc_manager+0x1ab/0x2b0 [ 7794.202864] [<ffffffff81027350>] ? bitmap_fill+0x33/0x33 [ 7794.266298] [<ffffffff8101c6b7>] kthread+0x107/0x130 [ 7794.325572] [<ffffffff8101c5b0>] ? __kthread_parkme+0x90/0x90 [ 7794.394205] [<ffffffff8100b462>] ret_from_fork+0x22/0x30 So faulting source code is: static int handle_pte_fault ( struct vm_area_struct * vma , unsigned long address , unsigned int flags , pte_t * pte , pmd_t * pmd ) { .... if ( vma -> vm_ops && vma -> vm_ops -> fault ) return do_linear_fault ( vma , address , flags , pte , pmd , entry ) .... Something wrong with vma ? At this loader stage, this vma is a temporaty stack vma created for saving argv and envp . So I look back into the code that created this vma: managers / memory / loader / core . c : static int __bprm_mm_init ( struct lego_binprm * bprm ) { int err ; struct vm_area_struct * vma = NULL ; struct lego_mm_struct * mm = bprm -> mm ; bprm -> vma = vma = kmalloc ( sizeof ( * vma ), GFP_KERNEL ); if ( ! vma ) return - ENOMEM ; The code after this does NOT do necessary cleanup. The vm_ops happens to have some garbage value from last user. So it is not 0, so the above vma->vm_ops is true, and it will try to read vma->vm_ops->fault . And that, my friend, is where garbage turns into crash. This presents a series of potential bugs. Ugh, memory safety !","title":"02/12 Mon Cloudy"},{"location":"lego/log/log-02-2018/#0209-fri-cloudy","text":"Tried to modify Phoneix code: replace realloc with malloc+mempcy . Thus the mremap syscall is avoided, but it still has general protection fault. Same with yesterday, corrupted at __strcmp_sse42 , with corrupted RSI or RDI . So I guess it is not about mremap itself at all. I will follow yesterday\u2019s checking list.","title":"02/09 Fri Cloudy"},{"location":"lego/log/log-02-2018/#0208-thur-cloudy","text":"00000000004272d0 <__strcmp_sse42>: 4272d0: 89 f1 mov %esi,%ecx 4272d2: 89 f8 mov %edi,%eax 4272d4: 48 83 e1 3f and $0x3f,%rcx 4272d8: 48 83 e0 3f and $0x3f,%rax 4272dc: 83 f9 30 cmp $0x30,%ecx 4272df: 77 3f ja 427320 <__strcmp_sse42+0x50> 4272e1: 83 f8 30 cmp $0x30,%eax 4272e4: 77 3a ja 427320 <__strcmp_sse42+0x50> 4272e6: f3 0f 6f 0f movdqu (%rdi),%xmm1 * 4272ea: f3 0f 6f 16 movdqu (%rsi),%xmm2 4272ee: 66 0f ef c0 pxor %xmm0,%xmm0 4272f2: 66 0f 74 c1 pcmpeqb %xmm1,%xmm0 4272f6: 66 0f 74 ca pcmpeqb %xmm2,%xmm1 4272fa: 66 0f f8 c8 psubb %xmm0,%xmm1 4272fe: 66 0f d7 d1 pmovmskb %xmm1,%edx 427302: 81 ea ff ff 00 00 sub $0xffff,%edx 427308: 0f 85 42 0d 00 00 jne 428050 <__strcmp_sse42+0xd80> 42730e: 48 83 c6 10 add $0x10,%rsi 427312: 48 83 c7 10 add $0x10,%rdi 427316: 66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 42731d: 00 00 00 427320: 48 83 e6 f0 and $0xfffffffffffffff0,%rsi 427324: 48 83 e7 f0 and $0xfffffffffffffff0,%rdi 427328: ba ff ff 00 00 mov $0xffff,%edx 42732d: 45 31 c0 xor %r8d,%r8d 427330: 83 e1 0f and $0xf,%ecx 427333: 83 e0 0f and $0xf,%eax 427336: 66 0f ef c0 pxor %xmm0,%xmm0 42733a: 39 c1 cmp %eax,%ecx 42733c: 74 32 je 427370 <__strcmp_sse42+0xa0> 42733e: 77 07 ja 427347 <__strcmp_sse42+0x77> 427340: 41 89 d0 mov %edx,%r8d 427343: 91 xchg %eax,%ecx 427344: 48 87 f7 xchg %rsi,%rdi * 427347: 66 0f 6f 17 movdqa (%rdi),%xmm2 (RDI: 0000000000000000) Frustrating! What is wrong with multithread program? Because of broken FPU-switch code? of inappropriate TLB flush? of IB corrupts memory? of what? ugh? I\u2019m done with this random guess and frustrated general protection or segfault, I need to first make sure underlying kernel is 100% percent correct, this is a checking list: fpu save/restore always fail at some XMM instruction always with corrupted RDI or RSI switch_to_asm %gs and %fs switch_mm (pgd) stack frame set_arch_tls (%fs) glibc\u2019s way of using per thread data some cpu may miss tlb flush kernel entry/exit assembly current_task macro stack_stratch per-cpu data in entry.S futex clear_tid set_tid shared mm robust list interrupts vector array APIC setup IO-APIC timer interrupt cpu_init and Trampoline faked kernel version P side pgfault handling code (SMP) and M side pgfault handling (SMP) mremap, munmap check pgtable boundary In all, check SMP implications Is there any code, that is solely used to test if the underlying kernel has appropriate behaviors? Like glibc test code? How to protect kernel virtual memory? Any existing solutions in Linux? What is the implication of multiple CPU entering kernel at the same time? How can it corrupt user pages? Maybe: kernel entry code, per-cpu data in entry code, fpu code, switch_to, scheduler. Why it always fail at those FPU code i.e. the strcmp function? I failed to compile without those sse, any solution? How it hurt performance?","title":"02/08 Thur Cloudy"},{"location":"lego/log/log-02-2018/#0207-wed-cloudy","text":"20:07 Pushed a small patch on mremap issue. Hope it will work. mremap really makes the whole thing very interesting, will be a very good research finding on combing virtual cache and operating system. Need to go gym with a friend, will be back on debugging late tonight. 9:30 Have two meetings to do today, and an security class, won\u2019t have too much time coding during daytime.","title":"02/07 Wed Cloudy"},{"location":"lego/log/log-02-2018/#0206-tue-sunny","text":"Well. We\u2019ve ruled out both smp_call_function and workqueue yesterday with Yiying\u2019s help. But the multi-thread word-count still fails :-( Single thread word-count just finished 4GB dataset (with 8GB pcache). So what could be still wrong with multithread one???? chill check exit code (Checked) check pcache\u2019s usage of task_struct, should always use the group_leader check cpu boot code and check the switch code again I believe pinpoint the issue in multithread word-count can solve a lot issues, it must be some thread creation, removal, schedule things. How about adding a lock for ibapi, make it sequential? Sweet, I tried, finally it is a bug that we are able to debug . 22:39 Done for today. I\u2019m trying to patch move_pte and pcache_move_pte . Although in theory we defenitly need to patch it, I keep thinking the code before should not trigger any serious bus or memory corruption. Ugh. Maybe it is concurrent mremap that one of them remap from A to B, while another one remap from C to A. It is possible. But my dead brain can not think of this anymore. I\u2019m going to hit the gym and do some squats. 17:01 Criminal found: mremap() and virtual cache did the crime. Interesting, I have not seen any research paper, tech-reports, writeup, code about this, not even the OVC paper, which, by the way, I think they must consider this case. Otherwise, a mremap will simply crash its virtual cache. Many thanks went to my smoke-and-think time. 15:14 Something new came up! After adding a spinlock for ibapi, this showed up (I tried one more time after this, which does not show up). We are lucky to catch this. At least I know where to look at. Also, this is defenitly triggered by mremap . It is seems it is overlapped mremap() . One thing I did not know is which thread trigger this bug, the sweep thread? Cause mremap related pcache rmap functions do not use rmap_get_locked_pte . [ 3826.048774] normal_p2s_open(): f_name: word_100MB.txt, mode: 04400, flags: 0 [ 3827.891622] SYSC_mremap(cpu18): move: [0x7fffe5788000 - 0x7fffe5806000] -> [0x7fffe531b000 - 0x7fffe5399000] [ 3828.178643] SYSC_mremap(cpu14): move: [0x7fffe5941000 - 0x7fffe5980000] -> [0x7fffe57c7000 - 0x7fffe5806000] **** ERROR: mismatched PTE and rmap **** rmap->owner_process: word_count-pthr uva: 0x7fffe57c8000 ptep: ffff88107efe0e40, rmap->page_table: ffff88107efe0e40 **** pcache_pfn: 0x1257c8, pte_pfn: 0x125942 14:00 word_count-pthread : 100MB dataset pcache : 8GB, 8-way victim : 8 entries [ 1294.845313] STDOUT: ---[ Wordcount: Running... ]--- [ 1294.903661] STDOUT: ---[ o; ]--- [ 1294.946301] normal_p2s_open(): f_name: /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt, mode: 04400, flags: 0 [ 1295.100517] SYSC_close(): [4] -> [/sys/devices/system/cpu/online] [ 1295.594658] word_count-pthr[59] general protection ip:4272ea sp:7ffff1b8ed28 error:0 [ 1295.685236] CPU: 10 PID: 59 Comm: word_count-pthr 4.0.0-lego+ #113 [ 1295.759070] RIP: 0033:[<00000000004272ea>] [<00000000004272ea>] 0x4272ea [ 1295.840184] RSP: 002b:00007ffff1b8ed28 EFLAGS: 00010283 [ 1295.903621] RAX: 000000000000000f RBX: 00007fffe5a3d010 RCX: 0000000000000001 [ 1295.988893] RDX: 0000000000000000 RSI: 4854005942004441 RDI: 00007ffff1c1e80f [ 1296.074166] RBP: 00007ffff1c1e80f R08: 0000000000000000 R09: 0000000000000010 [ 1296.211435] R10: 0000000000427ce0 R11: 00007ffff1bbb3ba R12: 0000000000001de4 [ 1296.296711] R13: 00000000006e4a80 R14: 0000000000001d9e R15: 0000000000001dc1 [ 1296.433978] FS: 00007ffff1b8f700(0000) GS:ffff88107fca0000(0000) knlGS:0000000000000000 [ 1296.582686] CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [ 1296.963297] CR2: 00007ffff1c1e000 CR3: 000000207fd8a000 CR4: 00000000000406a0 So what is this ip:4272ea , let us objdump the binary: 0000000000425e60 <strcmp>: 425e60: 48 8d 05 69 14 00 00 lea 0x1469(%rip),%rax # 4272d0 <__strcmp_sse42> 425e67: f7 05 5f b8 2b 00 00 testl $0x100000,0x2bb85f(%rip) # 6e16d0 <_dl_x86_cpu_features+0x10> 425e6e: 00 10 00 425e71: 75 1a jne 425e8d <strcmp+0x2d> 425e73: 48 8d 05 46 b0 00 00 lea 0xb046(%rip),%rax # 430ec0 <__strcmp_ssse3> 425e7a: f7 05 4c b8 2b 00 00 testl $0x200,0x2bb84c(%rip) # 6e16d0 <_dl_x86_cpu_features+0x10> 425e81: 02 00 00 425e84: 75 07 jne 425e8d <strcmp+0x2d> 425e86: 48 8d 05 03 00 00 00 lea 0x3(%rip),%rax # 425e90 <__GI_strcmp> 425e8d: c3 retq 425e8e: 66 90 xchg %ax,%ax .. .. .. .. 00000000004272d0 <__strcmp_sse42>: 4272d0: 89 f1 mov %esi,%ecx 4272d2: 89 f8 mov %edi,%eax 4272d4: 48 83 e1 3f and $0x3f,%rcx 4272d8: 48 83 e0 3f and $0x3f,%rax 4272dc: 83 f9 30 cmp $0x30,%ecx 4272df: 77 3f ja 427320 <__strcmp_sse42+0x50> 4272e1: 83 f8 30 cmp $0x30,%eax 4272e4: 77 3a ja 427320 <__strcmp_sse42+0x50> 4272e6: f3 0f 6f 0f movdqu (%rdi),%xmm1 * 4272ea: f3 0f 6f 16 movdqu (%rsi),%xmm2 4272ee: 66 0f ef c0 pxor %xmm0,%xmm0 You can see %rsi has some garbage value RSI: 4854005942004441 . Something went wrong. Will it be our FPU? I\u2019m not quite sure. If FPU code has error, why single-thread one succeed? Why it only shows up at multithread ones?","title":"02/06 Tue Sunny"},{"location":"lego/log/log-02-2018/#0205-mon-sunny","text":"From yesterday\u2019s testing of Phoenix, it looks like something is wrong in smp_call_functions() . They are invoked through tlb flush , which was further invoked by mremap , or munmap . The warning from smp is: [ 1260.586696 ] WARNING : CPU : 0 PID : 73 at kernel / smp . c : 129 generic_smp_call_function_single_interrupt + 0xb8 / 0x160 [ 1260.705251 ] CPU : 0 PID : 73 Comm : word_count - pthr 4.0.0 - lego + # 99 [ 1260.777008 ] Stack : [ 1260.800927 ] ffff88207fdffef8 ffffffff8100ec67 ffff88107fc00000 ffff88107fc00000 [ 1260.888283 ] ffffffff8100d410 ffff88207fe23df0 ffff88207fdfff08 ffffffff8100ed5f [ 1260.975639 ] ffff88207fdfff38 ffffffff8100fe68 00007f ffe58c3010 0000000000000f 96 [ 1261.062995 ] 000000000000f 960 0000000000000f 95 ffff88207fdfff48 ffffffff810020dd [ 1261.150351 ] 00007f fff58869c1 ffffffff8100b2e9 0000000000000f 96 0000000000000f 95 [ 1261.237707 ] Call Trace : [ 1261.266825 ] < TSK > [ 1261.289704 ] [ < ffffffff8100ec76 > ] __warn . constprop .0 + 0xa6 / 0x100 [ 1261.359381 ] [ < ffffffff8100d410 > ] ? pgd_free + 0x90 / 0x90 [ 1261.419699 ] [ < ffffffff8100ed5f > ] warn_slowpath_null + 0xf / 0x20 [ 1261.487295 ] [ < ffffffff8100fe68 > ] generic_smp_call_function_single_interrupt + 0xb8 / 0x160 [ 1261.581931 ] [ < ffffffff810020dd > ] call_function_interrupt + 0x1d / 0x20 [ 1261.655767 ] [ < ffffffff8100b2e9 > ] smp__call_function_interrupt + 0x69 / 0x70 So I decided to look into smp.c a little bit to find out if there is something wrong (I wrote it long time ago). The warning itself is true, it means some inconsistent behavior.. I saw alloc_percpu stuff during call_function_init , hence probably I also need to check percpu code a little code cause I\u2019m not sure if I port all the functionalities. In all, today\u2019s task, check percpu and smp_call_function code. Esp, percpu code, they are crucial and very hard to relate real bugs to it. Well\u2026 things changed. I found a more serious bug: something about cpuhotplug , even though lego is not using it. cpuhotplug is a set of implict callbacks to all different subsystems who want to do some initialization work on each offline->online cpu. Let us dig into how secondary cpu boots: Trampoline .. setup 64 bit mode start_secondary () smp_callin () notify_cpu_starting () ... while ( st -> state < target ) { st -> state ++ ; cpuhp_invoke_callback ( cpu , st -> state , true , NULL ); } cpuhp_invoke_callback () See? There will be some callbacks! What are those callbacks exactly? Well, they are predefined at the kernel/cpu.c . To save the trouble of reading code, I just print what functions are executed, the log is: [ 0.118235] cpuhp_invoke_callback(): 136 CPU:0 page_writeback_cpu_online+0x0/0x20 [ 0.368478] cpuhp_invoke_callback(): 136 CPU:1 smpboot_create_threads+0x0/0x90 [ 0.370196] cpuhp_invoke_callback(): 136 CPU:1 perf_event_init_cpu+0x0/0xa0 [ 0.370403] cpuhp_invoke_callback(): 136 CPU:1 workqueue_prepare_cpu+0x0/0x80 [ 0.371112] cpuhp_invoke_callback(): 136 CPU:1 hrtimers_prepare_cpu+0x0/0x60 [ 0.371339] cpuhp_invoke_callback(): 136 CPU:1 smpcfd_prepare_cpu+0x0/0x80 [ 0.371584] cpuhp_invoke_callback(): 136 CPU:1 relay_prepare_cpu+0x0/0xe0 [ 0.371794] cpuhp_invoke_callback(): 136 CPU:1 rcutree_prepare_cpu+0x0/0x170 [ 0.372333] cpuhp_invoke_callback(): 136 CPU:1 notify_prepare+0x0/0xa0 [ 0.372744] cpuhp_invoke_callback(): 136 CPU:1 bringup_cpu+0x0/0x100 [ 0.008000] cpuhp_invoke_callback(): 136 CPU:1 sched_cpu_starting+0x0/0x60 [ 0.926124] cpuhp_invoke_callback(): 136 CPU:1 smpboot_unpark_threads+0x0/0x90 [ 0.926124] cpuhp_invoke_callback(): 136 CPU:1 perf_event_init_cpu+0x0/0xa0 [ 0.927028] cpuhp_invoke_callback(): 136 CPU:1 workqueue_online_cpu+0x0/0x2a0 [ 0.927768] cpuhp_invoke_callback(): 136 CPU:1 rcutree_online_cpu+0x0/0x70 [ 0.928045] cpuhp_invoke_callback(): 136 CPU:1 notify_online+0x0/0x20 [ 0.928256] cpuhp_invoke_callback(): 136 CPU:1 page_writeback_cpu_online+0x0/0x20 [ 0.928527] cpuhp_invoke_callback(): 136 CPU:1 sched_cpu_activate+0x0/0x190 [ 0.929084] cpuhp_invoke_callback(): 136 CPU:2 smpboot_create_threads+0x0/0x90 [ 0.930240] cpuhp_invoke_callback(): 136 CPU:2 perf_event_init_cpu+0x0/0xa0 [ 0.930434] cpuhp_invoke_callback(): 136 CPU:2 workqueue_prepare_cpu+0x0/0x80 [ 0.931070] cpuhp_invoke_callback(): 136 CPU:2 hrtimers_prepare_cpu+0x0/0x60 [ 0.931264] cpuhp_invoke_callback(): 136 CPU:2 smpcfd_prepare_cpu+0x0/0x80 [ 0.931464] cpuhp_invoke_callback(): 136 CPU:2 relay_prepare_cpu+0x0/0xe0 [ 0.931649] cpuhp_invoke_callback(): 136 CPU:2 rcutree_prepare_cpu+0x0/0x170 [ 0.932245] cpuhp_invoke_callback(): 136 CPU:2 notify_prepare+0x0/0xa0 [ 0.932475] cpuhp_invoke_callback(): 136 CPU:2 bringup_cpu+0x0/0x100 [ 0.008000] cpuhp_invoke_callback(): 136 CPU:2 sched_cpu_starting+0x0/0x60 [ 1.005023] cpuhp_invoke_callback(): 136 CPU:2 smpboot_unpark_threads+0x0/0x90 [ 1.005065] cpuhp_invoke_callback(): 136 CPU:2 perf_event_init_cpu+0x0/0xa0 [ 1.005408] cpuhp_invoke_callback(): 136 CPU:2 workqueue_online_cpu+0x0/0x2a0 [ 1.005729] cpuhp_invoke_callback(): 136 CPU:2 rcutree_online_cpu+0x0/0x70 [ 1.006029] cpuhp_invoke_callback(): 136 CPU:2 notify_online+0x0/0x20 [ 1.006206] cpuhp_invoke_callback(): 136 CPU:2 page_writeback_cpu_online+0x0/0x20 [ 1.006549] cpuhp_invoke_callback(): 136 CPU:2 sched_cpu_activate+0x0/0x190 Interesting! Currently, Lego need to add the smpboot_create_threads() , workqueue_prepare_cpu() , workqueue_prepare_cpu() , bringup_cpu() , smpboot_unpark_threads() , workqueue_online_cpu() . This hidden things is really hard to find and not easy to track during boot. Especially during boot, they should do something like for_each_online_cpu and init one by one. But I guess, after adding support of cpu hotplug, code kind of merged. Some stuff will be executed whenever a cpu has been teardown or bought up. And bang, why not use the same set of hotplug during boot, right? Well.","title":"02/05 Mon Sunny"},{"location":"lego/log/log-03-2018/","text":"March 2018 \u00b6 03/31 Sat \u00b6 Stay humble. Be real. 03/30 Fri \u00b6 Our scheduling, or IB do have issues. I must revisit this. The case is: in P, we boot only 12 cores, and three of them are used by flush, sweep, and IB. So there are 9 cores left for user. Phoenix create 24 threads. During the run, a lot ib timeout will happen. If we have a good scheduling, this should never happen. I probably need to check more on this. Anyway. Today I reorganized the opcode things. And now I\u2019m adding the final large piece of Lego: replication. It should be much simpler than the pcache part. I will first write down what code I need to add, e.g., opcode, handler, buffer mgmt etc. End of day. Want to write down some simple thoughts on building system. Building system is fun, but you have to know that devil is in the details. And, you may end up debugging for many many hours on a very very little issue. But that is how it is. Building system does not mean you are always working on fantastic beautiful ideas. It is always about those little bugs, little things, trivial fixes, that make your system robust and usable. For example, the patch Yilun sent me today is about handling special cases of stat and lseek. The patch does not improve any performance or adding fancy features, it is a minor fix to make user progam run. But this enable us to run TF. I think it is a great patch and it stands for 90% of building systems in middle or late stage. Of course, there are other trivial things on building systems: 1) initialize every possible used variables, can be local variables, malloced buffers. 2) have decent cleanup, which is a counterpart of your initialization, like dequeue list, decrease counter etc. 3) Clear coding style, write code for others, for yourself when you read the code two weeks later. This one is hard, need experience. But can be learned. I think Yilun and Yutong both improved a lot during this project. Me? I learned this from NVM emulator protect. It is a painful one, but also a valuable one. 4) Decent protect source file organization. 5) Remember, draw, the connections between subsystems. By adding this new feature to this subsystem A, will it broke subsystem B, which is using subsystem A. Something like this. 6) clear mind on lock usage, multithread issue. This is the most difficult one. I would say I learned this by coding pcache, or mm. I would say, mm is the most difficult multithread issue one can encounter. 03/26 Mon \u00b6 Spent several days on replication design. Now I\u2019m back on coding and debuging track. Fixed a bug introduced by per-pte lock. A one hided by previous one big giant page table lock. Also add an option to boot socket 0 only if Processor is configured. This is because pcache is normally registered at socket 0, if we schedule user threads to sockets other than socket 0, that will have bad performance. 03/22 Thur \u00b6 Clear Registers for execve() \u00b6 Want to figure out execve problem today. Check if pcache is clean after process_exit. Check if pgtable is clean. Well. Checked, both are clean. The bug looks like the return of main, evevntually does not go to library\u2019s exit. Is it because library pages are not loaded properly? Since the number of pgfault equals to normal setting, I guess it may originate from Memory side. TLB is also flushed, so TLB should not be a hidden issue. Going to check checsum. Well, checsum is okay too. Syscall execve will change ip, sp, flags registers. So it will use iretq instead of sysexit to return to userspace. Got an insteresting IB bug after execve. The CPU5 seems fail to return to userspace, and the CPU0 has the IB bug followed: [ 1201.940681 ] CPU : 5 PID : 32 Comm : seq . o 4.0.0 - lego - ys + # 609 [ 1202.006200 ] RIP : 0033 : [ < 0000000000401 d1d > ] [ < 0000000000401 d1d > ] 0x401d1d [ 1202.087320 ] RSP : 002 b : 00007f ffffffedb0 EFLAGS : 00000200 [ 1202.150760 ] RAX : 0000000000000000 RBX : 00000000004002e0 RCX : 000000000043 b2c7 [ 1202.236041 ] RDX : 00007f ffffffedc8 RSI : 00007f ffffffeb40 RDI : 000000000048f9f 0 [ 1202.321320 ] RBP : 00007f ffffffeb60 R08 : 00000000006 ba4a0 R09 : 00000000006 bc880 [ 1202.406601 ] R10 : 000000000000000f R11 : 0000000000000246 R12 : 0000000000000000 [ 1202.491881 ] R13 : 0000000000401 930 R14 : 0000000000401 9 c0 R15 : 0000000000000006 [ 1202.577161 ] FS : 0000000000000000 ( 0000 ) GS : ffff88207fc40000 ( 0000 ) knlGS : 0000000000000000 [ 1202.673880 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 1202.742521 ] CR2 : 000000000042 c9a0 CR3 : 000000207f c2f000 CR4 : 00000000000406 a0 [ 1220.465601 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000020 [ 1220.557225 ] IP : [ < ffffffff810591ef > ] ib_mad_completion_handler + 0x6f / 0x7c0 [ 1220.638344 ] PGD 0 [ 1220.662265 ] Oops : 0000 [ # 1 ] SMP PROCESSOR [ 1220.710105 ] CPU : 0 PID : 27 Comm : ib_mad_completi 4.0.0 - lego - ys + # 609 [ 1220.786025 ] RIP : 0010 : [ < ffffffff810591ef > ] [ < ffffffff810591ef > ] ib_mad_completion_handler + 0x6f / 0x7c0 [ 1220.896265 ] RSP : 0000 : ffff88103eea7e30 EFLAGS : 00010246 [ 1220.959704 ] RAX : 0000000000000000 RBX : ffff88103eeac728 RCX : 0000000000000001 [ 1221.044985 ] RDX : 000000002 8000000 RSI : ffff88103ee8f000 RDI : ffff88107ff841d8 [ 1221.130265 ] RBP : ffff88103eea7ec0 R08 : 0000000000000000 R09 : ffff88103eea03c0 [ 1221.215545 ] R10 : ffff88103eea7ea0 R11 : 0000000000000001 R12 : ffff88103ee8c3f0 [ 1221.300825 ] R13 : ffff88103ee8c4e8 R14 : ffff88103eeac620 R15 : ffff88103eeac5f8 [ 1221.386106 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc00000 ( 0000 ) knlGS : 0000000000000000 [ 1221.482825 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 1221.551466 ] CR2 : 0000000000000020 CR3 : 000000000113 d000 CR4 : 00000000000406 b0 [ 1221.636746 ] Stack : [ 1221.660666 ] ffff88103eeaac10 ffff881000000001 ffff88103eeaac10 ffff88103eeaab50 [ 1221.748026 ] ffff88107fc05d80 ffff88103eea0000 ffff88103eeac728 000000 8000000000 [ 1221.835386 ] 0000012 83 eea7ea8 ffff88103ee8c9a8 000000007f cf2000 ffff000000000000 [ 1221.922746 ] ffff88107fcf0000 ffff88207ff6cbd8 ffff88107fcf76e8 ffff88103ee8c3f0 [ 1222.010106 ] ffffffff81059180 0000000000000000 ffff88103eea7f48 ffffffff81020866 [ 1222.097466 ] Call Trace : [ 1222.126586 ] < TSK > [ 1222.149466 ] [ < ffffffff81059180 > ] ? ib_mad_send_done_handler . isra .21 + 0x1d0 / 0x1d0 [ 1222.236826 ] [ < ffffffff81020866 > ] kthread + 0xf6 / 0x120 [ 1222.295066 ] [ < ffffffff81020770 > ] ? __kthread_parkme + 0x70 / 0x70 [ 1222.363707 ] [ < ffffffff8100e4b2 > ] ret_from_fork + 0x22 / 0x30 [ root @ wuklab12 : LegoOS git :( master )] $ addr2line - e vmImage - i ffffffff810591ef / root / ys / LegoOS / drivers / infiniband / core / mad . c : 1899 / root / ys / LegoOS / drivers / infiniband / core / mad . c : 2324 It is ib_mad_recv_done_handler () Well\u2026 Eventually, at 22:09, I figured out.. After I cleaned up all registers (except IP, SP, CS, SS, FLAGS) within start_thread, the execve\u2019ed program can run to end successfully. I did not clear the registers because linux does not clear it. I thought this is fine. Glibc should clear it anyway, right? But anyway, this works. 03/21 Wed \u00b6 Task 1: add some checking in ib, flush, sweep thread. 1) If cpu changed, 2) if nr_threads on this core > 1. Had an issue while testing: execve(). I ran a exec.o first, then do execve to run seq.o: wuklab13 0321 -10 [ 970.380252 ] STDOUT : --- [ uname () : --- [ 970.431212 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x44605d flags : 0x150 [ 1101.862429 ] mlx4_ib_handle_error_cqe syndrome 21 [ 1101.915570 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1101.969649 ] send request failed at connection 4 as 12 [ 1102.029968 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1102.084046 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1102.138125 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1102.192203 ] fit_poll_cq : failed status ( 5 ) for wr_id 1054 [ 1102.256681 ] fit_poll_cq : failed status ( 5 ) for wr_id 1055 [ 1102.321160 ] csum : 442 a97c0 , reply -> csum : 2 d352c33 [ 1102.377319 ] fit_poll_cq : connection 4 Recv weird event as -1 [ 1102.444916 ] pcache : ffff880180011180 mapcount : 0 refcount : 1 flags :( allocated | usable ) kva : ffff880100446000 [ 1102.558273 ] fit_poll_cq : failed status ( 5 ) for wr_id 1056 [ 1102.622751 ] pcache dumped because : csum mismatch [ 1102.677871 ] fit_poll_cq : connection 4 Recv weird event as -30704 [ 1102.749627 ] ------------ [ cut here ] ------------ [ 1102.804746 ] fit_poll_cq : failed status ( 5 ) for wr_id 1057 [ 1102.869225 ] BUG : failure at managers / processor / pcache / fault . c : 237 / __pcache_do_fill_page () ! [ 1102.968022 ] fit_poll_cq : connection 4 Recv weird event as -30704 [ 1103.039780 ] Kernel Panic - not syncing : BUG ! [ 1103.090739 ] CPU : 5 PID : 32 Comm : seq . o 4.0.0 - lego - ys + # 599 [ 1103.156256 ] Stack : [ 1103.180177 ] ffff88103e85be18 ffffffff8102676c ffffffff00000008 ffff88103e85be28 [ 1103.267533 ] ffff88103e85bde0 0000000021475542 00000000000002 96 ffff88103e85ba10 [ 1103.354892 ] ffffffff810195c5 ffff88207fc44980 0000000000000005 ffff88103e85ba28 [ 1103.442249 ] ffffffff81016c75 ffff88103e85ba40 ffff88103e85ba50 ffffffff810065d4 [ 1103.529607 ] ffffffff811d36e0 000000000000003 9 ffffffff81081718 ffff88103e85bb80 [ 1103.616964 ] Call Trace : 03/20 Tue \u00b6 Task 1: calculate failure numbers Task 2: read 0319-4 Log Task 3: opt pte lock Hmm, I finished the per-pte per-pmd lock patch. I think it works. But I do found an issue. When I run MT+2GB, it will create 24 threads. Since I marked 3 CPUs inactive, so all new 24 threads will be scheduled to other cores (I may need to check this!). At some point, Lego P either stuck, or a lot ibapi_send_reply timeout. When I change the cpu_online to may 0-6 , it finished. When I change it to 0-18 , also succeed. I really doubt if actually those pinned threads are not pinned. Need to check. IB Bug again \u00b6 Running MT-phoenix, 2GB, somehow crashed in the middle: [ 60095.857381 ] SYSC_close () CPU6 PID : 33 [ fd : 4 ] -> [ / proc / stat ] [ 60286.127359 ] mlx4_ib_handle_error_cqe syndrome 21 [ 60286.180503 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.234582 ] send request failed at connection 4 as 12 [ 60286.294903 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.348981 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.403062 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.457141 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.511221 ] send request failed at connection 4 as 5 [ 60286.570500 ] fit_poll_cq : failed status ( 5 ) for wr_id 1056 [ 60286.634980 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.689059 ] fit_poll_cq : failed status ( 5 ) for wr_id 1057 [ 60286.753539 ] send request failed at connection 4 as 5 [ 60286.812819 ] fit_poll_cq : failed status ( 5 ) for wr_id 1058 [ 60286.877298 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.931378 ] fit_poll_cq : failed status ( 5 ) for wr_id 1059 [ 60286.995857 ] send request failed at connection 4 as 5 [ 60287.055138 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.109217 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.163297 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.217376 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.271456 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.325536 ] send request failed at connection 4 as 5 [ 60287.384815 ] fit_poll_cq : failed status ( 5 ) for wr_id 1060 [ 60287.449294 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.503375 ] BUG : unable to handle kernel NULL pointer dereference at ( null ) [ 60287.596973 ] IP : [ < ffffffff81063ffd > ] fit_poll_cq + 0x4dd / 0x530 [ 60287.664574 ] send request failed at connection 4 as 5 [ 60287.723853 ] PGD 0 [ 60287.747772 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.801852 ] Oops : 0002 [ # 1 ] PREEMPT SMP PROCESSOR [ 60287.858013 ] send request failed at connection 4 as 5 [ 60287.917292 ] CPU : 2 PID : 29 Comm : recvpollcq 4.0.0 - lego - ys + # 569 [ 60287.988010 ] RIP : 0010 : [ < ffffffff81063ffd > ] [ < ffffffff81063ffd > ] fit_poll_cq + 0x4dd / 0x530 [ 60288.084731 ] RSP : 0000 : ffff88103e84fd88 EFLAGS : 00010206 [ 60288.148170 ] RAX : 000000000000100 8 RBX : ffff88103e848438 RCX : 0000000000000014 [ 60288.233450 ] RDX : 0000000000000000 RSI : ffffffff811d36e0 RDI : ffffffff811dac08 [ 60288.318728 ] RBP : ffff88103e84fea8 R08 : 0000000000000000 R09 : 0000000000000000 [ 60288.404008 ] R10 : 0000000000000002 R11 : 0000000000000004 R12 : 0000000000000000 [ 60288.489288 ] R13 : ffff88207fd6e008 R14 : 0000000000000004 R15 : ffff88103e84fda0 [ 60288.574568 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60288.628647 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc20000 ( 0000 ) knlGS : 0000000000000000 [ 60288.725367 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 60288.794006 ] CR2 : 0000000000000000 CR3 : 000000000113 d000 CR4 : 00000000000406 a0 [ 60288.879285 ] send request failed at connection 4 as 5 [ 60288.938565 ] Stack : [ 60288.962484 ] ffffffff810031d9 000 801 d43e84fda0 0000000000000007 0000000000000424 [ 60289.049844 ] 000000 8100000005 00001008000000f 9 ffff88103e848868 00616e6440000014 [ 60289.137204 ] 0020004000000002 ffff88207fc00000 0000000000000425 000000 8100000005 [ 60289.224563 ] 00001008000000f 9 ffff88103e848868 007370654000000 d 0010004000000002 [ 60289.311922 ] ffffffff81010000 0000000000000426 000000 8100000005 00001008000000f 9 [ 60289.399282 ] Call Trace : [ 60289.428402 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60289.482482 ] < TSK > [ 60289.505361 ] [ < ffffffff810031d9 > ] ? native_smp_send_reschedule + 0x39 / 0x50 [ 60289.584400 ] send request failed at connection 4 as 5 [ 60289.643680 ] [ < ffffffff81010000 > ] ? __ioremap_caller + 0x170 / 0x570 [ 60289.714400 ] [ < ffffffff81060000 > ] ? cm_work_handler + 0x270 / 0x1450 [ 60289.785119 ] [ < ffffffff81064050 > ] ? fit_poll_cq + 0x530 / 0x530 [ 60289.850639 ] [ < ffffffff81064064 > ] fit_poll_cq_pass + 0x14 / 0x30 [ 60289.917198 ] [ < ffffffff81020c06 > ] kthread + 0xf6 / 0x120 [ 60289.975438 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60290.029518 ] [ < ffffffff81020b10 > ] ? __kthread_parkme + 0x70 / 0x70 [ 60290.098157 ] [ < ffffffff8100e722 > ] ret_from_fork + 0x22 / 0x30 Uuh: [ 1002.803051 ] mlx4_ib_handle_error_cqe syndrome 1 [ 1002.855153 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1002.909232 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1002.963310 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1003.017390 ] fit_poll_cq : failed status ( 1 ) for wr_id 512 [ 1003.080829 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000200 [ 1003.174425 ] IP : [ < ffffffff8105d499 > ] fit_poll_cq + 0x179 / 0x510 [ 1003.242024 ] PGD 0 [ 1003.265943 ] Oops : 0000 [ # 1 ] SMP MEMORY [ 1003.310661 ] CPU : 2 PID : 29 Comm : recvpollcq 4.0.0 - lego - ys + # 149 [ 1003.381380 ] RIP : 0010 : [ < ffffffff8105d499 > ] [ < ffffffff8105d499 > ] fit_poll_cq + 0x179 / 0x510 [ 1003.478098 ] RSP : 0000 : ffff88104e84fd88 EFLAGS : 00010246 [ 1003.541537 ] RAX : ffff880000000000 RBX : ffff88104e848008 RCX : 00000000000000 80 [ 1003.626814 ] RDX : 0000000000000200 RSI : ffffffff811c76e0 RDI : ffffffff811d0988 [ 1003.712092 ] RBP : ffff88104e84fea8 R08 : 0000000000000000 R09 : 0000000000000000 [ 1003.797369 ] R10 : 0000000000000002 R11 : 0000000000000004 R12 : 0000000000000000 [ 1003.882648 ] R13 : ffff88207ff75008 R14 : 0000000000000004 R15 : ffff88104e84fda0 [ 1003.967925 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc20000 ( 0000 ) knlGS : 0000000000000000 [ 1004.064644 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 1004.133282 ] CR2 : 0000000000000200 CR3 : 0000000001131000 CR4 : 00000000000406 a0 [ 1004.218559 ] Stack : [ 1004.242479 ] ffffffff810031a9 ffff88104e84fda0 ffffffff81018ef4 0000000000000200 [ 1004.329837 ] 000000 8000000001 0000004 8000000 d7 ffff88104e848c98 00000000 81019302 [ 1004.417194 ] 0014000000000000 ffff88207fc00000 0000000000000201 ffffffff00000005 [ 1004.504552 ] ffff8810000000f9 ffff88104e848c98 0000000000000000 ffff88104e84fe38 [ 1004.591910 ] ffffffff810195a4 0000000000000202 ffff881000000005 ffff8810000000f9 [ 1004.679268 ] Call Trace : [ 1004.708388 ] < TSK > [ 1004.731267 ] [ < ffffffff810031a9 > ] ? native_smp_send_reschedule + 0x39 / 0x50 [ 1004.810305 ] [ < ffffffff81018ef4 > ] ? resched_curr + 0x34 / 0x40 [ 1004.874783 ] [ < ffffffff810195a4 > ] ? try_to_wake_up + 0xe4 / 0x1f0 [ 1004.942382 ] [ < ffffffff8105f458 > ] ? __schedule + 0xf8 / 0x1e0 [ 1005.005820 ] [ < ffffffff8105d830 > ] ? fit_poll_cq + 0x510 / 0x510 [ 1005.071338 ] [ < ffffffff8105d844 > ] fit_poll_cq_pass + 0x14 / 0x30 [ 1005.137897 ] [ < ffffffff8101fdc6 > ] kthread + 0xf6 / 0x120 [ 1005.196135 ] [ < ffffffff8101fcd0 > ] ? __kthread_parkme + 0x70 / 0x70 [ 1005.264773 ] [ < ffffffff8100e472 > ] ret_from_fork + 0x22 / 0x30 03/19 Mon \u00b6 Not too many days left!!! Got to design full replication mechanism and algorithm today. Merged pull request for pipe , pipe2 and /dev/null from Yilun. Our simple file op mgmt concerns me. I left a note at kernel/fork.c. Got a bug report from Yilun, syscall execv failed. To be honest, I\u2019ve never tried this syscall, always call it directly within kernel. [ 943.650712 ] CPU6 PID17 sys_execve + 0x0 / 0x10 [ 943.701899 ] BUG : unable to handle kernel paging request at 00000000004 90523 [ 943.702776 ] IP : [ < ffffffff8103db86 > ] strrchr + 0x6 / 0x20 [ 943.711501 ] PGD 0 [ 943.711911 ] Oops : 0000 [ # 1 ] SMP PROCESSOR [ 943.712433 ] CPU : 6 PID : 17 Comm : word_count - pthr 4.0.0 - lego + # 64 [ 943.713126 ] RIP : 0010 : [ < ffffffff8103db86 > ] [ < ffffffff8103db86 > ] strrchr + 0x6 / 0x20 [ 943.714090 ] RSP : 001 8 : ffff88083e4bfe98 EFLAGS : 00010246 [ 943.714724 ] RAX : 0000000000000000 RBX : ffff88083e4b3780 RCX : 0000000000000000 [ 943.715511 ] RDX : 00000000f fffffff RSI : 000000000000002f RDI : 00000000004 90523 [ 943.716297 ] RBP : ffff88083e4bfe98 R08 : 0000160000000000 R09 : ffff88083e4b8400 [ 943.717085 ] R10 : ffff880000000000 R11 : 6 db6db6db6db6db7 R12 : ffff88083e4b8000 [ 943.717871 ] R13 : ffff88083e4e6290 R14 : 00000000004 90523 R15 : ffff88083e4b3920 [ 943.718683 ] FS : 0000000000000000 ( 0000 ) GS : ffff88083fd80000 ( 0000 ) knlGS : 0000000000000000 [ 943.719650 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 943.720319 ] CR2 : 00000000004 90523 CR3 : 000000083e4 e7000 CR4 : 00000000000406 a0 [ 943.721106 ] Stack : [ 943.721459 ] ffff88083e4bff18 ffffffff8102c6bf ffff880800000000 0000000000000e10 [ 943.722541 ] 00007f ffffffedb0 0000000000400 d0d ffff88083e4c0000 00000000004 90523 [ 943.723624 ] ffff88083e4b9008 00007f ffffffed30 000000 8400000084 ffff88083e4bff58 [ 943.724706 ] 000000000000003 b 0000000000401 9 d0 0000000000401 a60 0000000000000000 [ 943.725789 ] ffff88083e4bff28 ffffffff8102c989 ffff88083e4bff48 ffffffff8100e5f5 [ 943.726870 ] Call Trace : [ 943.727260 ] < TSK > [ 943.727619 ] [ < ffffffff8102c6bf > ] do_execve + 0x4af / 0x770 [ 943.728236 ] [ < ffffffff8102c989 > ] sys_execve + 0x9 / 0x10 [ 943.728868 ] [ < ffffffff8100e5f5 > ] do_syscall_64 + 0x45 / 0xd0 [ 943.729499 ] [ < ffffffff8100d4ec > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 943.730222 ] < EOT > [ 943.730570 ] Code : d2 74 18 40 38 f2 89 f1 75 06 eb 0f 38 ca 74 0 b 48 83 c0 01 0f b6 10 84 d2 75 f1 5 d c3 0f 1f 84 00 00 00 00 00 55 31 c0 48 89 e5 < 0f > b6 17 40 38 f2 48 0f 44 c7 48 83 c7 01 84 d2 75 ee 5 d c3 66 [ 943.735455 ] RIP [ < ffffffff8103db86 > ] strrchr + 0x6 / 0x20 [ 943.736120 ] RSP < ffff88083e4bfe98 > [ 943.736598 ] CR2 : 00000000004 90523 It is setup_new_exec() -> set_task_comm() . I passed the user pointer to set_task_comm() , which I should pass a kernel pointer. And I actually found we missed a function: do_close_on_exec() . I also add a note above. Random IB Bug \u00b6 Another weird bug after pathing loader. Actually, I tried the same setting twice, the second time it works. I guess this is some random IB bug. (Setting: 1P, 1M, 1S. Running a simple exec.c testing program, this have not reach that point yet.) wuklab13 031 9-2 [ 496.288272 ] p2m_fork ( cpu0 ) : I cur : 1 - kernel_init new : 31 [ 496.349624 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000004 [ 496.443216 ] IP : [ < ffffffff81064935 > ] fit_send_reply_with_rdma_write_with_imm + 0x65 / 0x3b0 [ 496.538892 ] PGD 0 [ 496.562811 ] Oops : 0002 [ # 1 ] PREEMPT SMP PROCESSOR [ 496.618968 ] CPU : 0 PID : 1 Comm : kernel_init 4.0.0 - lego - ys + # 559 [ 496.689684 ] RIP : 0010 : [ < ffffffff81064935 > ] [ < ffffffff81064935 > ] fit_send_reply_with_rdma_write_with_imm + 0x65 / 0x3b0 [ 496.814478 ] RSP : 0000 : ffff88107fcf7d00 EFLAGS : 00010202 [ 496.877915 ] RAX : 000000000000004 c RBX : 0000000000000004 RCX : 000000000000002 c [ 496.963190 ] RDX : 0000000000000004 RSI : 0000000000000001 RDI : ffff88207ff6d008 [ 497.048466 ] RBP : ffff88107fcf7d98 R08 : ffff88107fcf7e3c R09 : 0000000000000004 [ 497.133742 ] R10 : ffffffff81145fe0 R11 : 000000000000001 c R12 : 000000000000002 c [ 497.219018 ] R13 : 0000000000000001 R14 : ffff88107fcf7e40 R15 : ffff88207ff6d008 [ 497.304293 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc00000 ( 0000 ) knlGS : 0000000000000000 [ 497.401009 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 497.469645 ] CR2 : 0000000000000004 CR3 : 000000000113 d000 CR4 : 00000000000406 b0 [ 497.554922 ] Stack : [ 497.578840 ] ffff88107fcf7d08 0000000000000000 00000000000002 82 ffffffff81077b10 [ 497.666195 ] 000000000000003 a 000000047f cf7e18 ffff88107fcf7e3c ffff88107fd5ed88 [ 497.753552 ] 000000010000002 c ffffff9b00000040 0000000000000034 ffffffff81145fe0 [ 497.840906 ] ffff88107fcf7db0 00000000000002 97 ffff88107fd5ed88 000000000000002 c [ 497.928263 ] ffff88107fcf7e3c ffff88107fcf7e40 000000000000003 9 ffff88107fcf7dc8 [ 498.015618 ] Call Trace : [ 498.044736 ] < TSK > [ 498.067615 ] [ < ffffffff810622ff > ] ibapi_send_reply_timeout + 0x3f / 0x50 [ 498.142492 ] [ < ffffffff8103b0d4 > ] ? net_send_reply_timeout + 0x94 / 0x132 [ 498.218408 ] [ < ffffffff8103b0d4 > ] net_send_reply_timeout + 0x94 / 0x132 [ 498.292244 ] [ < ffffffff8102c683 > ] p2m_fork + 0xd3 / 0x200 [ 498.351521 ] [ < ffffffff8101f490 > ] do_fork + 0xf0 / 0x150 [ 498.409758 ] [ < ffffffff8101f514 > ] kernel_thread + 0x24 / 0x30 [ 498.473195 ] [ < ffffffff8115bf21 > ] processor_manager_init + 0x21 / 0x50 [ 498.545991 ] [ < ffffffff81000354 > ] kernel_init + 0x94 / 0x120 [ 498.608388 ] [ < ffffffff810002c0 > ] ? 0xffffffff810002c0 [ 498.668706 ] [ < ffffffff81019b0a > ] ? schedule_tail + 0xa / 0x40 [ 498.733182 ] [ < ffffffff810002c0 > ] ? 0xffffffff810002c0 [ 498.793499 ] [ < ffffffff8100e762 > ] ret_from_fork + 0x22 / 0x30 [ 498.856936 ] < EOT > 03/18 Sun \u00b6 Got a bug report after enable preempt and sweep thread [ 582.545444 ] pcache : ffff8801812cb680 mapcount : 1 refcount : 2 flags :( locked | allocated | usable | valid | reclaim ) kva : ffff88014b2da000 [ 582.678677 ] pcache dumped because : PCACHE_BUG_ON_PCM ( pcache_mapped ( pcm )) [ 582.758760 ] rmap : ffff88207e5e37e8 flags : 0x0 owner - tgid : 33 user_va : 0x7fff0b2da000 ptep : ffff88207e4a86d0 [ 582.870046 ] pte : ffff88207e4a86d0 pfn : 0x0 flags :() [ 582.926210 ] ------------ [ cut here ] ------------ [ 582.981333 ] BUG : failure at managers / processor / pcache / victim . c : 604 / victim_finish_insert () ! [ 583.080137 ] Kernel Panic - not syncing : BUG ! ... ... [ 588.847239 ] nr_pgfault : 591101 [ 588.883641 ] nr_clflush : 66176 [ 588.919003 ] nr_pgfault_wp : 0 [ 588.953325 ] nr_pgfault_wp_cow : 0 [ 588.991806 ] nr_pgfault_wp_reuse : 0 [ 589.032368 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 589.091651 ] nr_pcache_fill_from_memory : 587057 [ 589.144694 ] nr_pcache_fill_from_victim : 4038 [ 589.195656 ] nr_pcache_eviction_triggered : 439562 [ 589.250780 ] nr_pcache_eviction_eagain_freeable : 373382 [ 589.312143 ] nr_pcache_eviction_eagain_concurrent : 0 [ 589.370386 ] nr_pcache_eviction_failure_find : 0 [ 589.423429 ] nr_pcache_eviction_failure_evict : 0 [ 589.477512 ] nr_pcache_eviction_succeed : 66176 [ 589.529514 ] nr_victim_eviction_triggered : 733361 [ 589.584638 ] nr_victim_eviction_eagain : 671227 [ 589.636640 ] nr_victim_eviction_succeed : 62134 [ 589.688642 ] nr_victim_prepare_insert : 66180 [ 589.738566 ] nr_victim_finish_insert : 66176 [ 589.787447 ] nr_victim_flush_submitted : 66176 [ 589.838411 ] nr_victim_flush_finished : 66176 [ 589.888332 ] nr_victim_flush_async_run : 0 [ 589.935135 ] nr_victim_flush_sync : 0 [ 589.976738 ] nr_sweep_run : 50580 [ 590.014179 ] nr_sweep_nr_pset : 116770383 [ 590.059943 ] nr_sweep_nr_moved_pcm : 100686435 This is an interesting bug. Two threads, one doing munmap or mremap, one doing eviction. They are using the same pcm. munmap and mremap will use pte_get_and_clear() to get the pcm. While eviction will call pcache_try_to_unamp , which will further call rmap_get_locked_pte() , in which we check if the pte is none, if it is, then we know this is under munmap or mremap, then we skip. This is absolutely wrong. When pcache_try_to_unamp is called by eviction, it should always unmap ALL rmap. The above case is triggered because both two threads skip the final __pcache_remove_rmap . Hmm, looks like open/close filename is wrong. I need to check. Last Log from MT+2GB, computation finished: wuklab13 031 8-10 [ 627.280016 ] **** ERROR : *** current : 32 : kevict_sweepd caller : ( null ) **** [ pte == rmap -> page_table ] && [ pcache_pfn != pte_pfn ] **** rmap -> owner_process : word_count - pthr uva : 0x7fff78f52000 ptep : ffff88107e87fa90 , rmap -> page_table : ffff88107e87fa90 **** pcache_pfn : 0x168f52 , pte_pfn : 0x178f52 [ 627.624239 ] rmap : ffff88107dc73740 flags : 0x0 owner - tgid : 33 user_va : 0x7fff78f52000 ptep : ffff88107e87fa90 [ 627.735513 ] pte : ffff88107e87fa90 pfn : 0x0 flags :() [ 627.791670 ] pcache_rmap dumped because : Corrupted RMAP [ 627.853026 ] pcache : ffff880181a3d480 mapcount : 1 refcount : 2 flags :( locked | allocated | usable | valid ) kva : ffff880168f52000 [ 627.979901 ] pcache dumped because : Corrupted RMAP [ 628.036057 ] ------------ [ cut here ] ------------ [ 628.091175 ] BUG : failure at managers / processor / pcache / rmap . c : 109 / report_bad_rmap () ! [ 628.182691 ] Kernel Panic - not syncing : BUG ! [ 628.233647 ] CPU : 5 PID : 32 Comm : kevict_sweepd 4.0.0 - lego - ys + # 543 [ 628.307483 ] Stack : [ 628.331401 ] ffff88107e85bd00 ffffffff81026d24 000000000000000 8 ffff88107e85bd10 [ 628.418756 ] ffff88107e85bcc8 0000000021475542 0000000000000000 0000000000000000 [ 628.506113 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 628.593468 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 628.680823 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 628.768179 ] Call Trace : [ 628.797299 ] < TSK > [ 628.820176 ] [ < ffffffff81026d30 > ] panic + 0xc2 / 0x102 [ 628.876334 ] [ < ffffffff8101c6ac > ] ? task_tick_rt + 0x2c / 0xd0 [ 628.940811 ] [ < ffffffff8101c6ac > ] ? task_tick_rt + 0x2c / 0xd0 [ 629.005288 ] [ < ffffffff81019bfc > ] ? scheduler_tick + 0x5c / 0x70 [ 629.071843 ] [ < ffffffff81017195 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 629.144639 ] [ < ffffffff81006704 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 629.217436 ] [ < ffffffff8100e4da > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 629.295432 ] [ < ffffffff81012d94 > ] ? printk + 0x124 / 0x1c0 [ 629.355748 ] [ < ffffffff8103ad1f > ] report_bad_rmap + 0x144 / 0x144 [ 629.423345 ] [ < ffffffff81031046 > ] pcache_referenced_trylock_one + 0x1c6 / 0x2c0 [ 629.505500 ] [ < ffffffff8100e4da > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 629.583497 ] [ < ffffffff810328a1 > ] rmap_walk + 0x71 / 0xe0 [ 629.642774 ] [ < ffffffff81033329 > ] pcache_referenced_trylock + 0x59 / 0xd0 03/17 Sat \u00b6 I\u2019m too tired today. Coding side, I will only optimize sweep. Besides, I will book tickets for Iceland trip. 03/16 Friday \u00b6 Task 1 : Add physical memory counter. It is a per-zone based counter, even though there is also some global counters. In Linux, per-cpu counter is first accumlated, global counter is updated only when per-cpu ones overflow. Lego\u2019s initial version save the trouble of per-cpu counter, I only port one global counter today, because I\u2019m not quite confident about our percpu_alloc\u2026 Anway, the info is reported in the format of manager_sysinfo . Do note this is different from the oirginal sysinfo structure, which is used by sysinfo syscall. Task 2 : Patch get_random_number and /dev/urandom /dev/random. Others wrote the code, but he did not stick to the tradition of format naming. So I have to rewrite some of them. Sigh. Task 3 : optimize sweep 03/15 Thur \u00b6 Forgot to write the log yesterday. I actually solved the major bug, the refcount and eviction one. That is really nasty. I basically used pte lock, pcache_lock, and refcount to synchronize between eviction routine and other users such as munmap, mremap, write-protected-handler. I\u2019m really not sure if this mode can be reproduced if I have any other similar systems. But I\u2019m glad that I find a way to do this. Today I got few tasks going on. First merge storage syscall branch, then add sched_yield syscall, add zone/node counters, and probably patch get_random_number. Task 1 : Merge Yilun\u2019s storage pull request, has bunch syscalls. I\u2019m reviewing now. truncate ftruncate getdents getcwd mkdir rmdir creat unlink unlinkat readlink statfs sync Task 2 : Add sched_yield() . Fairly simple. Task 3 : Add physical memory counter. Fairly complex. The underlying is built long time ago. Need to pick up some. Well some facts: pg_data_t (and zone) is allcoated by alloc_node_data if NUMA is configured. all zones are built and initliazed in memory_init() in Lego stats are reset to 0 when pg_data_t allocated (DUH?). Played directly in page_alloc.c Have to continue tomorrow. Task 4 : Patch get_random_number and /dev/urandom 03/13 Wed \u00b6 The slow victim flush issue is solved by pinning the thread to a core and remove that core from active_cpu mask. Today I\u2019m going to solve the SMP object issue. I\u2019m hoping by solving this, we can have a complete working pcache and victim cache. Continue yesterday\u2019s log: wuklab13 0313 -12 [ 1073.616269 ] pcache : ffff880180777a80 mapcount : 0 refcount : 3 flags :( locked | allocated | usable ) kva : ffff88011ddea000 [ 1073.734941 ] __clflush_one () : EFAULT : bad address tsk : 32 user_va : 0x7fff4ddea000 [ 1073.822304 ] pcache dumped because : evict / ref bug [ 1073.987667 ] BUG : failure at managers / processor / pcache / evict . c : 301 / pcache_evict_line () ! [ 1074.082308 ] BUG : failure at managers / processor / pcache / rmap . c : 763 / pcache_zap_pte () ! [ 1074.172789 ] Kernel Panic - not syncing : BUG ! [ 1074.223751 ] CPU : 23 PID : 50 Comm : word_count - pthr 4.0.0 - lego - ys + # 476 Time CPU0 CPU1 0 pcache_evict_line() zap_pte_range() 1 find @pcm to evict prepare to unmap pte which points to @pcm 2 lock_pcache() .. 3 pcache_try_to_unmap() pte_offset_lock() 4 try to lock pte pcache_zap_pte() 5 ..spin.. trylock_pcache (failed) 6 ..spin.. unlock pte 7 lock pte trylock pcache 8 clear pte ..spin.. 9 unlock pte ..spin.. 10 unlock pcache ..spin.. 11 .. lock pcache 12 .. lock pte 13 .. HERE, should check if pte changed! Huh, patched both eviction and other code. Use refcount, pcache lock, pte lock to synchronize between all users. Make sure a going-to-be-evicted pcm will not be used by others. And others will not have a chance to use such line. 03/12 Tue \u00b6 Continue victim cache. The current conclusion is victim has a unbalanced input and output rate. That is why some cores timeout and abort. Got some more clean log. The log told us that the flushd_victim is too slow at flushing content. Next I going to print the current flush queue content. Make sure that they are really not flushed. If so, I want to add code to flush sync. [ 318.193591 ] CPU4 PID : 54 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207f81d340 , pset_idx : 1869 , nr_lru : 7 [ 318.330986 ] -- Start Dump Victim Cache -- [ 318.388190 ] -- CPU4 [ word_count - pthr ][ pid = 54 , tgid = 32 ] -- [ 318.456835 ] victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d200 [ 318.627406 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90748000 [ 318.707492 ] pset : ffff88207f81d200 set_idx : 1864 nr_lru : 8 [ 318.775096 ] [ 318.792778 ] victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d240 [ 318.963349 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90749000 [ 319.043435 ] pset : ffff88207f81d240 set_idx : 1865 nr_lru : 8 [ 319.111040 ] [ 319.128721 ] victim : ffff88207ff71090 index : 2 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d180 [ 319.299292 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90746000 [ 319.379378 ] pset : ffff88207f81d180 set_idx : 1862 nr_lru : 8 [ 319.446983 ] [ 319.464664 ] victim : ffff88207ff710d8 index : 3 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d280 [ 319.635237 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074a000 [ 319.715321 ] pset : ffff88207f81d280 set_idx : 1866 nr_lru : 8 [ 319.782927 ] [ 319.800608 ] victim : ffff88207ff71120 index : 4 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d140 [ 319.971179 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90745000 [ 320.051265 ] pset : ffff88207f81d140 set_idx : 1861 nr_lru : 8 [ 320.118870 ] [ 320.136551 ] victim : ffff88207ff71168 index : 5 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d300 [ 320.307123 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074c000 [ 320.387208 ] pset : ffff88207f81d300 set_idx : 1868 nr_lru : 8 [ 320.454813 ] [ 320.472494 ] victim : ffff88207ff711b0 index : 6 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d1c0 [ 320.643066 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90747000 [ 320.723152 ] pset : ffff88207f81d1c0 set_idx : 1863 nr_lru : 8 [ 320.790756 ] [ 320.808438 ] victim : ffff88207ff711f8 index : 7 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d2c0 [ 320.979009 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074b000 [ 321.059096 ] pset : ffff88207f81d2c0 set_idx : 1867 nr_lru : 8 [ 321.126700 ] [ 321.144381 ] -- End Dump Victim Cache -- [ 321.200545 ] CPU4 PID : 54 fail to allocate pcache or victim cache lines . [ 321.278552 ] word_count - pthr [ 54 ] : segfault at 0x74d000 ip 00000000004024 9 d sp 00007f ff7674cd80 error 6 [ 321.511925 ] nr_pgfault : 551908 [ 321.546357 ] nr_clflush : 33449 [ 321.581718 ] nr_pgfault_wp : 0 [ 321.616040 ] nr_pgfault_wp_cow : 0 [ 321.654523 ] nr_pgfault_wp_reuse : 0 [ 321.695087 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 321.754371 ] nr_pcache_fill_from_memory : 546067 [ 321.807414 ] nr_pcache_fill_from_victim : 5750 [ 321.858378 ] nr_pcache_eviction_triggered : 38689 [ 321.912461 ] nr_pcache_eviction_eagain : 5239 [ 321.962385 ] nr_pcache_eviction_succeed : 33449 [ 322.014389 ] nr_victim_eviction_triggered : 41887455 [ 322.071592 ] nr_victim_eviction_eagain : 41859764 [ 322.125676 ] nr_victim_eviction_succeed : 27691 [ 322.177680 ] nr_victim_prepare_insert : 33450 [ 322.227603 ] nr_victim_finish_insert : 33449 [ 322.276487 ] nr_victim_flush_submitted : 33449 [ 322.327451 ] nr_victim_flush_finished : 33449 [ 322.377374 ] nr_victim_flush_async_run : 26989 [ 322.428338 ] nr_victim_flush_sync : 0 Yes, this victims are truly not being flushed. They are inside the flush_queue. No bug, hoo! Just some performance coding issues. But god why the flushd does not get a chance to run in 10 seconds? Hmm\u2026 [ 5520.236187 ] __clflush_one () : EFAULT : bad address tsk : 32 user_va : 0x7fff464fa000 [ 5530.404269 ] CPU4 PID : 54 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207f81d340 , pset_idx : 1869 , nr_lru : 7 [ 5530.541664 ] CPU4 PID54 -- Start Dump Victim Cache [ 0 ] [ 5530.606147 ] CPU4 PID54 victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d1c0 [ 5530.789194 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90747000 [ 5530.880717 ] CPU4 PID54 rmap to pset : ffff88207f81d1c0 set_idx : 1863 nr_lru : 8 [ 5530.968080 ] CPU4 PID54 victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d280 [ 5531.151128 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074a000 [ 5531.242652 ] CPU4 PID54 rmap to pset : ffff88207f81d280 set_idx : 1866 nr_lru : 8 [ 5531.330015 ] CPU4 PID54 victim : ffff88207ff71090 index : 2 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d300 [ 5531.513063 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074c000 [ 5531.604586 ] CPU4 PID54 rmap to pset : ffff88207f81d300 set_idx : 1868 nr_lru : 8 [ 5531.691950 ] CPU4 PID54 victim : ffff88207ff710d8 index : 3 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d2c0 [ 5531.874997 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074b000 [ 5531.966521 ] CPU4 PID54 rmap to pset : ffff88207f81d2c0 set_idx : 1867 nr_lru : 8 [ 5532.053885 ] CPU4 PID54 victim : ffff88207ff71120 index : 4 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d200 [ 5532.236932 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90748000 [ 5532.328456 ] CPU4 PID54 rmap to pset : ffff88207f81d200 set_idx : 1864 nr_lru : 8 [ 5532.415819 ] CPU4 PID54 victim : ffff88207ff71168 index : 5 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d240 [ 5532.598867 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90749000 [ 5532.690390 ] CPU4 PID54 rmap to pset : ffff88207f81d240 set_idx : 1865 nr_lru : 8 [ 5532.777753 ] CPU4 PID54 victim : ffff88207ff711b0 index : 6 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d180 [ 5532.960802 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90746000 [ 5533.052325 ] CPU4 PID54 rmap to pset : ffff88207f81d180 set_idx : 1862 nr_lru : 8 [ 5533.139689 ] CPU4 PID54 victim : ffff88207ff711f8 index : 7 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d140 [ 5533.322736 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90745000 [ 5533.414259 ] CPU4 PID54 rmap to pset : ffff88207f81d140 set_idx : 1861 nr_lru : 8 [ 5533.501623 ] CPU4 PID54 -- End Dump Victim Cache [ 0 ] [ 5533.566106 ] CPU4 PID54 -- Start Dump Victim Flush Queue [ 0 ] [ 5533.635789 ] CPU4 PID54 victim : ffff88207ff711f8 index : 7 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d140 [ 5533.818837 ] CPU4 PID54 victim : ffff88207ff711b0 index : 6 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d180 [ 5534.001884 ] CPU4 PID54 victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d1c0 [ 5534.184931 ] CPU4 PID54 victim : ffff88207ff71120 index : 4 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d200 [ 5534.367978 ] CPU4 PID54 victim : ffff88207ff71168 index : 5 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d240 [ 5534.551025 ] CPU4 PID54 victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d280 [ 5534.734074 ] CPU4 PID54 victim : ffff88207ff710d8 index : 3 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d2c0 [ 5534.917120 ] CPU4 PID54 victim : ffff88207ff71090 index : 2 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d300 [ 5535.100168 ] CPU4 PID54 -- End Dump Victim Flush Queue [ 0 ] [ 5535.169851 ] CPU4 PID : 54 fail to allocate pcache or victim cache lines . [ 5535.247854 ] word_count - pthr [ 54 ] : segfault at 0x74d000 ip 00000000004024 9 d sp 00007f ff7674cd80 error 6 [ 5535.480513 ] nr_pgfault : 549578 [ 5535.514943 ] nr_clflush : 31822 [ 5535.550304 ] nr_pgfault_wp : 0 [ 5535.584625 ] nr_pgfault_wp_cow : 0 [ 5535.623107 ] nr_pgfault_wp_reuse : 0 [ 5535.663669 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 5535.722952 ] nr_pcache_fill_from_memory : 544279 [ 5535.775993 ] nr_pcache_fill_from_victim : 5201 [ 5535.826955 ] nr_pcache_eviction_triggered : 37437 [ 5535.881038 ] nr_pcache_eviction_eagain : 5614 [ 5535.930960 ] nr_pcache_eviction_succeed : 31822 [ 5535.982963 ] nr_victim_eviction_triggered : 42000029 [ 5536.040165 ] nr_victim_eviction_eagain : 41973416 [ 5536.094247 ] nr_victim_eviction_succeed : 26613 [ 5536.146249 ] nr_victim_prepare_insert : 31823 [ 5536.196171 ] nr_victim_finish_insert : 31822 [ 5536.245052 ] nr_victim_flush_submitted : 31822 [ 5536.296015 ] nr_victim_flush_finished : 31822 [ 5536.345937 ] nr_victim_flush_async_run : 26718 [ 5536.396899 ] nr_victim_flush_sync : 0 Hmm, got some interesting bug, which never happened before. We did a unmap before finish_insert , so the mapcount must be zero. Since we have the Reclaim set for the candidate. But it looks like other code does not too much about the Reclaim bit. I need to check. [ 1009.676839 ] victim_flush_async CPU4 jobs 1 [ 1009.725830 ] victim_flush_async CPU4 jobs 1 [ 1009.774423 ] victim_flush_async CPU4 jobs 1 [ 1009.823147 ] __clflush_one () : EFAULT : bad address tsk : 32 user_va : 0x7fff465fc000 [ 1009.910479 ] pcache : ffff88018098d740 mapcount : 1 refcount : 3 flags :( locked | allocated | usable | valid | reclaim ) kva : ffff88012635d000 [ 1010.045652 ] pcache dumped because : PCACHE_BUG_ON_PCM ( pcache_mapped ( pcm )) [ 1010.125725 ] victim_flush_async CPU4 jobs 1 [ 1010.174602 ] ------------ [ cut here ] ------------ [ 1010.229717 ] BUG : failure at managers / processor / pcache / victim . c : 601 / victim_finish_insert () ! [ 1010.328509 ] victim_flush_async CPU4 jobs 1 [ 1010.377385 ] Kernel Panic - not syncing : BUG ! [ 1010.428341 ] CPU : 20 PID : 47 Comm : word_count - pthr 4.0.0 - lego - ys + # 468 [ 1010.505294 ] Stack : [ 1010.529212 ] ffff881f2040fe08 ffffffff810259f4 000000000000000 8 ffff881f2040fe18 [ 1010.616565 ] ffff881f2040fdd0 0000000021475542 0000000000000000 0000000000000000 [ 1010.703918 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 1010.791270 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 1010.878623 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 1010.965976 ] Call Trace : [ 1010.995095 ] < TSK > [ 1011.017972 ] [ < ffffffff81025a00 > ] panic + 0xc2 / 0x102 [ 1011.074127 ] [ < ffffffff81063a8a > ] ? client_internal_poll_sendcq + 0x2a / 0x80 [ 1011.154202 ] [ < ffffffff81063c2d > ] ? client_send_message_with_rdma_write_with_imm_request + 0x14d / 0x360 [ 1011.262351 ] [ < ffffffff8101bffc > ] ? task_tick_rt + 0x2c / 0xd0 [ 1011.326827 ] [ < ffffffff81019755 > ] ? scheduler_tick + 0x55 / 0x60 [ 1011.393382 ] [ < ffffffff81016e25 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 1011.466175 ] [ < ffffffff810066e4 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 1011.538969 ] [ < ffffffff8100e4aa > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 1011.616964 ] [ < ffffffff81012cfd > ] ? printk + 0x11d / 0x1b0 [ 1011.677279 ] [ < ffffffff81032a19 > ] victim_finish_insert + 0x89 / 0x230 [ 1011.749032 ] [ < ffffffff81031a99 > ] pcache_evict_line + 0x79 / 0x280 [ 1011.817667 ] [ < ffffffff8102f00a > ] pcache_alloc + 0x23a / 0x340 [ 1011.882141 ] [ < ffffffff8102e4da > ] common_do_fill_page + 0x2a / 0x1b0 [ 1011.952856 ] [ < ffffffff8102e160 > ] ? pcache_meta_to_kva + 0x30 / 0x30 [ 1012.023570 ] [ < ffffffff8102e802 > ] pcache_handle_fault + 0x1a2 / 0x660 [ 1012.095324 ] [ < ffffffff810102b2 > ] do_page_fault + 0xa2 / 0x1a0 [ 1012.159799 ] [ < ffffffff8100dadf > ] page_fault + 0x1f / 0x30 Interesting. Memory consistency issue? Actually, I\u2019m not sure if it is the v->flags = 0 issue. Others use atomic bit operations to play with this flag, while the reset is a simple store. I checked the list operations, all of them are protected by spinlock. So the below should never happen in theory. I\u2019m changing the v->flags = 0 to smp_store_mb(v->flags, 0) , which is a xchg in x86. Same for pcache. [ 1773.814490] CPU17 PID44 victim:ffff88207ff71000 index:0 refcount:1 nr_fill:0 locked:0 flags:(allocated|usable) pcm: (null) pset: (null) [ 1773.979705] CPU17 PID44 hit[0] owner: [word_count-pthr][32] addr: 0x7fff95b1c000 [ 1774.072260] CPU17 PID44 rmap to pset:ffff88207f96c700 set_idx: 23324 nr_lru:8 [ 1774.161694] CPU17 PID44 victim dumped because: PCACHE_BUG_ON_VICTIM(!VictimUsable(v)) [ 1774.259451] ------------[ cut here ]------------ [ 1774.314567] BUG: failure at managers/processor/pcache/victim.c:231/find_victim_to_evict()! [ 1774.413363] Kernel Panic - not syncing: BUG! [ 1774.464320] CPU: 17 PID: 44 Comm: word_count-pthr 4.0.0-lego-ys+ #47 ... [ 1781.363348] nr_pcache_fill_from_victim: 2 Did another run. I added an explicit wake_up_victim_flushd if victim failed to evict any line. But this fails with IB failure.. [ 2336.950087 ] CPU4 PID : 54 Abort victim alloc ( 20010 ms ) nr_usable_victims : 8 req from pset : ffff88207f81d340 , pset_idx : 1869 , nr_lru : 7 [ 2337.087474 ] CPU4 PID54 -- Start Dump Victim Cache [ 0 ] [ 2337.151955 ] CPU4 PID54 victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d280 [ 2337.334999 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074a000 [ 2337.426521 ] CPU4 PID54 rmap to pset : ffff88207f81d280 set_idx : 1866 nr_lru : 8 [ 2337.513883 ] CPU4 PID54 victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d2c0 [ 2337.696927 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074b000 [ 2337.788450 ] CPU4 PID54 rmap to pset : ffff88207f81d2c0 set_idx : 1867 nr_lru : 8 ... ... [ 2340.111861 ] CPU4 PID54 -- Start Dump Victim Flush Queue [ 0 ] [ 2340.181543 ] CPU4 PID54 victim : ffff88207ff71090 index : 2 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d140 [ 2340.364587 ] CPU4 PID54 victim : ffff88207ff71120 index : 4 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d180 [ 2340.547632 ] CPU4 PID54 victim : ffff88207ff711f8 index : 7 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d1c0 [ 2340.730675 ] CPU4 PID54 victim : ffff88207ff71168 index : 5 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d200 [ 2340.913720 ] CPU4 PID54 victim : ffff88207ff711b0 index : 6 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d240 [ 2341.096763 ] CPU4 PID54 victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d280 [ 2341.279808 ] CPU4 PID54 victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d2c0 [ 2341.462851 ] CPU4 PID54 victim : ffff88207ff710d8 index : 3 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d300 [ 2341.645895 ] CPU4 PID54 -- End Dump Victim Flush Queue [ 0 ] [ 2341.715577 ] CPU4 PID : 54 fail to allocate pcache or victim cache lines . [ 2341.793579 ] word_count - pthr [ 54 ] : segfault at 0x74d000 ip 00000000004024 9 d sp 00007f ff7674cd80 error 6 [ 2476.201442 ] mlx4_ib_handle_error_cqe syndrome 21 [ 2476.254590 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2476.308670 ] send request failed at connection 4 as 12 [ 2476.368991 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2476.423073 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2476.477153 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2476.531236 ] client_poll_cq : failed status ( 5 ) for wr_id 1051 [ 2476.598837 ] client_poll_cq : failed status ( 5 ) for wr_id 1052 [ 2476.666438 ] __clflush_one () : EPERM : Operation not permitted tsk : 32 user_va : 0x7fff90745000 [ 2476.765240 ] client_poll_cq : connection 4 Recv weird event as -30704 [ 2476.840122 ] client_poll_cq : failed status ( 5 ) for wr_id 1053 [ 2476.907724 ] client_poll_cq : connection 4 Recv weird event as -30704 [ 2476.982605 ] client_poll_cq : failed status ( 5 ) for wr_id 1054 [ 2477.050207 ] client_poll_cq : connection 4 Recv weird event as -30704 [ 2477.125089 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.179169 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.233251 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.287332 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.341414 ] client_poll_cq : failed status ( 5 ) for wr_id 1055 [ 2477.409016 ] client_poll_cq : failed status ( 5 ) for wr_id 1056 .. .. [ 2477.761583 ] client_poll_cq : connection 4 Recv weird event as -30704 [ 2477.836464 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.890545 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.944626 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.998707 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2478.052789 ] client_poll_cq : failed status ( 5 ) for wr_id 1059 [ 2478.120392 ] BUG : unable to handle kernel NULL pointer dereference at ( null ) [ 2478.213992 ] IP : [ < ffffffff81064894 > ] client_poll_cq + 0x1f4 / 0x6c0 [ 2478.284714 ] PGD 0 [ 2478.308635 ] Oops : 0002 [ # 1 ] SMP PROCESSOR [ 2478.356476 ] CPU : 2 PID : 29 Comm : recvpollcq 4.0.0 - lego - ys + # 473 [ 2478.427197 ] RIP : 0010 : [ < ffffffff81064894 > ] [ < ffffffff81064894 > ] client_poll_cq + 0x1f4 / 0x6c0 [ 2478.527040 ] RSP : 0000 : ffff88107e143d90 EFLAGS : 00010246 [ 2478.590481 ] RAX : 0000000000000000 RBX : ffff88207fc6e000 RCX : 0000000000000000 [ 2478.675762 ] RDX : 000000000000100 8 RSI : ffffffff811d36e0 RDI : ffffffff811dab08 [ 2478.761044 ] RBP : ffff88107e143eb0 R08 : 0000000000000000 R09 : 0000000000000000 [ 2478.846327 ] R10 : 0000000000000002 R11 : 0000000000000004 R12 : ffff88207fd4f000 [ 2478.931609 ] R13 : 0000000000000004 R14 : ffff88107e143da8 R15 : 0000000000000000 [ 2479.016890 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc20000 ( 0000 ) knlGS : 0000000000000000 [ 2479.113613 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 2479.182254 ] CR2 : 0000000000000000 CR3 : 000000000113 d000 CR4 : 00000000000406 a0 [ 2479.267536 ] Stack : [ 2479.291457 ] ffff88107e143da0 001012 9 c81019794 0000000000000001 0000000000000423 [ 2479.378818 ] 000000 8100000005 00001008000000f 9 ffff88207fd39000 0000000040000000 [ 2479.466180 ] 000f 004000000002 ffff88107e140000 0000000000000424 ffff881000000005 [ 2479.553542 ] 00000000000000f 9 ffff88207fd39000 ffff88107e143e38 ffffffff81019e44 [ 2479.640904 ] 0000000000000001 0000000000000425 ffff881000000005 ffffffff000000f9 [ 2479.728266 ] Call Trace : [ 2479.757386 ] < TSK > [ 2479.780268 ] [ < ffffffff81019e44 > ] ? try_to_wake_up + 0xe4 / 0x1f0 [ 2479.847869 ] [ < ffffffff81066d78 > ] ? __schedule + 0xf8 / 0x1e0 [ 2479.911311 ] [ < ffffffff81064d60 > ] ? client_poll_cq + 0x6c0 / 0x6c0 [ 2479.979952 ] [ < ffffffff81064d70 > ] client_poll_cq_pass + 0x10 / 0x20 [ 2480.049634 ] [ < ffffffff81020336 > ] kthread + 0xf6 / 0x110 [ 2480.107875 ] [ < ffffffff81020240 > ] ? __kthread_parkme + 0x70 / 0x70 [ 2480.176516 ] [ < ffffffff8100e732 > ] ret_from_fork + 0x22 / 0x30 A classical SMP bug. Lucky to find this one. Let me try to describe this. There are two CPU1. CPU0 and CPU1. CPU0 is doing eviction while CPU1 is doing munmap->pcache_zap_pte. The CPU0 slected a pcm, while this pcm happen to be zapped at the same time by CPU1. There are not enough actions to either 1) prevent CPU0 from selecting this pcm, 2) prevent CPU1 from using this pcm. Both solutions might be work. But we need as least one. wuklab13 0313 -12 [ 1073.616269 ] pcache : ffff880180777a80 mapcount : 0 refcount : 3 flags :( locked | allocated | usable ) kva : ffff88011ddea000 [ 1073.734941 ] __clflush_one () : EFAULT : bad address tsk : 32 user_va : 0x7fff4ddea000 [ 1073.822304 ] pcache dumped because : evict / ref bug [ 1073.987667 ] BUG : failure at managers / processor / pcache / evict . c : 301 / pcache_evict_line () ! [ 1074.082308 ] BUG : failure at managers / processor / pcache / rmap . c : 763 / pcache_zap_pte () ! [ 1074.172789 ] Kernel Panic - not syncing : BUG ! [ 1074.223751 ] CPU : 23 PID : 50 Comm : word_count - pthr 4.0.0 - lego - ys + # 476 03/11 Mon \u00b6 Debug victim cache \u00b6 Morning. Today I will continue debugging victim and clflush, running with MT phoenix+2GB, seq+4GB. Sounds good. Digging into yesterday\u2019s 21th run log. The warning comes from victim_alloc_slowpath . The allocation abort after 10 seconds timeout. And interestingly, a lot threads abort. (The case is, pset is full, so pcache_alloc will try to evict one to victim cache. But victim cache is full as well. So it needs to evict one victim cache line too. Somehow this does not proceed as planned.) I guess somewhere deadlock happens. [ 1682.040428 ] WARNING : CPU : 7 PID : 34 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1682.161063 ] WARNING : CPU : 19 PID : 46 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1686.602779 ] WARNING : CPU : 10 PID : 37 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1687.384837 ] WARNING : CPU : 3 PID : 53 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1687.505474 ] WARNING : CPU : 21 PID : 48 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1687.737386 ] WARNING : CPU : 16 PID : 43 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1687.859063 ] WARNING : CPU : 4 PID : 54 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1688.034819 ] WARNING : CPU : 6 PID : 56 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1688.210574 ] WARNING : CPU : 14 PID : 41 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1688.488246 ] WARNING : CPU : 5 PID : 55 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1689.598935 ] WARNING : CPU : 22 PID : 49 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1689.953565 ] WARNING : CPU : 0 PID : 51 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1691.740234 ] WARNING : CPU : 13 PID : 40 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1691.861911 ] WARNING : CPU : 1 PID : 52 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1791.554552 ] WARNING : CPU : 11 PID : 38 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 1 st run. MT+2GB. Victim allocation as predicted. Somehow I already forgot how the code is designed. I need to take a detailed reread. Along the testing, fixed a bug in eviction code: handle failed evict_line properly. If eviction mechanism failed, we need to clear what the algorithm part has done. This is also related to yesterday\u2019s big idea: always do proper cleanup. Many thanks go to pcache free checking, help me to find this bug. Less is more. I printed too much useless info when pcache_alloc or victim_alloc fail. I removed all the dump_pset from the failing path. It can give me a much more clean message to debug. Hmm, it is really weird. I dump all victims once alloc timeout. You can see that all victim are not Flushed, that means none of them can be evicted. Take a look at the stat. Hmm, I probabaly should not do this per-cpu counter?? ... [ 4751.460819 ] -- Start Dump Victim Cache -- [ 4751.518022 ] -- CPU19 [ word_count - pthr ][ pid = 46 , tgid = 32 ] -- [ 4751.587706 ] victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800440 [ 4751.747872 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff20011000 [ 4751.827955 ] pset : ffff88207f800440 set_idx : 17 nr_lru : 8 [ 4751.893478 ] [ 4751.911159 ] victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f8003c0 [ 4752.071326 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff2000f000 [ 4752.428060 ] pset : ffff88207f8003c0 set_idx : 15 nr_lru : 8 [ 4752.630868 ] [ 4752.931441 ] victim : ffff88207ff71090 index : 2 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800540 [ 4753.370339 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff20015000 [ 4753.450422 ] pset : ffff88207f800540 set_idx : 21 nr_lru : 8 [ 4753.515945 ] [ 4753.533627 ] victim : ffff88207ff710d8 index : 3 refcount : 3 nr_fill : 1 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207fbdff40 [ 4753.693792 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fffbf7fd000 [ 4753.773875 ] pset : ffff88207fbdff40 set_idx : 63485 nr_lru : 7 [ 4753.842518 ] [ 4753.860199 ] victim : ffff88207ff71120 index : 4 refcount : 3 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800500 [ 4754.020367 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff20014000 [ 4754.100449 ] pset : ffff88207f800500 set_idx : 20 nr_lru : 8 [ 4754.165971 ] [ 4754.183653 ] victim : ffff88207ff71168 index : 5 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800480 [ 4754.343819 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff30012000 [ 4754.423902 ] pset : ffff88207f800480 set_idx : 18 nr_lru : 8 [ 4754.489426 ] [ 4754.507106 ] victim : ffff88207ff711b0 index : 6 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f8004c0 [ 4754.808718 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff30013000 [ 4754.888802 ] pset : ffff88207f8004c0 set_idx : 19 nr_lru : 8 [ 4754.954325 ] [ 4754.972006 ] victim : ffff88207ff711f8 index : 7 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800400 [ 4755.132172 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff20010000 [ 4755.212255 ] pset : ffff88207f800400 set_idx : 16 nr_lru : 8 [ 4755.277778 ] [ 4755.295458 ] -- End Dump Victim Cache -- ... [ 4757.948641 ] nr_pgfault : 313898 [ 4757.983067 ] nr_clflush : 488 [ 4758.016347 ] nr_pgfault_wp : 0 [ 4758.050669 ] nr_pgfault_wp_cow : 0 [ 4758.089151 ] nr_pgfault_wp_reuse : 0 [ 4758.129713 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 4758.188995 ] nr_pcache_fill_from_memory : 313833 [ 4758.242038 ] nr_pcache_fill_from_victim : 54 [ 4758.290919 ] nr_pcache_eviction_triggered : 243280263 [ 4758.349161 ] nr_pcache_eviction_eagain : 243279763 [ 4758.404283 ] nr_pcache_eviction_succeed : 488 [ 4758.454207 ] nr_victim_eviction : 426 [ 4758.495807 ] nr_victim_prepare_insert : 500 [ 4758.543649 ] nr_victim_finish_insert : 488 [ 4758.590451 ] nr_victim_flush_submitted : 488 [ 4758.639333 ] nr_victim_flush_finished : 488 I counted it wrong. Below is the log. Since nr_victim_flushd_run * 8 = nr_victim_flush_finished , it basically means for every run, victim_flushd needs to flush all 8 victims, which implies eviction rate is much higher than the flushd running rate. nr_pcache_fill_from_victim: 21 , which means there are some succeed refills, but I don\u2019t know how it can improve performance. [ 475.468489 ] CPU4 PID : 54 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207f800000 , pset_idx : 0 , nr_lru : 7 [ 475.602752 ] CPU3 PID : 53 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207f900a00 , pset_idx : 16424 , nr_lru : 7 [ 476.029145 ] CPU5 PID : 55 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207fbdff40 , pset_idx : 63485 , nr_lru : 7 [ 476.169542 ] CPU9 PID : 36 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207f900000 , pset_idx : 16384 , nr_lru : 7 [ 477.360322 ] CPU1 PID : 52 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207fbfff80 , pset_idx : 65534 , nr_lru : 7 [ 479.206291 ] CPU18 PID : 45 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207fb00000 , pset_idx : 49152 , nr_lru : 7 [ 475.743150 ] -- Start Dump Victim Cache -- [ 475.800350 ] -- CPU4 [ word_count - pthr ][ pid = 54 , tgid = 32 ] -- [ 475.868989 ] victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800a80 [ 476.309940 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff3002a000 [ 476.390020 ] pset : ffff88207f800a80 set_idx : 42 nr_lru : 8 [ 476.455538 ] [ 476.473218 ] victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800bc0 [ 476.633376 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff4002f000 [ 476.713453 ] pset : ffff88207f800bc0 set_idx : 47 nr_lru : 8 [ 476.778972 ] [ 476.796652 ] victim : ffff88207ff71090 index : 2 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800b80 [ 476.956809 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff3002e000 [ 477.036889 ] pset : ffff88207f800b80 set_idx : 46 nr_lru : 8 [ 477.102406 ] [ 477.120086 ] victim : ffff88207ff710d8 index : 3 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800a00 [ 477.280245 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff30028000 [ 477.500721 ] pset : ffff88207f800a00 set_idx : 40 nr_lru : 8 [ 477.566239 ] [ 477.583918 ] victim : ffff88207ff71120 index : 4 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800b40 [ 477.744077 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff3002d000 [ 477.824155 ] pset : ffff88207f800b40 set_idx : 45 nr_lru : 8 [ 477.889673 ] [ 477.907353 ] victim : ffff88207ff71168 index : 5 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800b00 [ 478.067511 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff3002c000 [ 478.147590 ] pset : ffff88207f800b00 set_idx : 44 nr_lru : 8 [ 478.213109 ] [ 478.230788 ] victim : ffff88207ff711b0 index : 6 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800a40 [ 478.390946 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff30029000 [ 478.471024 ] pset : ffff88207f800a40 set_idx : 41 nr_lru : 8 [ 478.536542 ] [ 478.554222 ] victim : ffff88207ff711f8 index : 7 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800ac0 [ 478.714380 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff3002b000 [ 478.794458 ] pset : ffff88207f800ac0 set_idx : 43 nr_lru : 8 [ 478.859977 ] [ 478.877657 ] -- End Dump Victim Cache -- [ 480.324070 ] nr_pgfault : 372353 [ 480.358494 ] nr_clflush : 336 [ 480.391774 ] nr_pgfault_wp : 0 [ 480.426093 ] nr_pgfault_wp_cow : 0 [ 480.464573 ] nr_pgfault_wp_reuse : 0 [ 480.505132 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 480.564410 ] nr_pcache_fill_from_memory : 372326 [ 480.617450 ] nr_pcache_fill_from_victim : 21 [ 480.666330 ] nr_pcache_eviction_triggered : 178320088 [ 480.724569 ] nr_pcache_eviction_eagain : 178319746 [ 480.779687 ] nr_pcache_eviction_succeed : 336 [ 480.829606 ] nr_victim_eviction_triggered : 20589049 [ 480.886805 ] nr_victim_eviction_eagain : 20588741 [ 480.940885 ] nr_victim_eviction_succeed : 308 [ 480.990804 ] nr_victim_prepare_insert : 342 [ 481.038643 ] nr_victim_finish_insert : 336 [ 481.085442 ] nr_victim_flush_submitted : 336 [ 481.134321 ] nr_victim_flush_finished : 336 [ 481.182161 ] nr_victim_flushd_run : 42 03/10 Sun \u00b6 Fix bug from __unhash_procees() \u00b6 [Summary]: a bug cause by laziness. When fork happens, the new thread is added into parent\u2019s thread_group list. However, we forgot to remove it when the new thread exit. Thus, the field in parent\u2019s thread_group will point to a freed page. To make it worse, the freed page got allocated again. In our case, the page was used by pgtable. So, when the parent tries to use that field, it simply corrupts pgtable. This bug is fixed by this commit: 64d43fc. Got something going on. Huh. Anyway, pick up what left last night. 8 th run, [ 426.595911] SYSC_mmap(cpu5): ret_addr:0x7ffefbeac000 pte page got allocated [ 426.653216] pmd is none index 0x1e3 line 567 from_addr 0x7ffefc6acd90 [ 426.734334] __pte_alloc(): for addr: 0x7ffefc6acd90 pte_index: ac [ 426.807132] pte is none index 0x38 line 574 from_addr 0x7ffefc6acd90 [ 427.304148] pte is none index 0x38 line 576 from_addr 0x7ffefc6acd90 this addr seems fine [ 427.382251] pte is none index 0x38 line 567 from_addr 0x7ffefc6abe78 [ 427.462329] pte is none index 0x38 line 574 from_addr 0x7ffefc6abe78 [ 427.644439] pte is none index 0x38 line 576 from_addr 0x7ffefc6abe78 Something happen in between corrupted pgtable [ 427.722547] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000) [ 427.858779] line: 567 from_addr: 0x6fc6d8 pte.cont: 0xffff88207e8c31c0 [ 427.938858] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000) [ 428.075095] line: 574 from_addr: 0x6fc6d8 pte.cont: 0xffff88207e8c31c0 9 th run, found actually it created another thread. And it exit. And it corrupted aftet the pid33 exit. Bang, it should be something wrong in exit(). wuklab13 0311 -4 [ 813.127325 ] CPU6 pid : 33 pmd is none index 0x1e3 line 586 from_addr 0x4b0db0 [ 813.214683 ] CPU5 pid : 32 pmd is none index 0x1e3 line 593 from_addr 0x6f4768 [ 813.302042 ] CPU6 pid : 33 pmd is none index 0x1e3 line 593 from_addr 0x4b0db0 [ 813.397836 ] CPU5 pid : 32 pmd is none index 0x1e3 line 595 from_addr 0x6f4768 [ 813.593364 ] CPU6 pid : 33 pmd is none index 0x1e3 line 595 from_addr 0x4b0db0 [ 813.678751 ] do_exit () pid : 33 , tgid : 32 code : 0x0 [ 814.474321 ] CPU5 pid : 32 pmd is none index 0x1e3 line 567 from_addr 0x7ffefc6acd90 [ 814.567918 ] CPU5 pid : 32 pmd is none index 0x1e3 line 575 from_addr 0x7ffefc6acd90 [ 814.661516 ] CPU5 pid : 32 pmd is none index 0x1e3 line 583 from_addr 0x7ffefc6acd90 [ 814.755115 ] CPU5 pid : 32 pmd is none index 0x1e3 line 586 from_addr 0x7ffefc6acd90 [ 814.848714 ] __pte_alloc () : for addr : 0x7ffefc6acd90 pte_index : ac [ 814.921511 ] CPU5 pid : 32 pte is none index 0x38 line 593 from_addr 0x7ffefc6acd90 [ 815.125249 ] CPU5 pid : 32 pte is none index 0x38 line 595 from_addr 0x7ffefc6acd90 [ 815.215833 ] After pcache_handle_fault [ 815.259511 ] CPU5 pid : 32 pte is none index 0x38 line 726 from_addr 0x7ffefc6acd90 [ 815.352071 ] CPU5 pid : 32 pte is none index 0x38 line 567 from_addr 0x7ffefc6abe78 [ 815.444627 ] CPU5 pid : 32 pte is none index 0x38 line 575 from_addr 0x7ffefc6abe78 [ 815.537186 ] CPU5 pid : 32 pte is none index 0x38 line 583 from_addr 0x7ffefc6abe78 [ 815.629744 ] CPU5 pid : 32 pte is none index 0x38 line 586 from_addr 0x7ffefc6abe78 [ 815.722303 ] CPU5 pid : 32 pte is none index 0x38 line 593 from_addr 0x7ffefc6abe78 [ 815.916890 ] CPU5 pid : 32 pte is none index 0x38 line 595 from_addr 0x7ffefc6abe78 [ 816.007471 ] After pcache_handle_fault [ 816.051151 ] CPU5 pid : 32 pte is none index 0x38 line 726 from_addr 0x7ffefc6abe78 [ 816.143715 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 816.279946 ] do_exit () pid : 34 , tgid : 32 code : 0x0 [ 816.331945 ] CPU5 pid : 32 line : 567 from_addr : 0x6fc6d8 pte . cont : 0xffff88207e8c31c0 10 th run, actually 2 threads are created. When pid 33 exit, everything stays okay. But after fork of pid 34. It went wrong: wuklab13 0311 -8 [ 609.490893 ] do_exit () pid : 33 , tgid : 32 code : 0x0 [ 609.542894 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 401 from_addr 0x0 [ 609.640661 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 443 from_addr 0x0 [ 609.738429 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 465 from_addr 0x0 [ 609.836197 ] exit_mm : 378 mm -> users 2 mm -> count 1 [ 609.891320 ] exit_mm : 380 mm -> users 1 mm -> count 1 [ 609.946445 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 468 from_addr 0x0 [ 610.044212 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 471 from_addr 0x0 [ 610.141979 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 474 from_addr 0x0 [ 610.239747 ] SYSC_mmap ( cpu5 ) : ret_addr : 0x7ffefbeac000 [ 610.299031 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 482 from_addr 0x0 [ 610.396798 ] CPU5 pid : 32 caller : pcache_handle_fault pmd is none index 0x1e3 line 568 from_addr 0x7ffefc6acd90 [ 610.518489 ] CPU5 pid : 32 caller : pcache_handle_fault pmd is none index 0x1e3 line 576 from_addr 0x7ffefc6acd90 [ 610.640178 ] CPU5 pid : 32 caller : pcache_handle_fault pmd is none index 0x1e3 line 584 from_addr 0x7ffefc6acd90 [ 610.761866 ] CPU5 pid : 32 caller : pcache_handle_fault pmd is none index 0x1e3 line 587 from_addr 0x7ffefc6acd90 [ 610.883557 ] __pte_alloc () : for addr : 0x7ffefc6acd90 pte_index : ac [ 610.956362 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 594 from_addr 0x7ffefc6acd90 [ 611.179051 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 596 from_addr 0x7ffefc6acd90 [ 611.297723 ] After pcache_handle_fault [ 611.341406 ] CPU5 pid : 32 caller : do_page_fault pte is none index 0x38 line 726 from_addr 0x7ffefc6acd90 [ 611.455816 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 568 from_addr 0x7ffefc6abe78 [ 611.576464 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 576 from_addr 0x7ffefc6abe78 [ 611.697113 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 584 from_addr 0x7ffefc6abe78 [ 611.817762 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 587 from_addr 0x7ffefc6abe78 [ 611.938412 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 594 from_addr 0x7ffefc6abe78 [ 612.161103 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 596 from_addr 0x7ffefc6abe78 [ 612.279778 ] After pcache_handle_fault [ 612.323461 ] CPU5 pid : 32 caller : do_page_fault pte is none index 0x38 line 726 from_addr 0x7ffefc6abe78 [ 612.437875 ] do_fork : current : 32 new : 34 [ 612.484676 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 612.620924 ] do_exit () pid : 34 , tgid : 32 code : 0x0 [ 612.672928 ] CPU5 pid : 32 caller : pcache_handle_faultline : 568 from_addr : 0x6fc6d8 pte . cont : 0xffff88207e8c31c0 [ 612.793577 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 612.929828 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 613.066078 ] CPU7 pid : 34 caller : do_exitline : 401 from_addr : 0x0 pte . cont : 0xffff88207e8c31c0 11 th run, found it orignate from copy_process() . Good. [ 869.591729 ] CPU5 pid : 32 caller : do_fork pte is none index 0x38 line 886 from_addr 0x0 [ 869.688449 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 869.824681 ] CPU5 pid : 32 caller : do_fork line : 894 from_addr : 0x0 pte . cont : 0xffff88207e8c31c0 12 th run, found the opeation that corrupt pgtable: [ 1099.974106 ] CPU5 pid : 32 caller : copy_process pte is none index 0x38 line 897 from_addr 0x0 [ 1100.076032 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 1100.212282 ] CPU5 pid : 32 caller : copy_process line : 902 from_addr : 0x0 pte . cont : 0xffff88207e8c31c0 896 if ( current -> tgid == 32 ) 897 jasmine ( 0 , __LINE__ , __func__ ); 898 899 list_add_tail ( & p -> thread_group , 900 & p -> group_leader -> thread_group ); 901 if ( current -> tgid == 32 ) 902 jasmine ( 0 , __LINE__ , __func__ ); 13 th run, interesting, the list_add_tail write to the pgtable. pte.cont = 0xffff88207e8c31c0, p->thread_group: 0xffff88207e8c31c0 . [ 916.269942 ] CPU5 pid : 32 caller : copy_process pte is none index 0x38 line 898 from_addr 0x0 [ 916.371863 ] p : ffff88207e8c3000 p -> group_leader : ffff88107e190000 ( 32 ) p -> thread_group : ffff88207e8c31c0 leader -> thread_grou : ffff88107e1901c0 [ 916.523705 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 916.659947 ] CPU5 pid : 32 caller : copy_process line : 906 from_addr : 0x0 pte . cont : 0xffff88207e8c31c0 [ 916.769148 ] p : ffff88207e8c3000 p -> group_leader : ffff88107e190000 ( 32 ) p -> thread_group : ffff88207e8c31c0 leader -> thread_grou : ffff88107e1901c0 14 th run, got an log like this. Clearly, the pte is written the value of p->thread_group. But the leader\u2019s pointer is correct. Weird, going to dig deeper. p: ffff88207e8c3000 p->group_leader: ffff88107e189000(32) p->thread_group: ffff88207e8c31c0 leader->thread_group: ffff88107e1891c0 pte page: ffff88207e8b5000 pte: ffff88207e8b51c0 pte.cont: ffff88207e8c31c0 15 th run, found the bug. wuklab13 0311 -15 [ 1474.477687 ] dup_task_struct () : current : 32 new : ffff88207e8b5000 .. while pid 33 exit so the ffff88207e8b5000 is freed but allocated again by pte_alloc [ 1481.420200 ] __pte_alloc () : CPU5 for addr : 0x7ffefc6acd90 pte_index : ac new pte page : ffff88207e8b5000 However , we forgot to remove it from group_leader ' s thread_group [ 1485.895938 ] p : ffff88207e8c3000 p -> group_leader : ffff88107e19b000 ( 32 ) p -> thread_group : ffff88207e8c31c0 leader -> thread_group : ffff88107e19b1c0 [ 1486.047784 ] tg -> next : ffff88207e8c31c8 tg -> prev : ffff88207e8c31c0 leader -> tg -> next ffff88107e19b1c8 leader -> tg -> prev ffff88107e19b1c0 [ 1486.191311 ] next ffff88107e19b1c0 prev ffff88207e8b51c0 next ffff88107e19b1c0 [ 1486.276594 ] CPU5 pid : 32 caller : __list_add pte is none index 0x38 line 61 from_addr 0x0 page : 0xffff88207e8b5000 [ 1486.401399 ] CPU5 pid : 32 caller : __list_add pte is none index 0x38 line 65 from_addr 0x0 page : 0xffff88207e8b5000 [ 1486.526203 ] CPU5 pid : 32 caller : __list_add pte is none index 0x38 line 69 from_addr 0x0 page : 0xffff88207e8b5000 [ 1486.651010 ] CPU5 pid : 32 caller : __list_add pte is none index 0x38 line 73 from_addr 0x0 page : 0xffff88207e8b5000 [ 1486.775814 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 1486.912060 ] CPU5 pid : 32 caller : __list_add line : 77 from_addr : 0x0 pte . cont : 0xffff88207e8c31c0 16 th run, damn, after patching __unhash_process() , it finally works. Going to workout, see you tonight. victim report error \u00b6 17 th run. The phoenix program has bug itself, it is not able to run with 4GB dataset. So try it with 2GB dataset. Uuh, the log is too long. __put_vicim report a victim that has wrong flags. Going to disable the evict log and try again. 18 th run. Happen to run seq with 100MB\u2026 It actually half finished. But the printf of phoenix has funny chars. I guess memory is corrupted. The log shows it is ib_mad_completion. [ 2244.018806 ] Processor : Processor manager is running . [ 2246.394568 ] STDOUT : --- [ envp [ 0 ] HOME =/ ] --- [ 2246.447719 ] STDOUT : --- [ envp [ 1 ] TERM = linux ] --- [ 2246.507003 ] STDOUT : --- [ argv [ 0 ] / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count - seq ] --- [ 2246.618289 ] STDOUT : --- [ argv [ 1 ] / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count_datafiles / word_100MB . txt ] --- [ 2258.805633 ] STDOUT : --- [ Word - Count - Seq : Computation Completed 12.46633 sec ] --- [ 2258.923180 ] SYSC_close () : [ 4 ] -> [ / proc / meminfo ] [ 2258.995743 ] STDOUT : --- [ Use len is 123748 [ 2263.484774 ] STDOUT : --- [ THE : 1115050 ] --- [ 2263.666785 ] STDOUT : --- [ OF : 615296 ] --- [ 2266.103660 ] STDOUT : --- [ AND : 545303 ( a lot funny chars , deleted .) ] --- [ 2267.016837 ] Code : [ 2267.038680 ] STDOUT : --- [ TO : 475179 +> \u00d5\u00fe\u00da\u00e9\u00d8 ^ G \u00a7 < 87 > k < 80 > z ^ T < 86 > ruJ \u00b7\u00bf\u00bb < 9 e > \u00e9\u00de\u00ed\u00d1 r\u00dc\u00d5 ^ W\u00e5 ^ W *^ _ {( \u00ca ? R\u00f9a\u00e9\u00f6 \u00f7 8 \u00ed < 91 > \u00dc\u00e8 < 8f > \u00f2\u00bf i ^? \u00e8 4 < 94 > \u00d7\u00b2\u00c9\u00b5 ^ V \u00bf\u00ab\u00eb P ] \u00ed\u00ef h ^ G\u00ca\u00eb < 98 >^ T \u00d7 Qp\u00b9O \u00ae\u00ef ^ \\\u00da ^?^ A\u00ed < 91 > \u00d9 v\u00ddBy ^ _\u00e9iwP ^ r < 97 > \u00eb\u00f9\u00ef\u00df ] \u00a3\u00df\u00ad < 98 >< 81 > \u00f8 < 85 > \u00ce Ey ^ Y\u00e5 ^? V\u00f9\u00ba ^ Y\u00de\u00f5\u00cb ] r5\u00c9\u00f0 ^^ ' < 92 > \u00c9 ] ^ ] P ^ \u00c7 i \u00bb z : \u00d4 ^ S \u00ae e < 8 a >+ \\\u00e9 < 8 a > \u00ae\u00b1\u00e0 E\u00d5\u00ce , \u00f0\u00d2\u00e2 3 \u00c1 _ ^ P_ ^ H ^ [ | \u00b8\u00ae\u00e1 s\u00edF \u00bf m < 95 >< 9 d >?< 82 > \u00f2 : \u00be\u00de\u00f5 3 \u00ca\u00d7 T\u00fc \u00ae ] --- [ 2263.339165 ] BUG : unable to handle kernel paging request at ffffffffffff8100 [ 2263.422369 ] IP : [ < ffffffffffff8100 > ] 0xffffffffffff8100 [ 2263.570058 ] PGD 1140067 PUD 1142067 PMD 0 [ 2263.618942 ] Oops : 0010 [ # 1 ] SMP PROCESSOR [ 2264.705811 ] CPU : 0 PID : 27 Comm : ib_mad_completi 4.0.0 - lego - ys + # 408 [ 2264.781736 ] RIP : 0010 : [ < ffffffffffff8100 > ] [ < ffffffffffff8100 > ] 0xffffffffffff8100 [ 2264.873262 ] RSP : 0000 : ffff88107efabc90 EFLAGS : 00010046 [ 2264.936705 ] RAX : 5636000000000098 RBX : db5affffffffffff RCX : 0000000000000001 [ 2265.021990 ] RDX : ffff88107efabd38 RSI : 0000000000000000 RDI : 4460f fffffff8114 [ 2265.107277 ] RBP : ffff88107efabce0 R08 : 000000000000001f R09 : ffff88107efa43c0 [ 2265.192561 ] R10 : ffff88107efabe68 R11 : 0000000000000001 R12 : ac02000004ecbdbd [ 2265.277847 ] R13 : 0000000000000000 R14 : ffff88107efa4228 R15 : ffff88107e1ab000 [ 2265.363133 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc00000 ( 0000 ) knlGS : 0000000000000000 [ 2265.459858 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 2265.528503 ] CR2 : ffffffffffff8100 CR3 : 000000000113 d000 CR4 : 00000000000406 b0 [ 2265.613789 ] Stack : [ 2265.637710 ] ffffffff810151a7 00000000000000 82 ffff88107fc04980 0000000000000000 [ 2265.725075 ] ffff88107efabcc8 ffff88107fc04980 0000000000000000 0000000000000000 [ 2265.812441 ] ffff88107efa4228 ffff88107e1ab000 ffff88107efabcf8 ffffffff81016e17 [ 2265.899806 ] 000000007 efabe20 ffff88107efabd20 ffffffff810066f4 ffffffff81072f20 [ 2265.987172 ] ffff88107fc05e00 ffff88107efa4000 ffff88107efabe08 ffffffff8100e4aa [ 2266.074538 ] Call Trace : [ 2266.206626 ] < TSK > [ 2266.229507 ] [ < ffffffff810151a7 > ] ? update_wall_time + 0x47 / 0x6b0 [ 2266.299192 ] [ < ffffffff81016e17 > ] tick_handle_periodic + 0x67 / 0x70 [ 2266.369916 ] [ < ffffffff810066f4 > ] apic_timer_interrupt + 0x54 / 0x90 [ 2266.440641 ] [ < ffffffff8100e4aa > ] smp__apic_timer_interrupt + 0x6a / 0x70 [ 2266.516565 ] [ < ffffffff810663b8 > ] ? __schedule + 0xf8 / 0x1e0 [ 2266.580010 ] [ < ffffffff810664b3 > ] schedule + 0x13 / 0x30 [ 2266.638254 ] [ < ffffffff81058c97 > ] ib_mad_completion_handler + 0x2b7 / 0x860 [ 2266.716258 ] [ < ffffffff810589e0 > ] ? ib_mad_send_done_handler . isra .22 + 0x1d0 / 0x1d0 [ 2266.803624 ] [ < ffffffff81020376 > ] kthread + 0xf6 / 0x110 [ 2266.861867 ] [ < ffffffff81020280 > ] ? __kthread_parkme + 0x70 / 0x70 [ 2266.930512 ] [ < ffffffff8100e732 > ] ret_from_fork + 0x22 / 0x30 [ 2266.993955 ] < EOT > 19 th , try seq+100MB again. Well succeed. I guess I start S too later. So that thread has issues. We run 12.3 sec, while linux run 9.7 sec. 20 th , try seq+4GB data. Linux runs 314.4 sec . Lego runs 403 sec . But Lego has some clflush error messages. I don\u2019t know why actually. [ 794.604628 ] Processor : Processor manager is running . [ 796.884884 ] STDOUT : --- [ envp [ 0 ] HOME =/ ] --- [ 796.938032 ] STDOUT : --- [ envp [ 1 ] TERM = linux ] --- [ 796.997312 ] STDOUT : --- [ argv [ 0 ] / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count - seq ] --- [ 797.108596 ] STDOUT : --- [ argv [ 1 ] / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count_datafiles / word_4GB . txt ] --- [ 980.640200 ] __clflush_one () : EFAULT : bad address [ 980.692315 ] __clflush_one () : EFAULT : bad address [ 980.746397 ] __clflush_one () : EFAULT : bad address [ 980.800478 ] __clflush_one () : EFAULT : bad address [ 980.854559 ] __clflush_one () : EFAULT : bad address [ 980.908642 ] __clflush_one () : EFAULT : bad address [ 980.962723 ] __clflush_one () : EFAULT : bad address [ 981.016804 ] __clflush_one () : EFAULT : bad address [ 981.070886 ] __clflush_one () : EFAULT : bad address [ 981.124968 ] __clflush_one () : EFAULT : bad address [ 981.179048 ] __clflush_one () : EFAULT : bad address [ 981.233129 ] __clflush_one () : EFAULT : bad address [ 981.287211 ] __clflush_one () : EFAULT : bad address [ 981.341293 ] __clflush_one () : EFAULT : bad address [ 981.395375 ] __clflush_one () : EFAULT : bad address [ 981.449456 ] __clflush_one () : EFAULT : bad address [ 981.503538 ] __clflush_one () : EFAULT : bad address [ 981.557619 ] __clflush_one () : EFAULT : bad address [ 981.611702 ] __clflush_one () : EFAULT : bad address [ 981.665782 ] __clflush_one () : EFAULT : bad address [ 981.719863 ] __clflush_one () : EFAULT : bad address [ 981.773945 ] __clflush_one () : EFAULT : bad address [ 981.828026 ] __clflush_one () : EFAULT : bad address [ 981.882108 ] __clflush_one () : EFAULT : bad address [ 981.936188 ] __clflush_one () : EFAULT : bad address [ 981.990271 ] __clflush_one () : EFAULT : bad address [ 982.044352 ] __clflush_one () : EFAULT : bad address [ 982.098434 ] __clflush_one () : EFAULT : bad address [ 982.152515 ] __clflush_one () : EFAULT : bad address [ 982.206596 ] __clflush_one () : EFAULT : bad address [ 1200.759741 ] STDOUT : --- [ Word - Count - Seq : Computation Completed 403.519401 sec ] --- ... [ 1200.989480 ] STDOUT : --- [ THE : 44602000 ... [ 1201.755779 ] do_group_exit () pid : 32 , tgid : 32 exit_code : 0x0 [ 1201.819136 ] do_exit () pid : 32 , tgid : 32 code : 0x0 [ 1201.872451 ] nr_pgfault : 1049525 [ 1201.908579 ] nr_pgfault_wp : 0 [ 1201.942899 ] nr_pgfault_wp_cow : 0 [ 1201.981380 ] nr_pgfault_wp_reuse : 0 [ 1202.021941 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 1202.081223 ] nr_pcache_fill_from_memory : 1045393 [ 1202.135304 ] nr_pcache_fill_from_victim : 4132 [ 1202.186265 ] nr_pcache_eviction : 525230 [ 1202.230987 ] nr_victim_eviction : 521090 21th run. Do not have time and energy to debug the clflush issue. I just want to run MT+2GB again. Well victim has issues! Some warning are triggered. Log is wuklab13:~/ys/0311-22 . Continue tomorrow! Good night world. (Such a lonly phd.) 03/10 Sat \u00b6 Running python hello world. Tried to make kmalloc use buddy directly. put_pcache in pcache_zap_pte \u00b6 So this time, python keep running for a long time. But P crashed when the first time eviction was triggered. Below is log from S side, those libraries do not exist, so these log are fine: S: [Mar10 10:39] handle_access_request /etc/ld.so.preload 4, -2 [Mar10 10:44] local_file_open : Cannot open required file [/usr/lib64/python2.7/site.so]. [ +0.352839] local_file_open : Cannot open required file [/usr/lib64/python2.7/sitemodule.so]. [ +22.254465] local_file_open : Cannot open required file [/usr/lib64/python2.7/os.so]. [ +0.350759] local_file_open : Cannot open required file [/usr/lib64/python2.7/osmodule.so]. [Mar10 10:45] local_file_open : Cannot open required file [/usr/lib64/python2.7/posixpath.so]. [ +0.358045] local_file_open : Cannot open required file [/usr/lib64/python2.7/posixpathmodule.so]. [ +13.421033] local_file_open : Cannot open required file [/usr/lib64/python2.7/stat.so]. [ +0.352838] local_file_open : Cannot open required file [/usr/lib64/python2.7/statmodule.so]. [Mar10 10:46] local_file_open : Cannot open required file [/usr/lib64/python2.7/genericpath.so]. [ +0.360126] local_file_open : Cannot open required file [/usr/lib64/python2.7/genericpathmodule.so]. [ +11.582165] local_file_open : Cannot open required file [/usr/lib64/python2.7/warnings.so]. [ +0.357003] local_file_open : Cannot open required file [/usr/lib64/python2.7/warningsmodule.so]. [ +11.989828] local_file_open : Cannot open required file [/usr/lib64/python2.7/linecache.so]. [ +0.358043] local_file_open : Cannot open required file [/usr/lib64/python2.7/linecachemodule.so]. [Mar10 10:47] local_file_open : Cannot open required file [/usr/lib64/python2.7/types.so]. [ +0.353879] local_file_open : Cannot open required file [/usr/lib64/python2.7/typesmodule.so]. Weird P\u2019s bug, seems like the pcm returned by evict_find_line has issue. Well, I\u2019m trying to debug what is going with this set. wuklab13 0310 -2 [ 1046.880649 ] SYSC_read () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff6e117e0 [ 1046.959692 ] fd : 8 , buf : 00007f fff7ffb000 , count : 4096 [ 1048.726624 ] pcache_evict_line () : pset : ffff88207f9ffec0 , for uva : 0x7ffff7ffb000 [ 1048.813053 ] ------------ [ cut here ] ------------ [ 1048.868174 ] BUG : failure at . / include / processor / pcache . h : 284 / pcache_meta_to_pcache_set () ! [ 1048.965937 ] Kernel Panic - not syncing : BUG ! [ 1049.016898 ] CPU : 5 PID : 32 Comm : python 4.0.0 - lego - ys + # 347 [ 1049.083460 ] Stack : [ 1049.107380 ] ffff88107e18fca8 ffffffff81026f1c 000000000000000 8 ffff88107e18fcb8 [ 1049.194743 ] ffff88107e18fc70 0000000021475542 0000000000000000 0000000000000000 [ 1049.282107 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 1049.369468 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 1049.456832 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 1049.544193 ] Call Trace : [ 1049.573315 ] < TSK > [ 1049.596195 ] [ < ffffffff81026f28 > ] panic + 0xc2 / 0xeb [ 1049.651318 ] [ < ffffffff8101c3fc > ] ? task_tick_rt + 0x2c / 0xd0 [ 1049.715799 ] [ < ffffffff81019a65 > ] ? scheduler_tick + 0x55 / 0x60 [ 1049.782360 ] [ < ffffffff81017035 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 1049.855163 ] [ < ffffffff81006764 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 1049.927966 ] [ < ffffffff8101c3fc > ] ? task_tick_rt + 0x2c / 0xd0 [ 1049.992447 ] [ < ffffffff81019a65 > ] ? scheduler_tick + 0x55 / 0x60 [ 1050.059009 ] [ < ffffffff81017035 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 1050.131812 ] [ < ffffffff8103c41a > ] ? put_dec + 0x1a / 0x80 [ 1050.191093 ] [ < ffffffff81006764 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 1050.263895 ] [ < ffffffff8100e56a > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 1050.341897 ] [ < ffffffff81012ded > ] ? printk + 0x11d / 0x1b0 [ 1050.402219 ] [ < ffffffff810340c5 > ] dump_pcache_meta + 0xc5 / 0xd0 [ 1050.468782 ] [ < ffffffff81034588 > ] pcache_evict_line + 0x158 / 0x220 [ 1050.538463 ] [ < ffffffff81030f5e > ] pcache_alloc + 0x22e / 0x2f0 [ 1050.602945 ] [ < ffffffff8103015a > ] common_do_fill_page + 0x2a / 0x430 [ 1050.673668 ] [ < ffffffff8102fb20 > ] ? pcache_meta_to_kva + 0x30 / 0x30 [ 1050.744389 ] [ < ffffffff81030702 > ] pcache_handle_fault + 0x1a2 / 0x6c0 [ 1050.816152 ] [ < ffffffff810103d2 > ] do_page_fault + 0xa2 / 0x1a0 [ 1050.880634 ] [ < ffffffff8100db9f > ] page_fault + 0x1f / 0x30 [ 1050.940955 ] [ < ffffffff8103bb82 > ] ? copy_user_enhanced_fast_string + 0x2 / 0x10 [ 1051.023118 ] [ < ffffffff81038423 > ] ? normal_p2m_read + 0x233 / 0x330 [ 1051.092800 ] [ < ffffffff810363ce > ] sys_read + 0x9e / 0x160 [ 1051.152081 ] [ < ffffffff810268d0 > ] ? strace_enter_default + 0x30 / 0x40 [ 1051.224884 ] [ < ffffffff8100e935 > ] do_syscall_64 + 0x45 / 0xd0 [ 1051.288326 ] [ < ffffffff8100d82c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 Interesting, added several debug messages. The bug is I forgot to put_pcache when a rmap was zapped. One rmap counts one refcount (effectively one process), thus when a rmap was zapped, we should decrease the refcount. I found I\u2019ve already done so for pcache_remove_rmap , and pcache_move_pte . But damn, forgot this one. I remember this code was written before fork+pcache. So.. I don\u2019t have a big picture at that time. Multithreaded system plus background reclaim really a very rigours design usage of refcount and lock . [ 1418.038411] CPU5 PID32 sys_read+0x0/0xa0 [ 1418.085227] pcache_evict_line(): pset: ffff88207f9ffec0, for uva: 0x7ffff7ffb000 [ 1418.173617] pset:ffff88207f9ffec0 set_idx: 32763 nr_lru:8 [ 1418.238105] pcache:ffff8801801ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880107ffb000 [ 1418.351476] pcache:ffff8801805ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880117ffb000 [ 1418.464847] pcache:ffff8801809ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880127ffb000 [ 1418.578220] pcache:ffff880180dffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880137ffb000 [ 1418.691591] pcache:ffff8801811ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880147ffb000 [ 1418.804963] pcache:ffff8801815ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880157ffb000 [ 1418.918334] pcache:ffff8801819ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880167ffb000 [ 1419.031706] pcache:ffff880181dffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880177ffb000 [ 1419.145077] After dump pset [ 1419.176280] pcache:ffff8801801ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880107ffb000 [ 1419.289652] pcache dumped because: evict_find_line_lru [ 1419.351018] pcache:ffff8801805ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880117ffb000 [ 1419.464389] pcache dumped because: evict_find_line_lru [ 1419.525757] pcache:ffff8801809ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880127ffb000 [ 1419.639127] pcache dumped because: evict_find_line_lru [ 1419.700494] pcache:ffff880180dffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880137ffb000 [ 1419.813865] pcache dumped because: evict_find_line_lru [ 1419.875231] pcache:ffff8801811ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880147ffb000 [ 1419.988604] pcache dumped because: evict_find_line_lru [ 1420.049969] pcache:ffff8801815ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880157ffb000 [ 1420.163341] pcache dumped because: evict_find_line_lru [ 1420.224708] pcache:ffff8801819ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880167ffb000 [ 1420.338079] pcache dumped because: evict_find_line_lru [ 1420.399445] pcache:ffff880181dffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880177ffb000 [ 1420.512817] pcache dumped because: evict_find_line_lru [ 1420.574183] evict_find_line_lru(): pcm: ffff88207f9ffea8 [ 1420.637631] ------------[ cut here ]------------ [ 1420.692756] BUG: failure at ./include/processor/pcache.h:340/pcache_meta_to_kva()! [ 1420.783245] Kernel Panic - not syncing: BUG! [ 1420.834210] CPU: 5 PID: 32 Comm: python 4.0.0-lego-ys+ #349 [ 1420.900777] Stack: python hello world run to end \u00b6 Glad to say, python hello world finished, even with some missed syscalls. Especially the stdin stuff, so the string is actually not printed out. Log is wuklab13:~/ys/0310-4 [ 3149.540308 ] CPU5 PID32 sys_ioctl + 0x0 / 0x10 [ 3149.588144 ] CPU5 PID32 sys_ioctl + 0x0 / 0x10 [ 3149.635982 ] CPU5 PID32 sys_write + 0x0 / 0xa0 [ 3149.683818 ] STDOUT : --- [ >>> ] --- [ 3149.726456 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff6d9aeb0 flags : 0x150 [ 3149.926247 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff6d9aeb0 flags : 0x150 ret : 0 ( OKAY ) [ 3150.033464 ] CPU5 PID32 sys_newfstat + 0x0 / 0x10 [ 3150.084420 ] CPU5 PID32 sys_ioctl + 0x0 / 0x10 [ 3150.132256 ] strace__mmap cpu5 addr = 0x0 , len = 0x1000 , prot ( 0x3 ) = PROT_READ | PROT_WRITE , flags ( 0x22 ) = MAP_PRIVATE | MAP_ANONYMOUS , fd = 18446744073709551615 ( ), off = 0x0 [ 3150.301772 ] CPU5 PID32 sys_read + 0x0 / 0xa0 [ 3150.348562 ] ------------ [ cut here ] ------------ [ 3150.403679 ] WARNING : CPU : 5 PID : 32 at managers / processor / fs / stdio . c : 24 stdio_file_read + 0x30 / 0x50 [ 3150.509751 ] Process wants STDIN ! [ 3150.546149 ] CPU : 5 PID : 32 Comm : python 4.0.0 - lego - ys + # 352 [ 3150.612705 ] Stack : [ 3150.636624 ] ffff88107e18fe90 ffffffff81012b15 ffffffff811464e0 00007f fff7ffb000 [ 3150.723977 ] 0000000000000400 00007f fff70e5640 ffff88107e18fef0 ffffffff81012bd2 [ 3150.811331 ] ffffffff81079d6b ffff881000000018 ffff88107e18ff00 ffff88107e18fec0 [ 3150.898687 ] 0000000000000020 ffffffff810346b0 0000000000000022 ffffffff811464f0 [ 3150.986040 ] 00007f fff7fdf740 0000000000000000 ffff88107e18ff00 ffffffff81035ac0 [ 3151.073394 ] Call Trace : [ 3151.102514 ] < TSK > [ 3151.125392 ] [ < ffffffff81012b21 > ] __warn . constprop .0 + 0x91 / 0xd0 [ 3151.194028 ] [ < ffffffff81012bd2 > ] warn_slowpath_fmt + 0x42 / 0x50 [ 3151.261623 ] [ < ffffffff810346b0 > ] ? sweep_pset_lru + 0x220 / 0x220 [ 3151.330259 ] [ < ffffffff81035ac0 > ] stdio_file_read + 0x30 / 0x50 [ 3151.395775 ] [ < ffffffff810346e3 > ] sys_read + 0x33 / 0xa0 [ 3151.454010 ] [ < ffffffff8100e875 > ] do_syscall_64 + 0x45 / 0xd0 [ 3151.517446 ] [ < ffffffff8100d76c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 3151.593362 ] < EOT > [ 3151.616240 ] --- [ end trace 0000000000000000 ] --- [ 3151.671360 ] CPU5 PID32 sys_write + 0x0 / 0xa0 [ 3151.719194 ] STDOUT : --- [ ] --- [ 3151.759756 ] CPU5 PID32 sys_close + 0x0 / 0x140 [ 3151.808628 ] SYSC_close () : [ 3 ] -> [ / root / ys / py_hello . py ] [ 3151.871028 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a79380 flags : 0x150 [ 3152.070817 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a79380 flags : 0x150 ret : 0 ( OKAY ) [ 3152.178033 ] CPU5 PID32 sys_rt_sigaction + 0x0 / 0xb0 [ 3152.234151 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a77f60 flags : 0x150 [ 3152.432941 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a77f60 flags : 0x150 ret : 0 ( OKAY ) [ 3152.540242 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff73ee794 flags : 0x150 [ 3152.739952 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff73ee794 flags : 0x150 ret : 0 ( OKAY ) [ 3152.847171 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff715b278 flags : 0x150 [ 3153.046958 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff715b278 flags : 0x150 ret : 0 ( OKAY ) [ 3153.154179 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff6de74f0 flags : 0x150 [ 3153.353965 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff6de74f0 flags : 0x150 ret : 0 ( OKAY ) [ 3153.461180 ] CPU5 PID32 sys_exit_group + 0x0 / 0x10 Trying phoenix pthread again \u00b6 4GB pcache, 1GB dataset. 1 th run with CONFIG_STRACE on, 1GB dataset finished, result is correct. 2 th run without CONFIG_STRACE, 1GB dataset stuck. Two weird things: open/close dev/cpu/online file too many times than a normal linux run IB stucked So next I\u2019m going to try add a lock to ibapi, see if it is ib internal deadlock issue. wuklab13 0310 -7 [ 702.895936 ] Processor : Processor manager is running . [ 722.400159 ] STDOUT : --- [ envp [ 0 ] HOME =/ ] --- [ 722.453307 ] STDOUT : --- [ envp [ 1 ] TERM = linux ] --- [ 722.512589 ] STDOUT : --- [ argv [ 0 ] / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count - pthread ] --- [ 722.628036 ] STDOUT : --- [ argv [ 1 ] / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count_datafiles / word_1GB . txt ] --- [ 722.759101 ] STDOUT : --- [ Wordcount : Running ... ] --- [ 722.819406 ] STDOUT : --- [ ] --- [ 722.860139 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 722.940653 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.011483 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.084287 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.157090 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.229894 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.302698 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.375502 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.448306 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.521111 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.593914 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.666718 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.739522 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.812326 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.885130 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 766.701260 ] ibapi_send_reply () polling timeout ( 30010 ms ), caller : net_send_reply_timeout + 0x11b / 0x1ee [ 766.809538 ] net_send_reply_timeout () caller : __pcache_do_fill_page + 0x82 / 0x140 [ 766.895863 ] word_count - pthr [ 65 ] : segfault at 0x7fffb5eba000 ip 00000000004024 9 d sp 00007f ffb5e9ad80 error 6 [ 767.012348 ] CPU : 15 PID : 65 Comm : word_count - pthr 4.0.0 - lego - ys + # 359 [ 767.089312 ] RIP : 0033 : [ < 00000000004024 9 d > ] [ < 00000000004024 9 d > ] 0x40249d [ 767.170436 ] RSP : 002 b : 00007f ffb5e9ad80 EFLAGS : 00010216 [ 767.233879 ] RAX : 00007f ffb5eba000 RBX : 00000000000013 88 RCX : 000000000000004f [ 767.319164 ] RDX : 00007f ffe4ea92a4 RSI : 00007f ffe626fac9 RDI : 00007f ffe4ea92a4 [ 767.404449 ] RBP : 00000000007540e0 R08 : 0000000000000000 R09 : 0000000000014f a0 [ 767.489733 ] R10 : 0000000000427f b0 R11 : 0000000000000202 R12 : 0000000000012 b12 [ 767.575018 ] R13 : 00007f ff496ab890 R14 : 00007f ff48704fb0 R15 : 00000000000013 88 [ 767.660303 ] FS : 00007f ffb5e9b700 ( 0000 ) GS : ffff88207fce0000 ( 0000 ) knlGS : 0000000000000000 [ 767.757028 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 767.825671 ] CR2 : 00007f ffb5eba000 CR3 : 000000207f e3a000 CR4 : 00000000000406 a0 [ 767.910958 ] get_signal () : dequeue_signr : 11 , handler : ( null ) [ 767.987928 ] get_signal () : dequeue_signr : 9 , handler : ( null ) 3 th run, without STRACE, with locked ibapi, it finished, result is correct. Runtime: 18.692936 sec . [ 555.423623 ] nr_pgfault : 288100 [ 555.458042 ] nr_pgfault_wp : 0 [ 555.492360 ] nr_pgfault_wp_cow : 0 [ 555.530838 ] nr_pgfault_wp_reuse : 0 [ 555.571396 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 555.630673 ] nr_pcache_fill_from_memory : 288081 [ 555.683710 ] nr_pcache_fill_from_victim : 12 [ 555.732588 ] nr_pcache_eviction : 494 [ 555.774187 ] nr_victim_eviction : 474 4 th run, same setting with the 3 th run, same result. But the nr_pgfault differs, I guess it is due to runtime things. Runtime: 19.12861 sec . [ 469.891700 ] nr_pgfault : 288119 [ 469.926123 ] nr_pgfault_wp : 0 [ 469.960444 ] nr_pgfault_wp_cow : 0 [ 469.998924 ] nr_pgfault_wp_reuse : 0 [ 470.039484 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 470.098764 ] nr_pcache_fill_from_memory : 288093 [ 470.151805 ] nr_pcache_fill_from_victim : 12 [ 470.200684 ] nr_pcache_eviction : 513 [ 470.242285 ] nr_victim_eviction : 493 5 th run, same with 4 th , succeed, Runtime: 18.653879 sec . [ 313.202348] nr_pgfault: 288070 [ 313.236772] nr_pgfault_wp: 0 [ 313.271093] nr_pgfault_wp_cow: 0 [ 313.309575] nr_pgfault_wp_reuse: 0 [ 313.350139] nr_pgfault_due_to_concurrent_eviction: 0 [ 313.409421] nr_pcache_fill_from_memory: 288052 [ 313.462465] nr_pcache_fill_from_victim: 6 [ 313.510307] nr_pcache_eviction: 446 [ 313.551909] nr_victim_eviction: 432 6 th , setting is the same, but with 4GB dataset, crashed: [ 512.028141 ] Processor : Processor manager is running . [ 529.375605 ] STDOUT : --- [ Wordcount : Running ... ] --- [ 529.435906 ] STDOUT : --- [ ] --- [ 529.476660 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 529.555983 ] ------------ [ cut here ] ------------ [ 529.609128 ] BUG : failure at managers / processor / pcache / rmap . c : 735 / pcache_zap_pte () ! [ 529.699613 ] Kernel Panic - not syncing : BUG ! [ 529.750576 ] CPU : 5 PID : 32 Comm : word_count - pthr 4.0.0 - lego - ys + # 361 [ 529.826500 ] Stack : [ 529.850422 ] ffff88107e1a3dd8 ffffffff810259b4 000000000000000 8 ffff88107e1a3de8 [ 529.937787 ] ffff88107e1a3da0 0000000021475542 0000000000000000 0000000000000000 [ 530.025152 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 530.112517 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 530.199882 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 530.287247 ] Call Trace : [ 530.316370 ] < TSK > [ 530.339251 ] [ < ffffffff810259c0 > ] panic + 0xc2 / 0xeb [ 530.394374 ] [ < ffffffff8106190a > ] ? client_internal_poll_sendcq + 0x2a / 0x80 [ 530.474458 ] [ < ffffffff8101bfcc > ] ? task_tick_rt + 0x2c / 0xd0 [ 530.538943 ] [ < ffffffff81019725 > ] ? scheduler_tick + 0x55 / 0x60 [ 530.605506 ] [ < ffffffff81016df5 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 530.678311 ] [ < ffffffff8103768a > ] ? put_dec + 0x1a / 0x80 [ 530.737595 ] [ < ffffffff810066f4 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 530.810398 ] [ < ffffffff8100e4aa > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 530.888403 ] [ < ffffffff81012ccd > ] ? printk + 0x11d / 0x1b0 [ 530.948726 ] [ < ffffffff81030429 > ] pcache_zap_pte + 0xf9 / 0x160 [ 531.014250 ] [ < ffffffff8102f090 > ] ? __pcache_move_pte_fastpath + 0x50 / 0x50 [ 531.093295 ] [ < ffffffff8102c8dc > ] unmap_page_range + 0x32c / 0x3b0 [ 531.161940 ] [ < ffffffff8102c97e > ] release_pgtable + 0x1e / 0x40 [ 531.227463 ] [ < ffffffff8102bfb3 > ] sys_munmap + 0xc3 / 0x120 [ 531.288827 ] [ < ffffffff8100e86d > ] do_syscall_64 + 0x3d / 0xc0 [ 531.352270 ] [ < ffffffff8100d76c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 7 th run, add debug info, does not seem that useful: ] --- [ 15755.579501 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 15755.672760 ] pte : ffff88107e1a3dd8 pfn : 0x8207e80b flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 15755.807015 ] pte dumped because : Invalid pte [ 15755.856932 ] address : 0x7ffefc638000 [ 15755.899569 ] ------------ [ cut here ] ------------ [ 15755.954684 ] BUG : failure at managers / processor / pcache / rmap . c : 747 / pcache_zap_pte () ! [ 15756.045159 ] Kernel Panic - not syncing : BUG ! [ 15756.096114 ] CPU : 5 PID : 32 Comm : word_count - pt Tried several times, even with mmap/munmap debug option on, it crashed at the same point. Key is address 0x7ffefc638000 , and the mmap() related to it. Close to find the bug. Latest log in 0310-18. 03/09 Fri \u00b6 Find bug in kmalloc \u00b6 Tried to print pud in every syscall and catch the criminal: wuklab13 030 9-1 [ 320.088684 ] CPU5 PID32 sys_close + 0x0 / 0x1f0 [ 320.137567 ] do_syscall_64 () : enter pgd ffff88207fccf000 , pgd . cont_va ffff88207fc6f000 , pud_index = 0x0 pud : ffff88207fc6f000 [ 320.269657 ] SYSC_close () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff7df3c37 [ 320.349742 ] 3 [ 320.372624 ] SYSC_close () : [ 3 ] -> [ / lib64 / libpython2 .7 . so .1.0 ] [ 320.441268 ] SYSC_close () cpu ( 5 ) tsk ( 32 / 32 / python ) ret : 0x0 ( 0 ) [ 320.510954 ] do_syscall_64 () : leave pgd ffff88207fccf000 , pgd . cont_va ffff88207fc6f000 , pud_index = 0x0 pud : ffff88207fc6f000 [ 320.643043 ] addr : 0x7ffff7a101f0 , pgd : ffff88207fccf7f8 [ 320.709607 ] addr : 0x7ffff7a101f0 , pgd : ffff88207fccf7f8 pud ffff88207fcaeff8 [ 320.798014 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a101f0 flags : 0x50 [ 320.995755 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a101f0 flags : 0x50 ret : 0 ( OKAY ) [ 321.101944 ] addr : 0x7ffff7a21749 , pgd : ffff88207fccf7f8 [ 321.168509 ] addr : 0x7ffff7a21749 , pgd : ffff88207fccf7f8 pud ffff88207fcaeff8 [ 321.256914 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a21749 flags : 0x50 [ 321.454651 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a21749 flags : 0x50 ret : 0 ( OKAY ) [ 321.560845 ] addr : 0x7ffff7ff2fda , pgd : ffff88207fccf7f8 [ 321.627409 ] addr : 0x7ffff7ff2fda , pgd : ffff88207fccf7f8 pud ffff88207fcaeff8 [ 321.715815 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7ff2fda flags : 0x50 [ 321.913553 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7ff2fda flags : 0x50 ret : 0 ( OKAY ) [ 322.019745 ] CPU5 PID32 sys_open + 0x0 / 0x10 [ 322.066548 ] do_syscall_64 () : enter pgd ffff88207fccf000 , pgd . cont_va ffff9001801ff000 , pud_index = 0x0 pud : ffff9001801ff000 [ 322.198638 ] SYSC_open () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff7df3b27 [ 322.277683 ] f_name : / lib64 / libpthread . so .0 , flags : 80000 , mode : e150 [ 322.357780 ] SYSC_open () cpu ( 5 ) tsk ( 32 / 32 / python ) ret : 0x3 ( 3 ) [ 322.426414 ] do_syscall_64 () : leave pgd ffff88207fccf000 , pgd . cont_va ffff9001801ff000 , pud_index = 0x0 pud : ffff9001801ff000 After printing more in pcache_handle_fault, I found who corrupted pgtable: wuklab13 030 9-5 [ 661.308584 ] CPU5 PID32 sys_close + 0x0 / 0x1f0 [ 661.357466 ] do_syscall_64 () : enter pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 661.489557 ] SYSC_close () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff7df3c37 [ 661.569642 ] 3 [ 661.592525 ] SYSC_close () : [ 3 ] -> [ / lib64 / libpython2 .7 . so .1.0 ] [ 661.661170 ] SYSC_close () cpu ( 5 ) tsk ( 32 / 32 / python ) ret : 0x0 ( 0 ) [ 661.730854 ] do_syscall_64 () : leave pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 661.862944 ] pcache_handle_fault () : enter pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 662.001275 ] addr : 0x7ffff7a101f0 , pgd : ffff88207fccf7f8 [ 662.067840 ] addr : 0x7ffff7a101f0 , pgd : ffff88207fccf7f8 pud ffff88207fcafff8 [ 662.156247 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a101f0 flags : 0x50 [ 662.353985 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a101f0 flags : 0x50 ret : 0 ( OKAY ) [ 662.460176 ] pcache_handle_fault () : leave pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 662.600586 ] pcache_handle_fault () : enter pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 662.738916 ] addr : 0x7ffff7a21749 , pgd : ffff88207fccf7f8 [ 662.805481 ] addr : 0x7ffff7a21749 , pgd : ffff88207fccf7f8 pud ffff88207fcafff8 [ 662.893888 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a21749 flags : 0x50 [ 663.091636 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a21749 flags : 0x50 ret : 0 ( OKAY ) [ 663.197831 ] pcache_handle_fault () : leave pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 663.338242 ] pcache_handle_fault () : enter pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 663.476572 ] addr : 0x7ffff7ff2fda , pgd : ffff88207fccf7f8 [ 663.543135 ] addr : 0x7ffff7ff2fda , pgd : ffff88207fccf7f8 pud ffff88207fcafff8 [ 663.631543 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7ff2fda flags : 0x50 [ 663.829279 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7ff2fda flags : 0x50 ret : 0 ( OKAY ) [ 663.935472 ] pcache_handle_fault () : leave pgd ffff88207fccf000 , pgd . cont_va ffff9001801ff000 , pud_index = 0x0 pud : ffff9001801ff000 [ 664.075884 ] CPU5 PID32 sys_open + 0x0 / 0x10 [ 664.122686 ] do_syscall_64 () : enter pgd ffff88207fccf000 , pgd . cont_va ffff9001801ff000 , pud_index = 0x0 pud : ffff9001801ff000 [ 664.254776 ] SYSC_open () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff7df3b27 [ 664.333821 ] f_name : / lib64 / libpthread . so .0 , flags : 80000 , mode : e150 [ 664.413918 ] SYSC_open () cpu ( 5 ) tsk ( 32 / 32 / python ) ret : 0x3 ( 3 ) [ 664.482552 ] do_syscall_64 () : leave pgd ffff88207fccf000 , pgd . cont_va ffff9001801ff000 , pud_index = 0x0 pud : ffff9001801ff000 Then, try catching bug with address 0x7ffff7ff2fda fault. Printing still being the most effective way to debug. :-) Dig further, I found pgtable corrupted after pcache_add_rmap() , namely after alloc_pcache_rmap() : [ 5024.482570 ] pcache_add_rmap () 343 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 5024.613601 ] alloc_pcache_rmap () : size : 56 , rmap : ffff88207fccefd0 [ 5024.686396 ] pcache_add_rmap () 358 pgd ffff88207fccf000 , pgd . cont_va ffff90207fcce000 , pud_index = 0x0 pud : ffff90207fcce000 Well, rmap: ffff88207fccefd0 & ffff90207fcce000 , clearly [ 843.916517 ] pcache_add_rmap () 372 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 844.047557 ] alloc_pcache_rmap () 60 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 844.179638 ] alloc_pcache_rmap () : size : 56 , rmap : ffff88207fccefd0 [ 844.252438 ] alloc_pcache_rmap () 71 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 844.384517 ] alloc_pcache_rmap () : size : 56 , rmap : ffff88207fccefd0 [ 844.457317 ] alloc_pcache_rmap () 85 pgd ffff88207fccf000 , pgd . cont_va ffff90207fcce000 , pud_index = 0x0 pud : ffff90207fcce000 [ 844.589398 ] pcache_add_rmap () 387 pgd ffff88207fccf000 , pgd . cont_va ffff90207fcce000 , pud_index = 0x0 pud : ffff90207fcce000 46 static struct pcache_rmap * alloc_pcache_rmap ( void ) 47 { 48 struct pcache_rmap * rmap ; 49 50 pgd_t * pgd ; 51 pud_t * pud ; 52 unsigned long addr ; 53 struct mm_struct * mm = current -> mm ; 54 55 if ( pall ) { 56 addr = 0x601008 ; 57 pgd = pgd_offset ( mm , addr ); 58 pud = pud_alloc ( mm , pgd , addr ); 59 pr_info ( \"%s() %d pgd %p, pgd.cont_va %lx, pud_index=%#lx pud: %p \\n \" , 60 __func__ , __LINE__ , pgd , pgd_page_vaddr ( * pgd ), pud_index ( addr ), ( void * ) pud ); 61 } 62 63 rmap = kmalloc ( sizeof ( * rmap ), GFP_KERNEL ); 64 65 if ( pall ) { 66 addr = 0x601008 ; 67 pgd = pgd_offset ( mm , addr ); 68 pud = pud_alloc ( mm , pgd , addr ); 69 pr_info ( \"%s(): size: %zu, rmap: %p \\n \" , __func__ , sizeof ( * rmap ), rmap ); 70 pr_info ( \"%s() %d pgd %p, pgd.cont_va %lx, pud_index=%#lx pud: %p \\n \" , 71 __func__ , __LINE__ , pgd , pgd_page_vaddr ( * pgd ), pud_index ( addr ), ( void * ) pud ); 72 } 73 74 if ( rmap ) { 75 INIT_LIST_HEAD ( & rmap -> next ); 76 rmap -> flags = 0 ; 77 } 78 79 if ( pall ) { 80 addr = 0x601008 ; 81 pgd = pgd_offset ( mm , addr ); 82 pud = pud_alloc ( mm , pgd , addr ); 83 pr_info ( \"%s(): size: %zu, rmap: %p \\n \" , __func__ , sizeof ( * rmap ), rmap ); 84 pr_info ( \"%s() %d pgd %p, pgd.cont_va %lx, pud_index=%#lx pud: %p \\n \" , 85 __func__ , __LINE__ , pgd , pgd_page_vaddr ( * pgd ), pud_index ( addr ), ( void * ) pud ); 86 } 87 88 return rmap ; 89 } Narrow it down to INIT_LIST_HEAD : [ 1334.548682 ] alloc_pcache_rmap () : size : 56 , rmap : ffff88207fccefd0 [ 1334.621487 ] alloc_pcache_rmap () 71 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 1334.753576 ] alloc_pcache_rmap () 76 & rmap -> next ffff88207fcceff8 & flags ffff88207fccefd8 [ 1334.922067 ] alloc_pcache_rmap () 86 pgd ffff88207fccf000 , pgd . cont_va ffff90207fcce000 , pud_index = 0x0 pud : ffff90207fcce000 [ 1335.126962 ] alloc_pcache_rmap () 98 pgd ffff88207fccf000 , pgd . cont_va ffff90207fcce000 , pud_index = 0x0 pud : ffff90207fcce000 74 if ( rmap ) { 75 pr_info ( \"%s() %d &rmap->next %p &flags %p \\n \" , 76 __func__ , __LINE__ , & rmap -> next , & rmap -> flags ); 77 78 INIT_LIST_HEAD ( & rmap -> next ); 79 80 if ( pall ) { 81 addr = 0x601008 ; 82 pgd = pgd_offset ( mm , addr ); 83 pud = pud_alloc ( mm , pgd , addr ); 84 pr_info ( \"%s(): size: %zu, rmap: %p \\n \" , __func__ , sizeof ( * rmap ), rmap ); 85 pr_info ( \"%s() %d pgd %p, pgd.cont_va %lx, pud_index=%#lx pud: %p \\n \" , 86 __func__ , __LINE__ , pgd , pgd_page_vaddr ( * pgd ), pud_index ( addr ), ( void * ) pud ); 87 } 88 89 rmap -> flags = 0 ; 90 } Seriously, if this is running on user-level on VM, I would be able to find the bug maybe in 30min. But I spent several hours to find it out with physical machine. Damn you physical machine. Hmm, this func is used A LOT. How can it fail at this point? Possible reasons: kmalloced area happen to intersect with pgtable? one physical page is mapped twice? one to pgtable, one by this rmap. tty/serial code has bug? Really ancient code. After add a few printk, IB seems stuck. And this happens just with few more lines of code! Why? code size matters? [ 722.381469 ] pcache_handle_fault () : enter pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 722.519778 ] addr : 0x7ffff7feffcc , pgd : ffff88207fccf7f8 [ 722.586334 ] addr : 0x7ffff7feffcc , pgd : ffff88207fccf7f8 pud ffff88207fcafff8 [ 722.674727 ] Before fill address = 0x7ffff7feffcc set_idx : 0x7fef [ 722.743362 ] pcache : ffff8801801ffbc0 mapcount : 0 refcount : 1 flags :( allocated | usable ) set_idx = 0x7fef kva : ffff880107fef000 [ 722.872312 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7feffcc flags : 0x50 [ 722.967985 ] __pcache_do_fill_page () : before net pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 last line Well, the following finding finally find the bug line. And it kind of explains the above bug. Probably kmalloc\u2019ed area has issues, so IB is touching wrong data. The following bug is related to kmalloc, the rmap is 56 bytes, and it should be within 1 single page, but it is not: [ 1862.307427 ] pcache_add_rmap () 413 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 1862.438477 ] alloc_pcache_rmap () 86 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 1862.570568 ] sp -> units : 50 SLOB_UNITS : 32 [ 1862.617372 ] alloc_pcache_rmap () : size : 56 , rmap : ffff88207fccefd0 [ 1862.690178 ] alloc_pcache_rmap () 97 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 1862.822268 ] alloc_pcache_rmap () 104 & rmap -> next ffff88207fcceff8 & flags ffff88207fccefd8 [ 1862.918995 ] __INIT_LIST_HEAD () : next ffff88207fcceff8 prev ffff88207fccf000 [ 1863.002202 ] __INIT_LIST_HEAD () 63 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 1863.133253 ] __INIT_LIST_HEAD () : next ffff88207fcceff8 prev ffff88207fccf000 [ 1863.216459 ] alloc_pcache_rmap () : size : 56 , rmap : ffff88207fccefd0 [ 1863.289265 ] alloc_pcache_rmap () 114 pgd ffff88207fccf000 , pgd . cont_va ffff90207fcce000 , pud_index = 0x0 pud : ffff90207fcce000 Analysis: The @prev field in line 7 has address ffff88207fccf000 , which happen to the pgd page ( pgd ffff88207fccf000 ). Thus when we do list->prev = list , it writes to the first 8 bytes of pgd page, corrupts the original pgd entry. That is why we see a corrupted pgd entry ( ffff90207fcce000 ). This roots from kmalloc, which should not allocate such an object that cross two pages. 03/08 Thur \u00b6 Took several days off. This morning finished the porting of wait4 and waitid , which actually has a lot code change. The concept and mechanism is fairly simple, but the legacy UNIX tradition make the implementation quite complex. Now, look back to finish debugging the pcache issue. It must be fixed this week. python \u00b6 Tried python hello_world.py , the program runs for a while and crashes at a deterministic point: wuklab13 and wuklab15 , ~/ ttyS1 [ 419097.929969 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a4b008 flags : 0x50 ret : 0 ( OKAY ) [ 419098.039145 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a4c010 flags : 0x50 [ 419098.306537 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a4c010 flags : 0x50 ret : 0 ( OKAY ) [ 419098.413756 ] CPU5 PID32 sys_mprotect + 0x0 / 0x90 [ 419098.465753 ] SYSC_mprotect () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff7df3d27 [ 419098.549990 ] start : 0x7ffff7d8c000 , len : 0x2000 , prot : 0x1 [ 419098.614469 ] BUG : unable to handle kernel paging request at ffff9001801ff000 [ 419098.698703 ] IP : [ < ffffffff8102f7a9 > ] pcache_handle_fault + 0x69 / 0x6c0 [ 419098.774621 ] PGD 0 [ 419098.799579 ] Oops : 0000 [ # 1 ] SMP PROCESSOR [ 419098.848457 ] CPU : 5 PID : 32 Comm : python 4.0.0 - lego - ys + # 312 [ 419098.916054 ] RIP : 0010 : [ < ffffffff8102f7a9 > ] [ < ffffffff8102f7a9 > ] pcache_handle_fault + 0x69 / 0x6c0 [ 419099.021089 ] RSP : 0000 : ffff88107e857ed8 EFLAGS : 000102 86 [ 419099.085567 ] RAX : ffff9001801ff000 RBX : ffff9001801ff000 RCX : 00003f fffffff000 [ 419099.171884 ] RDX : 00000801801f f000 RSI : 000000000060100 8 RDI : ffff88107e83d648 [ 419099.258199 ] RBP : ffff88107e857f18 R08 : 00007f fff7fe3000 R09 : 00007f fff7fe3000 [ 419099.344516 ] R10 : 0000000000000000 R11 : 0000000000000206 R12 : 000000000060100 8 [ 419099.430832 ] R13 : ffff88107e83d648 R14 : 0000000000000050 R15 : 00007f fff7ffe150 [ 419099.517149 ] FS : 00007f fff7fdf740 ( 0000 ) GS : ffff88207fc40000 ( 0000 ) knlGS : 0000000000000000 [ 419099.614905 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 419099.684582 ] CR2 : ffff9001801ff000 CR3 : 000000207f ccf000 CR4 : 00000000000406 a0 [ 419099.770899 ] Stack : [ 419099.795858 ] 00007f fff7d8c000 0000000000002000 0000000000000001 0000000000000004 [ 419099.884254 ] 000000000060100 8 ffff88107e857f58 0000000000000000 00007f fff7ffe150 [ 419099.972650 ] ffff88107e857f48 ffffffff81010082 0000000000000000 0000000000000001 [ 419100.061047 ] 0003 92 c29c720ba2 0000000000000000 00007f ffffffdc40 ffffffff8100d91f [ 419100.149442 ] 00007f fff7ffe150 0000000000000000 0003 92 c29c720ba2 0000000000000001 [ 419100.237839 ] Call Trace : [ 419100.267998 ] < TSK > [ 419100.291917 ] [ < ffffffff81010082 > ] do_page_fault + 0xa2 / 0x1a0 [ 419100.357434 ] [ < ffffffff8100d91f > ] page_fault + 0x1f / 0x30 [ 419100.418792 ] < EOT > M : ... [ 419142.163396 ] handle_p2m_pcache_miss () cpu 4 I nid : 0 pid : 32 tgid : 32 flags : 50 vaddr : 0x7ffff7a4c010 [ 419142.268460 ] handle_p2m_pcache_miss () cpu 4 O nid : 0 pid : 32 tgid : 32 flags : 50 vaddr : 0x7ffff7a4c010 ( Last Message ) Dig deeper: int pcache_handle_fault ( struct mm_struct * mm , unsigned long address , unsigned long flags ) { .. pgd = pgd_offset ( mm , address ); pr_info ( \" addr: %#lx, pgd: %p \\n \" , address , pgd ); pud = pud_alloc ( mm , pgd , address ); pr_info ( \" addr: %#lx, pgd: %p pud %p \\n \" , address , pgd , pud ); if ( ! pud ) return VM_FAULT_OOM ; pmd = pmd_alloc ( mm , pud , address ); if ( ! pmd ) .. } [ 21130.503314 ] strace__mprotect cpu5 start = 0x7ffff7d8c000 , len = 0x2000 , prot ( 0x1 ) = PROT_READ [ 21130.598994 ] SYSC_mprotect () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff7df3d27 [ 21130.682193 ] start : 0x7ffff7d8c000 , len : 0x2000 , prot : 0x1 [ 21130.745635 ] addr : 0x601008 , pgd : ffff88207fccf000 [ 21130.805954 ] addr : 0x601008 , pgd : ffff88207fccf000 pud ffff9001801ff000 [ 21130.888116 ] BUG : unable to handle kernel paging request at ffff9001801ff000 [ 21130.971314 ] IP : [ < ffffffff8102fa11 > ] pcache_handle_fault + 0x91 / 0x6f0 Print pgd and pud info, these three messages are related and the last one leads to panic: wuklab13 ~/ ys / 030 8-6 [ 479.375498 ] addr : 0x400040 , pgd : ffff88207fccf000 [ 479.435819 ] pud_alloc_one () : addr : 0x400040 , pud : ffff88207fc6f000 [ 479.511739 ] pud_alloc () : addr : 0x400040 pgd ffff88207fccf000 , pgd . cont_va ffff88207fc6f000 , pud_index = 0x0 pud : ffff88207fc6f000 [ 479.649021 ] addr : 0x400040 , pgd : ffff88207fccf000 pud ffff88207fc6f000 [ 480.016381 ] addr : 0x600dd8 , pgd : ffff88207fccf000 [ 480.076701 ] pud_alloc () : addr : 0x600dd8 pgd ffff88207fccf000 , pgd . cont_va ffff88207fc6f000 , pud_index = 0x0 pud : ffff88207fc6f000 [ 480.213982 ] addr : 0x600dd8 , pgd : ffff88207fccf000 pud ffff88207fc6f000 [ 680.072819 ] addr : 0x601008 , pgd : ffff88207fccf000 [ 680.133138 ] pud_alloc () : addr : 0x601008 pgd ffff88207fccf000 , pgd . cont_va ffff90107e834000 , pud_index = 0x0 pud : ffff90107e834000 [ 680.270422 ] addr : 0x601008 , pgd : ffff88207fccf000 pud ffff90107e834000 [ 680.352583 ] BUG : unable to handle kernel paging request at ffff90107e834000 [ 680.435783 ] IP : [ < ffffffff8102fc43 > ] pcache_handle_fault + 0xb3 / 0x770 [ 680.510664 ] PGD 0 I need to check what happens between 480s to 680s. Something in between corrupted pgtable. I doubt it can be: copy_to_user related syscalls pcache establish mapping, mempcy all other memcpy strcpy etc stuff 03/02 Fri \u00b6 TODO: -add vsyscall- -pcache_exit_process: free rmap, free cacheline, etc. When rmap is NULL, we clearly should free this pcache.- pcache_exit_thread? I don\u2019t think we need this. All pcache related activities should relate to mm, or thread group leader, not one particular thread. check python bug use omnigraffle to draw the whole workflow of pcache. Phoenix, word_count-seq, 4G dataset, 4GB pcache: [ 273.268853] Processor: Processor manager is running. [ 573.272479] page:ffffea0071bb9660 count:0 mapcount:-128 [ 573.332903] flags: 0x200000000000300(slab|slob_free) [ 573.392182] page dumped because: VM_BUG_ON_PAGE(page_ref_count(page) == 0) [ 573.474340] ------------[ cut here ]------------ [ 573.529459] BUG: failure at ./include/lego/mm.h:251/put_page_testzero()! [ 573.609537] Kernel Panic - not syncing: BUG! [ 573.660496] CPU: 4 PID: 13 Comm: kvictim_flushd 4.0.0-lego+ #18 [ 573.731212] Stack: [ 573.755132] ffff88207e4bfe10 ffffffff81023644 0000000000000008 ffff88207e4bfe20 [ 573.842490] ffff88207e4bfdd8 0000000021475542 0000000000000000 0000000000000000 [ 573.929848] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 574.017205] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 574.104563] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 574.191921] Call Trace: [ 574.221039] <TSK> [ 574.243919] [<ffffffff81023650>] panic+0xc2/0xeb [ 574.299038] [<ffffffff8105a35a>] ? client_internal_poll_sendcq+0x2a/0x80 [ 574.379115] [<ffffffff8105a4fd>] ? client_send_message_with_rdma_write_with_imm_request+0x14d/0x360 [ 574.487273] [<ffffffff8101ac3c>] ? task_tick_rt+0x2c/0xd0 [ 574.551751] [<ffffffff81018395>] ? scheduler_tick+0x55/0x60 [ 574.618308] [<ffffffff81015a45>] ? tick_handle_periodic+0x45/0x70 [ 574.691107] [<ffffffff810064c4>] ? apic_timer_interrupt+0x54/0x90 [ 574.763905] [<ffffffff8100dbaa>] ? smp__apic_timer_interrupt+0x6a/0x70 [ 574.841903] [<ffffffff8101198d>] ? printk+0x11d/0x1b0 [ 574.902222] [<ffffffff81025c00>] __free_pages+0x2e0/0x3c0 [ 574.966699] [<ffffffff81028472>] kfree+0x62/0x480 [ 575.022858] [<ffffffff8102e6be>] victim_flush_func+0x15e/0x1e0 [ 575.092536] [<ffffffff8102e560>] ? victim_try_fill_pcache+0x390/0x390 [ 575.169494] [<ffffffff8101e446>] kthread+0xf6/0x120 [ 575.227733] [<ffffffff8101e350>] ? __kthread_parkme+0x70/0x70 [ 575.296371] [<ffffffff8100de32>] ret_from_fork+0x22/0x30 [ 575.359810] <EOT> 03/01 Thur \u00b6 Weird. [43181.388400] p2m_fork(cpu5): I cur:24-word_count-seq new:25 [43181.435341] p2m_fork(cpu5): O succeed cur:24-word_count-seq new:25 [43181.436013] __pcache_do_fill_page(): I pid:24 tgid:24 address:0x4158d0 flags:0x150 [43181.439246] __pcache_do_fill_page(): O pid:24 tgid:24 address:0x4158d0 flags:0x150 ret:0(OKAY) csum:0x9e8f028e [43181.510534] __pcache_do_fill_page(): I pid:25 tgid:25 address:0x415000 flags:0x150 [43181.517729] __pcache_do_fill_page(): O pid:25 tgid:25 address:0x415000 flags:0x150 ret:0(OKAY) csum:0xffff88029e8f028e After all, it is TLB issue. I forgot to flush tlb after making the original pte read-only during fork. So the parent will be also to continue RW some pages, which should be process-private. Lego\u2019s current TLB flush is very native, we do tlbflush after each pte changes. This will have worse performance compared to linux\u2019s batch flush. Today\u2019s case is flush tlb after making pte read-only. And this really has to be performed one by one","title":"March 2018"},{"location":"lego/log/log-03-2018/#march-2018","text":"","title":"March 2018"},{"location":"lego/log/log-03-2018/#0331-sat","text":"Stay humble. Be real.","title":"03/31 Sat"},{"location":"lego/log/log-03-2018/#0330-fri","text":"Our scheduling, or IB do have issues. I must revisit this. The case is: in P, we boot only 12 cores, and three of them are used by flush, sweep, and IB. So there are 9 cores left for user. Phoenix create 24 threads. During the run, a lot ib timeout will happen. If we have a good scheduling, this should never happen. I probably need to check more on this. Anyway. Today I reorganized the opcode things. And now I\u2019m adding the final large piece of Lego: replication. It should be much simpler than the pcache part. I will first write down what code I need to add, e.g., opcode, handler, buffer mgmt etc. End of day. Want to write down some simple thoughts on building system. Building system is fun, but you have to know that devil is in the details. And, you may end up debugging for many many hours on a very very little issue. But that is how it is. Building system does not mean you are always working on fantastic beautiful ideas. It is always about those little bugs, little things, trivial fixes, that make your system robust and usable. For example, the patch Yilun sent me today is about handling special cases of stat and lseek. The patch does not improve any performance or adding fancy features, it is a minor fix to make user progam run. But this enable us to run TF. I think it is a great patch and it stands for 90% of building systems in middle or late stage. Of course, there are other trivial things on building systems: 1) initialize every possible used variables, can be local variables, malloced buffers. 2) have decent cleanup, which is a counterpart of your initialization, like dequeue list, decrease counter etc. 3) Clear coding style, write code for others, for yourself when you read the code two weeks later. This one is hard, need experience. But can be learned. I think Yilun and Yutong both improved a lot during this project. Me? I learned this from NVM emulator protect. It is a painful one, but also a valuable one. 4) Decent protect source file organization. 5) Remember, draw, the connections between subsystems. By adding this new feature to this subsystem A, will it broke subsystem B, which is using subsystem A. Something like this. 6) clear mind on lock usage, multithread issue. This is the most difficult one. I would say I learned this by coding pcache, or mm. I would say, mm is the most difficult multithread issue one can encounter.","title":"03/30 Fri"},{"location":"lego/log/log-03-2018/#0326-mon","text":"Spent several days on replication design. Now I\u2019m back on coding and debuging track. Fixed a bug introduced by per-pte lock. A one hided by previous one big giant page table lock. Also add an option to boot socket 0 only if Processor is configured. This is because pcache is normally registered at socket 0, if we schedule user threads to sockets other than socket 0, that will have bad performance.","title":"03/26 Mon"},{"location":"lego/log/log-03-2018/#0322-thur","text":"","title":"03/22 Thur"},{"location":"lego/log/log-03-2018/#clear-registers-for-execve","text":"Want to figure out execve problem today. Check if pcache is clean after process_exit. Check if pgtable is clean. Well. Checked, both are clean. The bug looks like the return of main, evevntually does not go to library\u2019s exit. Is it because library pages are not loaded properly? Since the number of pgfault equals to normal setting, I guess it may originate from Memory side. TLB is also flushed, so TLB should not be a hidden issue. Going to check checsum. Well, checsum is okay too. Syscall execve will change ip, sp, flags registers. So it will use iretq instead of sysexit to return to userspace. Got an insteresting IB bug after execve. The CPU5 seems fail to return to userspace, and the CPU0 has the IB bug followed: [ 1201.940681 ] CPU : 5 PID : 32 Comm : seq . o 4.0.0 - lego - ys + # 609 [ 1202.006200 ] RIP : 0033 : [ < 0000000000401 d1d > ] [ < 0000000000401 d1d > ] 0x401d1d [ 1202.087320 ] RSP : 002 b : 00007f ffffffedb0 EFLAGS : 00000200 [ 1202.150760 ] RAX : 0000000000000000 RBX : 00000000004002e0 RCX : 000000000043 b2c7 [ 1202.236041 ] RDX : 00007f ffffffedc8 RSI : 00007f ffffffeb40 RDI : 000000000048f9f 0 [ 1202.321320 ] RBP : 00007f ffffffeb60 R08 : 00000000006 ba4a0 R09 : 00000000006 bc880 [ 1202.406601 ] R10 : 000000000000000f R11 : 0000000000000246 R12 : 0000000000000000 [ 1202.491881 ] R13 : 0000000000401 930 R14 : 0000000000401 9 c0 R15 : 0000000000000006 [ 1202.577161 ] FS : 0000000000000000 ( 0000 ) GS : ffff88207fc40000 ( 0000 ) knlGS : 0000000000000000 [ 1202.673880 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 1202.742521 ] CR2 : 000000000042 c9a0 CR3 : 000000207f c2f000 CR4 : 00000000000406 a0 [ 1220.465601 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000020 [ 1220.557225 ] IP : [ < ffffffff810591ef > ] ib_mad_completion_handler + 0x6f / 0x7c0 [ 1220.638344 ] PGD 0 [ 1220.662265 ] Oops : 0000 [ # 1 ] SMP PROCESSOR [ 1220.710105 ] CPU : 0 PID : 27 Comm : ib_mad_completi 4.0.0 - lego - ys + # 609 [ 1220.786025 ] RIP : 0010 : [ < ffffffff810591ef > ] [ < ffffffff810591ef > ] ib_mad_completion_handler + 0x6f / 0x7c0 [ 1220.896265 ] RSP : 0000 : ffff88103eea7e30 EFLAGS : 00010246 [ 1220.959704 ] RAX : 0000000000000000 RBX : ffff88103eeac728 RCX : 0000000000000001 [ 1221.044985 ] RDX : 000000002 8000000 RSI : ffff88103ee8f000 RDI : ffff88107ff841d8 [ 1221.130265 ] RBP : ffff88103eea7ec0 R08 : 0000000000000000 R09 : ffff88103eea03c0 [ 1221.215545 ] R10 : ffff88103eea7ea0 R11 : 0000000000000001 R12 : ffff88103ee8c3f0 [ 1221.300825 ] R13 : ffff88103ee8c4e8 R14 : ffff88103eeac620 R15 : ffff88103eeac5f8 [ 1221.386106 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc00000 ( 0000 ) knlGS : 0000000000000000 [ 1221.482825 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 1221.551466 ] CR2 : 0000000000000020 CR3 : 000000000113 d000 CR4 : 00000000000406 b0 [ 1221.636746 ] Stack : [ 1221.660666 ] ffff88103eeaac10 ffff881000000001 ffff88103eeaac10 ffff88103eeaab50 [ 1221.748026 ] ffff88107fc05d80 ffff88103eea0000 ffff88103eeac728 000000 8000000000 [ 1221.835386 ] 0000012 83 eea7ea8 ffff88103ee8c9a8 000000007f cf2000 ffff000000000000 [ 1221.922746 ] ffff88107fcf0000 ffff88207ff6cbd8 ffff88107fcf76e8 ffff88103ee8c3f0 [ 1222.010106 ] ffffffff81059180 0000000000000000 ffff88103eea7f48 ffffffff81020866 [ 1222.097466 ] Call Trace : [ 1222.126586 ] < TSK > [ 1222.149466 ] [ < ffffffff81059180 > ] ? ib_mad_send_done_handler . isra .21 + 0x1d0 / 0x1d0 [ 1222.236826 ] [ < ffffffff81020866 > ] kthread + 0xf6 / 0x120 [ 1222.295066 ] [ < ffffffff81020770 > ] ? __kthread_parkme + 0x70 / 0x70 [ 1222.363707 ] [ < ffffffff8100e4b2 > ] ret_from_fork + 0x22 / 0x30 [ root @ wuklab12 : LegoOS git :( master )] $ addr2line - e vmImage - i ffffffff810591ef / root / ys / LegoOS / drivers / infiniband / core / mad . c : 1899 / root / ys / LegoOS / drivers / infiniband / core / mad . c : 2324 It is ib_mad_recv_done_handler () Well\u2026 Eventually, at 22:09, I figured out.. After I cleaned up all registers (except IP, SP, CS, SS, FLAGS) within start_thread, the execve\u2019ed program can run to end successfully. I did not clear the registers because linux does not clear it. I thought this is fine. Glibc should clear it anyway, right? But anyway, this works.","title":"Clear Registers for execve()"},{"location":"lego/log/log-03-2018/#0321-wed","text":"Task 1: add some checking in ib, flush, sweep thread. 1) If cpu changed, 2) if nr_threads on this core > 1. Had an issue while testing: execve(). I ran a exec.o first, then do execve to run seq.o: wuklab13 0321 -10 [ 970.380252 ] STDOUT : --- [ uname () : --- [ 970.431212 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x44605d flags : 0x150 [ 1101.862429 ] mlx4_ib_handle_error_cqe syndrome 21 [ 1101.915570 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1101.969649 ] send request failed at connection 4 as 12 [ 1102.029968 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1102.084046 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1102.138125 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1102.192203 ] fit_poll_cq : failed status ( 5 ) for wr_id 1054 [ 1102.256681 ] fit_poll_cq : failed status ( 5 ) for wr_id 1055 [ 1102.321160 ] csum : 442 a97c0 , reply -> csum : 2 d352c33 [ 1102.377319 ] fit_poll_cq : connection 4 Recv weird event as -1 [ 1102.444916 ] pcache : ffff880180011180 mapcount : 0 refcount : 1 flags :( allocated | usable ) kva : ffff880100446000 [ 1102.558273 ] fit_poll_cq : failed status ( 5 ) for wr_id 1056 [ 1102.622751 ] pcache dumped because : csum mismatch [ 1102.677871 ] fit_poll_cq : connection 4 Recv weird event as -30704 [ 1102.749627 ] ------------ [ cut here ] ------------ [ 1102.804746 ] fit_poll_cq : failed status ( 5 ) for wr_id 1057 [ 1102.869225 ] BUG : failure at managers / processor / pcache / fault . c : 237 / __pcache_do_fill_page () ! [ 1102.968022 ] fit_poll_cq : connection 4 Recv weird event as -30704 [ 1103.039780 ] Kernel Panic - not syncing : BUG ! [ 1103.090739 ] CPU : 5 PID : 32 Comm : seq . o 4.0.0 - lego - ys + # 599 [ 1103.156256 ] Stack : [ 1103.180177 ] ffff88103e85be18 ffffffff8102676c ffffffff00000008 ffff88103e85be28 [ 1103.267533 ] ffff88103e85bde0 0000000021475542 00000000000002 96 ffff88103e85ba10 [ 1103.354892 ] ffffffff810195c5 ffff88207fc44980 0000000000000005 ffff88103e85ba28 [ 1103.442249 ] ffffffff81016c75 ffff88103e85ba40 ffff88103e85ba50 ffffffff810065d4 [ 1103.529607 ] ffffffff811d36e0 000000000000003 9 ffffffff81081718 ffff88103e85bb80 [ 1103.616964 ] Call Trace :","title":"03/21 Wed"},{"location":"lego/log/log-03-2018/#0320-tue","text":"Task 1: calculate failure numbers Task 2: read 0319-4 Log Task 3: opt pte lock Hmm, I finished the per-pte per-pmd lock patch. I think it works. But I do found an issue. When I run MT+2GB, it will create 24 threads. Since I marked 3 CPUs inactive, so all new 24 threads will be scheduled to other cores (I may need to check this!). At some point, Lego P either stuck, or a lot ibapi_send_reply timeout. When I change the cpu_online to may 0-6 , it finished. When I change it to 0-18 , also succeed. I really doubt if actually those pinned threads are not pinned. Need to check.","title":"03/20 Tue"},{"location":"lego/log/log-03-2018/#ib-bug-again","text":"Running MT-phoenix, 2GB, somehow crashed in the middle: [ 60095.857381 ] SYSC_close () CPU6 PID : 33 [ fd : 4 ] -> [ / proc / stat ] [ 60286.127359 ] mlx4_ib_handle_error_cqe syndrome 21 [ 60286.180503 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.234582 ] send request failed at connection 4 as 12 [ 60286.294903 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.348981 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.403062 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.457141 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.511221 ] send request failed at connection 4 as 5 [ 60286.570500 ] fit_poll_cq : failed status ( 5 ) for wr_id 1056 [ 60286.634980 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.689059 ] fit_poll_cq : failed status ( 5 ) for wr_id 1057 [ 60286.753539 ] send request failed at connection 4 as 5 [ 60286.812819 ] fit_poll_cq : failed status ( 5 ) for wr_id 1058 [ 60286.877298 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60286.931378 ] fit_poll_cq : failed status ( 5 ) for wr_id 1059 [ 60286.995857 ] send request failed at connection 4 as 5 [ 60287.055138 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.109217 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.163297 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.217376 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.271456 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.325536 ] send request failed at connection 4 as 5 [ 60287.384815 ] fit_poll_cq : failed status ( 5 ) for wr_id 1060 [ 60287.449294 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.503375 ] BUG : unable to handle kernel NULL pointer dereference at ( null ) [ 60287.596973 ] IP : [ < ffffffff81063ffd > ] fit_poll_cq + 0x4dd / 0x530 [ 60287.664574 ] send request failed at connection 4 as 5 [ 60287.723853 ] PGD 0 [ 60287.747772 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60287.801852 ] Oops : 0002 [ # 1 ] PREEMPT SMP PROCESSOR [ 60287.858013 ] send request failed at connection 4 as 5 [ 60287.917292 ] CPU : 2 PID : 29 Comm : recvpollcq 4.0.0 - lego - ys + # 569 [ 60287.988010 ] RIP : 0010 : [ < ffffffff81063ffd > ] [ < ffffffff81063ffd > ] fit_poll_cq + 0x4dd / 0x530 [ 60288.084731 ] RSP : 0000 : ffff88103e84fd88 EFLAGS : 00010206 [ 60288.148170 ] RAX : 000000000000100 8 RBX : ffff88103e848438 RCX : 0000000000000014 [ 60288.233450 ] RDX : 0000000000000000 RSI : ffffffff811d36e0 RDI : ffffffff811dac08 [ 60288.318728 ] RBP : ffff88103e84fea8 R08 : 0000000000000000 R09 : 0000000000000000 [ 60288.404008 ] R10 : 0000000000000002 R11 : 0000000000000004 R12 : 0000000000000000 [ 60288.489288 ] R13 : ffff88207fd6e008 R14 : 0000000000000004 R15 : ffff88103e84fda0 [ 60288.574568 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60288.628647 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc20000 ( 0000 ) knlGS : 0000000000000000 [ 60288.725367 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 60288.794006 ] CR2 : 0000000000000000 CR3 : 000000000113 d000 CR4 : 00000000000406 a0 [ 60288.879285 ] send request failed at connection 4 as 5 [ 60288.938565 ] Stack : [ 60288.962484 ] ffffffff810031d9 000 801 d43e84fda0 0000000000000007 0000000000000424 [ 60289.049844 ] 000000 8100000005 00001008000000f 9 ffff88103e848868 00616e6440000014 [ 60289.137204 ] 0020004000000002 ffff88207fc00000 0000000000000425 000000 8100000005 [ 60289.224563 ] 00001008000000f 9 ffff88103e848868 007370654000000 d 0010004000000002 [ 60289.311922 ] ffffffff81010000 0000000000000426 000000 8100000005 00001008000000f 9 [ 60289.399282 ] Call Trace : [ 60289.428402 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60289.482482 ] < TSK > [ 60289.505361 ] [ < ffffffff810031d9 > ] ? native_smp_send_reschedule + 0x39 / 0x50 [ 60289.584400 ] send request failed at connection 4 as 5 [ 60289.643680 ] [ < ffffffff81010000 > ] ? __ioremap_caller + 0x170 / 0x570 [ 60289.714400 ] [ < ffffffff81060000 > ] ? cm_work_handler + 0x270 / 0x1450 [ 60289.785119 ] [ < ffffffff81064050 > ] ? fit_poll_cq + 0x530 / 0x530 [ 60289.850639 ] [ < ffffffff81064064 > ] fit_poll_cq_pass + 0x14 / 0x30 [ 60289.917198 ] [ < ffffffff81020c06 > ] kthread + 0xf6 / 0x120 [ 60289.975438 ] mlx4_ib_handle_error_cqe syndrome 5 [ 60290.029518 ] [ < ffffffff81020b10 > ] ? __kthread_parkme + 0x70 / 0x70 [ 60290.098157 ] [ < ffffffff8100e722 > ] ret_from_fork + 0x22 / 0x30 Uuh: [ 1002.803051 ] mlx4_ib_handle_error_cqe syndrome 1 [ 1002.855153 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1002.909232 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1002.963310 ] mlx4_ib_handle_error_cqe syndrome 5 [ 1003.017390 ] fit_poll_cq : failed status ( 1 ) for wr_id 512 [ 1003.080829 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000200 [ 1003.174425 ] IP : [ < ffffffff8105d499 > ] fit_poll_cq + 0x179 / 0x510 [ 1003.242024 ] PGD 0 [ 1003.265943 ] Oops : 0000 [ # 1 ] SMP MEMORY [ 1003.310661 ] CPU : 2 PID : 29 Comm : recvpollcq 4.0.0 - lego - ys + # 149 [ 1003.381380 ] RIP : 0010 : [ < ffffffff8105d499 > ] [ < ffffffff8105d499 > ] fit_poll_cq + 0x179 / 0x510 [ 1003.478098 ] RSP : 0000 : ffff88104e84fd88 EFLAGS : 00010246 [ 1003.541537 ] RAX : ffff880000000000 RBX : ffff88104e848008 RCX : 00000000000000 80 [ 1003.626814 ] RDX : 0000000000000200 RSI : ffffffff811c76e0 RDI : ffffffff811d0988 [ 1003.712092 ] RBP : ffff88104e84fea8 R08 : 0000000000000000 R09 : 0000000000000000 [ 1003.797369 ] R10 : 0000000000000002 R11 : 0000000000000004 R12 : 0000000000000000 [ 1003.882648 ] R13 : ffff88207ff75008 R14 : 0000000000000004 R15 : ffff88104e84fda0 [ 1003.967925 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc20000 ( 0000 ) knlGS : 0000000000000000 [ 1004.064644 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 1004.133282 ] CR2 : 0000000000000200 CR3 : 0000000001131000 CR4 : 00000000000406 a0 [ 1004.218559 ] Stack : [ 1004.242479 ] ffffffff810031a9 ffff88104e84fda0 ffffffff81018ef4 0000000000000200 [ 1004.329837 ] 000000 8000000001 0000004 8000000 d7 ffff88104e848c98 00000000 81019302 [ 1004.417194 ] 0014000000000000 ffff88207fc00000 0000000000000201 ffffffff00000005 [ 1004.504552 ] ffff8810000000f9 ffff88104e848c98 0000000000000000 ffff88104e84fe38 [ 1004.591910 ] ffffffff810195a4 0000000000000202 ffff881000000005 ffff8810000000f9 [ 1004.679268 ] Call Trace : [ 1004.708388 ] < TSK > [ 1004.731267 ] [ < ffffffff810031a9 > ] ? native_smp_send_reschedule + 0x39 / 0x50 [ 1004.810305 ] [ < ffffffff81018ef4 > ] ? resched_curr + 0x34 / 0x40 [ 1004.874783 ] [ < ffffffff810195a4 > ] ? try_to_wake_up + 0xe4 / 0x1f0 [ 1004.942382 ] [ < ffffffff8105f458 > ] ? __schedule + 0xf8 / 0x1e0 [ 1005.005820 ] [ < ffffffff8105d830 > ] ? fit_poll_cq + 0x510 / 0x510 [ 1005.071338 ] [ < ffffffff8105d844 > ] fit_poll_cq_pass + 0x14 / 0x30 [ 1005.137897 ] [ < ffffffff8101fdc6 > ] kthread + 0xf6 / 0x120 [ 1005.196135 ] [ < ffffffff8101fcd0 > ] ? __kthread_parkme + 0x70 / 0x70 [ 1005.264773 ] [ < ffffffff8100e472 > ] ret_from_fork + 0x22 / 0x30","title":"IB Bug again"},{"location":"lego/log/log-03-2018/#0319-mon","text":"Not too many days left!!! Got to design full replication mechanism and algorithm today. Merged pull request for pipe , pipe2 and /dev/null from Yilun. Our simple file op mgmt concerns me. I left a note at kernel/fork.c. Got a bug report from Yilun, syscall execv failed. To be honest, I\u2019ve never tried this syscall, always call it directly within kernel. [ 943.650712 ] CPU6 PID17 sys_execve + 0x0 / 0x10 [ 943.701899 ] BUG : unable to handle kernel paging request at 00000000004 90523 [ 943.702776 ] IP : [ < ffffffff8103db86 > ] strrchr + 0x6 / 0x20 [ 943.711501 ] PGD 0 [ 943.711911 ] Oops : 0000 [ # 1 ] SMP PROCESSOR [ 943.712433 ] CPU : 6 PID : 17 Comm : word_count - pthr 4.0.0 - lego + # 64 [ 943.713126 ] RIP : 0010 : [ < ffffffff8103db86 > ] [ < ffffffff8103db86 > ] strrchr + 0x6 / 0x20 [ 943.714090 ] RSP : 001 8 : ffff88083e4bfe98 EFLAGS : 00010246 [ 943.714724 ] RAX : 0000000000000000 RBX : ffff88083e4b3780 RCX : 0000000000000000 [ 943.715511 ] RDX : 00000000f fffffff RSI : 000000000000002f RDI : 00000000004 90523 [ 943.716297 ] RBP : ffff88083e4bfe98 R08 : 0000160000000000 R09 : ffff88083e4b8400 [ 943.717085 ] R10 : ffff880000000000 R11 : 6 db6db6db6db6db7 R12 : ffff88083e4b8000 [ 943.717871 ] R13 : ffff88083e4e6290 R14 : 00000000004 90523 R15 : ffff88083e4b3920 [ 943.718683 ] FS : 0000000000000000 ( 0000 ) GS : ffff88083fd80000 ( 0000 ) knlGS : 0000000000000000 [ 943.719650 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 943.720319 ] CR2 : 00000000004 90523 CR3 : 000000083e4 e7000 CR4 : 00000000000406 a0 [ 943.721106 ] Stack : [ 943.721459 ] ffff88083e4bff18 ffffffff8102c6bf ffff880800000000 0000000000000e10 [ 943.722541 ] 00007f ffffffedb0 0000000000400 d0d ffff88083e4c0000 00000000004 90523 [ 943.723624 ] ffff88083e4b9008 00007f ffffffed30 000000 8400000084 ffff88083e4bff58 [ 943.724706 ] 000000000000003 b 0000000000401 9 d0 0000000000401 a60 0000000000000000 [ 943.725789 ] ffff88083e4bff28 ffffffff8102c989 ffff88083e4bff48 ffffffff8100e5f5 [ 943.726870 ] Call Trace : [ 943.727260 ] < TSK > [ 943.727619 ] [ < ffffffff8102c6bf > ] do_execve + 0x4af / 0x770 [ 943.728236 ] [ < ffffffff8102c989 > ] sys_execve + 0x9 / 0x10 [ 943.728868 ] [ < ffffffff8100e5f5 > ] do_syscall_64 + 0x45 / 0xd0 [ 943.729499 ] [ < ffffffff8100d4ec > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 943.730222 ] < EOT > [ 943.730570 ] Code : d2 74 18 40 38 f2 89 f1 75 06 eb 0f 38 ca 74 0 b 48 83 c0 01 0f b6 10 84 d2 75 f1 5 d c3 0f 1f 84 00 00 00 00 00 55 31 c0 48 89 e5 < 0f > b6 17 40 38 f2 48 0f 44 c7 48 83 c7 01 84 d2 75 ee 5 d c3 66 [ 943.735455 ] RIP [ < ffffffff8103db86 > ] strrchr + 0x6 / 0x20 [ 943.736120 ] RSP < ffff88083e4bfe98 > [ 943.736598 ] CR2 : 00000000004 90523 It is setup_new_exec() -> set_task_comm() . I passed the user pointer to set_task_comm() , which I should pass a kernel pointer. And I actually found we missed a function: do_close_on_exec() . I also add a note above.","title":"03/19 Mon"},{"location":"lego/log/log-03-2018/#random-ib-bug","text":"Another weird bug after pathing loader. Actually, I tried the same setting twice, the second time it works. I guess this is some random IB bug. (Setting: 1P, 1M, 1S. Running a simple exec.c testing program, this have not reach that point yet.) wuklab13 031 9-2 [ 496.288272 ] p2m_fork ( cpu0 ) : I cur : 1 - kernel_init new : 31 [ 496.349624 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000004 [ 496.443216 ] IP : [ < ffffffff81064935 > ] fit_send_reply_with_rdma_write_with_imm + 0x65 / 0x3b0 [ 496.538892 ] PGD 0 [ 496.562811 ] Oops : 0002 [ # 1 ] PREEMPT SMP PROCESSOR [ 496.618968 ] CPU : 0 PID : 1 Comm : kernel_init 4.0.0 - lego - ys + # 559 [ 496.689684 ] RIP : 0010 : [ < ffffffff81064935 > ] [ < ffffffff81064935 > ] fit_send_reply_with_rdma_write_with_imm + 0x65 / 0x3b0 [ 496.814478 ] RSP : 0000 : ffff88107fcf7d00 EFLAGS : 00010202 [ 496.877915 ] RAX : 000000000000004 c RBX : 0000000000000004 RCX : 000000000000002 c [ 496.963190 ] RDX : 0000000000000004 RSI : 0000000000000001 RDI : ffff88207ff6d008 [ 497.048466 ] RBP : ffff88107fcf7d98 R08 : ffff88107fcf7e3c R09 : 0000000000000004 [ 497.133742 ] R10 : ffffffff81145fe0 R11 : 000000000000001 c R12 : 000000000000002 c [ 497.219018 ] R13 : 0000000000000001 R14 : ffff88107fcf7e40 R15 : ffff88207ff6d008 [ 497.304293 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc00000 ( 0000 ) knlGS : 0000000000000000 [ 497.401009 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 497.469645 ] CR2 : 0000000000000004 CR3 : 000000000113 d000 CR4 : 00000000000406 b0 [ 497.554922 ] Stack : [ 497.578840 ] ffff88107fcf7d08 0000000000000000 00000000000002 82 ffffffff81077b10 [ 497.666195 ] 000000000000003 a 000000047f cf7e18 ffff88107fcf7e3c ffff88107fd5ed88 [ 497.753552 ] 000000010000002 c ffffff9b00000040 0000000000000034 ffffffff81145fe0 [ 497.840906 ] ffff88107fcf7db0 00000000000002 97 ffff88107fd5ed88 000000000000002 c [ 497.928263 ] ffff88107fcf7e3c ffff88107fcf7e40 000000000000003 9 ffff88107fcf7dc8 [ 498.015618 ] Call Trace : [ 498.044736 ] < TSK > [ 498.067615 ] [ < ffffffff810622ff > ] ibapi_send_reply_timeout + 0x3f / 0x50 [ 498.142492 ] [ < ffffffff8103b0d4 > ] ? net_send_reply_timeout + 0x94 / 0x132 [ 498.218408 ] [ < ffffffff8103b0d4 > ] net_send_reply_timeout + 0x94 / 0x132 [ 498.292244 ] [ < ffffffff8102c683 > ] p2m_fork + 0xd3 / 0x200 [ 498.351521 ] [ < ffffffff8101f490 > ] do_fork + 0xf0 / 0x150 [ 498.409758 ] [ < ffffffff8101f514 > ] kernel_thread + 0x24 / 0x30 [ 498.473195 ] [ < ffffffff8115bf21 > ] processor_manager_init + 0x21 / 0x50 [ 498.545991 ] [ < ffffffff81000354 > ] kernel_init + 0x94 / 0x120 [ 498.608388 ] [ < ffffffff810002c0 > ] ? 0xffffffff810002c0 [ 498.668706 ] [ < ffffffff81019b0a > ] ? schedule_tail + 0xa / 0x40 [ 498.733182 ] [ < ffffffff810002c0 > ] ? 0xffffffff810002c0 [ 498.793499 ] [ < ffffffff8100e762 > ] ret_from_fork + 0x22 / 0x30 [ 498.856936 ] < EOT >","title":"Random IB Bug"},{"location":"lego/log/log-03-2018/#0318-sun","text":"Got a bug report after enable preempt and sweep thread [ 582.545444 ] pcache : ffff8801812cb680 mapcount : 1 refcount : 2 flags :( locked | allocated | usable | valid | reclaim ) kva : ffff88014b2da000 [ 582.678677 ] pcache dumped because : PCACHE_BUG_ON_PCM ( pcache_mapped ( pcm )) [ 582.758760 ] rmap : ffff88207e5e37e8 flags : 0x0 owner - tgid : 33 user_va : 0x7fff0b2da000 ptep : ffff88207e4a86d0 [ 582.870046 ] pte : ffff88207e4a86d0 pfn : 0x0 flags :() [ 582.926210 ] ------------ [ cut here ] ------------ [ 582.981333 ] BUG : failure at managers / processor / pcache / victim . c : 604 / victim_finish_insert () ! [ 583.080137 ] Kernel Panic - not syncing : BUG ! ... ... [ 588.847239 ] nr_pgfault : 591101 [ 588.883641 ] nr_clflush : 66176 [ 588.919003 ] nr_pgfault_wp : 0 [ 588.953325 ] nr_pgfault_wp_cow : 0 [ 588.991806 ] nr_pgfault_wp_reuse : 0 [ 589.032368 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 589.091651 ] nr_pcache_fill_from_memory : 587057 [ 589.144694 ] nr_pcache_fill_from_victim : 4038 [ 589.195656 ] nr_pcache_eviction_triggered : 439562 [ 589.250780 ] nr_pcache_eviction_eagain_freeable : 373382 [ 589.312143 ] nr_pcache_eviction_eagain_concurrent : 0 [ 589.370386 ] nr_pcache_eviction_failure_find : 0 [ 589.423429 ] nr_pcache_eviction_failure_evict : 0 [ 589.477512 ] nr_pcache_eviction_succeed : 66176 [ 589.529514 ] nr_victim_eviction_triggered : 733361 [ 589.584638 ] nr_victim_eviction_eagain : 671227 [ 589.636640 ] nr_victim_eviction_succeed : 62134 [ 589.688642 ] nr_victim_prepare_insert : 66180 [ 589.738566 ] nr_victim_finish_insert : 66176 [ 589.787447 ] nr_victim_flush_submitted : 66176 [ 589.838411 ] nr_victim_flush_finished : 66176 [ 589.888332 ] nr_victim_flush_async_run : 0 [ 589.935135 ] nr_victim_flush_sync : 0 [ 589.976738 ] nr_sweep_run : 50580 [ 590.014179 ] nr_sweep_nr_pset : 116770383 [ 590.059943 ] nr_sweep_nr_moved_pcm : 100686435 This is an interesting bug. Two threads, one doing munmap or mremap, one doing eviction. They are using the same pcm. munmap and mremap will use pte_get_and_clear() to get the pcm. While eviction will call pcache_try_to_unamp , which will further call rmap_get_locked_pte() , in which we check if the pte is none, if it is, then we know this is under munmap or mremap, then we skip. This is absolutely wrong. When pcache_try_to_unamp is called by eviction, it should always unmap ALL rmap. The above case is triggered because both two threads skip the final __pcache_remove_rmap . Hmm, looks like open/close filename is wrong. I need to check. Last Log from MT+2GB, computation finished: wuklab13 031 8-10 [ 627.280016 ] **** ERROR : *** current : 32 : kevict_sweepd caller : ( null ) **** [ pte == rmap -> page_table ] && [ pcache_pfn != pte_pfn ] **** rmap -> owner_process : word_count - pthr uva : 0x7fff78f52000 ptep : ffff88107e87fa90 , rmap -> page_table : ffff88107e87fa90 **** pcache_pfn : 0x168f52 , pte_pfn : 0x178f52 [ 627.624239 ] rmap : ffff88107dc73740 flags : 0x0 owner - tgid : 33 user_va : 0x7fff78f52000 ptep : ffff88107e87fa90 [ 627.735513 ] pte : ffff88107e87fa90 pfn : 0x0 flags :() [ 627.791670 ] pcache_rmap dumped because : Corrupted RMAP [ 627.853026 ] pcache : ffff880181a3d480 mapcount : 1 refcount : 2 flags :( locked | allocated | usable | valid ) kva : ffff880168f52000 [ 627.979901 ] pcache dumped because : Corrupted RMAP [ 628.036057 ] ------------ [ cut here ] ------------ [ 628.091175 ] BUG : failure at managers / processor / pcache / rmap . c : 109 / report_bad_rmap () ! [ 628.182691 ] Kernel Panic - not syncing : BUG ! [ 628.233647 ] CPU : 5 PID : 32 Comm : kevict_sweepd 4.0.0 - lego - ys + # 543 [ 628.307483 ] Stack : [ 628.331401 ] ffff88107e85bd00 ffffffff81026d24 000000000000000 8 ffff88107e85bd10 [ 628.418756 ] ffff88107e85bcc8 0000000021475542 0000000000000000 0000000000000000 [ 628.506113 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 628.593468 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 628.680823 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 628.768179 ] Call Trace : [ 628.797299 ] < TSK > [ 628.820176 ] [ < ffffffff81026d30 > ] panic + 0xc2 / 0x102 [ 628.876334 ] [ < ffffffff8101c6ac > ] ? task_tick_rt + 0x2c / 0xd0 [ 628.940811 ] [ < ffffffff8101c6ac > ] ? task_tick_rt + 0x2c / 0xd0 [ 629.005288 ] [ < ffffffff81019bfc > ] ? scheduler_tick + 0x5c / 0x70 [ 629.071843 ] [ < ffffffff81017195 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 629.144639 ] [ < ffffffff81006704 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 629.217436 ] [ < ffffffff8100e4da > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 629.295432 ] [ < ffffffff81012d94 > ] ? printk + 0x124 / 0x1c0 [ 629.355748 ] [ < ffffffff8103ad1f > ] report_bad_rmap + 0x144 / 0x144 [ 629.423345 ] [ < ffffffff81031046 > ] pcache_referenced_trylock_one + 0x1c6 / 0x2c0 [ 629.505500 ] [ < ffffffff8100e4da > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 629.583497 ] [ < ffffffff810328a1 > ] rmap_walk + 0x71 / 0xe0 [ 629.642774 ] [ < ffffffff81033329 > ] pcache_referenced_trylock + 0x59 / 0xd0","title":"03/18 Sun"},{"location":"lego/log/log-03-2018/#0317-sat","text":"I\u2019m too tired today. Coding side, I will only optimize sweep. Besides, I will book tickets for Iceland trip.","title":"03/17 Sat"},{"location":"lego/log/log-03-2018/#0316-friday","text":"Task 1 : Add physical memory counter. It is a per-zone based counter, even though there is also some global counters. In Linux, per-cpu counter is first accumlated, global counter is updated only when per-cpu ones overflow. Lego\u2019s initial version save the trouble of per-cpu counter, I only port one global counter today, because I\u2019m not quite confident about our percpu_alloc\u2026 Anway, the info is reported in the format of manager_sysinfo . Do note this is different from the oirginal sysinfo structure, which is used by sysinfo syscall. Task 2 : Patch get_random_number and /dev/urandom /dev/random. Others wrote the code, but he did not stick to the tradition of format naming. So I have to rewrite some of them. Sigh. Task 3 : optimize sweep","title":"03/16 Friday"},{"location":"lego/log/log-03-2018/#0315-thur","text":"Forgot to write the log yesterday. I actually solved the major bug, the refcount and eviction one. That is really nasty. I basically used pte lock, pcache_lock, and refcount to synchronize between eviction routine and other users such as munmap, mremap, write-protected-handler. I\u2019m really not sure if this mode can be reproduced if I have any other similar systems. But I\u2019m glad that I find a way to do this. Today I got few tasks going on. First merge storage syscall branch, then add sched_yield syscall, add zone/node counters, and probably patch get_random_number. Task 1 : Merge Yilun\u2019s storage pull request, has bunch syscalls. I\u2019m reviewing now. truncate ftruncate getdents getcwd mkdir rmdir creat unlink unlinkat readlink statfs sync Task 2 : Add sched_yield() . Fairly simple. Task 3 : Add physical memory counter. Fairly complex. The underlying is built long time ago. Need to pick up some. Well some facts: pg_data_t (and zone) is allcoated by alloc_node_data if NUMA is configured. all zones are built and initliazed in memory_init() in Lego stats are reset to 0 when pg_data_t allocated (DUH?). Played directly in page_alloc.c Have to continue tomorrow. Task 4 : Patch get_random_number and /dev/urandom","title":"03/15 Thur"},{"location":"lego/log/log-03-2018/#0313-wed","text":"The slow victim flush issue is solved by pinning the thread to a core and remove that core from active_cpu mask. Today I\u2019m going to solve the SMP object issue. I\u2019m hoping by solving this, we can have a complete working pcache and victim cache. Continue yesterday\u2019s log: wuklab13 0313 -12 [ 1073.616269 ] pcache : ffff880180777a80 mapcount : 0 refcount : 3 flags :( locked | allocated | usable ) kva : ffff88011ddea000 [ 1073.734941 ] __clflush_one () : EFAULT : bad address tsk : 32 user_va : 0x7fff4ddea000 [ 1073.822304 ] pcache dumped because : evict / ref bug [ 1073.987667 ] BUG : failure at managers / processor / pcache / evict . c : 301 / pcache_evict_line () ! [ 1074.082308 ] BUG : failure at managers / processor / pcache / rmap . c : 763 / pcache_zap_pte () ! [ 1074.172789 ] Kernel Panic - not syncing : BUG ! [ 1074.223751 ] CPU : 23 PID : 50 Comm : word_count - pthr 4.0.0 - lego - ys + # 476 Time CPU0 CPU1 0 pcache_evict_line() zap_pte_range() 1 find @pcm to evict prepare to unmap pte which points to @pcm 2 lock_pcache() .. 3 pcache_try_to_unmap() pte_offset_lock() 4 try to lock pte pcache_zap_pte() 5 ..spin.. trylock_pcache (failed) 6 ..spin.. unlock pte 7 lock pte trylock pcache 8 clear pte ..spin.. 9 unlock pte ..spin.. 10 unlock pcache ..spin.. 11 .. lock pcache 12 .. lock pte 13 .. HERE, should check if pte changed! Huh, patched both eviction and other code. Use refcount, pcache lock, pte lock to synchronize between all users. Make sure a going-to-be-evicted pcm will not be used by others. And others will not have a chance to use such line.","title":"03/13 Wed"},{"location":"lego/log/log-03-2018/#0312-tue","text":"Continue victim cache. The current conclusion is victim has a unbalanced input and output rate. That is why some cores timeout and abort. Got some more clean log. The log told us that the flushd_victim is too slow at flushing content. Next I going to print the current flush queue content. Make sure that they are really not flushed. If so, I want to add code to flush sync. [ 318.193591 ] CPU4 PID : 54 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207f81d340 , pset_idx : 1869 , nr_lru : 7 [ 318.330986 ] -- Start Dump Victim Cache -- [ 318.388190 ] -- CPU4 [ word_count - pthr ][ pid = 54 , tgid = 32 ] -- [ 318.456835 ] victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d200 [ 318.627406 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90748000 [ 318.707492 ] pset : ffff88207f81d200 set_idx : 1864 nr_lru : 8 [ 318.775096 ] [ 318.792778 ] victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d240 [ 318.963349 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90749000 [ 319.043435 ] pset : ffff88207f81d240 set_idx : 1865 nr_lru : 8 [ 319.111040 ] [ 319.128721 ] victim : ffff88207ff71090 index : 2 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d180 [ 319.299292 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90746000 [ 319.379378 ] pset : ffff88207f81d180 set_idx : 1862 nr_lru : 8 [ 319.446983 ] [ 319.464664 ] victim : ffff88207ff710d8 index : 3 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d280 [ 319.635237 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074a000 [ 319.715321 ] pset : ffff88207f81d280 set_idx : 1866 nr_lru : 8 [ 319.782927 ] [ 319.800608 ] victim : ffff88207ff71120 index : 4 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d140 [ 319.971179 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90745000 [ 320.051265 ] pset : ffff88207f81d140 set_idx : 1861 nr_lru : 8 [ 320.118870 ] [ 320.136551 ] victim : ffff88207ff71168 index : 5 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d300 [ 320.307123 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074c000 [ 320.387208 ] pset : ffff88207f81d300 set_idx : 1868 nr_lru : 8 [ 320.454813 ] [ 320.472494 ] victim : ffff88207ff711b0 index : 6 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d1c0 [ 320.643066 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90747000 [ 320.723152 ] pset : ffff88207f81d1c0 set_idx : 1863 nr_lru : 8 [ 320.790756 ] [ 320.808438 ] victim : ffff88207ff711f8 index : 7 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d2c0 [ 320.979009 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074b000 [ 321.059096 ] pset : ffff88207f81d2c0 set_idx : 1867 nr_lru : 8 [ 321.126700 ] [ 321.144381 ] -- End Dump Victim Cache -- [ 321.200545 ] CPU4 PID : 54 fail to allocate pcache or victim cache lines . [ 321.278552 ] word_count - pthr [ 54 ] : segfault at 0x74d000 ip 00000000004024 9 d sp 00007f ff7674cd80 error 6 [ 321.511925 ] nr_pgfault : 551908 [ 321.546357 ] nr_clflush : 33449 [ 321.581718 ] nr_pgfault_wp : 0 [ 321.616040 ] nr_pgfault_wp_cow : 0 [ 321.654523 ] nr_pgfault_wp_reuse : 0 [ 321.695087 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 321.754371 ] nr_pcache_fill_from_memory : 546067 [ 321.807414 ] nr_pcache_fill_from_victim : 5750 [ 321.858378 ] nr_pcache_eviction_triggered : 38689 [ 321.912461 ] nr_pcache_eviction_eagain : 5239 [ 321.962385 ] nr_pcache_eviction_succeed : 33449 [ 322.014389 ] nr_victim_eviction_triggered : 41887455 [ 322.071592 ] nr_victim_eviction_eagain : 41859764 [ 322.125676 ] nr_victim_eviction_succeed : 27691 [ 322.177680 ] nr_victim_prepare_insert : 33450 [ 322.227603 ] nr_victim_finish_insert : 33449 [ 322.276487 ] nr_victim_flush_submitted : 33449 [ 322.327451 ] nr_victim_flush_finished : 33449 [ 322.377374 ] nr_victim_flush_async_run : 26989 [ 322.428338 ] nr_victim_flush_sync : 0 Yes, this victims are truly not being flushed. They are inside the flush_queue. No bug, hoo! Just some performance coding issues. But god why the flushd does not get a chance to run in 10 seconds? Hmm\u2026 [ 5520.236187 ] __clflush_one () : EFAULT : bad address tsk : 32 user_va : 0x7fff464fa000 [ 5530.404269 ] CPU4 PID : 54 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207f81d340 , pset_idx : 1869 , nr_lru : 7 [ 5530.541664 ] CPU4 PID54 -- Start Dump Victim Cache [ 0 ] [ 5530.606147 ] CPU4 PID54 victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d1c0 [ 5530.789194 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90747000 [ 5530.880717 ] CPU4 PID54 rmap to pset : ffff88207f81d1c0 set_idx : 1863 nr_lru : 8 [ 5530.968080 ] CPU4 PID54 victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d280 [ 5531.151128 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074a000 [ 5531.242652 ] CPU4 PID54 rmap to pset : ffff88207f81d280 set_idx : 1866 nr_lru : 8 [ 5531.330015 ] CPU4 PID54 victim : ffff88207ff71090 index : 2 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d300 [ 5531.513063 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074c000 [ 5531.604586 ] CPU4 PID54 rmap to pset : ffff88207f81d300 set_idx : 1868 nr_lru : 8 [ 5531.691950 ] CPU4 PID54 victim : ffff88207ff710d8 index : 3 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d2c0 [ 5531.874997 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074b000 [ 5531.966521 ] CPU4 PID54 rmap to pset : ffff88207f81d2c0 set_idx : 1867 nr_lru : 8 [ 5532.053885 ] CPU4 PID54 victim : ffff88207ff71120 index : 4 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d200 [ 5532.236932 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90748000 [ 5532.328456 ] CPU4 PID54 rmap to pset : ffff88207f81d200 set_idx : 1864 nr_lru : 8 [ 5532.415819 ] CPU4 PID54 victim : ffff88207ff71168 index : 5 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d240 [ 5532.598867 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90749000 [ 5532.690390 ] CPU4 PID54 rmap to pset : ffff88207f81d240 set_idx : 1865 nr_lru : 8 [ 5532.777753 ] CPU4 PID54 victim : ffff88207ff711b0 index : 6 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d180 [ 5532.960802 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90746000 [ 5533.052325 ] CPU4 PID54 rmap to pset : ffff88207f81d180 set_idx : 1862 nr_lru : 8 [ 5533.139689 ] CPU4 PID54 victim : ffff88207ff711f8 index : 7 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d140 [ 5533.322736 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff90745000 [ 5533.414259 ] CPU4 PID54 rmap to pset : ffff88207f81d140 set_idx : 1861 nr_lru : 8 [ 5533.501623 ] CPU4 PID54 -- End Dump Victim Cache [ 0 ] [ 5533.566106 ] CPU4 PID54 -- Start Dump Victim Flush Queue [ 0 ] [ 5533.635789 ] CPU4 PID54 victim : ffff88207ff711f8 index : 7 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d140 [ 5533.818837 ] CPU4 PID54 victim : ffff88207ff711b0 index : 6 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d180 [ 5534.001884 ] CPU4 PID54 victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d1c0 [ 5534.184931 ] CPU4 PID54 victim : ffff88207ff71120 index : 4 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d200 [ 5534.367978 ] CPU4 PID54 victim : ffff88207ff71168 index : 5 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d240 [ 5534.551025 ] CPU4 PID54 victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d280 [ 5534.734074 ] CPU4 PID54 victim : ffff88207ff710d8 index : 3 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d2c0 [ 5534.917120 ] CPU4 PID54 victim : ffff88207ff71090 index : 2 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d300 [ 5535.100168 ] CPU4 PID54 -- End Dump Victim Flush Queue [ 0 ] [ 5535.169851 ] CPU4 PID : 54 fail to allocate pcache or victim cache lines . [ 5535.247854 ] word_count - pthr [ 54 ] : segfault at 0x74d000 ip 00000000004024 9 d sp 00007f ff7674cd80 error 6 [ 5535.480513 ] nr_pgfault : 549578 [ 5535.514943 ] nr_clflush : 31822 [ 5535.550304 ] nr_pgfault_wp : 0 [ 5535.584625 ] nr_pgfault_wp_cow : 0 [ 5535.623107 ] nr_pgfault_wp_reuse : 0 [ 5535.663669 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 5535.722952 ] nr_pcache_fill_from_memory : 544279 [ 5535.775993 ] nr_pcache_fill_from_victim : 5201 [ 5535.826955 ] nr_pcache_eviction_triggered : 37437 [ 5535.881038 ] nr_pcache_eviction_eagain : 5614 [ 5535.930960 ] nr_pcache_eviction_succeed : 31822 [ 5535.982963 ] nr_victim_eviction_triggered : 42000029 [ 5536.040165 ] nr_victim_eviction_eagain : 41973416 [ 5536.094247 ] nr_victim_eviction_succeed : 26613 [ 5536.146249 ] nr_victim_prepare_insert : 31823 [ 5536.196171 ] nr_victim_finish_insert : 31822 [ 5536.245052 ] nr_victim_flush_submitted : 31822 [ 5536.296015 ] nr_victim_flush_finished : 31822 [ 5536.345937 ] nr_victim_flush_async_run : 26718 [ 5536.396899 ] nr_victim_flush_sync : 0 Hmm, got some interesting bug, which never happened before. We did a unmap before finish_insert , so the mapcount must be zero. Since we have the Reclaim set for the candidate. But it looks like other code does not too much about the Reclaim bit. I need to check. [ 1009.676839 ] victim_flush_async CPU4 jobs 1 [ 1009.725830 ] victim_flush_async CPU4 jobs 1 [ 1009.774423 ] victim_flush_async CPU4 jobs 1 [ 1009.823147 ] __clflush_one () : EFAULT : bad address tsk : 32 user_va : 0x7fff465fc000 [ 1009.910479 ] pcache : ffff88018098d740 mapcount : 1 refcount : 3 flags :( locked | allocated | usable | valid | reclaim ) kva : ffff88012635d000 [ 1010.045652 ] pcache dumped because : PCACHE_BUG_ON_PCM ( pcache_mapped ( pcm )) [ 1010.125725 ] victim_flush_async CPU4 jobs 1 [ 1010.174602 ] ------------ [ cut here ] ------------ [ 1010.229717 ] BUG : failure at managers / processor / pcache / victim . c : 601 / victim_finish_insert () ! [ 1010.328509 ] victim_flush_async CPU4 jobs 1 [ 1010.377385 ] Kernel Panic - not syncing : BUG ! [ 1010.428341 ] CPU : 20 PID : 47 Comm : word_count - pthr 4.0.0 - lego - ys + # 468 [ 1010.505294 ] Stack : [ 1010.529212 ] ffff881f2040fe08 ffffffff810259f4 000000000000000 8 ffff881f2040fe18 [ 1010.616565 ] ffff881f2040fdd0 0000000021475542 0000000000000000 0000000000000000 [ 1010.703918 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 1010.791270 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 1010.878623 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 1010.965976 ] Call Trace : [ 1010.995095 ] < TSK > [ 1011.017972 ] [ < ffffffff81025a00 > ] panic + 0xc2 / 0x102 [ 1011.074127 ] [ < ffffffff81063a8a > ] ? client_internal_poll_sendcq + 0x2a / 0x80 [ 1011.154202 ] [ < ffffffff81063c2d > ] ? client_send_message_with_rdma_write_with_imm_request + 0x14d / 0x360 [ 1011.262351 ] [ < ffffffff8101bffc > ] ? task_tick_rt + 0x2c / 0xd0 [ 1011.326827 ] [ < ffffffff81019755 > ] ? scheduler_tick + 0x55 / 0x60 [ 1011.393382 ] [ < ffffffff81016e25 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 1011.466175 ] [ < ffffffff810066e4 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 1011.538969 ] [ < ffffffff8100e4aa > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 1011.616964 ] [ < ffffffff81012cfd > ] ? printk + 0x11d / 0x1b0 [ 1011.677279 ] [ < ffffffff81032a19 > ] victim_finish_insert + 0x89 / 0x230 [ 1011.749032 ] [ < ffffffff81031a99 > ] pcache_evict_line + 0x79 / 0x280 [ 1011.817667 ] [ < ffffffff8102f00a > ] pcache_alloc + 0x23a / 0x340 [ 1011.882141 ] [ < ffffffff8102e4da > ] common_do_fill_page + 0x2a / 0x1b0 [ 1011.952856 ] [ < ffffffff8102e160 > ] ? pcache_meta_to_kva + 0x30 / 0x30 [ 1012.023570 ] [ < ffffffff8102e802 > ] pcache_handle_fault + 0x1a2 / 0x660 [ 1012.095324 ] [ < ffffffff810102b2 > ] do_page_fault + 0xa2 / 0x1a0 [ 1012.159799 ] [ < ffffffff8100dadf > ] page_fault + 0x1f / 0x30 Interesting. Memory consistency issue? Actually, I\u2019m not sure if it is the v->flags = 0 issue. Others use atomic bit operations to play with this flag, while the reset is a simple store. I checked the list operations, all of them are protected by spinlock. So the below should never happen in theory. I\u2019m changing the v->flags = 0 to smp_store_mb(v->flags, 0) , which is a xchg in x86. Same for pcache. [ 1773.814490] CPU17 PID44 victim:ffff88207ff71000 index:0 refcount:1 nr_fill:0 locked:0 flags:(allocated|usable) pcm: (null) pset: (null) [ 1773.979705] CPU17 PID44 hit[0] owner: [word_count-pthr][32] addr: 0x7fff95b1c000 [ 1774.072260] CPU17 PID44 rmap to pset:ffff88207f96c700 set_idx: 23324 nr_lru:8 [ 1774.161694] CPU17 PID44 victim dumped because: PCACHE_BUG_ON_VICTIM(!VictimUsable(v)) [ 1774.259451] ------------[ cut here ]------------ [ 1774.314567] BUG: failure at managers/processor/pcache/victim.c:231/find_victim_to_evict()! [ 1774.413363] Kernel Panic - not syncing: BUG! [ 1774.464320] CPU: 17 PID: 44 Comm: word_count-pthr 4.0.0-lego-ys+ #47 ... [ 1781.363348] nr_pcache_fill_from_victim: 2 Did another run. I added an explicit wake_up_victim_flushd if victim failed to evict any line. But this fails with IB failure.. [ 2336.950087 ] CPU4 PID : 54 Abort victim alloc ( 20010 ms ) nr_usable_victims : 8 req from pset : ffff88207f81d340 , pset_idx : 1869 , nr_lru : 7 [ 2337.087474 ] CPU4 PID54 -- Start Dump Victim Cache [ 0 ] [ 2337.151955 ] CPU4 PID54 victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d280 [ 2337.334999 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074a000 [ 2337.426521 ] CPU4 PID54 rmap to pset : ffff88207f81d280 set_idx : 1866 nr_lru : 8 [ 2337.513883 ] CPU4 PID54 victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d2c0 [ 2337.696927 ] CPU4 PID54 hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff9074b000 [ 2337.788450 ] CPU4 PID54 rmap to pset : ffff88207f81d2c0 set_idx : 1867 nr_lru : 8 ... ... [ 2340.111861 ] CPU4 PID54 -- Start Dump Victim Flush Queue [ 0 ] [ 2340.181543 ] CPU4 PID54 victim : ffff88207ff71090 index : 2 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d140 [ 2340.364587 ] CPU4 PID54 victim : ffff88207ff71120 index : 4 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d180 [ 2340.547632 ] CPU4 PID54 victim : ffff88207ff711f8 index : 7 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d1c0 [ 2340.730675 ] CPU4 PID54 victim : ffff88207ff71168 index : 5 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d200 [ 2340.913720 ] CPU4 PID54 victim : ffff88207ff711b0 index : 6 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d240 [ 2341.096763 ] CPU4 PID54 victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d280 [ 2341.279808 ] CPU4 PID54 victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d2c0 [ 2341.462851 ] CPU4 PID54 victim : ffff88207ff710d8 index : 3 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207f81d300 [ 2341.645895 ] CPU4 PID54 -- End Dump Victim Flush Queue [ 0 ] [ 2341.715577 ] CPU4 PID : 54 fail to allocate pcache or victim cache lines . [ 2341.793579 ] word_count - pthr [ 54 ] : segfault at 0x74d000 ip 00000000004024 9 d sp 00007f ff7674cd80 error 6 [ 2476.201442 ] mlx4_ib_handle_error_cqe syndrome 21 [ 2476.254590 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2476.308670 ] send request failed at connection 4 as 12 [ 2476.368991 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2476.423073 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2476.477153 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2476.531236 ] client_poll_cq : failed status ( 5 ) for wr_id 1051 [ 2476.598837 ] client_poll_cq : failed status ( 5 ) for wr_id 1052 [ 2476.666438 ] __clflush_one () : EPERM : Operation not permitted tsk : 32 user_va : 0x7fff90745000 [ 2476.765240 ] client_poll_cq : connection 4 Recv weird event as -30704 [ 2476.840122 ] client_poll_cq : failed status ( 5 ) for wr_id 1053 [ 2476.907724 ] client_poll_cq : connection 4 Recv weird event as -30704 [ 2476.982605 ] client_poll_cq : failed status ( 5 ) for wr_id 1054 [ 2477.050207 ] client_poll_cq : connection 4 Recv weird event as -30704 [ 2477.125089 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.179169 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.233251 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.287332 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.341414 ] client_poll_cq : failed status ( 5 ) for wr_id 1055 [ 2477.409016 ] client_poll_cq : failed status ( 5 ) for wr_id 1056 .. .. [ 2477.761583 ] client_poll_cq : connection 4 Recv weird event as -30704 [ 2477.836464 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.890545 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.944626 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2477.998707 ] mlx4_ib_handle_error_cqe syndrome 5 [ 2478.052789 ] client_poll_cq : failed status ( 5 ) for wr_id 1059 [ 2478.120392 ] BUG : unable to handle kernel NULL pointer dereference at ( null ) [ 2478.213992 ] IP : [ < ffffffff81064894 > ] client_poll_cq + 0x1f4 / 0x6c0 [ 2478.284714 ] PGD 0 [ 2478.308635 ] Oops : 0002 [ # 1 ] SMP PROCESSOR [ 2478.356476 ] CPU : 2 PID : 29 Comm : recvpollcq 4.0.0 - lego - ys + # 473 [ 2478.427197 ] RIP : 0010 : [ < ffffffff81064894 > ] [ < ffffffff81064894 > ] client_poll_cq + 0x1f4 / 0x6c0 [ 2478.527040 ] RSP : 0000 : ffff88107e143d90 EFLAGS : 00010246 [ 2478.590481 ] RAX : 0000000000000000 RBX : ffff88207fc6e000 RCX : 0000000000000000 [ 2478.675762 ] RDX : 000000000000100 8 RSI : ffffffff811d36e0 RDI : ffffffff811dab08 [ 2478.761044 ] RBP : ffff88107e143eb0 R08 : 0000000000000000 R09 : 0000000000000000 [ 2478.846327 ] R10 : 0000000000000002 R11 : 0000000000000004 R12 : ffff88207fd4f000 [ 2478.931609 ] R13 : 0000000000000004 R14 : ffff88107e143da8 R15 : 0000000000000000 [ 2479.016890 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc20000 ( 0000 ) knlGS : 0000000000000000 [ 2479.113613 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 2479.182254 ] CR2 : 0000000000000000 CR3 : 000000000113 d000 CR4 : 00000000000406 a0 [ 2479.267536 ] Stack : [ 2479.291457 ] ffff88107e143da0 001012 9 c81019794 0000000000000001 0000000000000423 [ 2479.378818 ] 000000 8100000005 00001008000000f 9 ffff88207fd39000 0000000040000000 [ 2479.466180 ] 000f 004000000002 ffff88107e140000 0000000000000424 ffff881000000005 [ 2479.553542 ] 00000000000000f 9 ffff88207fd39000 ffff88107e143e38 ffffffff81019e44 [ 2479.640904 ] 0000000000000001 0000000000000425 ffff881000000005 ffffffff000000f9 [ 2479.728266 ] Call Trace : [ 2479.757386 ] < TSK > [ 2479.780268 ] [ < ffffffff81019e44 > ] ? try_to_wake_up + 0xe4 / 0x1f0 [ 2479.847869 ] [ < ffffffff81066d78 > ] ? __schedule + 0xf8 / 0x1e0 [ 2479.911311 ] [ < ffffffff81064d60 > ] ? client_poll_cq + 0x6c0 / 0x6c0 [ 2479.979952 ] [ < ffffffff81064d70 > ] client_poll_cq_pass + 0x10 / 0x20 [ 2480.049634 ] [ < ffffffff81020336 > ] kthread + 0xf6 / 0x110 [ 2480.107875 ] [ < ffffffff81020240 > ] ? __kthread_parkme + 0x70 / 0x70 [ 2480.176516 ] [ < ffffffff8100e732 > ] ret_from_fork + 0x22 / 0x30 A classical SMP bug. Lucky to find this one. Let me try to describe this. There are two CPU1. CPU0 and CPU1. CPU0 is doing eviction while CPU1 is doing munmap->pcache_zap_pte. The CPU0 slected a pcm, while this pcm happen to be zapped at the same time by CPU1. There are not enough actions to either 1) prevent CPU0 from selecting this pcm, 2) prevent CPU1 from using this pcm. Both solutions might be work. But we need as least one. wuklab13 0313 -12 [ 1073.616269 ] pcache : ffff880180777a80 mapcount : 0 refcount : 3 flags :( locked | allocated | usable ) kva : ffff88011ddea000 [ 1073.734941 ] __clflush_one () : EFAULT : bad address tsk : 32 user_va : 0x7fff4ddea000 [ 1073.822304 ] pcache dumped because : evict / ref bug [ 1073.987667 ] BUG : failure at managers / processor / pcache / evict . c : 301 / pcache_evict_line () ! [ 1074.082308 ] BUG : failure at managers / processor / pcache / rmap . c : 763 / pcache_zap_pte () ! [ 1074.172789 ] Kernel Panic - not syncing : BUG ! [ 1074.223751 ] CPU : 23 PID : 50 Comm : word_count - pthr 4.0.0 - lego - ys + # 476","title":"03/12 Tue"},{"location":"lego/log/log-03-2018/#0311-mon","text":"","title":"03/11 Mon"},{"location":"lego/log/log-03-2018/#debug-victim-cache","text":"Morning. Today I will continue debugging victim and clflush, running with MT phoenix+2GB, seq+4GB. Sounds good. Digging into yesterday\u2019s 21th run log. The warning comes from victim_alloc_slowpath . The allocation abort after 10 seconds timeout. And interestingly, a lot threads abort. (The case is, pset is full, so pcache_alloc will try to evict one to victim cache. But victim cache is full as well. So it needs to evict one victim cache line too. Somehow this does not proceed as planned.) I guess somewhere deadlock happens. [ 1682.040428 ] WARNING : CPU : 7 PID : 34 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1682.161063 ] WARNING : CPU : 19 PID : 46 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1686.602779 ] WARNING : CPU : 10 PID : 37 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1687.384837 ] WARNING : CPU : 3 PID : 53 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1687.505474 ] WARNING : CPU : 21 PID : 48 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1687.737386 ] WARNING : CPU : 16 PID : 43 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1687.859063 ] WARNING : CPU : 4 PID : 54 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1688.034819 ] WARNING : CPU : 6 PID : 56 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1688.210574 ] WARNING : CPU : 14 PID : 41 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1688.488246 ] WARNING : CPU : 5 PID : 55 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1689.598935 ] WARNING : CPU : 22 PID : 49 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1689.953565 ] WARNING : CPU : 0 PID : 51 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1691.740234 ] WARNING : CPU : 13 PID : 40 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1691.861911 ] WARNING : CPU : 1 PID : 52 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 [ 1791.554552 ] WARNING : CPU : 11 PID : 38 at managers / processor / pcache / victim . c : 447 victim_prepare_insert + 0x322 / 0x4b0 1 st run. MT+2GB. Victim allocation as predicted. Somehow I already forgot how the code is designed. I need to take a detailed reread. Along the testing, fixed a bug in eviction code: handle failed evict_line properly. If eviction mechanism failed, we need to clear what the algorithm part has done. This is also related to yesterday\u2019s big idea: always do proper cleanup. Many thanks go to pcache free checking, help me to find this bug. Less is more. I printed too much useless info when pcache_alloc or victim_alloc fail. I removed all the dump_pset from the failing path. It can give me a much more clean message to debug. Hmm, it is really weird. I dump all victims once alloc timeout. You can see that all victim are not Flushed, that means none of them can be evicted. Take a look at the stat. Hmm, I probabaly should not do this per-cpu counter?? ... [ 4751.460819 ] -- Start Dump Victim Cache -- [ 4751.518022 ] -- CPU19 [ word_count - pthr ][ pid = 46 , tgid = 32 ] -- [ 4751.587706 ] victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800440 [ 4751.747872 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff20011000 [ 4751.827955 ] pset : ffff88207f800440 set_idx : 17 nr_lru : 8 [ 4751.893478 ] [ 4751.911159 ] victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f8003c0 [ 4752.071326 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff2000f000 [ 4752.428060 ] pset : ffff88207f8003c0 set_idx : 15 nr_lru : 8 [ 4752.630868 ] [ 4752.931441 ] victim : ffff88207ff71090 index : 2 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800540 [ 4753.370339 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff20015000 [ 4753.450422 ] pset : ffff88207f800540 set_idx : 21 nr_lru : 8 [ 4753.515945 ] [ 4753.533627 ] victim : ffff88207ff710d8 index : 3 refcount : 3 nr_fill : 1 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207fbdff40 [ 4753.693792 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fffbf7fd000 [ 4753.773875 ] pset : ffff88207fbdff40 set_idx : 63485 nr_lru : 7 [ 4753.842518 ] [ 4753.860199 ] victim : ffff88207ff71120 index : 4 refcount : 3 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800500 [ 4754.020367 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff20014000 [ 4754.100449 ] pset : ffff88207f800500 set_idx : 20 nr_lru : 8 [ 4754.165971 ] [ 4754.183653 ] victim : ffff88207ff71168 index : 5 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800480 [ 4754.343819 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff30012000 [ 4754.423902 ] pset : ffff88207f800480 set_idx : 18 nr_lru : 8 [ 4754.489426 ] [ 4754.507106 ] victim : ffff88207ff711b0 index : 6 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f8004c0 [ 4754.808718 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff30013000 [ 4754.888802 ] pset : ffff88207f8004c0 set_idx : 19 nr_lru : 8 [ 4754.954325 ] [ 4754.972006 ] victim : ffff88207ff711f8 index : 7 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800400 [ 4755.132172 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff20010000 [ 4755.212255 ] pset : ffff88207f800400 set_idx : 16 nr_lru : 8 [ 4755.277778 ] [ 4755.295458 ] -- End Dump Victim Cache -- ... [ 4757.948641 ] nr_pgfault : 313898 [ 4757.983067 ] nr_clflush : 488 [ 4758.016347 ] nr_pgfault_wp : 0 [ 4758.050669 ] nr_pgfault_wp_cow : 0 [ 4758.089151 ] nr_pgfault_wp_reuse : 0 [ 4758.129713 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 4758.188995 ] nr_pcache_fill_from_memory : 313833 [ 4758.242038 ] nr_pcache_fill_from_victim : 54 [ 4758.290919 ] nr_pcache_eviction_triggered : 243280263 [ 4758.349161 ] nr_pcache_eviction_eagain : 243279763 [ 4758.404283 ] nr_pcache_eviction_succeed : 488 [ 4758.454207 ] nr_victim_eviction : 426 [ 4758.495807 ] nr_victim_prepare_insert : 500 [ 4758.543649 ] nr_victim_finish_insert : 488 [ 4758.590451 ] nr_victim_flush_submitted : 488 [ 4758.639333 ] nr_victim_flush_finished : 488 I counted it wrong. Below is the log. Since nr_victim_flushd_run * 8 = nr_victim_flush_finished , it basically means for every run, victim_flushd needs to flush all 8 victims, which implies eviction rate is much higher than the flushd running rate. nr_pcache_fill_from_victim: 21 , which means there are some succeed refills, but I don\u2019t know how it can improve performance. [ 475.468489 ] CPU4 PID : 54 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207f800000 , pset_idx : 0 , nr_lru : 7 [ 475.602752 ] CPU3 PID : 53 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207f900a00 , pset_idx : 16424 , nr_lru : 7 [ 476.029145 ] CPU5 PID : 55 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207fbdff40 , pset_idx : 63485 , nr_lru : 7 [ 476.169542 ] CPU9 PID : 36 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207f900000 , pset_idx : 16384 , nr_lru : 7 [ 477.360322 ] CPU1 PID : 52 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207fbfff80 , pset_idx : 65534 , nr_lru : 7 [ 479.206291 ] CPU18 PID : 45 Abort victim alloc ( 10010 ms ) nr_usable_victims : 8 req from pset : ffff88207fb00000 , pset_idx : 49152 , nr_lru : 7 [ 475.743150 ] -- Start Dump Victim Cache -- [ 475.800350 ] -- CPU4 [ word_count - pthr ][ pid = 54 , tgid = 32 ] -- [ 475.868989 ] victim : ffff88207ff71000 index : 0 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800a80 [ 476.309940 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff3002a000 [ 476.390020 ] pset : ffff88207f800a80 set_idx : 42 nr_lru : 8 [ 476.455538 ] [ 476.473218 ] victim : ffff88207ff71048 index : 1 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800bc0 [ 476.633376 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff4002f000 [ 476.713453 ] pset : ffff88207f800bc0 set_idx : 47 nr_lru : 8 [ 476.778972 ] [ 476.796652 ] victim : ffff88207ff71090 index : 2 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800b80 [ 476.956809 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff3002e000 [ 477.036889 ] pset : ffff88207f800b80 set_idx : 46 nr_lru : 8 [ 477.102406 ] [ 477.120086 ] victim : ffff88207ff710d8 index : 3 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800a00 [ 477.280245 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff30028000 [ 477.500721 ] pset : ffff88207f800a00 set_idx : 40 nr_lru : 8 [ 477.566239 ] [ 477.583918 ] victim : ffff88207ff71120 index : 4 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800b40 [ 477.744077 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff3002d000 [ 477.824155 ] pset : ffff88207f800b40 set_idx : 45 nr_lru : 8 [ 477.889673 ] [ 477.907353 ] victim : ffff88207ff71168 index : 5 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800b00 [ 478.067511 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff3002c000 [ 478.147590 ] pset : ffff88207f800b00 set_idx : 44 nr_lru : 8 [ 478.213109 ] [ 478.230788 ] victim : ffff88207ff711b0 index : 6 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800a40 [ 478.390946 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff30029000 [ 478.471024 ] pset : ffff88207f800a40 set_idx : 41 nr_lru : 8 [ 478.536542 ] [ 478.554222 ] victim : ffff88207ff711f8 index : 7 refcount : 2 nr_fill : 0 locked : 0 flags :( allocated | usable | hasdata ) pcm : ( null ) pset : ffff88207f800ac0 [ 478.714380 ] hit [ 0 ] owner : [ word_count - pthr ][ 32 ] addr : 0x7fff3002b000 [ 478.794458 ] pset : ffff88207f800ac0 set_idx : 43 nr_lru : 8 [ 478.859977 ] [ 478.877657 ] -- End Dump Victim Cache -- [ 480.324070 ] nr_pgfault : 372353 [ 480.358494 ] nr_clflush : 336 [ 480.391774 ] nr_pgfault_wp : 0 [ 480.426093 ] nr_pgfault_wp_cow : 0 [ 480.464573 ] nr_pgfault_wp_reuse : 0 [ 480.505132 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 480.564410 ] nr_pcache_fill_from_memory : 372326 [ 480.617450 ] nr_pcache_fill_from_victim : 21 [ 480.666330 ] nr_pcache_eviction_triggered : 178320088 [ 480.724569 ] nr_pcache_eviction_eagain : 178319746 [ 480.779687 ] nr_pcache_eviction_succeed : 336 [ 480.829606 ] nr_victim_eviction_triggered : 20589049 [ 480.886805 ] nr_victim_eviction_eagain : 20588741 [ 480.940885 ] nr_victim_eviction_succeed : 308 [ 480.990804 ] nr_victim_prepare_insert : 342 [ 481.038643 ] nr_victim_finish_insert : 336 [ 481.085442 ] nr_victim_flush_submitted : 336 [ 481.134321 ] nr_victim_flush_finished : 336 [ 481.182161 ] nr_victim_flushd_run : 42","title":"Debug victim cache"},{"location":"lego/log/log-03-2018/#0310-sun","text":"","title":"03/10 Sun"},{"location":"lego/log/log-03-2018/#fix-bug-from-__unhash_procees","text":"[Summary]: a bug cause by laziness. When fork happens, the new thread is added into parent\u2019s thread_group list. However, we forgot to remove it when the new thread exit. Thus, the field in parent\u2019s thread_group will point to a freed page. To make it worse, the freed page got allocated again. In our case, the page was used by pgtable. So, when the parent tries to use that field, it simply corrupts pgtable. This bug is fixed by this commit: 64d43fc. Got something going on. Huh. Anyway, pick up what left last night. 8 th run, [ 426.595911] SYSC_mmap(cpu5): ret_addr:0x7ffefbeac000 pte page got allocated [ 426.653216] pmd is none index 0x1e3 line 567 from_addr 0x7ffefc6acd90 [ 426.734334] __pte_alloc(): for addr: 0x7ffefc6acd90 pte_index: ac [ 426.807132] pte is none index 0x38 line 574 from_addr 0x7ffefc6acd90 [ 427.304148] pte is none index 0x38 line 576 from_addr 0x7ffefc6acd90 this addr seems fine [ 427.382251] pte is none index 0x38 line 567 from_addr 0x7ffefc6abe78 [ 427.462329] pte is none index 0x38 line 574 from_addr 0x7ffefc6abe78 [ 427.644439] pte is none index 0x38 line 576 from_addr 0x7ffefc6abe78 Something happen in between corrupted pgtable [ 427.722547] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000) [ 427.858779] line: 567 from_addr: 0x6fc6d8 pte.cont: 0xffff88207e8c31c0 [ 427.938858] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000) [ 428.075095] line: 574 from_addr: 0x6fc6d8 pte.cont: 0xffff88207e8c31c0 9 th run, found actually it created another thread. And it exit. And it corrupted aftet the pid33 exit. Bang, it should be something wrong in exit(). wuklab13 0311 -4 [ 813.127325 ] CPU6 pid : 33 pmd is none index 0x1e3 line 586 from_addr 0x4b0db0 [ 813.214683 ] CPU5 pid : 32 pmd is none index 0x1e3 line 593 from_addr 0x6f4768 [ 813.302042 ] CPU6 pid : 33 pmd is none index 0x1e3 line 593 from_addr 0x4b0db0 [ 813.397836 ] CPU5 pid : 32 pmd is none index 0x1e3 line 595 from_addr 0x6f4768 [ 813.593364 ] CPU6 pid : 33 pmd is none index 0x1e3 line 595 from_addr 0x4b0db0 [ 813.678751 ] do_exit () pid : 33 , tgid : 32 code : 0x0 [ 814.474321 ] CPU5 pid : 32 pmd is none index 0x1e3 line 567 from_addr 0x7ffefc6acd90 [ 814.567918 ] CPU5 pid : 32 pmd is none index 0x1e3 line 575 from_addr 0x7ffefc6acd90 [ 814.661516 ] CPU5 pid : 32 pmd is none index 0x1e3 line 583 from_addr 0x7ffefc6acd90 [ 814.755115 ] CPU5 pid : 32 pmd is none index 0x1e3 line 586 from_addr 0x7ffefc6acd90 [ 814.848714 ] __pte_alloc () : for addr : 0x7ffefc6acd90 pte_index : ac [ 814.921511 ] CPU5 pid : 32 pte is none index 0x38 line 593 from_addr 0x7ffefc6acd90 [ 815.125249 ] CPU5 pid : 32 pte is none index 0x38 line 595 from_addr 0x7ffefc6acd90 [ 815.215833 ] After pcache_handle_fault [ 815.259511 ] CPU5 pid : 32 pte is none index 0x38 line 726 from_addr 0x7ffefc6acd90 [ 815.352071 ] CPU5 pid : 32 pte is none index 0x38 line 567 from_addr 0x7ffefc6abe78 [ 815.444627 ] CPU5 pid : 32 pte is none index 0x38 line 575 from_addr 0x7ffefc6abe78 [ 815.537186 ] CPU5 pid : 32 pte is none index 0x38 line 583 from_addr 0x7ffefc6abe78 [ 815.629744 ] CPU5 pid : 32 pte is none index 0x38 line 586 from_addr 0x7ffefc6abe78 [ 815.722303 ] CPU5 pid : 32 pte is none index 0x38 line 593 from_addr 0x7ffefc6abe78 [ 815.916890 ] CPU5 pid : 32 pte is none index 0x38 line 595 from_addr 0x7ffefc6abe78 [ 816.007471 ] After pcache_handle_fault [ 816.051151 ] CPU5 pid : 32 pte is none index 0x38 line 726 from_addr 0x7ffefc6abe78 [ 816.143715 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 816.279946 ] do_exit () pid : 34 , tgid : 32 code : 0x0 [ 816.331945 ] CPU5 pid : 32 line : 567 from_addr : 0x6fc6d8 pte . cont : 0xffff88207e8c31c0 10 th run, actually 2 threads are created. When pid 33 exit, everything stays okay. But after fork of pid 34. It went wrong: wuklab13 0311 -8 [ 609.490893 ] do_exit () pid : 33 , tgid : 32 code : 0x0 [ 609.542894 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 401 from_addr 0x0 [ 609.640661 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 443 from_addr 0x0 [ 609.738429 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 465 from_addr 0x0 [ 609.836197 ] exit_mm : 378 mm -> users 2 mm -> count 1 [ 609.891320 ] exit_mm : 380 mm -> users 1 mm -> count 1 [ 609.946445 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 468 from_addr 0x0 [ 610.044212 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 471 from_addr 0x0 [ 610.141979 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 474 from_addr 0x0 [ 610.239747 ] SYSC_mmap ( cpu5 ) : ret_addr : 0x7ffefbeac000 [ 610.299031 ] CPU6 pid : 33 caller : do_exit pmd is none index 0x1e3 line 482 from_addr 0x0 [ 610.396798 ] CPU5 pid : 32 caller : pcache_handle_fault pmd is none index 0x1e3 line 568 from_addr 0x7ffefc6acd90 [ 610.518489 ] CPU5 pid : 32 caller : pcache_handle_fault pmd is none index 0x1e3 line 576 from_addr 0x7ffefc6acd90 [ 610.640178 ] CPU5 pid : 32 caller : pcache_handle_fault pmd is none index 0x1e3 line 584 from_addr 0x7ffefc6acd90 [ 610.761866 ] CPU5 pid : 32 caller : pcache_handle_fault pmd is none index 0x1e3 line 587 from_addr 0x7ffefc6acd90 [ 610.883557 ] __pte_alloc () : for addr : 0x7ffefc6acd90 pte_index : ac [ 610.956362 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 594 from_addr 0x7ffefc6acd90 [ 611.179051 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 596 from_addr 0x7ffefc6acd90 [ 611.297723 ] After pcache_handle_fault [ 611.341406 ] CPU5 pid : 32 caller : do_page_fault pte is none index 0x38 line 726 from_addr 0x7ffefc6acd90 [ 611.455816 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 568 from_addr 0x7ffefc6abe78 [ 611.576464 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 576 from_addr 0x7ffefc6abe78 [ 611.697113 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 584 from_addr 0x7ffefc6abe78 [ 611.817762 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 587 from_addr 0x7ffefc6abe78 [ 611.938412 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 594 from_addr 0x7ffefc6abe78 [ 612.161103 ] CPU5 pid : 32 caller : pcache_handle_fault pte is none index 0x38 line 596 from_addr 0x7ffefc6abe78 [ 612.279778 ] After pcache_handle_fault [ 612.323461 ] CPU5 pid : 32 caller : do_page_fault pte is none index 0x38 line 726 from_addr 0x7ffefc6abe78 [ 612.437875 ] do_fork : current : 32 new : 34 [ 612.484676 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 612.620924 ] do_exit () pid : 34 , tgid : 32 code : 0x0 [ 612.672928 ] CPU5 pid : 32 caller : pcache_handle_faultline : 568 from_addr : 0x6fc6d8 pte . cont : 0xffff88207e8c31c0 [ 612.793577 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 612.929828 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 613.066078 ] CPU7 pid : 34 caller : do_exitline : 401 from_addr : 0x0 pte . cont : 0xffff88207e8c31c0 11 th run, found it orignate from copy_process() . Good. [ 869.591729 ] CPU5 pid : 32 caller : do_fork pte is none index 0x38 line 886 from_addr 0x0 [ 869.688449 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 869.824681 ] CPU5 pid : 32 caller : do_fork line : 894 from_addr : 0x0 pte . cont : 0xffff88207e8c31c0 12 th run, found the opeation that corrupt pgtable: [ 1099.974106 ] CPU5 pid : 32 caller : copy_process pte is none index 0x38 line 897 from_addr 0x0 [ 1100.076032 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 1100.212282 ] CPU5 pid : 32 caller : copy_process line : 902 from_addr : 0x0 pte . cont : 0xffff88207e8c31c0 896 if ( current -> tgid == 32 ) 897 jasmine ( 0 , __LINE__ , __func__ ); 898 899 list_add_tail ( & p -> thread_group , 900 & p -> group_leader -> thread_group ); 901 if ( current -> tgid == 32 ) 902 jasmine ( 0 , __LINE__ , __func__ ); 13 th run, interesting, the list_add_tail write to the pgtable. pte.cont = 0xffff88207e8c31c0, p->thread_group: 0xffff88207e8c31c0 . [ 916.269942 ] CPU5 pid : 32 caller : copy_process pte is none index 0x38 line 898 from_addr 0x0 [ 916.371863 ] p : ffff88207e8c3000 p -> group_leader : ffff88107e190000 ( 32 ) p -> thread_group : ffff88207e8c31c0 leader -> thread_grou : ffff88107e1901c0 [ 916.523705 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 916.659947 ] CPU5 pid : 32 caller : copy_process line : 906 from_addr : 0x0 pte . cont : 0xffff88207e8c31c0 [ 916.769148 ] p : ffff88207e8c3000 p -> group_leader : ffff88107e190000 ( 32 ) p -> thread_group : ffff88207e8c31c0 leader -> thread_grou : ffff88107e1901c0 14 th run, got an log like this. Clearly, the pte is written the value of p->thread_group. But the leader\u2019s pointer is correct. Weird, going to dig deeper. p: ffff88207e8c3000 p->group_leader: ffff88107e189000(32) p->thread_group: ffff88207e8c31c0 leader->thread_group: ffff88107e1891c0 pte page: ffff88207e8b5000 pte: ffff88207e8b51c0 pte.cont: ffff88207e8c31c0 15 th run, found the bug. wuklab13 0311 -15 [ 1474.477687 ] dup_task_struct () : current : 32 new : ffff88207e8b5000 .. while pid 33 exit so the ffff88207e8b5000 is freed but allocated again by pte_alloc [ 1481.420200 ] __pte_alloc () : CPU5 for addr : 0x7ffefc6acd90 pte_index : ac new pte page : ffff88207e8b5000 However , we forgot to remove it from group_leader ' s thread_group [ 1485.895938 ] p : ffff88207e8c3000 p -> group_leader : ffff88107e19b000 ( 32 ) p -> thread_group : ffff88207e8c31c0 leader -> thread_group : ffff88107e19b1c0 [ 1486.047784 ] tg -> next : ffff88207e8c31c8 tg -> prev : ffff88207e8c31c0 leader -> tg -> next ffff88107e19b1c8 leader -> tg -> prev ffff88107e19b1c0 [ 1486.191311 ] next ffff88107e19b1c0 prev ffff88207e8b51c0 next ffff88107e19b1c0 [ 1486.276594 ] CPU5 pid : 32 caller : __list_add pte is none index 0x38 line 61 from_addr 0x0 page : 0xffff88207e8b5000 [ 1486.401399 ] CPU5 pid : 32 caller : __list_add pte is none index 0x38 line 65 from_addr 0x0 page : 0xffff88207e8b5000 [ 1486.526203 ] CPU5 pid : 32 caller : __list_add pte is none index 0x38 line 69 from_addr 0x0 page : 0xffff88207e8b5000 [ 1486.651010 ] CPU5 pid : 32 caller : __list_add pte is none index 0x38 line 73 from_addr 0x0 page : 0xffff88207e8b5000 [ 1486.775814 ] pte : ffff88207e8b51c0 pfn : 0x8207e8c3 flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 1486.912060 ] CPU5 pid : 32 caller : __list_add line : 77 from_addr : 0x0 pte . cont : 0xffff88207e8c31c0 16 th run, damn, after patching __unhash_process() , it finally works. Going to workout, see you tonight.","title":"Fix bug from __unhash_procees()"},{"location":"lego/log/log-03-2018/#victim-report-error","text":"17 th run. The phoenix program has bug itself, it is not able to run with 4GB dataset. So try it with 2GB dataset. Uuh, the log is too long. __put_vicim report a victim that has wrong flags. Going to disable the evict log and try again. 18 th run. Happen to run seq with 100MB\u2026 It actually half finished. But the printf of phoenix has funny chars. I guess memory is corrupted. The log shows it is ib_mad_completion. [ 2244.018806 ] Processor : Processor manager is running . [ 2246.394568 ] STDOUT : --- [ envp [ 0 ] HOME =/ ] --- [ 2246.447719 ] STDOUT : --- [ envp [ 1 ] TERM = linux ] --- [ 2246.507003 ] STDOUT : --- [ argv [ 0 ] / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count - seq ] --- [ 2246.618289 ] STDOUT : --- [ argv [ 1 ] / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count_datafiles / word_100MB . txt ] --- [ 2258.805633 ] STDOUT : --- [ Word - Count - Seq : Computation Completed 12.46633 sec ] --- [ 2258.923180 ] SYSC_close () : [ 4 ] -> [ / proc / meminfo ] [ 2258.995743 ] STDOUT : --- [ Use len is 123748 [ 2263.484774 ] STDOUT : --- [ THE : 1115050 ] --- [ 2263.666785 ] STDOUT : --- [ OF : 615296 ] --- [ 2266.103660 ] STDOUT : --- [ AND : 545303 ( a lot funny chars , deleted .) ] --- [ 2267.016837 ] Code : [ 2267.038680 ] STDOUT : --- [ TO : 475179 +> \u00d5\u00fe\u00da\u00e9\u00d8 ^ G \u00a7 < 87 > k < 80 > z ^ T < 86 > ruJ \u00b7\u00bf\u00bb < 9 e > \u00e9\u00de\u00ed\u00d1 r\u00dc\u00d5 ^ W\u00e5 ^ W *^ _ {( \u00ca ? R\u00f9a\u00e9\u00f6 \u00f7 8 \u00ed < 91 > \u00dc\u00e8 < 8f > \u00f2\u00bf i ^? \u00e8 4 < 94 > \u00d7\u00b2\u00c9\u00b5 ^ V \u00bf\u00ab\u00eb P ] \u00ed\u00ef h ^ G\u00ca\u00eb < 98 >^ T \u00d7 Qp\u00b9O \u00ae\u00ef ^ \\\u00da ^?^ A\u00ed < 91 > \u00d9 v\u00ddBy ^ _\u00e9iwP ^ r < 97 > \u00eb\u00f9\u00ef\u00df ] \u00a3\u00df\u00ad < 98 >< 81 > \u00f8 < 85 > \u00ce Ey ^ Y\u00e5 ^? V\u00f9\u00ba ^ Y\u00de\u00f5\u00cb ] r5\u00c9\u00f0 ^^ ' < 92 > \u00c9 ] ^ ] P ^ \u00c7 i \u00bb z : \u00d4 ^ S \u00ae e < 8 a >+ \\\u00e9 < 8 a > \u00ae\u00b1\u00e0 E\u00d5\u00ce , \u00f0\u00d2\u00e2 3 \u00c1 _ ^ P_ ^ H ^ [ | \u00b8\u00ae\u00e1 s\u00edF \u00bf m < 95 >< 9 d >?< 82 > \u00f2 : \u00be\u00de\u00f5 3 \u00ca\u00d7 T\u00fc \u00ae ] --- [ 2263.339165 ] BUG : unable to handle kernel paging request at ffffffffffff8100 [ 2263.422369 ] IP : [ < ffffffffffff8100 > ] 0xffffffffffff8100 [ 2263.570058 ] PGD 1140067 PUD 1142067 PMD 0 [ 2263.618942 ] Oops : 0010 [ # 1 ] SMP PROCESSOR [ 2264.705811 ] CPU : 0 PID : 27 Comm : ib_mad_completi 4.0.0 - lego - ys + # 408 [ 2264.781736 ] RIP : 0010 : [ < ffffffffffff8100 > ] [ < ffffffffffff8100 > ] 0xffffffffffff8100 [ 2264.873262 ] RSP : 0000 : ffff88107efabc90 EFLAGS : 00010046 [ 2264.936705 ] RAX : 5636000000000098 RBX : db5affffffffffff RCX : 0000000000000001 [ 2265.021990 ] RDX : ffff88107efabd38 RSI : 0000000000000000 RDI : 4460f fffffff8114 [ 2265.107277 ] RBP : ffff88107efabce0 R08 : 000000000000001f R09 : ffff88107efa43c0 [ 2265.192561 ] R10 : ffff88107efabe68 R11 : 0000000000000001 R12 : ac02000004ecbdbd [ 2265.277847 ] R13 : 0000000000000000 R14 : ffff88107efa4228 R15 : ffff88107e1ab000 [ 2265.363133 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc00000 ( 0000 ) knlGS : 0000000000000000 [ 2265.459858 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 2265.528503 ] CR2 : ffffffffffff8100 CR3 : 000000000113 d000 CR4 : 00000000000406 b0 [ 2265.613789 ] Stack : [ 2265.637710 ] ffffffff810151a7 00000000000000 82 ffff88107fc04980 0000000000000000 [ 2265.725075 ] ffff88107efabcc8 ffff88107fc04980 0000000000000000 0000000000000000 [ 2265.812441 ] ffff88107efa4228 ffff88107e1ab000 ffff88107efabcf8 ffffffff81016e17 [ 2265.899806 ] 000000007 efabe20 ffff88107efabd20 ffffffff810066f4 ffffffff81072f20 [ 2265.987172 ] ffff88107fc05e00 ffff88107efa4000 ffff88107efabe08 ffffffff8100e4aa [ 2266.074538 ] Call Trace : [ 2266.206626 ] < TSK > [ 2266.229507 ] [ < ffffffff810151a7 > ] ? update_wall_time + 0x47 / 0x6b0 [ 2266.299192 ] [ < ffffffff81016e17 > ] tick_handle_periodic + 0x67 / 0x70 [ 2266.369916 ] [ < ffffffff810066f4 > ] apic_timer_interrupt + 0x54 / 0x90 [ 2266.440641 ] [ < ffffffff8100e4aa > ] smp__apic_timer_interrupt + 0x6a / 0x70 [ 2266.516565 ] [ < ffffffff810663b8 > ] ? __schedule + 0xf8 / 0x1e0 [ 2266.580010 ] [ < ffffffff810664b3 > ] schedule + 0x13 / 0x30 [ 2266.638254 ] [ < ffffffff81058c97 > ] ib_mad_completion_handler + 0x2b7 / 0x860 [ 2266.716258 ] [ < ffffffff810589e0 > ] ? ib_mad_send_done_handler . isra .22 + 0x1d0 / 0x1d0 [ 2266.803624 ] [ < ffffffff81020376 > ] kthread + 0xf6 / 0x110 [ 2266.861867 ] [ < ffffffff81020280 > ] ? __kthread_parkme + 0x70 / 0x70 [ 2266.930512 ] [ < ffffffff8100e732 > ] ret_from_fork + 0x22 / 0x30 [ 2266.993955 ] < EOT > 19 th , try seq+100MB again. Well succeed. I guess I start S too later. So that thread has issues. We run 12.3 sec, while linux run 9.7 sec. 20 th , try seq+4GB data. Linux runs 314.4 sec . Lego runs 403 sec . But Lego has some clflush error messages. I don\u2019t know why actually. [ 794.604628 ] Processor : Processor manager is running . [ 796.884884 ] STDOUT : --- [ envp [ 0 ] HOME =/ ] --- [ 796.938032 ] STDOUT : --- [ envp [ 1 ] TERM = linux ] --- [ 796.997312 ] STDOUT : --- [ argv [ 0 ] / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count - seq ] --- [ 797.108596 ] STDOUT : --- [ argv [ 1 ] / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count_datafiles / word_4GB . txt ] --- [ 980.640200 ] __clflush_one () : EFAULT : bad address [ 980.692315 ] __clflush_one () : EFAULT : bad address [ 980.746397 ] __clflush_one () : EFAULT : bad address [ 980.800478 ] __clflush_one () : EFAULT : bad address [ 980.854559 ] __clflush_one () : EFAULT : bad address [ 980.908642 ] __clflush_one () : EFAULT : bad address [ 980.962723 ] __clflush_one () : EFAULT : bad address [ 981.016804 ] __clflush_one () : EFAULT : bad address [ 981.070886 ] __clflush_one () : EFAULT : bad address [ 981.124968 ] __clflush_one () : EFAULT : bad address [ 981.179048 ] __clflush_one () : EFAULT : bad address [ 981.233129 ] __clflush_one () : EFAULT : bad address [ 981.287211 ] __clflush_one () : EFAULT : bad address [ 981.341293 ] __clflush_one () : EFAULT : bad address [ 981.395375 ] __clflush_one () : EFAULT : bad address [ 981.449456 ] __clflush_one () : EFAULT : bad address [ 981.503538 ] __clflush_one () : EFAULT : bad address [ 981.557619 ] __clflush_one () : EFAULT : bad address [ 981.611702 ] __clflush_one () : EFAULT : bad address [ 981.665782 ] __clflush_one () : EFAULT : bad address [ 981.719863 ] __clflush_one () : EFAULT : bad address [ 981.773945 ] __clflush_one () : EFAULT : bad address [ 981.828026 ] __clflush_one () : EFAULT : bad address [ 981.882108 ] __clflush_one () : EFAULT : bad address [ 981.936188 ] __clflush_one () : EFAULT : bad address [ 981.990271 ] __clflush_one () : EFAULT : bad address [ 982.044352 ] __clflush_one () : EFAULT : bad address [ 982.098434 ] __clflush_one () : EFAULT : bad address [ 982.152515 ] __clflush_one () : EFAULT : bad address [ 982.206596 ] __clflush_one () : EFAULT : bad address [ 1200.759741 ] STDOUT : --- [ Word - Count - Seq : Computation Completed 403.519401 sec ] --- ... [ 1200.989480 ] STDOUT : --- [ THE : 44602000 ... [ 1201.755779 ] do_group_exit () pid : 32 , tgid : 32 exit_code : 0x0 [ 1201.819136 ] do_exit () pid : 32 , tgid : 32 code : 0x0 [ 1201.872451 ] nr_pgfault : 1049525 [ 1201.908579 ] nr_pgfault_wp : 0 [ 1201.942899 ] nr_pgfault_wp_cow : 0 [ 1201.981380 ] nr_pgfault_wp_reuse : 0 [ 1202.021941 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 1202.081223 ] nr_pcache_fill_from_memory : 1045393 [ 1202.135304 ] nr_pcache_fill_from_victim : 4132 [ 1202.186265 ] nr_pcache_eviction : 525230 [ 1202.230987 ] nr_victim_eviction : 521090 21th run. Do not have time and energy to debug the clflush issue. I just want to run MT+2GB again. Well victim has issues! Some warning are triggered. Log is wuklab13:~/ys/0311-22 . Continue tomorrow! Good night world. (Such a lonly phd.)","title":"victim report error"},{"location":"lego/log/log-03-2018/#0310-sat","text":"Running python hello world. Tried to make kmalloc use buddy directly.","title":"03/10 Sat"},{"location":"lego/log/log-03-2018/#put_pcache-in-pcache_zap_pte","text":"So this time, python keep running for a long time. But P crashed when the first time eviction was triggered. Below is log from S side, those libraries do not exist, so these log are fine: S: [Mar10 10:39] handle_access_request /etc/ld.so.preload 4, -2 [Mar10 10:44] local_file_open : Cannot open required file [/usr/lib64/python2.7/site.so]. [ +0.352839] local_file_open : Cannot open required file [/usr/lib64/python2.7/sitemodule.so]. [ +22.254465] local_file_open : Cannot open required file [/usr/lib64/python2.7/os.so]. [ +0.350759] local_file_open : Cannot open required file [/usr/lib64/python2.7/osmodule.so]. [Mar10 10:45] local_file_open : Cannot open required file [/usr/lib64/python2.7/posixpath.so]. [ +0.358045] local_file_open : Cannot open required file [/usr/lib64/python2.7/posixpathmodule.so]. [ +13.421033] local_file_open : Cannot open required file [/usr/lib64/python2.7/stat.so]. [ +0.352838] local_file_open : Cannot open required file [/usr/lib64/python2.7/statmodule.so]. [Mar10 10:46] local_file_open : Cannot open required file [/usr/lib64/python2.7/genericpath.so]. [ +0.360126] local_file_open : Cannot open required file [/usr/lib64/python2.7/genericpathmodule.so]. [ +11.582165] local_file_open : Cannot open required file [/usr/lib64/python2.7/warnings.so]. [ +0.357003] local_file_open : Cannot open required file [/usr/lib64/python2.7/warningsmodule.so]. [ +11.989828] local_file_open : Cannot open required file [/usr/lib64/python2.7/linecache.so]. [ +0.358043] local_file_open : Cannot open required file [/usr/lib64/python2.7/linecachemodule.so]. [Mar10 10:47] local_file_open : Cannot open required file [/usr/lib64/python2.7/types.so]. [ +0.353879] local_file_open : Cannot open required file [/usr/lib64/python2.7/typesmodule.so]. Weird P\u2019s bug, seems like the pcm returned by evict_find_line has issue. Well, I\u2019m trying to debug what is going with this set. wuklab13 0310 -2 [ 1046.880649 ] SYSC_read () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff6e117e0 [ 1046.959692 ] fd : 8 , buf : 00007f fff7ffb000 , count : 4096 [ 1048.726624 ] pcache_evict_line () : pset : ffff88207f9ffec0 , for uva : 0x7ffff7ffb000 [ 1048.813053 ] ------------ [ cut here ] ------------ [ 1048.868174 ] BUG : failure at . / include / processor / pcache . h : 284 / pcache_meta_to_pcache_set () ! [ 1048.965937 ] Kernel Panic - not syncing : BUG ! [ 1049.016898 ] CPU : 5 PID : 32 Comm : python 4.0.0 - lego - ys + # 347 [ 1049.083460 ] Stack : [ 1049.107380 ] ffff88107e18fca8 ffffffff81026f1c 000000000000000 8 ffff88107e18fcb8 [ 1049.194743 ] ffff88107e18fc70 0000000021475542 0000000000000000 0000000000000000 [ 1049.282107 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 1049.369468 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 1049.456832 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 1049.544193 ] Call Trace : [ 1049.573315 ] < TSK > [ 1049.596195 ] [ < ffffffff81026f28 > ] panic + 0xc2 / 0xeb [ 1049.651318 ] [ < ffffffff8101c3fc > ] ? task_tick_rt + 0x2c / 0xd0 [ 1049.715799 ] [ < ffffffff81019a65 > ] ? scheduler_tick + 0x55 / 0x60 [ 1049.782360 ] [ < ffffffff81017035 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 1049.855163 ] [ < ffffffff81006764 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 1049.927966 ] [ < ffffffff8101c3fc > ] ? task_tick_rt + 0x2c / 0xd0 [ 1049.992447 ] [ < ffffffff81019a65 > ] ? scheduler_tick + 0x55 / 0x60 [ 1050.059009 ] [ < ffffffff81017035 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 1050.131812 ] [ < ffffffff8103c41a > ] ? put_dec + 0x1a / 0x80 [ 1050.191093 ] [ < ffffffff81006764 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 1050.263895 ] [ < ffffffff8100e56a > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 1050.341897 ] [ < ffffffff81012ded > ] ? printk + 0x11d / 0x1b0 [ 1050.402219 ] [ < ffffffff810340c5 > ] dump_pcache_meta + 0xc5 / 0xd0 [ 1050.468782 ] [ < ffffffff81034588 > ] pcache_evict_line + 0x158 / 0x220 [ 1050.538463 ] [ < ffffffff81030f5e > ] pcache_alloc + 0x22e / 0x2f0 [ 1050.602945 ] [ < ffffffff8103015a > ] common_do_fill_page + 0x2a / 0x430 [ 1050.673668 ] [ < ffffffff8102fb20 > ] ? pcache_meta_to_kva + 0x30 / 0x30 [ 1050.744389 ] [ < ffffffff81030702 > ] pcache_handle_fault + 0x1a2 / 0x6c0 [ 1050.816152 ] [ < ffffffff810103d2 > ] do_page_fault + 0xa2 / 0x1a0 [ 1050.880634 ] [ < ffffffff8100db9f > ] page_fault + 0x1f / 0x30 [ 1050.940955 ] [ < ffffffff8103bb82 > ] ? copy_user_enhanced_fast_string + 0x2 / 0x10 [ 1051.023118 ] [ < ffffffff81038423 > ] ? normal_p2m_read + 0x233 / 0x330 [ 1051.092800 ] [ < ffffffff810363ce > ] sys_read + 0x9e / 0x160 [ 1051.152081 ] [ < ffffffff810268d0 > ] ? strace_enter_default + 0x30 / 0x40 [ 1051.224884 ] [ < ffffffff8100e935 > ] do_syscall_64 + 0x45 / 0xd0 [ 1051.288326 ] [ < ffffffff8100d82c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 Interesting, added several debug messages. The bug is I forgot to put_pcache when a rmap was zapped. One rmap counts one refcount (effectively one process), thus when a rmap was zapped, we should decrease the refcount. I found I\u2019ve already done so for pcache_remove_rmap , and pcache_move_pte . But damn, forgot this one. I remember this code was written before fork+pcache. So.. I don\u2019t have a big picture at that time. Multithreaded system plus background reclaim really a very rigours design usage of refcount and lock . [ 1418.038411] CPU5 PID32 sys_read+0x0/0xa0 [ 1418.085227] pcache_evict_line(): pset: ffff88207f9ffec0, for uva: 0x7ffff7ffb000 [ 1418.173617] pset:ffff88207f9ffec0 set_idx: 32763 nr_lru:8 [ 1418.238105] pcache:ffff8801801ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880107ffb000 [ 1418.351476] pcache:ffff8801805ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880117ffb000 [ 1418.464847] pcache:ffff8801809ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880127ffb000 [ 1418.578220] pcache:ffff880180dffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880137ffb000 [ 1418.691591] pcache:ffff8801811ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880147ffb000 [ 1418.804963] pcache:ffff8801815ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880157ffb000 [ 1418.918334] pcache:ffff8801819ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880167ffb000 [ 1419.031706] pcache:ffff880181dffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880177ffb000 [ 1419.145077] After dump pset [ 1419.176280] pcache:ffff8801801ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880107ffb000 [ 1419.289652] pcache dumped because: evict_find_line_lru [ 1419.351018] pcache:ffff8801805ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880117ffb000 [ 1419.464389] pcache dumped because: evict_find_line_lru [ 1419.525757] pcache:ffff8801809ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880127ffb000 [ 1419.639127] pcache dumped because: evict_find_line_lru [ 1419.700494] pcache:ffff880180dffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880137ffb000 [ 1419.813865] pcache dumped because: evict_find_line_lru [ 1419.875231] pcache:ffff8801811ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880147ffb000 [ 1419.988604] pcache dumped because: evict_find_line_lru [ 1420.049969] pcache:ffff8801815ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880157ffb000 [ 1420.163341] pcache dumped because: evict_find_line_lru [ 1420.224708] pcache:ffff8801819ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880167ffb000 [ 1420.338079] pcache dumped because: evict_find_line_lru [ 1420.399445] pcache:ffff880181dffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880177ffb000 [ 1420.512817] pcache dumped because: evict_find_line_lru [ 1420.574183] evict_find_line_lru(): pcm: ffff88207f9ffea8 [ 1420.637631] ------------[ cut here ]------------ [ 1420.692756] BUG: failure at ./include/processor/pcache.h:340/pcache_meta_to_kva()! [ 1420.783245] Kernel Panic - not syncing: BUG! [ 1420.834210] CPU: 5 PID: 32 Comm: python 4.0.0-lego-ys+ #349 [ 1420.900777] Stack:","title":"put_pcache in pcache_zap_pte"},{"location":"lego/log/log-03-2018/#python-hello-world-run-to-end","text":"Glad to say, python hello world finished, even with some missed syscalls. Especially the stdin stuff, so the string is actually not printed out. Log is wuklab13:~/ys/0310-4 [ 3149.540308 ] CPU5 PID32 sys_ioctl + 0x0 / 0x10 [ 3149.588144 ] CPU5 PID32 sys_ioctl + 0x0 / 0x10 [ 3149.635982 ] CPU5 PID32 sys_write + 0x0 / 0xa0 [ 3149.683818 ] STDOUT : --- [ >>> ] --- [ 3149.726456 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff6d9aeb0 flags : 0x150 [ 3149.926247 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff6d9aeb0 flags : 0x150 ret : 0 ( OKAY ) [ 3150.033464 ] CPU5 PID32 sys_newfstat + 0x0 / 0x10 [ 3150.084420 ] CPU5 PID32 sys_ioctl + 0x0 / 0x10 [ 3150.132256 ] strace__mmap cpu5 addr = 0x0 , len = 0x1000 , prot ( 0x3 ) = PROT_READ | PROT_WRITE , flags ( 0x22 ) = MAP_PRIVATE | MAP_ANONYMOUS , fd = 18446744073709551615 ( ), off = 0x0 [ 3150.301772 ] CPU5 PID32 sys_read + 0x0 / 0xa0 [ 3150.348562 ] ------------ [ cut here ] ------------ [ 3150.403679 ] WARNING : CPU : 5 PID : 32 at managers / processor / fs / stdio . c : 24 stdio_file_read + 0x30 / 0x50 [ 3150.509751 ] Process wants STDIN ! [ 3150.546149 ] CPU : 5 PID : 32 Comm : python 4.0.0 - lego - ys + # 352 [ 3150.612705 ] Stack : [ 3150.636624 ] ffff88107e18fe90 ffffffff81012b15 ffffffff811464e0 00007f fff7ffb000 [ 3150.723977 ] 0000000000000400 00007f fff70e5640 ffff88107e18fef0 ffffffff81012bd2 [ 3150.811331 ] ffffffff81079d6b ffff881000000018 ffff88107e18ff00 ffff88107e18fec0 [ 3150.898687 ] 0000000000000020 ffffffff810346b0 0000000000000022 ffffffff811464f0 [ 3150.986040 ] 00007f fff7fdf740 0000000000000000 ffff88107e18ff00 ffffffff81035ac0 [ 3151.073394 ] Call Trace : [ 3151.102514 ] < TSK > [ 3151.125392 ] [ < ffffffff81012b21 > ] __warn . constprop .0 + 0x91 / 0xd0 [ 3151.194028 ] [ < ffffffff81012bd2 > ] warn_slowpath_fmt + 0x42 / 0x50 [ 3151.261623 ] [ < ffffffff810346b0 > ] ? sweep_pset_lru + 0x220 / 0x220 [ 3151.330259 ] [ < ffffffff81035ac0 > ] stdio_file_read + 0x30 / 0x50 [ 3151.395775 ] [ < ffffffff810346e3 > ] sys_read + 0x33 / 0xa0 [ 3151.454010 ] [ < ffffffff8100e875 > ] do_syscall_64 + 0x45 / 0xd0 [ 3151.517446 ] [ < ffffffff8100d76c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 3151.593362 ] < EOT > [ 3151.616240 ] --- [ end trace 0000000000000000 ] --- [ 3151.671360 ] CPU5 PID32 sys_write + 0x0 / 0xa0 [ 3151.719194 ] STDOUT : --- [ ] --- [ 3151.759756 ] CPU5 PID32 sys_close + 0x0 / 0x140 [ 3151.808628 ] SYSC_close () : [ 3 ] -> [ / root / ys / py_hello . py ] [ 3151.871028 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a79380 flags : 0x150 [ 3152.070817 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a79380 flags : 0x150 ret : 0 ( OKAY ) [ 3152.178033 ] CPU5 PID32 sys_rt_sigaction + 0x0 / 0xb0 [ 3152.234151 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a77f60 flags : 0x150 [ 3152.432941 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a77f60 flags : 0x150 ret : 0 ( OKAY ) [ 3152.540242 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff73ee794 flags : 0x150 [ 3152.739952 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff73ee794 flags : 0x150 ret : 0 ( OKAY ) [ 3152.847171 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff715b278 flags : 0x150 [ 3153.046958 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff715b278 flags : 0x150 ret : 0 ( OKAY ) [ 3153.154179 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff6de74f0 flags : 0x150 [ 3153.353965 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff6de74f0 flags : 0x150 ret : 0 ( OKAY ) [ 3153.461180 ] CPU5 PID32 sys_exit_group + 0x0 / 0x10","title":"python hello world run to end"},{"location":"lego/log/log-03-2018/#trying-phoenix-pthread-again","text":"4GB pcache, 1GB dataset. 1 th run with CONFIG_STRACE on, 1GB dataset finished, result is correct. 2 th run without CONFIG_STRACE, 1GB dataset stuck. Two weird things: open/close dev/cpu/online file too many times than a normal linux run IB stucked So next I\u2019m going to try add a lock to ibapi, see if it is ib internal deadlock issue. wuklab13 0310 -7 [ 702.895936 ] Processor : Processor manager is running . [ 722.400159 ] STDOUT : --- [ envp [ 0 ] HOME =/ ] --- [ 722.453307 ] STDOUT : --- [ envp [ 1 ] TERM = linux ] --- [ 722.512589 ] STDOUT : --- [ argv [ 0 ] / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count - pthread ] --- [ 722.628036 ] STDOUT : --- [ argv [ 1 ] / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count_datafiles / word_1GB . txt ] --- [ 722.759101 ] STDOUT : --- [ Wordcount : Running ... ] --- [ 722.819406 ] STDOUT : --- [ ] --- [ 722.860139 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 722.940653 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.011483 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.084287 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.157090 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.229894 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.302698 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.375502 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.448306 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.521111 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.593914 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.666718 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.739522 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.812326 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 723.885130 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 766.701260 ] ibapi_send_reply () polling timeout ( 30010 ms ), caller : net_send_reply_timeout + 0x11b / 0x1ee [ 766.809538 ] net_send_reply_timeout () caller : __pcache_do_fill_page + 0x82 / 0x140 [ 766.895863 ] word_count - pthr [ 65 ] : segfault at 0x7fffb5eba000 ip 00000000004024 9 d sp 00007f ffb5e9ad80 error 6 [ 767.012348 ] CPU : 15 PID : 65 Comm : word_count - pthr 4.0.0 - lego - ys + # 359 [ 767.089312 ] RIP : 0033 : [ < 00000000004024 9 d > ] [ < 00000000004024 9 d > ] 0x40249d [ 767.170436 ] RSP : 002 b : 00007f ffb5e9ad80 EFLAGS : 00010216 [ 767.233879 ] RAX : 00007f ffb5eba000 RBX : 00000000000013 88 RCX : 000000000000004f [ 767.319164 ] RDX : 00007f ffe4ea92a4 RSI : 00007f ffe626fac9 RDI : 00007f ffe4ea92a4 [ 767.404449 ] RBP : 00000000007540e0 R08 : 0000000000000000 R09 : 0000000000014f a0 [ 767.489733 ] R10 : 0000000000427f b0 R11 : 0000000000000202 R12 : 0000000000012 b12 [ 767.575018 ] R13 : 00007f ff496ab890 R14 : 00007f ff48704fb0 R15 : 00000000000013 88 [ 767.660303 ] FS : 00007f ffb5e9b700 ( 0000 ) GS : ffff88207fce0000 ( 0000 ) knlGS : 0000000000000000 [ 767.757028 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 767.825671 ] CR2 : 00007f ffb5eba000 CR3 : 000000207f e3a000 CR4 : 00000000000406 a0 [ 767.910958 ] get_signal () : dequeue_signr : 11 , handler : ( null ) [ 767.987928 ] get_signal () : dequeue_signr : 9 , handler : ( null ) 3 th run, without STRACE, with locked ibapi, it finished, result is correct. Runtime: 18.692936 sec . [ 555.423623 ] nr_pgfault : 288100 [ 555.458042 ] nr_pgfault_wp : 0 [ 555.492360 ] nr_pgfault_wp_cow : 0 [ 555.530838 ] nr_pgfault_wp_reuse : 0 [ 555.571396 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 555.630673 ] nr_pcache_fill_from_memory : 288081 [ 555.683710 ] nr_pcache_fill_from_victim : 12 [ 555.732588 ] nr_pcache_eviction : 494 [ 555.774187 ] nr_victim_eviction : 474 4 th run, same setting with the 3 th run, same result. But the nr_pgfault differs, I guess it is due to runtime things. Runtime: 19.12861 sec . [ 469.891700 ] nr_pgfault : 288119 [ 469.926123 ] nr_pgfault_wp : 0 [ 469.960444 ] nr_pgfault_wp_cow : 0 [ 469.998924 ] nr_pgfault_wp_reuse : 0 [ 470.039484 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 470.098764 ] nr_pcache_fill_from_memory : 288093 [ 470.151805 ] nr_pcache_fill_from_victim : 12 [ 470.200684 ] nr_pcache_eviction : 513 [ 470.242285 ] nr_victim_eviction : 493 5 th run, same with 4 th , succeed, Runtime: 18.653879 sec . [ 313.202348] nr_pgfault: 288070 [ 313.236772] nr_pgfault_wp: 0 [ 313.271093] nr_pgfault_wp_cow: 0 [ 313.309575] nr_pgfault_wp_reuse: 0 [ 313.350139] nr_pgfault_due_to_concurrent_eviction: 0 [ 313.409421] nr_pcache_fill_from_memory: 288052 [ 313.462465] nr_pcache_fill_from_victim: 6 [ 313.510307] nr_pcache_eviction: 446 [ 313.551909] nr_victim_eviction: 432 6 th , setting is the same, but with 4GB dataset, crashed: [ 512.028141 ] Processor : Processor manager is running . [ 529.375605 ] STDOUT : --- [ Wordcount : Running ... ] --- [ 529.435906 ] STDOUT : --- [ ] --- [ 529.476660 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 529.555983 ] ------------ [ cut here ] ------------ [ 529.609128 ] BUG : failure at managers / processor / pcache / rmap . c : 735 / pcache_zap_pte () ! [ 529.699613 ] Kernel Panic - not syncing : BUG ! [ 529.750576 ] CPU : 5 PID : 32 Comm : word_count - pthr 4.0.0 - lego - ys + # 361 [ 529.826500 ] Stack : [ 529.850422 ] ffff88107e1a3dd8 ffffffff810259b4 000000000000000 8 ffff88107e1a3de8 [ 529.937787 ] ffff88107e1a3da0 0000000021475542 0000000000000000 0000000000000000 [ 530.025152 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 530.112517 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 530.199882 ] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 530.287247 ] Call Trace : [ 530.316370 ] < TSK > [ 530.339251 ] [ < ffffffff810259c0 > ] panic + 0xc2 / 0xeb [ 530.394374 ] [ < ffffffff8106190a > ] ? client_internal_poll_sendcq + 0x2a / 0x80 [ 530.474458 ] [ < ffffffff8101bfcc > ] ? task_tick_rt + 0x2c / 0xd0 [ 530.538943 ] [ < ffffffff81019725 > ] ? scheduler_tick + 0x55 / 0x60 [ 530.605506 ] [ < ffffffff81016df5 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 530.678311 ] [ < ffffffff8103768a > ] ? put_dec + 0x1a / 0x80 [ 530.737595 ] [ < ffffffff810066f4 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 530.810398 ] [ < ffffffff8100e4aa > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 530.888403 ] [ < ffffffff81012ccd > ] ? printk + 0x11d / 0x1b0 [ 530.948726 ] [ < ffffffff81030429 > ] pcache_zap_pte + 0xf9 / 0x160 [ 531.014250 ] [ < ffffffff8102f090 > ] ? __pcache_move_pte_fastpath + 0x50 / 0x50 [ 531.093295 ] [ < ffffffff8102c8dc > ] unmap_page_range + 0x32c / 0x3b0 [ 531.161940 ] [ < ffffffff8102c97e > ] release_pgtable + 0x1e / 0x40 [ 531.227463 ] [ < ffffffff8102bfb3 > ] sys_munmap + 0xc3 / 0x120 [ 531.288827 ] [ < ffffffff8100e86d > ] do_syscall_64 + 0x3d / 0xc0 [ 531.352270 ] [ < ffffffff8100d76c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 7 th run, add debug info, does not seem that useful: ] --- [ 15755.579501 ] SYSC_close () : [ 4 ] -> [ / sys / devices / system / cpu / online ] [ 15755.672760 ] pte : ffff88107e1a3dd8 pfn : 0x8207e80b flags :( dirty | large | global | softw4 | pkey0 | pkey1 | pkey2 | pkey3 | nx | 0x3ff800000000000 ) [ 15755.807015 ] pte dumped because : Invalid pte [ 15755.856932 ] address : 0x7ffefc638000 [ 15755.899569 ] ------------ [ cut here ] ------------ [ 15755.954684 ] BUG : failure at managers / processor / pcache / rmap . c : 747 / pcache_zap_pte () ! [ 15756.045159 ] Kernel Panic - not syncing : BUG ! [ 15756.096114 ] CPU : 5 PID : 32 Comm : word_count - pt Tried several times, even with mmap/munmap debug option on, it crashed at the same point. Key is address 0x7ffefc638000 , and the mmap() related to it. Close to find the bug. Latest log in 0310-18.","title":"Trying phoenix pthread again"},{"location":"lego/log/log-03-2018/#0309-fri","text":"","title":"03/09 Fri"},{"location":"lego/log/log-03-2018/#find-bug-in-kmalloc","text":"Tried to print pud in every syscall and catch the criminal: wuklab13 030 9-1 [ 320.088684 ] CPU5 PID32 sys_close + 0x0 / 0x1f0 [ 320.137567 ] do_syscall_64 () : enter pgd ffff88207fccf000 , pgd . cont_va ffff88207fc6f000 , pud_index = 0x0 pud : ffff88207fc6f000 [ 320.269657 ] SYSC_close () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff7df3c37 [ 320.349742 ] 3 [ 320.372624 ] SYSC_close () : [ 3 ] -> [ / lib64 / libpython2 .7 . so .1.0 ] [ 320.441268 ] SYSC_close () cpu ( 5 ) tsk ( 32 / 32 / python ) ret : 0x0 ( 0 ) [ 320.510954 ] do_syscall_64 () : leave pgd ffff88207fccf000 , pgd . cont_va ffff88207fc6f000 , pud_index = 0x0 pud : ffff88207fc6f000 [ 320.643043 ] addr : 0x7ffff7a101f0 , pgd : ffff88207fccf7f8 [ 320.709607 ] addr : 0x7ffff7a101f0 , pgd : ffff88207fccf7f8 pud ffff88207fcaeff8 [ 320.798014 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a101f0 flags : 0x50 [ 320.995755 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a101f0 flags : 0x50 ret : 0 ( OKAY ) [ 321.101944 ] addr : 0x7ffff7a21749 , pgd : ffff88207fccf7f8 [ 321.168509 ] addr : 0x7ffff7a21749 , pgd : ffff88207fccf7f8 pud ffff88207fcaeff8 [ 321.256914 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a21749 flags : 0x50 [ 321.454651 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a21749 flags : 0x50 ret : 0 ( OKAY ) [ 321.560845 ] addr : 0x7ffff7ff2fda , pgd : ffff88207fccf7f8 [ 321.627409 ] addr : 0x7ffff7ff2fda , pgd : ffff88207fccf7f8 pud ffff88207fcaeff8 [ 321.715815 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7ff2fda flags : 0x50 [ 321.913553 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7ff2fda flags : 0x50 ret : 0 ( OKAY ) [ 322.019745 ] CPU5 PID32 sys_open + 0x0 / 0x10 [ 322.066548 ] do_syscall_64 () : enter pgd ffff88207fccf000 , pgd . cont_va ffff9001801ff000 , pud_index = 0x0 pud : ffff9001801ff000 [ 322.198638 ] SYSC_open () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff7df3b27 [ 322.277683 ] f_name : / lib64 / libpthread . so .0 , flags : 80000 , mode : e150 [ 322.357780 ] SYSC_open () cpu ( 5 ) tsk ( 32 / 32 / python ) ret : 0x3 ( 3 ) [ 322.426414 ] do_syscall_64 () : leave pgd ffff88207fccf000 , pgd . cont_va ffff9001801ff000 , pud_index = 0x0 pud : ffff9001801ff000 After printing more in pcache_handle_fault, I found who corrupted pgtable: wuklab13 030 9-5 [ 661.308584 ] CPU5 PID32 sys_close + 0x0 / 0x1f0 [ 661.357466 ] do_syscall_64 () : enter pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 661.489557 ] SYSC_close () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff7df3c37 [ 661.569642 ] 3 [ 661.592525 ] SYSC_close () : [ 3 ] -> [ / lib64 / libpython2 .7 . so .1.0 ] [ 661.661170 ] SYSC_close () cpu ( 5 ) tsk ( 32 / 32 / python ) ret : 0x0 ( 0 ) [ 661.730854 ] do_syscall_64 () : leave pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 661.862944 ] pcache_handle_fault () : enter pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 662.001275 ] addr : 0x7ffff7a101f0 , pgd : ffff88207fccf7f8 [ 662.067840 ] addr : 0x7ffff7a101f0 , pgd : ffff88207fccf7f8 pud ffff88207fcafff8 [ 662.156247 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a101f0 flags : 0x50 [ 662.353985 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a101f0 flags : 0x50 ret : 0 ( OKAY ) [ 662.460176 ] pcache_handle_fault () : leave pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 662.600586 ] pcache_handle_fault () : enter pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 662.738916 ] addr : 0x7ffff7a21749 , pgd : ffff88207fccf7f8 [ 662.805481 ] addr : 0x7ffff7a21749 , pgd : ffff88207fccf7f8 pud ffff88207fcafff8 [ 662.893888 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a21749 flags : 0x50 [ 663.091636 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a21749 flags : 0x50 ret : 0 ( OKAY ) [ 663.197831 ] pcache_handle_fault () : leave pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 663.338242 ] pcache_handle_fault () : enter pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 663.476572 ] addr : 0x7ffff7ff2fda , pgd : ffff88207fccf7f8 [ 663.543135 ] addr : 0x7ffff7ff2fda , pgd : ffff88207fccf7f8 pud ffff88207fcafff8 [ 663.631543 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7ff2fda flags : 0x50 [ 663.829279 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7ff2fda flags : 0x50 ret : 0 ( OKAY ) [ 663.935472 ] pcache_handle_fault () : leave pgd ffff88207fccf000 , pgd . cont_va ffff9001801ff000 , pud_index = 0x0 pud : ffff9001801ff000 [ 664.075884 ] CPU5 PID32 sys_open + 0x0 / 0x10 [ 664.122686 ] do_syscall_64 () : enter pgd ffff88207fccf000 , pgd . cont_va ffff9001801ff000 , pud_index = 0x0 pud : ffff9001801ff000 [ 664.254776 ] SYSC_open () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff7df3b27 [ 664.333821 ] f_name : / lib64 / libpthread . so .0 , flags : 80000 , mode : e150 [ 664.413918 ] SYSC_open () cpu ( 5 ) tsk ( 32 / 32 / python ) ret : 0x3 ( 3 ) [ 664.482552 ] do_syscall_64 () : leave pgd ffff88207fccf000 , pgd . cont_va ffff9001801ff000 , pud_index = 0x0 pud : ffff9001801ff000 Then, try catching bug with address 0x7ffff7ff2fda fault. Printing still being the most effective way to debug. :-) Dig further, I found pgtable corrupted after pcache_add_rmap() , namely after alloc_pcache_rmap() : [ 5024.482570 ] pcache_add_rmap () 343 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 5024.613601 ] alloc_pcache_rmap () : size : 56 , rmap : ffff88207fccefd0 [ 5024.686396 ] pcache_add_rmap () 358 pgd ffff88207fccf000 , pgd . cont_va ffff90207fcce000 , pud_index = 0x0 pud : ffff90207fcce000 Well, rmap: ffff88207fccefd0 & ffff90207fcce000 , clearly [ 843.916517 ] pcache_add_rmap () 372 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 844.047557 ] alloc_pcache_rmap () 60 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 844.179638 ] alloc_pcache_rmap () : size : 56 , rmap : ffff88207fccefd0 [ 844.252438 ] alloc_pcache_rmap () 71 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 844.384517 ] alloc_pcache_rmap () : size : 56 , rmap : ffff88207fccefd0 [ 844.457317 ] alloc_pcache_rmap () 85 pgd ffff88207fccf000 , pgd . cont_va ffff90207fcce000 , pud_index = 0x0 pud : ffff90207fcce000 [ 844.589398 ] pcache_add_rmap () 387 pgd ffff88207fccf000 , pgd . cont_va ffff90207fcce000 , pud_index = 0x0 pud : ffff90207fcce000 46 static struct pcache_rmap * alloc_pcache_rmap ( void ) 47 { 48 struct pcache_rmap * rmap ; 49 50 pgd_t * pgd ; 51 pud_t * pud ; 52 unsigned long addr ; 53 struct mm_struct * mm = current -> mm ; 54 55 if ( pall ) { 56 addr = 0x601008 ; 57 pgd = pgd_offset ( mm , addr ); 58 pud = pud_alloc ( mm , pgd , addr ); 59 pr_info ( \"%s() %d pgd %p, pgd.cont_va %lx, pud_index=%#lx pud: %p \\n \" , 60 __func__ , __LINE__ , pgd , pgd_page_vaddr ( * pgd ), pud_index ( addr ), ( void * ) pud ); 61 } 62 63 rmap = kmalloc ( sizeof ( * rmap ), GFP_KERNEL ); 64 65 if ( pall ) { 66 addr = 0x601008 ; 67 pgd = pgd_offset ( mm , addr ); 68 pud = pud_alloc ( mm , pgd , addr ); 69 pr_info ( \"%s(): size: %zu, rmap: %p \\n \" , __func__ , sizeof ( * rmap ), rmap ); 70 pr_info ( \"%s() %d pgd %p, pgd.cont_va %lx, pud_index=%#lx pud: %p \\n \" , 71 __func__ , __LINE__ , pgd , pgd_page_vaddr ( * pgd ), pud_index ( addr ), ( void * ) pud ); 72 } 73 74 if ( rmap ) { 75 INIT_LIST_HEAD ( & rmap -> next ); 76 rmap -> flags = 0 ; 77 } 78 79 if ( pall ) { 80 addr = 0x601008 ; 81 pgd = pgd_offset ( mm , addr ); 82 pud = pud_alloc ( mm , pgd , addr ); 83 pr_info ( \"%s(): size: %zu, rmap: %p \\n \" , __func__ , sizeof ( * rmap ), rmap ); 84 pr_info ( \"%s() %d pgd %p, pgd.cont_va %lx, pud_index=%#lx pud: %p \\n \" , 85 __func__ , __LINE__ , pgd , pgd_page_vaddr ( * pgd ), pud_index ( addr ), ( void * ) pud ); 86 } 87 88 return rmap ; 89 } Narrow it down to INIT_LIST_HEAD : [ 1334.548682 ] alloc_pcache_rmap () : size : 56 , rmap : ffff88207fccefd0 [ 1334.621487 ] alloc_pcache_rmap () 71 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 1334.753576 ] alloc_pcache_rmap () 76 & rmap -> next ffff88207fcceff8 & flags ffff88207fccefd8 [ 1334.922067 ] alloc_pcache_rmap () 86 pgd ffff88207fccf000 , pgd . cont_va ffff90207fcce000 , pud_index = 0x0 pud : ffff90207fcce000 [ 1335.126962 ] alloc_pcache_rmap () 98 pgd ffff88207fccf000 , pgd . cont_va ffff90207fcce000 , pud_index = 0x0 pud : ffff90207fcce000 74 if ( rmap ) { 75 pr_info ( \"%s() %d &rmap->next %p &flags %p \\n \" , 76 __func__ , __LINE__ , & rmap -> next , & rmap -> flags ); 77 78 INIT_LIST_HEAD ( & rmap -> next ); 79 80 if ( pall ) { 81 addr = 0x601008 ; 82 pgd = pgd_offset ( mm , addr ); 83 pud = pud_alloc ( mm , pgd , addr ); 84 pr_info ( \"%s(): size: %zu, rmap: %p \\n \" , __func__ , sizeof ( * rmap ), rmap ); 85 pr_info ( \"%s() %d pgd %p, pgd.cont_va %lx, pud_index=%#lx pud: %p \\n \" , 86 __func__ , __LINE__ , pgd , pgd_page_vaddr ( * pgd ), pud_index ( addr ), ( void * ) pud ); 87 } 88 89 rmap -> flags = 0 ; 90 } Seriously, if this is running on user-level on VM, I would be able to find the bug maybe in 30min. But I spent several hours to find it out with physical machine. Damn you physical machine. Hmm, this func is used A LOT. How can it fail at this point? Possible reasons: kmalloced area happen to intersect with pgtable? one physical page is mapped twice? one to pgtable, one by this rmap. tty/serial code has bug? Really ancient code. After add a few printk, IB seems stuck. And this happens just with few more lines of code! Why? code size matters? [ 722.381469 ] pcache_handle_fault () : enter pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 722.519778 ] addr : 0x7ffff7feffcc , pgd : ffff88207fccf7f8 [ 722.586334 ] addr : 0x7ffff7feffcc , pgd : ffff88207fccf7f8 pud ffff88207fcafff8 [ 722.674727 ] Before fill address = 0x7ffff7feffcc set_idx : 0x7fef [ 722.743362 ] pcache : ffff8801801ffbc0 mapcount : 0 refcount : 1 flags :( allocated | usable ) set_idx = 0x7fef kva : ffff880107fef000 [ 722.872312 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7feffcc flags : 0x50 [ 722.967985 ] __pcache_do_fill_page () : before net pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 last line Well, the following finding finally find the bug line. And it kind of explains the above bug. Probably kmalloc\u2019ed area has issues, so IB is touching wrong data. The following bug is related to kmalloc, the rmap is 56 bytes, and it should be within 1 single page, but it is not: [ 1862.307427 ] pcache_add_rmap () 413 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 1862.438477 ] alloc_pcache_rmap () 86 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 1862.570568 ] sp -> units : 50 SLOB_UNITS : 32 [ 1862.617372 ] alloc_pcache_rmap () : size : 56 , rmap : ffff88207fccefd0 [ 1862.690178 ] alloc_pcache_rmap () 97 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 1862.822268 ] alloc_pcache_rmap () 104 & rmap -> next ffff88207fcceff8 & flags ffff88207fccefd8 [ 1862.918995 ] __INIT_LIST_HEAD () : next ffff88207fcceff8 prev ffff88207fccf000 [ 1863.002202 ] __INIT_LIST_HEAD () 63 pgd ffff88207fccf000 , pgd . cont_va ffff88207fcae000 , pud_index = 0x0 pud : ffff88207fcae000 [ 1863.133253 ] __INIT_LIST_HEAD () : next ffff88207fcceff8 prev ffff88207fccf000 [ 1863.216459 ] alloc_pcache_rmap () : size : 56 , rmap : ffff88207fccefd0 [ 1863.289265 ] alloc_pcache_rmap () 114 pgd ffff88207fccf000 , pgd . cont_va ffff90207fcce000 , pud_index = 0x0 pud : ffff90207fcce000 Analysis: The @prev field in line 7 has address ffff88207fccf000 , which happen to the pgd page ( pgd ffff88207fccf000 ). Thus when we do list->prev = list , it writes to the first 8 bytes of pgd page, corrupts the original pgd entry. That is why we see a corrupted pgd entry ( ffff90207fcce000 ). This roots from kmalloc, which should not allocate such an object that cross two pages.","title":"Find bug in kmalloc"},{"location":"lego/log/log-03-2018/#0308-thur","text":"Took several days off. This morning finished the porting of wait4 and waitid , which actually has a lot code change. The concept and mechanism is fairly simple, but the legacy UNIX tradition make the implementation quite complex. Now, look back to finish debugging the pcache issue. It must be fixed this week.","title":"03/08 Thur"},{"location":"lego/log/log-03-2018/#python","text":"Tried python hello_world.py , the program runs for a while and crashes at a deterministic point: wuklab13 and wuklab15 , ~/ ttyS1 [ 419097.929969 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a4b008 flags : 0x50 ret : 0 ( OKAY ) [ 419098.039145 ] __pcache_do_fill_page () : I pid : 32 tgid : 32 address : 0x7ffff7a4c010 flags : 0x50 [ 419098.306537 ] __pcache_do_fill_page () : O pid : 32 tgid : 32 address : 0x7ffff7a4c010 flags : 0x50 ret : 0 ( OKAY ) [ 419098.413756 ] CPU5 PID32 sys_mprotect + 0x0 / 0x90 [ 419098.465753 ] SYSC_mprotect () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff7df3d27 [ 419098.549990 ] start : 0x7ffff7d8c000 , len : 0x2000 , prot : 0x1 [ 419098.614469 ] BUG : unable to handle kernel paging request at ffff9001801ff000 [ 419098.698703 ] IP : [ < ffffffff8102f7a9 > ] pcache_handle_fault + 0x69 / 0x6c0 [ 419098.774621 ] PGD 0 [ 419098.799579 ] Oops : 0000 [ # 1 ] SMP PROCESSOR [ 419098.848457 ] CPU : 5 PID : 32 Comm : python 4.0.0 - lego - ys + # 312 [ 419098.916054 ] RIP : 0010 : [ < ffffffff8102f7a9 > ] [ < ffffffff8102f7a9 > ] pcache_handle_fault + 0x69 / 0x6c0 [ 419099.021089 ] RSP : 0000 : ffff88107e857ed8 EFLAGS : 000102 86 [ 419099.085567 ] RAX : ffff9001801ff000 RBX : ffff9001801ff000 RCX : 00003f fffffff000 [ 419099.171884 ] RDX : 00000801801f f000 RSI : 000000000060100 8 RDI : ffff88107e83d648 [ 419099.258199 ] RBP : ffff88107e857f18 R08 : 00007f fff7fe3000 R09 : 00007f fff7fe3000 [ 419099.344516 ] R10 : 0000000000000000 R11 : 0000000000000206 R12 : 000000000060100 8 [ 419099.430832 ] R13 : ffff88107e83d648 R14 : 0000000000000050 R15 : 00007f fff7ffe150 [ 419099.517149 ] FS : 00007f fff7fdf740 ( 0000 ) GS : ffff88207fc40000 ( 0000 ) knlGS : 0000000000000000 [ 419099.614905 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 419099.684582 ] CR2 : ffff9001801ff000 CR3 : 000000207f ccf000 CR4 : 00000000000406 a0 [ 419099.770899 ] Stack : [ 419099.795858 ] 00007f fff7d8c000 0000000000002000 0000000000000001 0000000000000004 [ 419099.884254 ] 000000000060100 8 ffff88107e857f58 0000000000000000 00007f fff7ffe150 [ 419099.972650 ] ffff88107e857f48 ffffffff81010082 0000000000000000 0000000000000001 [ 419100.061047 ] 0003 92 c29c720ba2 0000000000000000 00007f ffffffdc40 ffffffff8100d91f [ 419100.149442 ] 00007f fff7ffe150 0000000000000000 0003 92 c29c720ba2 0000000000000001 [ 419100.237839 ] Call Trace : [ 419100.267998 ] < TSK > [ 419100.291917 ] [ < ffffffff81010082 > ] do_page_fault + 0xa2 / 0x1a0 [ 419100.357434 ] [ < ffffffff8100d91f > ] page_fault + 0x1f / 0x30 [ 419100.418792 ] < EOT > M : ... [ 419142.163396 ] handle_p2m_pcache_miss () cpu 4 I nid : 0 pid : 32 tgid : 32 flags : 50 vaddr : 0x7ffff7a4c010 [ 419142.268460 ] handle_p2m_pcache_miss () cpu 4 O nid : 0 pid : 32 tgid : 32 flags : 50 vaddr : 0x7ffff7a4c010 ( Last Message ) Dig deeper: int pcache_handle_fault ( struct mm_struct * mm , unsigned long address , unsigned long flags ) { .. pgd = pgd_offset ( mm , address ); pr_info ( \" addr: %#lx, pgd: %p \\n \" , address , pgd ); pud = pud_alloc ( mm , pgd , address ); pr_info ( \" addr: %#lx, pgd: %p pud %p \\n \" , address , pgd , pud ); if ( ! pud ) return VM_FAULT_OOM ; pmd = pmd_alloc ( mm , pud , address ); if ( ! pmd ) .. } [ 21130.503314 ] strace__mprotect cpu5 start = 0x7ffff7d8c000 , len = 0x2000 , prot ( 0x1 ) = PROT_READ [ 21130.598994 ] SYSC_mprotect () cpu ( 5 ) tsk ( 32 / 32 / python ) user - ip : 0x7ffff7df3d27 [ 21130.682193 ] start : 0x7ffff7d8c000 , len : 0x2000 , prot : 0x1 [ 21130.745635 ] addr : 0x601008 , pgd : ffff88207fccf000 [ 21130.805954 ] addr : 0x601008 , pgd : ffff88207fccf000 pud ffff9001801ff000 [ 21130.888116 ] BUG : unable to handle kernel paging request at ffff9001801ff000 [ 21130.971314 ] IP : [ < ffffffff8102fa11 > ] pcache_handle_fault + 0x91 / 0x6f0 Print pgd and pud info, these three messages are related and the last one leads to panic: wuklab13 ~/ ys / 030 8-6 [ 479.375498 ] addr : 0x400040 , pgd : ffff88207fccf000 [ 479.435819 ] pud_alloc_one () : addr : 0x400040 , pud : ffff88207fc6f000 [ 479.511739 ] pud_alloc () : addr : 0x400040 pgd ffff88207fccf000 , pgd . cont_va ffff88207fc6f000 , pud_index = 0x0 pud : ffff88207fc6f000 [ 479.649021 ] addr : 0x400040 , pgd : ffff88207fccf000 pud ffff88207fc6f000 [ 480.016381 ] addr : 0x600dd8 , pgd : ffff88207fccf000 [ 480.076701 ] pud_alloc () : addr : 0x600dd8 pgd ffff88207fccf000 , pgd . cont_va ffff88207fc6f000 , pud_index = 0x0 pud : ffff88207fc6f000 [ 480.213982 ] addr : 0x600dd8 , pgd : ffff88207fccf000 pud ffff88207fc6f000 [ 680.072819 ] addr : 0x601008 , pgd : ffff88207fccf000 [ 680.133138 ] pud_alloc () : addr : 0x601008 pgd ffff88207fccf000 , pgd . cont_va ffff90107e834000 , pud_index = 0x0 pud : ffff90107e834000 [ 680.270422 ] addr : 0x601008 , pgd : ffff88207fccf000 pud ffff90107e834000 [ 680.352583 ] BUG : unable to handle kernel paging request at ffff90107e834000 [ 680.435783 ] IP : [ < ffffffff8102fc43 > ] pcache_handle_fault + 0xb3 / 0x770 [ 680.510664 ] PGD 0 I need to check what happens between 480s to 680s. Something in between corrupted pgtable. I doubt it can be: copy_to_user related syscalls pcache establish mapping, mempcy all other memcpy strcpy etc stuff","title":"python"},{"location":"lego/log/log-03-2018/#0302-fri","text":"TODO: -add vsyscall- -pcache_exit_process: free rmap, free cacheline, etc. When rmap is NULL, we clearly should free this pcache.- pcache_exit_thread? I don\u2019t think we need this. All pcache related activities should relate to mm, or thread group leader, not one particular thread. check python bug use omnigraffle to draw the whole workflow of pcache. Phoenix, word_count-seq, 4G dataset, 4GB pcache: [ 273.268853] Processor: Processor manager is running. [ 573.272479] page:ffffea0071bb9660 count:0 mapcount:-128 [ 573.332903] flags: 0x200000000000300(slab|slob_free) [ 573.392182] page dumped because: VM_BUG_ON_PAGE(page_ref_count(page) == 0) [ 573.474340] ------------[ cut here ]------------ [ 573.529459] BUG: failure at ./include/lego/mm.h:251/put_page_testzero()! [ 573.609537] Kernel Panic - not syncing: BUG! [ 573.660496] CPU: 4 PID: 13 Comm: kvictim_flushd 4.0.0-lego+ #18 [ 573.731212] Stack: [ 573.755132] ffff88207e4bfe10 ffffffff81023644 0000000000000008 ffff88207e4bfe20 [ 573.842490] ffff88207e4bfdd8 0000000021475542 0000000000000000 0000000000000000 [ 573.929848] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 574.017205] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 574.104563] 0000000000000000 0000000000000000 0000000000000000 0000000000000000 [ 574.191921] Call Trace: [ 574.221039] <TSK> [ 574.243919] [<ffffffff81023650>] panic+0xc2/0xeb [ 574.299038] [<ffffffff8105a35a>] ? client_internal_poll_sendcq+0x2a/0x80 [ 574.379115] [<ffffffff8105a4fd>] ? client_send_message_with_rdma_write_with_imm_request+0x14d/0x360 [ 574.487273] [<ffffffff8101ac3c>] ? task_tick_rt+0x2c/0xd0 [ 574.551751] [<ffffffff81018395>] ? scheduler_tick+0x55/0x60 [ 574.618308] [<ffffffff81015a45>] ? tick_handle_periodic+0x45/0x70 [ 574.691107] [<ffffffff810064c4>] ? apic_timer_interrupt+0x54/0x90 [ 574.763905] [<ffffffff8100dbaa>] ? smp__apic_timer_interrupt+0x6a/0x70 [ 574.841903] [<ffffffff8101198d>] ? printk+0x11d/0x1b0 [ 574.902222] [<ffffffff81025c00>] __free_pages+0x2e0/0x3c0 [ 574.966699] [<ffffffff81028472>] kfree+0x62/0x480 [ 575.022858] [<ffffffff8102e6be>] victim_flush_func+0x15e/0x1e0 [ 575.092536] [<ffffffff8102e560>] ? victim_try_fill_pcache+0x390/0x390 [ 575.169494] [<ffffffff8101e446>] kthread+0xf6/0x120 [ 575.227733] [<ffffffff8101e350>] ? __kthread_parkme+0x70/0x70 [ 575.296371] [<ffffffff8100de32>] ret_from_fork+0x22/0x30 [ 575.359810] <EOT>","title":"03/02 Fri"},{"location":"lego/log/log-03-2018/#0301-thur","text":"Weird. [43181.388400] p2m_fork(cpu5): I cur:24-word_count-seq new:25 [43181.435341] p2m_fork(cpu5): O succeed cur:24-word_count-seq new:25 [43181.436013] __pcache_do_fill_page(): I pid:24 tgid:24 address:0x4158d0 flags:0x150 [43181.439246] __pcache_do_fill_page(): O pid:24 tgid:24 address:0x4158d0 flags:0x150 ret:0(OKAY) csum:0x9e8f028e [43181.510534] __pcache_do_fill_page(): I pid:25 tgid:25 address:0x415000 flags:0x150 [43181.517729] __pcache_do_fill_page(): O pid:25 tgid:25 address:0x415000 flags:0x150 ret:0(OKAY) csum:0xffff88029e8f028e After all, it is TLB issue. I forgot to flush tlb after making the original pte read-only during fork. So the parent will be also to continue RW some pages, which should be process-private. Lego\u2019s current TLB flush is very native, we do tlbflush after each pte changes. This will have worse performance compared to linux\u2019s batch flush. Today\u2019s case is flush tlb after making pte read-only. And this really has to be performed one by one","title":"03/01 Thur"},{"location":"lego/log/log-04-2018/","text":"April 2018 \u00b6 05/04 Fri \u00b6 We made it. We\u2019ve done our part, now, it depends on reviewers. Please, be mercy, our hardworking deserves something good. 04/29 Sun \u00b6 Rolling. 04/26 Thus \u00b6 Fix the victim pte_same issue in SMP race cases. SMP is really pain in the ass, how many times? But\u2026 another victim ref count bug show up in SMP. First log in 0426-w15-\u00bd 0426 - w15 -1 / 3 [ 206.381646 ] CPU12 PID28 victim : ffff88207ff69120 index : 4 refcount : 0 nr_fill : 0 locked : 0 flags :( 0x2e )( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207ff72000 [ 206.416658 ] CPU12 PID28 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffd0000000 [ 206.433431 ] CPU12 PID28 victim : ffff88207ff69120 index : 4 refcount : 0 nr_fill : 0 locked : 0 flags :( 0x4e )( allocated | usable | hasdata | flushed ) pcm : ( null ) pset : ffff88207ff72000 [ 206.468429 ] CPU12 PID28 rmap to pset : ffff88207ff72000 set_idx : 0 nr_lru : 63 [ 206.484425 ] CPU12 PID28 victim dumped because : PCACHE_BUG_ON_VICTIM ( ! VictimAllocated ( v ) || ! VictimUsable ( v ) || ! VictimFlushed ( v ) || VictimWriteback ( v ) || VictimLocked ( v )) [ 206.543952 ] CPU : 12 PID : 28 Comm : python 4.0.0 - lego + # 274 [ 206.521849 ] WARNING : CPU : 12 PID : 28 at managers / processor / pcache / victim . c : 196 __put_victim_nolist + 0xa5 / 0xd0 [ 206.722631 ] [ < ffffffff8103b555 > ] __put_victim_nolist + 0xa5 / 0xd0 [ 206.729127 ] [ < ffffffff8103c419 > ] victim_try_fill_pcache + 0x2d9 / 0x460 [ 206.736107 ] [ < ffffffff8103b740 > ] ? victim_insert_hit_entry + 0x170 / 0x170 [ 206.743378 ] [ < ffffffff810371ea > ] pcache_handle_fault + 0x18a / 0x750 [ 206.399206 ] CPU8 PID19 victim : ffff88207ff69120 index : 4 refcount : 0 nr_fill : 0 locked : 0 flags :( 0x4e )( allocated | usable | hasdata | flushed ) pcm : ( null ) pset : ffff88207ff72000 [ 206.425092 ] CPU8 PID19 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffd0000000 [ 206.450977 ] CPU8 PID19 victim : ffff88207ff69120 index : 4 refcount : 0 nr_fill : 0 locked : 0 flags :( 0x4e )( allocated | usable | hasdata | flushed ) pcm : ( null ) pset : ffff88207ff72000 [ 206.476475 ] CPU8 PID19 rmap to pset : ffff88207ff72000 set_idx : 0 nr_lru : 63 [ 206.501779 ] CPU8 PID19 victim dumped because : PCACHE_BUG_ON_VICTIM ( victim_ref_count ( v ) == 0 ) [ 206.549963 ] CPU : 8 PID : 19 Comm : kvictim_flushd 4.0.0 - lego + # 274 [ 206.532803 ] WARNING : CPU : 8 PID : 19 at . / include / processor / pcache_victim . h : 119 __victim_flush_func + 0x1e4 / 0x1f0 04/25 \u00b6 Stay humble. Be real. 04/22 Sun \u00b6 Testing. Hardworking! 04/21 Sat \u00b6 Another major bug report in 0421-w15-19. Rmapped corrupted. lock issue? Fixed. It is handle_m2m_fork bug. pcache_miss_error + 0x20 Keep it going. I can not remember how many times I have seen this bug issue. And I have no idea. [ 714.144354 ] IP : [ < ffffffffffff8100 > ] 0xffffffffffff8100 [ 714.150171 ] PGD 115 c067 PUD 115e067 PMD 0 [ 714.154729 ] Oops : 0010 [ # 1 ] SMP PROCESSOR [ 714.159189 ] CPU : 0 PID : 15 Comm : ib_mad_completi 4.0.0 - lego + # 245 [ 714.165976 ] BUG : unable to handle kernel paging request at ffffffffffff8100 [ 714.173732 ] IP : [ < ffffffffffff8100 > ] 0xffffffffffff8100 [ 714.179549 ] PGD 115 c067 PUD 115e067 PMD 0 [ 714.184106 ] RIP : 0010 : [ < ffffffffffff8100 > ] [ < ffffffffffff8100 > ] 0xffffffffffff8100 [ 714.192638 ] RSP : 0000 : ffff88103e88fc80 EFLAGS : 00010046 [ 714.198552 ] RAX : 6e82000000000098 RBX : 7 b0bffffffffffff RCX : 0000000000000001 [ 714.206503 ] RDX : ffff88103e88fd28 RSI : 0000000000000000 RDI : 44 c0ffffffff8116 [ 714.214453 ] RBP : ffff88103e88fcd0 R08 : 000000000000001f R09 : ffff88103e8643c0 [ 714.222403 ] R10 : ffff88103e88fe68 R11 : 0000000000000001 R12 : a9670000018d71ba [ 714.230354 ] R13 : 0000000000000000 R14 : ffff88103e85d0f8 R15 : ffff88103dd58000 [ 714.238304 ] Oops : 0010 [ # 2 ] SMP PROCESSOR [ 714.242763 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc00000 ( 0000 ) knlGS : 0000000000000000 [ 714.251781 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 714.258180 ] CR2 : ffffffffffff8100 CR3 : 000000000115 9000 CR4 : 00000000000406 b0 [ 714.266130 ] CPU : 10 PID : 20 Comm : python 4.0.0 - lego + # 245 [ 714.272141 ] RIP : 0010 : [ < ffffffffffff8100 > ] [ < ffffffffffff8100 > ] 0xffffffffffff8100 [ 714.280673 ] RSP : 001 8 : ffff88103dd8fe10 EFLAGS : 00010202 [ 714.286588 ] RAX : ffff88101fa54270 RBX : 00000000000 c92a6 RCX : 0000000000000002 [ 714.294538 ] RDX : 00000000f fffffff RSI : 0000000000000000 RDI : 44 c0ffffffff8116 [ 714.302488 ] RBP : ffff88103dd8fe20 R08 : ffff88101fa6f000 R09 : ffff88101fa54400 [ 714.310439 ] R10 : ffff880000000000 R11 : 00000000407e9 c00 R12 : ffff88101fa54000 [ 714.318389 ] R13 : ffff88103dd68000 R14 : ffff88101fa60000 R15 : ffff88101fa54000 [ 714.326339 ] Stack : [ 714.328569 ] FS : 00007f fff7fdf740 ( 0000 ) GS : ffff88107fca0000 ( 0000 ) knlGS : 0000000000000000 [ 714.337585 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 714.343984 ] CR2 : ffffffffffff8100 CR3 : 000000103 dd9a000 CR4 : 00000000000406 a0 [ 714.351936 ] Stack : [ 714.354165 ] ffffffff810157f9 00000000003 d0f00 ffff88103dd8fec0 ffffffff8101dde5 [ 714.362309 ] ffff88103dd8fe68 ffffffff81036788 000000000000003 8 000000000000003 8 [ 714.370453 ] 00007f ffd89a79c0 ffff88101fa541c0 ffff88101fa54188 0000000000000000 [ 714.378598 ] 000000101f a60000 00007f ffd89a79d0 00007f ffd89a7700 0000000000000000 [ 714.386742 ] 00007f ffd89a6fb0 ffff88103dd8ff58 000000000000003 8 00000000003 d0f00 [ 714.394886 ] Call Trace : [ 714.397600 ] ffffffff81014f37 00000000000000 86 ffff88107fc05d80 ffff88103e864000 [ 714.405745 ] 0000000000000000 ffff88107fc04980 0000000000000000 0000000000000000 [ 714.413889 ] ffff88103e85d0f8 ffff88103dd58000 ffff88103e88fce8 ffffffff81016bb7 [ 714.422034 ] 000000007f c05d80 ffff88103e88fd10 ffffffff81006754 ffffffffffff0000 [ 714.430177 ] ffff88107fc05d80 ffff88103e864000 ffff88103e88fe00 ffffffff8100e4ea [ 714.438321 ] Call Trace : [ 714.441037 ] < TSK > [ 714.443169 ] [ < ffffffff810157f9 > ] ? ktime_get + 0x19 / 0x60 [ 714.448890 ] [ < ffffffff8101dde5 > ] copy_process + 0x2c5 / 0x1170 [ 714.454998 ] [ < ffffffff81036788 > ] ? strace_printflags + 0x88 / 0xc0 [ 714.461495 ] < TSK > [ 714.463627 ] [ < ffffffff81014f37 > ] ? update_wall_time + 0x47 / 0x6b0 [ 714.470123 ] [ < ffffffff81016bb7 > ] tick_handle_periodic + 0x67 / 0x70 [ 714.476716 ] [ < ffffffff81006754 > ] apic_timer_interrupt + 0x55 / 0x90 [ 714.483309 ] [ < ffffffff8101ecb6 > ] do_fork + 0x26 / 0x160 [ 714.488738 ] [ < ffffffff8101eea9 > ] sys_clone + 0x29 / 0x30 [ 714.494265 ] [ < ffffffff8100e8ad > ] do_syscall_64 + 0x3d / 0xd0 [ 714.500180 ] [ < ffffffff8100d7ac > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 714.507257 ] [ < ffffffff8100e4ea > ] smp__apic_timer_interrupt + 0x6a / 0x70 [ 714.514335 ] < EOT > 04/20 Fri \u00b6 Glad TF finally working now! Keep seeing this message from kernel. It have been many many times. Very deterministic. BUG : unable to handle kernel paging request at ffffffffffff8100 04/19 Thur \u00b6 Patched clflush to use tgid, n_nid directly without task_struct. In a 256M excache today (0419-w15-4), a timeout happen first, which will be handled as segfault to kill all threads. In an eviction->victim_prepare_hits, the get_memory_nodes() encounter the NULL again. Looks like the thread_group->mm got cleared before. \u00b6 04/18 Wed \u00b6 Try best to fix the pipe bug. (I found it by using my old way of debugging. By writing a function that test if PTE is corrupted or not. I put that function around the sycall enter/exit. So it help to find which syscall corrupt memory. I have used this stupid technique to find so many hard-to-find memory corruption bugs.....) do_close_on_exec dup2 Re-read Yutong\u2019s patch again. It touches a lot handler code. This has to be verified before using any nowait reply. pipe\u2019s wakeup may have issue? 0418-w15-41. 39sec 04/17 Tue \u00b6 Checking list: -pcache: ibapi use va or pa, does it matter?- No, I change it to use the VA. Then we don\u2019t have the need to use PA reply any more. =ib_mad, does it really corrupt Memory= Still not sure. Should be something come from the ib_poll_cq . M side per PTE lock, check if the lock is really the same lock! -Mail I20. Check CPT.- Dist-VMA First make sure, TF+no-dist-vma work on my own setting. Though sometimes random bug happen (I doubt it is IB). Then turn on dist-vma w/wo zerofill w/wo kfree w/wo all-zero Debug. w/wo M side per PTE lock Change most handlers to use TX buffer. Reduce the random mismatched reply case. P side watchdog patch: what to print -It looks like it is more easier to have bug when I turn on those debug counter printing. I probably should check those buffer mgmt. All next test have zerofill:- w print F 0417-w15-2(rmap_walk list_for_each_entrry #GP) F 0417-w15-3(pcache_copy_page_range corrupted PTE) F 0417-w15-4(fit_poll_cq+0x39 ib_poll_cq() \u2026) F 0417-w15-5(pcache_copy_page_range corrupted PTE) wo strace exit: S 0417-w15-6(each 100 step take ~39s/ Linux is ~34s) S 0417-w15-7(filling shuffle data, that works) F 0417-w15-8(pcache_copy_page_range+0x5d1) F 0417-w15-9(rmap_walk+0x47 #GP) disable strace: F 0417-w15-10(pcache_copy_page_range+0x5d1) Conclusion it has nothing to do with the strace thing. most of them fail around nr_reqs=19103 Why the pcache_copy_page_range always happen, after some fork, execve. w strace (fork, vfork, clone, execve) F 0417-w15-11 (pcache_cp_pg_range). Understand its flow. Back to make sure P side per PTE lock is correct. If it is pcache_cp fault, it always fail at nr_reqs=19103 . And it is: 1) python fork, 2) execve sh. S 0417-w15-12. With global PTE lock. Passed the failed stage above. F 0417-W15-13. With global PTE lock. Failed at pcache_cp. Same place. (Since global PTE lock also fail, so it is not the lock issue. Still someone write to wrong memory.) F 0417-w15-14. With global PTE lock. Same place. Found that I printed a misleading debug info. Modified a little bit to print the actual pte content. Hope can get some valid info next round. F 0417-w15-15. Same place. copy: addr: 0x7fffdca07000, ptecont: 0x8800000000000 . zap: ptent: 0x340 address: 0x7fffdca08000 . F 0417-w15-16. Well. BUG in ib_mad_send handler. I add the same checking in ib_mad_receive. This is really just used to catch it. Not fixing it. F 0417-w15-17. Again, addr: 0x7fffdc207000, ptecont: 0x8800000000000 F 0417-w15-18. addr: 0x7fffdca07000, ptecont: 0x8800000000000 Conclusion Only these two addresses addr: 0x7fffdca07000, ptecont: 0x8800000000000 pte:ffff88103ea87038 (0x8800000000000) pfn:0x0 flags:(0x8800000000000) addr: 0x7fffdc207000, ptecont: 0x8800000000000 pte:ffff88103ea97038 (0x8800000000000) pfn:0x0 flags:(0x8800000000000) Bug found. In pipe_read/write. It somehow corrupted memory. Damn. -Another first thing, check this weird log.. : Hmm, this log should be fine. mad_post is after recv_done_handler. So even if we detect corrupted memory in handler, it has nothing to do with mad_post. The root cause should come from ib_poll_cq, that is where we pass wc to, and where the wc.wr_id was filled in.- [ 3850.911144 ] ib_mad_recv_done_handler () : c1 : 2060 c2 : 12 wc -> wr_id : 0xffff88103eea1398 [ 3850.921881 ] ib_mad_post_receive_mads () : c1 : 2060 c2 : 13 recv_wr . wr_id : 0xffff88103eea1008 recv_queue : ffff88103ee42520 [ 3850.933620 ] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 13 [ 3850.942346 ] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 14 [ 3850.951266 ] ib_mad_recv_done_handler () : c1 : 2061 c2 : 13 wc -> wr_id : 0xffff88103eea1560 [ 3850.961999 ] ib_mad_post_receive_mads () : c1 : 2061 c2 : 14 recv_wr . wr_id : 0xffff88103eea11d0 recv_queue : ffff88103ee42520 [ 3850.973737 ] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 14 [ 3851.257563 ] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 15 [ 3851.266295 ] ib_mad_recv_done_handler () : c1 : 2062 c2 : 14 wc -> wr_id : 0xffff88103eea1728 [ 3851.277029 ] ib_mad_post_receive_mads () : c1 : 2062 c2 : 15 recv_wr . wr_id : 0xffff88103eea1398 recv_queue : ffff88103ee42520 [ 3851.288767 ] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 15 [ 3851.297493 ] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 16 [ 3851.306413 ] ib_mad_recv_done_handler () : c1 : 2063 c2 : 15 wc -> wr_id : 0xffff88103eea18f0 [ 3851.317147 ] ib_mad_post_receive_mads () : c1 : 2063 c2 : 16 recv_wr . wr_id : 0xffff88103eea1560 recv_queue : ffff88103ee42520 [ 3851.328886 ] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 16 [ 3851.903180 ] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 17 [ 3851.911913 ] ib_mad_recv_done_handler () : c1 : 2064 c2 : 16 wc -> wr_id : 0xffff88103eea1ab8 [ 3851.922646 ] ib_mad_post_receive_mads () : c1 : 2064 c2 : 17 recv_wr . wr_id : 0xffff88103eea1728 recv_queue : ffff88103ee42520 [ 3851.934384 ] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 17 [ 3851.943110 ] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 18 [ 3851.952030 ] ib_mad_recv_done_handler () : c1 : 2065 c2 : 17 wc -> wr_id : 0xffff88103eea1c80 [ 3851.962764 ] ib_mad_post_receive_mads () : c1 : 2065 c2 : 18 recv_wr . wr_id : 0xffff88103eea18f0 recv_queue : ffff88103ee42520 [ 3851.974502 ] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 18 [ 3864.723128 ] *** FIT layer ready to go ! [ 3864.727206 ] *** [ 3867.339488 ] Processor LLC Configurations : [ 3867.343760 ] PhysStart : 0x100000000 [ 3867.348705 ] VirtStart : 0xffff880100000000 [ 3867.354329 ] Registered Size : 0x400000000 [ 3867.359274 ] Actual Used Size : 0x208000000 [ 3867.364219 ] NR cachelines : 2097152 [ 3867.368776 ] Associativity : 8 [ 3867.372751 ] NR Sets : 262144 [ 3867.377210 ] Cacheline size : 4096 B [ 3867.381672 ] Metadata size : 64 B [ 3867.385937 ] NR cacheline bits : 12 [ 0 - 11 ] 0x0000000000000fff [ 3867.392821 ] NR set - index bits : 18 [ 12 - 29 ] 0x000000003ffff000 [ 3867.399705 ] NR tag bits : 34 [ 30 - 63 ] 0xffffffffc0000000 [ 3867.406588 ] NR pages for data : 2097152 [ 3867.411147 ] NR pages for meta : 32768 [ 3867.415509 ] Cacheline ( pa ) range : [ 0x100000000 - 0x2ffffffff ] [ 3867.423848 ] Metadata ( pa ) range : [ 0x300000000 - 0x307ffffff ] [ 3867.432186 ] Cacheline ( va ) range : [ 0xffff880100000000 - 0xffff8802ffffffff ] [ 3867.440524 ] Metadata ( va ) range : [ ffff880300000000 - 0xffff880307ffffff ] [ 3867.448862 ] pcache_set_map ( 064 B ) : [ ffff88207ec00000 - 0xffff88207fbfffff ] [ 3867.457201 ] Way cache stride : 0x40000000 [ 3867.462048 ] Memmap $ semantic : memblock reserved [ 3867.468156 ] NR victim $ entries : 8 [ 3867.472725 ] newpid : 1 home : 1 replica : 1 [ 3867.476980 ] p2m_fork ( cpu0 ) : I cur : 1 - kernel_init new : 20 [ 3867.482718 ] p2m_fork ( cpu0 ) : O succeed cur : 1 - kernel_init new : 20 [ 3867.489197 ] Processor : Processor manager is running . [ 3867.494724 ] Online CPU : 0 , 2 , 4 , 6 , 8 , 10 , 12 , 14 , 16 , 18 , 20 , 22 [ 3867.500444 ] Active CPU : 0 , 2 , 6 , 10 , 12 , 14 , 16 , 18 , 20 , 22 [ 3867.505777 ] [ 0 ] Thread [ kvictim_flushd : 19 ] pinned at CPU 8 [ 3867.511982 ] [ 1 ] Thread [ recvpollcq : 17 ] pinned at CPU 4 [ 3867.539217 ] do_close_on_exec () : TODO , not implemented . [ 3867.549209 ] STDOUT : --- [ Before execv ^ V ] --- [ 3867.553870 ] STDOUT : --- [ e --- [ 3867.557880 ] newpid : 20 home : 1 replica : 1 [ 3867.562248 ] p2m_fork ( cpu10 ) : I cur : 20 - exe . o new : 21 [ 3867.567560 ] p2m_fork ( cpu10 ) : O succeed cur : 20 - exe . o new : 21 [ 3867.573670 ] CPU12 PID21 sys_execve [ 3867.578681 ] do_close_on_exec () : TODO , not implemented . [ 3867.584215 ] CPU12 PID21 sys_execve = 0 , 0x0 [ 3867.599867 ] BUG : unable to handle kernel paging request at 000000040 8446080 [ 3867.607436 ] IP : [ < ffffffff8101bbbf > ] task_tick_rt + 0x1f / 0xd0 04/16 Mon \u00b6 Make dist-vma work with TF first. Tough work. 0416-w14-7 : 1) do_wp_page triggered, 2) dealock on per pte lock. This really should not happen. It is single worker. Basically means the page->lock is not intialized. Probabaly our per PTE lock implementation is wrong. [ 5220.250552 ] hb : worker [ 0 ] CPU 4 stucked [ 5220.254819 ] hb : common_header [ op = 0x20000000 src_nid : 0 ] [ 5220.260734 ] hb : msg [ pid = 21 , tgid = 21 , flags = 0x51 , vaddr = 0x7fff7b7fdfb8 ] [ 5220.267911 ] CPU : 4 PID : 31 Comm : thpool - worker0 4.0.0 - lego - ys + # 237 [ 5220.274890 ] RIP : 0010 : [ < ffffffff81031aa3 > ] [ < ffffffff81031aa3 > ] handle_lego_mm_fault + 0x373 / 0x4f0 handle_lego_mm_fault + 0x373 / 0x4ee : arch_spin_lock at arch / x86 / include / asm / spinlock . h : 21 ( inlined by ) spin_lock at include / lego / spinlock . h : 72 ( inlined by ) do_anonymous_page at managers / memory / vm / fault . c : 115 ( inlined by ) handle_pte_fault at managers / memory / vm / fault . c : 142 ( inlined by ) handle_lego_mm_fault at managers / memory / vm / fault . c : 225 A IB bug during normal run (P M S TF), this is REALLY weird: [ 395.259560 ] CPU12 PID21 sys_execve [ 395.263345 ] BUG : unable to handle kernel NULL pointer dereference at 00000000000001 a0 [ 395.272068 ] IP : [ < ffffffff81064c09 > ] fit_poll_cq + 0x39 / 0x530 fit_poll_cq + 0x39 / 0x523 : git :( test_vma )] $ . / scripts / faddr2line vmImage fit_poll_cq + 0x39 ib_poll_cq at include / rdma / ib_verbs . h : 1614 ( inlined by ) fit_poll_cq at net / lego / fit_internal . c : 1671 Catch the ib_mad bug once.. and mlx4_error follows. I added more checking to where the mad_queue was assigned. [ 787.471385 ] ib_mad_completion_handler 2365 got successful recv cq op 128 mad_got_one 15 [ 787.480124 ] BUG ! mad_list : ffff88103eea1728 mad_queue : ( null ) [ 787.487491 ] ------------ [ cut here ] ------------ [ 787.492630 ] WARNING : CPU : 0 PID : 15 at drivers / infiniband / core / mad . c : 1909 ib_mad_completion_handler + 0xa56 / 0xab0 04/15 Sun \u00b6 Trying TF myself. Had a bug report on 0415-w15-5, on fork, execve etc. [ 317.436811 ] newpid : 22 home : 1 replica : 1 [ 317.477701 ] pte : ffff88103e94a038 pfn : 0x0 flags :() [ 317.482752 ] pte dumped because : corrupted [ 317.487213 ] ------------ [ cut here ] ------------ [ 317.492352 ] WARNING : CPU : 14 PID : 22 at managers / processor / pgtable . c : 365 pcache_copy_page_range + 0x5d1 / 0x6c0 [ 317.503213 ] CPU : 14 PID : 22 Comm : python 4.0.0 - lego + # 93 [ 317.552082 ] Call Trace : [ 317.554799 ] < TSK > [ 317.556930 ] [ < ffffffff810123a1 > ] __warn . constprop .0 + 0x91 / 0xd0 [ 317.563330 ] [ < ffffffff8101246f > ] warn_slowpath_null + 0xf / 0x20 [ 317.569634 ] [ < ffffffff8102d401 > ] pcache_copy_page_range + 0x5d1 / 0x6c0 [ 317.576615 ] [ < ffffffff81037ed7 > ] fork_dup_pcache + 0x27 / 0x30 [ 317.582723 ] [ < ffffffff8101e514 > ] copy_process + 0xcf4 / 0x1140 [ 317.588833 ] [ < ffffffff8101e986 > ] do_fork + 0x26 / 0x160 [ 317.594264 ] [ < ffffffff8101eb89 > ] sys_clone + 0x29 / 0x30 [ 317.599789 ] [ < ffffffff8100e66d > ] do_syscall_64 + 0x3d / 0xd0 [ 317.605705 ] [ < ffffffff8100d56c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 317.612782 ] < EOT > [ 317.614917 ] --- [ end trace 0000000000000000 ] --- [ 317.625561 ] p2m_fork ( cpu14 ) : I cur : 22 - python new : 36 [ 330.209312 ] p2m_fork ( cpu14 ) : O succeed cur : 22 - python new : 36 [ 330.310909 ] ------------ [ cut here ] ------------ [ 330.315864 ] BUG : failure at managers / processor / pcache / rmap . c : 804 / pcache_zap_pte () ! [ 330.324302 ] Kernel Panic - not syncing : BUG ! [ 330.329050 ] CPU : 0 PID : 36 Comm : python 4.0.0 - lego + # 93 [ 330.377824 ] Call Trace : [ 330.380540 ] < TSK > [ 330.382672 ] [ < ffffffff81026493 > ] panic + 0xc2 / 0x105 [ 330.387908 ] [ < ffffffff8101bbcc > ] ? task_tick_rt + 0x2c / 0xd0 [ 330.393920 ] [ < ffffffff81019245 > ] ? scheduler_tick + 0x55 / 0x60 [ 330.400126 ] [ < ffffffff810168f5 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 330.406913 ] [ < ffffffff81006684 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 330.413700 ] [ < ffffffff8100e2aa > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 330.420973 ] [ < ffffffff810125ad > ] ? printk + 0x11d / 0x1b0 [ 330.426597 ] [ < ffffffff810375bc > ] pcache_zap_pte + 0x14c / 0x190 [ 330.432802 ] [ < ffffffff81035db0 > ] ? __pcache_remove_rmap_one + 0x70 / 0x70 [ 330.439978 ] [ < ffffffff8102cd25 > ] unmap_page_range + 0x325 / 0x3f0 [ 330.446379 ] [ < ffffffff8102ce0e > ] release_pgtable + 0x1e / 0x40 [ 330.452487 ] [ < ffffffff81037ef8 > ] pcache_process_exit + 0x18 / 0x20 [ 330.458984 ] [ < ffffffff8101d3c4 > ] mmput + 0x34 / 0xb0 [ 330.464123 ] [ < ffffffff8102c38d > ] do_execve + 0x42d / 0x760 [ 330.469845 ] [ < ffffffff8102c6c9 > ] sys_execve + 0x9 / 0x10 [ 330.475371 ] [ < ffffffff8100e66d > ] do_syscall_64 + 0x3d / 0xd0 [ 330.481286 ] [ < ffffffff8100d56c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 330.488364 ] < EOT > [ 330.490501 ] --- [ end Kernel panic - not syncing : BUG ! one more [ 369.223161] newpid: 22 home:1 replica: 1 [ 369.264307] pte:ffff88103ea41038 (0x0) pfn:0x0 flags:() [ 369.269938] pte dumped because: corrupted [ 369.274399] ------------[ cut here ]------------ [ 369.279538] WARNING: CPU: 14 PID: 22 at managers/processor/pgtable.c:365 pcache_copy_page_range+0x5d1/0x6c0 [ 369.290398] CPU: 14 PID: 22 Comm: python 4.0.0-lego+ #94 [ 369.296310] Stack: [ 369.341976] <TSK> [ 369.344107] [<ffffffff810123a1>] __warn.constprop.0+0x91/0xd0 [ 369.350508] [<ffffffff8101246f>] warn_slowpath_null+0xf/0x20 [ 369.356809] [<ffffffff8102d401>] pcache_copy_page_range+0x5d1/0x6c0 [ 369.363790] [<ffffffff81037f07>] fork_dup_pcache+0x27/0x30 [ 369.369897] [<ffffffff8101e514>] copy_process+0xcf4/0x1140 [ 369.376006] [<ffffffff8101e986>] do_fork+0x26/0x160 [ 369.381435] [<ffffffff8101eb89>] sys_clone+0x29/0x30 [ 369.386960] [<ffffffff8100e66d>] do_syscall_64+0x3d/0xd0 [ 369.392875] [<ffffffff8100d56c>] entry_SYSCALL64_slow_path+0x25/0x25 [ 369.399952] <EOT> [ 369.402086] ---[ end trace 0000000000000000 ]--- [ 369.412750] p2m_fork(cpu14): I cur:22-python new:36 [ 369.418215] p2m_fork(cpu14): O succeed cur:22-python new:36 [ 369.500829] ptent: 0x340 address: 0x7fffe2408000 [ 369.505783] pte:ffff88103dbe5040 (0x340) pfn:0x0 flags:(dirty|global|softw1) [ 369.513637] pte dumped because: corrupted [ 369.518095] ------------[ cut here ]------------ [ 369.523236] BUG: failure at managers/processor/pcache/rmap.c:808/pcache_zap_pte()! [ 369.531672] Kernel Panic - not syncing: BUG! 04/14 Sat \u00b6 Check if page table pages, page themselves are freed in munmap, at both P and M. Need to confirm. Will they do harm Implement replication Add IB counter 04/13 Fri \u00b6 Patched M side pgtable to use per PTE/PMD lock. So thpool in M will not be bottlnecked by the page_table_lock. ib_mad_recv_done_handler may corrupt memory, again. \u00b6 Somehow, during testing of this patch. Running with MT-Phoenix 1GB, the P side has reported bad pgd entries. I\u2019m using fork+execve way. The child(phoenix) already exit. This msg is printed when parent exit_mm. The pgd table should either be 0, or valid pud va. Memory corruption happened\u2026 [ 2551.687806 ] Kernel strace [ 2551.690715 ] Task : 21 : 21 nr_accumulated_threads : 1 [ 2551.696327 ] % time seconds usecs / call calls errors syscall [ 2551.703704 ] ------ -------------- ----------- --------- --------- ---------------- [ 2551.712141 ] 98.63 66.942660568 66942661 1 0 sys_wait4 [ 2551.719898 ] 0.45 0.457060789 457061 1 0 sys_clone [ 2551.727654 ] 0.20 0.204320071 51081 4 0 sys_brk [ 2551.735216 ] 0.40 0.040378189 40379 1 0 sys_mmap [ 2551.742876 ] 0.13 0.013682424 4561 3 0 sys_write [ 2551.750633 ] 0.10 0.000001039 2 1 0 sys_newfstat [ 2551.758681 ] 0.88 0.000000888 1 2 0 sys_rt_sigaction [ 2551.767114 ] 0.79 0.000000792 1 2 0 sys_futex [ 2551.774871 ] 0.77 0.000000770 1 1 0 sys_rt_sigprocmask [ 2551.783501 ] 0.54 0.000000548 1 1 0 sys_arch_prctl [ 2551.791742 ] 0.49 0.000000499 1 1 0 sys_newuname [ 2551.799789 ] 0.46 0.000000469 1 1 0 sys_getrlimit [ 2551.807933 ] 0.19 0.000000195 1 1 0 sys_set_tid_address [ 2551.816659 ] 0.19 0.000000190 1 1 0 sys_set_robust_list [ 2551.825386 ] 0.18 0.000000181 1 1 0 sys_ioctl [ 2551.833143 ] ------ -------------- ----------- --------- --------- ---------------- [ 2551.841577 ] 100.00 67.658107612 22 0 total [ 2551.848945 ] [ 2551.850591 ] [ 2551.852240 ] Kernel Profile Points [ 2551.855924 ] status name total nr avg . ns [ 2551.865621 ] ------- -------------------- ---------------- ---------------- ---------------- [ 2551.875317 ] off flush_tlb_others 0.000204992 58 3535 [ 2551.885014 ] off __do_kmalloc_node 0.300783843 281501 1069 [ 2551.894709 ] off __pcache_zerofill 0.009844770 16558 595 [ 2551.904404 ] off pcache_miss 54.414457906 257869 211016 [ 2551.914100 ] off pcache_flush 0.000000000 0 0 [ 2551.923795 ] ------- -------------------- ---------------- ---------------- ---------------- [ 2551.933490 ] [ 2552.074985 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956028 ( ffffffff81146ca0 ) [ 2552.084206 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956030 ( ffff88103e956030 ) [ 2552.093611 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956038 ( ffff88103e956030 ) [ 2552.103016 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956048 ( ffff88103cc48740 ) [ 2552.112421 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956050 ( 00000000000001 c0 ) [ 2552.121825 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956058 ( ffff88103eea2008 ) [ 2552.131230 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956060 ( ffff88103eea17d8 ) [ 2552.140635 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956068 ( ffff88103ee42520 ) [ 2552.150040 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9560e8 ( 000000103e9560f 0 ) [ 2552.159444 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956118 ( 010200 8081018101 ) [ 2552.168849 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956120 ( 3 c010b0012000000 ) [ 2552.178254 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956128 ( 0000000000001100 ) [ 2552.187659 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956138 ( 00000000f fffffff ) [ 2552.197064 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956158 ( 0307 8 a2402010101 ) [ 2552.206467 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956160 ( 0307 8 a2453946600 ) [ 2552.215872 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956168 ( 0307 8 a2450946600 ) [ 2552.225277 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956170 ( 0310 800051946600 ) [ 2552.234682 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956178 ( c902000100000000 ) [ 2552.244088 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956198 ( bfd0cc054a122000 ) [ 2552.253492 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561a0 ( 0000000000 98 b9c8 ) [ 2552.262897 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561a8 ( bfe0fe0610914e01 ) [ 2552.272302 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561b0 ( 000000000050f 2 c7 ) [ 2552.281706 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561b8 ( bfd9a30000ec5100 ) [ 2552.291111 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561c0 ( bffc91d40f20f2c7 ) [ 2552.300516 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561c8 ( 0f 20 cd054a20f2c7 ) [ 2552.309920 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561d0 ( 1094 edcf0f60edcf ) [ 2552.319325 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561d8 ( 0000000000000100 ) [ 2552.328730 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956218 ( 0000000000005 aa5 ) [ 2552.338151 ] nr_pgfault : 26 Second run, saw this invalid pointer deference again! Combined with the above log, I think ib_mad is definitely corrupting memory! I have to take a look. qp_info = mad_list->mad_queue->qp_info; Patching the handlers to use tx buffer. \u00b6 Patched. Once race condition: pcache_handle_miss use the page itself as the reply buffer. Assume later on, it changes to use nowait reply. When the reply is buffered in the queue and has not been sent. Another munmap comes in and invalidate this area, then the page will be freed. The data is invalidate. But this case seems abnormal. The application will not do so I guess. Check if page table pages, page themselves are freed in munmap, at both P and M. Need to confirm. \u00b6 Tonight task. Think about how to do the VMA replication, how to combine with the $ line replicaiton. \u00b6 04/12 Thur \u00b6 Patched zerofill. All done. Testing new driver fix with Phoenix - 1 st run, the mismatch reply is still there. mmap() replied address is different from the one printed. So segfault follows. (0412-w15-4) - 2st run, 3st run, succeed. 0412-w15-9 0412-w14-9 First time testing phoenix with zerofill (no net). Somehow, P has pcache timeout, but M\u2019s watchdog show there is no pending requests. This happen once before I remember\u2026 0412-w15-10. Have not seen this ib mad thing for a long time. Indeed somewhere is wrong. [ 297.794969] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 15 [ 297.803706] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020 [ 297.812431] IP: [<ffffffff81058937>] ib_mad_completion_handler+0xc7/0x810 2 04/11 Wed \u00b6 Adding anon first touch opt. 0411-p/m-9 : this log indicate M does not have any unhandled requests, but P side has 1 __pcache_fill timeout. It seems the message is lost somewhere. 0411-p/m-11 : catch one with the debug msg Yiying added. She says the M side send queue has 2 reqs. But poll does not return any error. Weird. Help debugging IB issue. 04/10 Tue \u00b6 Found. IB stuck. Damn. [ 2240.294960] RIP: 0010:[<ffffffff8104a6d8>] [<ffffffff8104a6d8>] mlx4_ib_poll_cq+0x378/0x6a0 [ 2242.694733] RIP: 0010:[<ffffffff8104a6d8>] [<ffffffff8104a6d8>] mlx4_ib_poll_cq+0x378/0x6a0 [ 2245.094524] RIP: 0010:[<ffffffff8104a6e3>] [<ffffffff8104a6e3>] mlx4_ib_poll_cq+0x383/0x6a0 [ 2247.494306] RIP: 0010:[<ffffffff8104a6d8>] [<ffffffff8104a6d8>] mlx4_ib_poll_cq+0x378/0x6a0 [ 2249.894088] RIP: 0010:[<ffffffff8104a6d8>] [<ffffffff8104a6d8>] mlx4_ib_poll_cq+0x378/0x6a0 [ 2252.293870] RIP: 0010:[<ffffffff8104a6d8>] [<ffffffff8104a6d8>] mlx4_ib_poll_cq+0x378/0x6a0 [ 2254.693651] RIP: 0010:[<ffffffff8104a6d8>] [<ffffffff8104a6d8>] mlx4_ib_poll_cq+0x378/0x6a0 [ 2257.093431] RIP: 0010:[<ffffffff8104a6e3>] [<ffffffff8104a6e3>] mlx4_ib_poll_cq+0x383/0x6a0 04/09 Mon \u00b6 thpool testing. 4 workers. MT-phoenix: [ root @ wuklab05 ys ] # cat 040 9 - p | grep __munmap [ 227.054974 ] CPU14 PID22 strace__munmap ([ 0x7fffb0ba9000 - 0x7fffb4000000 ], 54882304 ) = 0 , 0x0 [ 227.093466 ] CPU16 PID23 strace__munmap ([ 0x7fffab7ff000 - 0x7fffac000000 ], 8392704 ) = 0 , 0x0 [ 227.102773 ] CPU14 PID22 strace__munmap ([ 0x7fffb8000000 - 0x7fffb8ba9000 ], 12226560 ) = 0 , 0x0 [ 227.141265 ] CPU18 PID24 strace__munmap ([ 0x7fffa8000000 - 0x7fffac000000 ], 67108864 ) = 0 , 0x0 [ 227.150669 ] CPU16 PID23 strace__munmap ([ 0x7fffb0000000 - 0x7fffb37ff000 ], 58716160 ) = 0 , 0x0 [ 227.218248 ] CPU22 PID26 strace__munmap ([ 0x7fffa0000000 - 0x7fffa4000000 ], 67108864 ) = 0 , 0x0 [ 227.285826 ] CPU2 PID28 strace__munmap ([ 0x7fff98000000 - 0x7fff9c000000 ], 67108864 ) = 0 , 0x0 [ 227.440567 ] CPU14 PID31 strace__munmap ([ 0x7fff8a7fd000 - 0x7fff8c000000 ], 25178112 ) = 0 , 0x0 [ 227.449972 ] CPU12 PID30 strace__munmap ([ 0x7fff88000000 - 0x7fff8c000000 ], 67108864 ) = 0 , 0x0 [ 227.459376 ] CPU14 PID31 strace__munmap ([ 0x7fff90000000 - 0x7fff927fd000 ], 41930752 ) = 0 , 0x0 [ 227.490109 ] CPU18 PID33 strace__munmap ([ 0x7fff80000000 - 0x7fff84000000 ], 67108864 ) = 0 , 0x0 [ 227.723140 ] word_count - pthr [ 29 ] : segfault at 0x4e842010 ip 0000000000420354 sp 00007f ffb17f9bc0 error 6 0x4e842010 Print mmap on M, if segfault. Printed, the 0x4e842010 is never a valid address. thpool makes Memory side SMP. Probably bring some issues. Found: P CPU22 PID26 strace__mmap(addr=0x0, len=0xfb000, prot(0x3)=PROT_READ|PROT_WRITE, flags(0x22)=MAP_PRIVATE|MAP_ANONYMOUS, fd=18446744073709551615( ), off=0x0) = 1317351432, 0x4e853008 word_count-pthr[26]: segfault at 0x4e853010 ip 0000000000420354 sp 00007fff972a8bc0 error 6 M [ 583.120615] 00400000-004d9000 r-xp 00000000 /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread [ 583.131578] 006d9000-006dc000 rw-p 000d9000 /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread [ 583.142729] 006dc000-00755000 rw-p 00000000 [heap] [ 583.148254] 7fff529c9000-7fffb93aa000 rw-p 00000000 [ 583.153974] 7fffb93aa000-7ffff7fff000 rw-p 00000000 /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_1GB.txt [ 583.167355] 7ffffffde000-7ffffffff000 rw-p 00000000 [stack] [ 583.173753] ------------[ cut here ]------------ [ 583.178892] WARNING: CPU: 4 PID: 31 at managers/memory/handle_pcache/fault.c:55 handle_p2m_pcache_miss+0x18e/0x1d0 [ 583.190430] src_nid:0,pid:21,vaddr:0x4e853010 [ 583.195279] CPU: 4 PID: 31 Comm: thpool-worker0 4.0.0-lego-ys+ #90 Confirmed. I printed added a number to mmap requests. And the compare the results of both P and M. The data is wrong. Btw, I\u2019m only running 1 worker thread at M, which makes it single thread handling. So, I\u2019m going to, 1) first use kmalloc to get the reply buffer, and 2) revert back the IB MAX_OUT config, remove the #ifdef COMP_MEMORY. See if it is this patch\u2019s issue. P : CPU18 PID24 strace__mmap ( 30 ..) = -1325940736 , 0x7fffb0f7c000 CPU22 PID26 strace__mmap ( 31 ..) = 2144269992 , 0x7fcef6a8 M : ... handle_p2m_mmap () : 30 7f ffb0f7c000 handle_p2m_mmap () : 31 7f ffb0efe000 ... Anyway, this is temporary fixed by using kmalloced reply buffer. Spent whole afternoon and whole night. Finally figure out why timeout happen in P. It is because somewhere in the middle, M has 1 or more requests stucked/unhandled. Deadlock happen in the middle. Like this one. 5 requests queued waiting, 1 is being handled. And that 1 handler stuck. And it is handle_pcache_miss. Now, I need to find out where it stuck! thpool-worker0 nr_queued: 5 1 Oh, I really hope we can have some soft/hw lockdep, watchdog stuff . This should make out life much much much much much easier! 04/08 Sun \u00b6 Trying the fit_nowait patch. First try fit_nowait patch, without any chanegs to other code. See if this patch can work. Second, modify pcache to use reply_message_nowait. See if this can work. and improve performance. Third, if 2) can improve, perf. Move on to modify thpool patch. 1 st , P fail at ib_mad, during boot: [ 349.239220 ] Online CPU : 0 , 2 , 4 , 6 , 8 , 10 , 12 , 14 , 16 , 18 , 20 , 22 [ 349.244940 ] Active CPU : 0 , 2 , 6 , 10 , 12 , 14 , 16 , 18 , 20 , 22 [ 349.250272 ] [ 0 ] Thread [ kvictim_flushd : 19 ] pinned at CPU 8 [ 349.256478 ] [ 1 ] Thread [ recvpollcq : 17 ] pinned at CPU 4 [ 356.188819 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 13 [ 356.197545 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000020 [ 356.206270 ] IP : [ < ffffffff81058287 > ] ib_mad_completion_handler + 0xc7 / 0x810 2st run, P side, config MAX_OUT to 1. Then single-thread pheonix with 1GB data finished. But forgot to turn on the profile point. Run one more time. 3st run. Same with 2st run setting. But with profile on. Bug shows. Ugh. I still think it is because of ib_mad_handler. It must write to wrong memory locations, and corrupt things randomly. [ 456.237913 ] do_close_on_exec () : TODO , not implemented . ... [ 456.263274 ] BUG : unable to handle kernel paging request at 00000002f 4 bfbf58 [ 456.270843 ] IP : [ < ffffffff8101bbff > ] task_tick_rt + 0x1f / 0xd0 [ 456.277048 ] PGD 0 [ 456.279279 ] Thread overran stack , or stack corrupted [ 456.284804 ] Oops : 0000 [ # 1 ] SMP PROCESSOR [ 456.289265 ] CPU : 10 PID : 20 Comm : kevict_sweepd 4.0.0 - lego + # 40 [ 456.295858 ] RIP : 0010 : [ < ffffffff8101bbff > ] [ < ffffffff8101bbff > ] task_tick_rt + 0x1f / 0xd0 4st run, succeed. But it looks like the perf is very bad. Oh. but 99% of the pcache miss are file-backed, which will go to storage. So the number is actually doubled. With fit_nowait patch : [ 308.660051 ] Kernel Profile Points [ 308.663734 ] status name total nr avg . ns [ 308.673431 ] ------- -------------------- ---------------- ---------------- ---------------- [ 308.683128 ] off flush_tlb_others 0.000130715 53 2467 [ 308.692824 ] off __do_kmalloc_node 0.097344056 265647 367 [ 308.702521 ] off pcache_miss 4.504660891 258211 17446 [ 308.712218 ] off pcache_flush 0.000000000 0 0 [ 308.721914 ] ------- -------------------- ---------------- ---------------- ---------------- 5st run. Just run large malloc test. Looks better than yesterday\u2019s result. But I\u2019m using 15 as P today, instead of 13. So, let me try one more time to see if it is the machine. With fit_nowait patch : [ 674.382592 ] Kernel Profile Points [ 674.386277 ] status name total nr avg . ns [ 674.395974 ] ------- -------------------- ---------------- ---------------- ---------------- [ 674.405670 ] off flush_tlb_others 0.000130838 53 2469 [ 674.415366 ] off __do_kmalloc_node 1.604700641 1584917 1013 [ 674.425062 ] off pcache_miss 6.467938547 786571 8223 [ 674.434758 ] off pcache_flush 3.342783614 262225 12748 [ 674.444455 ] ------- -------------------- ---------------- ---------------- ---------------- [ 674.554497 ] nr_pgfault : 786513 [ 674.557706 ] nr_clflush : 262225 [ 674.561099 ] nr_pgfault_wp : 0 [ 674.564299 ] nr_pgfault_wp_cow : 0 [ 674.567887 ] nr_pgfault_wp_reuse : 0 [ 674.571668 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 674.577195 ] nr_pcache_fill_from_memory : 786511 [ 674.582139 ] nr_pcache_fill_from_victim : 2 6st run. Looks like the above fit_nowait can have 400ns improvement. But how come? I did not even change the pcache handling to use ibapi_nowait!!! Maybe random variation. Let me run more. Without fit_nowait patches [ 428.546738 ] Kernel Profile Points [ 428.550424 ] status name total nr avg . ns [ 428.560119 ] ------- -------------------- ---------------- ---------------- ---------------- [ 428.569815 ] off flush_tlb_others 0.000131140 53 2475 [ 428.579510 ] off __do_kmalloc_node 1.758704197 1331927 1321 [ 428.589205 ] off pcache_miss 6.807601189 786575 8655 [ 428.598899 ] off pcache_flush 3.699044847 262227 14107 [ 428.608594 ] ------- -------------------- ---------------- ---------------- ---------------- [ 428.618289 ] [ 428.718670 ] nr_pgfault : 786515 [ 428.721878 ] nr_clflush : 262227 [ 428.725272 ] nr_pgfault_wp : 0 [ 428.728470 ] nr_pgfault_wp_cow : 0 [ 428.732058 ] nr_pgfault_wp_reuse : 0 [ 428.735840 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 428.741365 ] nr_pcache_fill_from_memory : 786515 [ 428.746310 ] nr_pcache_fill_from_victim : 0 7 th run. without fit_nowait. without fit_nowait . [ 901.223090 ] Kernel Profile Points [ 901.226775 ] status name total nr avg . ns [ 901.236472 ] ------- -------------------- ---------------- ---------------- ---------------- [ 901.246168 ] off flush_tlb_others 0.000130802 53 2468 [ 901.255865 ] off __do_kmalloc_node 1.862575608 1331923 1399 [ 901.265560 ] off pcache_miss 6.814540477 786572 8664 [ 901.275257 ] off pcache_flush 3.699187003 262224 14107 [ 901.284953 ] ------- -------------------- ---------------- ---------------- ---------------- 8 th run. without fit_nowait. [ 321.514564 ] Kernel Profile Points [ 321.518250 ] status name total nr avg . ns [ 321.527945 ] ------- -------------------- ---------------- ---------------- ---------------- [ 321.537639 ] off flush_tlb_others 0.000130934 53 2471 [ 321.547335 ] off __do_kmalloc_node 2.216772665 1331939 1665 [ 321.557031 ] off pcache_miss 6.806060415 786573 8653 [ 321.566726 ] off pcache_flush 3.725455841 262231 14207 [ 321.576421 ] ------- -------------------- ---------------- ---------------- ---------------- 9 th run. with fit_nowait [ 374.847912 ] Kernel Profile Points [ 374.851597 ] status name total nr avg . ns [ 374.861293 ] ------- -------------------- ---------------- ---------------- ---------------- [ 374.870989 ] off flush_tlb_others 0.000130858 53 2470 [ 374.880684 ] off __do_kmalloc_node 1.485304454 1331934 1116 [ 374.890381 ] off pcache_miss 6.615317677 786582 8411 [ 374.900076 ] off pcache_flush 3.508328900 262234 13379 [ 374.909772 ] ------- -------------------- ---------------- ---------------- ---------------- 10 th run, with fit_nowait [ 225.211058] Kernel Profile Points [ 225.214743] status name total nr avg.ns [ 225.224440] ------- -------------------- ---------------- ---------------- ---------------- [ 225.234137] off flush_tlb_others 0.000131029 53 2473 [ 225.243833] off __do_kmalloc_node 1.211421872 1331984 910 [ 225.253529] off pcache_miss 6.583096125 786574 8370 [ 225.263226] off pcache_flush 3.464430818 262227 13212 [ 225.272922] ------- -------------------- ---------------- ---------------- ---------------- Sum: with fit_nowait: [ 225.253529] off pcache_miss 6.583096125 786574 8370 [ 225.263226] off pcache_flush 3.464430818 262227 13212 [ 374.890381] off pcache_miss 6.615317677 786582 8411 [ 374.900076] off pcache_flush 3.508328900 262234 13379 [ 674.425062] off pcache_miss 6.467938547 786571 8223 [ 674.434758] off pcache_flush 3.342783614 262225 12748 Without fit_nowait: [ 428.589205] off pcache_miss 6.807601189 786575 8655 [ 428.598899] off pcache_flush 3.699044847 262227 14107 [ 901.265560] off pcache_miss 6.814540477 786572 8664 [ 901.275257] off pcache_flush 3.699187003 262224 14107 [ 321.557031] off pcache_miss 6.806060415 786573 8653 [ 321.566726] off pcache_flush 3.725455841 262231 14207 04/07 Sat \u00b6 Well, now we finished all the profiling stuff. Continue on other work. Now I like listening Jazz while coding. Amazing Jazz, really good. Once again, ib_mad_completion_handler bug will happen. During application run, or even after application exit. [ 465.835447 ] nr_mremap_pset_diff : 0 [ 477.086886 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 21 [ 477.095620 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000020 [ 477.104345 ] IP : [ < ffffffff81058277 > ] ib_mad_completion_handler + 0xc7 / 0x810 ib_mad_completion_handler + 0xc7 / 0x808 : ib_mad_recv_done_handler at drivers / infiniband / core / mad . c : 1899 ( inlined by ) ib_mad_completion_handler at drivers / infiniband / core / mad . c : 2345 After remove net from pcache miss: [ 465.572131 ] Kernel Profile Points [ 465.575815 ] status name total nr avg . ns [ 465.585510 ] ------- -------------------- ---------------- ---------------- ---------------- [ 465.595206 ] off flush_tlb_others 0.000000000 0 0 [ 465.604901 ] off __do_kmalloc_node 0.656371295 1762220 373 [ 465.614597 ] off pcache_miss 7.172572671 786596 9119 [ 465.624291 ] off pcache_flush 3.698294960 262251 14103 [ 465.633987 ] ------- -------------------- ---------------- ---------------- ---------------- After remove net from pcache flush: [ 684.984000 ] Kernel Profile Points [ 684.987683 ] status name total nr avg . ns [ 684.997379 ] ------- -------------------- ---------------- ---------------- ---------------- [ 685.007074 ] off flush_tlb_others 0.000000000 0 0 [ 685.016770 ] off __do_kmalloc_node 0.627372836 1500543 419 [ 685.026464 ] off pcache_miss 7.128702028 786596 9063 [ 685.036159 ] off pcache_flush 3.660772506 262251 13960 [ 685.045855 ] ------- -------------------- ---------------- ---------------- ---------------- malloc, miss, flush are too slow. Especially the flush, how can it take 13.9us? It must be our handlers! lego_copy_to_user stuff. 04/06 Fri \u00b6 Well. Now we have in-kernel strace, in-kernel readprofile. Yummy. 04/05 Thur \u00b6 Discussion with Yilun. 1. munmap+nr_pgfault figure: count number of pgfaults between munmap, it should be an interesting figure. 2. track number of pgfault at: since there is no eviction, so any mmaped area at M should only have exactly one pcache fetch. 3. I probably want to use per-cpu counter. Anyway, continue strace work first. Finished. 04/04 Wed \u00b6 STRACE Performance \u00b6 TF has very bad performance. It is either due to the syscall or pcache. Now I\u2019m adding facilities to track syscall activities, including average latency, total time. Basic utilities of strace are done. But I somehow need to change the design of multithread strace. Previously, I naively make the thread group keep some info, and let all other threads use that info to do bookkeeping. But this is really hard and not accurate. We first need to make sure we are running on a non-preemptable kernel, so the per-cpu time tracking will be accurate. Besides, we also need to make sure threads do not migrate because of syscalls such as sched_setaffinity. Oh, well, so I though I have to use per-thread strace_info. The first design I thought is: accumulating the counter of one thread to its thread group leader, when it exit. But this is slightly complex, and will affect the thread group leader runtime. So the second solution I came up is let all threads within a process, chain their straec_info together. And normal thread does not need to accumulate the counter. It can just exit. While the thread group leader exit, it walk through the chain to accumulate the counters. This is simpler. Besides, the strace_info of dead thread is safe. No one will touch it. Yeh! Let us do this tomorrow. We will have a robust kernel version strace. SM Heartbeat \u00b6 Continue run some experiments on yesterday\u2019s case. One we sure is SM will keep sending requests to HCA. And it looks like it does not send in a very deterministic interval: [ 1224.034898 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 15 [ 1224.130616 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 15 [ 1224.222189 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 16 [ 1224.417181 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 16 [ 1393.159845 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 17 [ 1393.255546 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 17 [ 1393.347132 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 18 [ 1393.538972 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 18 [ 1449.437542 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 19 [ 1449.533248 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 19 [ 1449.624833 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 20 [ 1449.722512 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 20 [ 4322.423624 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 21 [ 4322.519328 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 21 [ 4322.610914 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 22 [ 4322.708594 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 22 [ 4350.750574 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 23 [ 4350.846278 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 23 [ 4350.937863 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 24 [ 4351.035543 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 24 [ 4519.690559 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 25 [ 4519.786262 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 25 [ 4519.877848 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 26 [ 4519.975527 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 26 [ 4576.396279 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 27 [ 4576.491979 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 27 [ 4576.583565 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 28 [ 4576.681245 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 28 [ 4942.886820 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 29 [ 4942.982523 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 29 [ 4943.074108 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 30 [ 4943.171789 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 30 04/03 Tue \u00b6 BUG BUG BUG \u00b6 Finished basic replication mechanism last night. Today merged several patches. And both Yilun and I think there is something wrong with ib_mad_completion_handler . It seems it will break things behind our back. This is one bug catched today: ib_mad_completion_handler \u00b6 At very early stage : [ 1174.406177 ] newpid : 20 home : 1 replica : 1 [ 1174.452983 ] p2m_fork ( cpu10 ) : I cur : 20 - exe . o new : 21 [ 1177.462795 ] ib_mad_completion_handler 2324 got successful recv cq op 128 mad_got_one 22 [ 1177.556502 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000020 [ 1177.650101 ] IP : [ < ffffffff81059104 > ] ib_mad_completion_handler + 0xb4 / 0x8a0 . / scripts / faddr2line vmImage ib_mad_completion_handler + 0xb4 ib_mad_completion_handler + 0xb4 / 0x899 : ib_mad_recv_done_handler at drivers / infiniband / core / mad . c : 1899 ( inlined by ) ib_mad_completion_handler at drivers / infiniband / core / mad . c : 2325 ib_mad_recv_done_handler () : 1899 : qp_info = mad_list -> mad_queue -> qp_info ; A more scared one after I changed ib_mad_completion_handler. Note that recvcq is the only thread running on cpu4: [ 863.887705 ] p2m_fork ( cpu10 ) : I cur : 20 - exe . o new : 21 [ 868.478424 ] p2m_fork ( cpu10 ) : O succeed cur : 20 - exe . o new : 21 [ 868.541991 ] BUG : unable to handle kernel NULL pointer dereference at 000000000000000 8 [ 868.635569 ] IP : [ < ffffffff810656d4 > ] __schedule + 0x94 / 0x1e0 [ 868.701090 ] PGD 0 [ 868.725010 ] general protection fault : 0000 [ # 1 ] SMP PROCESSOR [ 868.793651 ] CPU : 4 PID : 17 Comm : recvpollcq 4.0.0 - lego - ys + # 737 Source : clear_tsk_need_resched ( prev ); Even this one for Phoenix: [ 763.442043 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000010 [ 763.535636 ] IP : [ < ffffffff81018d6f > ] task_curr + 0xf / 0x30 [ 763.598035 ] PGD 103e956067 PUD 103e964067 PMD 0 [ 763.653154 ] Oops : 0000 [ # 1 ] SMP PROCESSOR [ 763.700992 ] CPU : 12 PID : 21 Comm : word_count - pthr 4.0.0 - lego - ys + # 740 [ 763.777950 ] RIP : 0010 : [ < ffffffff81018d6f > ] [ < ffffffff81018d6f > ] task_curr + 0xf / 0x30 This NEVER happen before. And this part of code should be correct. We\u2019ve ran a lot things.. I doubt if recent IB merge corrupt things. fit_poll_cq \u00b6 Another one: [ 690.401626 ] stat : / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count_datafiles / word_1GB . txt [ 690.507742 ] SYSC_close () CPU12 PID : 21 [ fd : 4 ] -> [ / sys / devices / system / cpu / online ] [ 713.899884 ] ib_mad_completion_handler 2337 got successful recv cq op 128 mad_got_one 21 [ 713.995606 ] ib_mad_completion_handler 2331 got successful send cq op 0 mad_got_one 21 [ 714.087185 ] ib_mad_completion_handler 2337 got successful recv cq op 128 mad_got_one 22 [ 714.184871 ] ib_mad_completion_handler 2331 got successful send cq op 0 mad_got_one 22 [ 742.078102 ] ib_mad_completion_handler 2337 got successful recv cq op 128 mad_got_one 23 [ 742.173810 ] ib_mad_completion_handler 2331 got successful send cq op 0 mad_got_one 23 [ 742.265399 ] ib_mad_completion_handler 2337 got successful recv cq op 128 mad_got_one 24 [ 742.363085 ] ib_mad_completion_handler 2331 got successful send cq op 0 mad_got_one 24 [ 847.063372 ] mlx4_ib_handle_error_cqe syndrome 21 [ 847.116511 ] mlx4_ib_handle_error_cqe syndrome 5 [ 847.170590 ] send request failed at connection 7 as 12 [ 847.230909 ] mlx4_ib_handle_error_cqe syndrome 5 [ 847.284988 ] mlx4_ib_handle_error_cqe syndrome 5 [ 847.339067 ] mlx4_ib_handle_error_cqe syndrome 5 [ 847.393146 ] fit_poll_cq : failed status ( 5 ) for wr_id 1832 [ 847.457624 ] fit_poll_cq : failed status ( 5 ) for wr_id 1833 [ 847.522103 ] fit_poll_cq : connection 7 Recv weird event as -1 [ 847.589701 ] fit_poll_cq : failed status ( 5 ) for wr_id 1834 [ 847.654179 ] fit_poll_cq : connection 7 Recv weird event as -30704 [ 847.725938 ] fit_poll_cq : failed status ( 5 ) for wr_id 1835 [ 847.790416 ] fit_poll_cq : connection 7 Recv weird event as -30704 [ 847.862174 ] mlx4_ib_handle_error_cqe syndrome 5 [ 847.916252 ] mlx4_ib_handle_error_cqe syndrome 5 [ 847.970331 ] mlx4_ib_handle_error_cqe syndrome 5 [ 848.024410 ] mlx4_ib_handle_error_cqe syndrome 5 [ 848.078490 ] fit_poll_cq : failed status ( 5 ) for wr_id 1836 [ 848.142967 ] fit_poll_cq : failed status ( 5 ) for wr_id 1837 [ 848.207446 ] fit_poll_cq : connection 7 Recv weird event as -1 [ 848.275044 ] fit_poll_cq : failed status ( 5 ) for wr_id 1838 [ 848.339523 ] fit_poll_cq : connection 7 Recv weird event as -30704 [ 848.411281 ] fit_poll_cq : failed status ( 5 ) for wr_id 1839 [ 848.475760 ] fit_poll_cq : connection 7 Recv weird event as -30704 [ 848.547517 ] mlx4_ib_handle_error_cqe syndrome 5 [ 848.601596 ] mlx4_ib_handle_error_cqe syndrome 5 [ 848.655675 ] mlx4_ib_handle_error_cqe syndrome 5 [ 848.709753 ] mlx4_ib_handle_error_cqe syndrome 5 [ 848.763832 ] fit_poll_cq : failed status ( 5 ) for wr_id 1840 [ 848.828313 ] BUG : unable to handle kernel NULL pointer dereference at ( null ) [ 848.921908 ] IP : [ < ffffffff8106346d > ] fit_poll_cq + 0x4ad / 0x510 [ 848.989507 ] PGD 0 [ 849.013426 ] Oops : 0002 [ # 1 ] SMP PROCESSOR [ 849.061265 ] CPU : 4 PID : 17 Comm : recvpollcq 4.0.0 - lego - ys + # 744 [ 849.131983 ] RIP : 0010 : [ < ffffffff8106346d > ] [ < ffffffff8106346d > ] fit_poll_cq + 0x4ad / 0x510 [ 849.228700 ] RSP : 0000 : ffff88103e813d88 EFLAGS : 00010246 [ 849.292139 ] RAX : 000000000000100 8 RBX : ffff88103effbad0 RCX : 0000000000000000 [ 849.377418 ] RDX : 0000000000000000 RSI : ffffffff811d46e0 RDI : ffffffff811dbc08 [ 849.462695 ] RBP : ffff88103e813ea8 R08 : 0000000000000000 R09 : 0000000000000000 [ 849.547973 ] R10 : 0000000000000002 R11 : 0000000000000004 R12 : 0000000000000000 [ 849.633251 ] R13 : ffff88103e801008 R14 : 0000000000000004 R15 : ffff88103e813da0 [ 849.718529 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc40000 ( 0000 ) knlGS : 0000000000000000 [ 849.815246 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 849.883884 ] CR2 : 0000000000000000 CR3 : 000000000113 d000 CR4 : 00000000000406 a0 [ 849.969163 ] Stack : [ 849.993082 ] ffffffff81003299 000001 b03e813da0 0000000000000004 0000000000000730 [ 850.080440 ] 000000 8100000005 00001008000000f 9 ffff88103eff8c50 002 c222040000000 [ 850.167798 ] 0010004000000002 ffff88107fc20000 0000000000000731 ffffffff00000005 [ 850.255156 ] ffff8810000000f9 ffff88103eff8c50 0000000000000000 ffff88103e813e38 [ 850.342513 ] ffffffff81019854 0000000000000732 ffff881000000005 ffff8810000000f9 [ 850.429871 ] Call Trace : [ 850.458992 ] < TSK > [ 850.481870 ] [ < ffffffff81003299 > ] ? native_smp_send_reschedule + 0x39 / 0x50 [ 850.560909 ] [ < ffffffff81019854 > ] ? try_to_wake_up + 0xe4 / 0x1f0 [ 850.628506 ] [ < ffffffff81065708 > ] ? __schedule + 0xf8 / 0x1e0 [ 850.691945 ] [ < ffffffff810634d0 > ] ? fit_poll_cq + 0x510 / 0x510 [ 850.757464 ] [ < ffffffff810634e4 > ] fit_poll_cq_pass + 0x14 / 0x30 [ 850.824021 ] [ < ffffffff81020636 > ] kthread + 0xf6 / 0x120 [ 850.882260 ] [ < ffffffff81020540 > ] ? __kthread_parkme + 0x70 / 0x70 [ 850.950898 ] [ < ffffffff8100e572 > ] ret_from_fork + 0x22 / 0x30 /* handle normal reply */ ... memcpy (( void * ) ctx -> reply_ready_indicators [ reply_indicator_index ], & length , sizeof ( int )); ... ( This is a bad memcpy : reply_indicator_index , ctx , etc should be checked .) IB Spec: QP, CQE, WQE, SEND \u00b6 The channel adapter detects the WQE posting and accesses the WQE. The channel adapter interprets the command, validates the WQE\u2019s virtual 12 addresses, translates it to physical addresses, and accesses the data. The outgoing message buffer is split into one or more packets. To each packet the channel adapter adds a transport header (sequence numbers, opcode, etc.). If the destination resides on a remote subnet the channel adapter adds a network header (source & destination GIDs). The channel adapter then adds the local route header and calculates both the variant and invariant checksums. For a Send operation, the QP retrieves the address of the receive buffer from the next WQE on its receive queue, translates it to physical addresses, and accesses memory writing the data. If this is not the last packet of the message, the QP saves the current write location in 38 its context and waits for the next packet at which time it continues writing the receive buffer until it receives a packet that indicates it is the last packet of the operation. It then updates the receive WQE, retires it, and sends an acknowledge message to the originator. When the originator receives an acknowledgment, it creates a CQE on the 5 CQ and retires the WQE from the send queue. A QP can have multiple outstanding messages at any one time but the 8 target always acknowledges in the order sent, thus WQEs are retired in the order that they are posted. 04/02 Mon \u00b6 Patching storage replica handler, able to finish today. 04/01 Sun \u00b6 Anyway. Summary of the day: replication at M almost done. Only flush part left. Storage also need a handler. But we still need code to recover. I\u2019m tired. :-( A month to go. Record a IB error. Using wuklab12 (P) and wuklab14(M+RAMFS), running usr/pcache_conflic.o: P [ 30801.296160 ] ibapi_send_reply () CPU : 8 PID : 19 timeout ( 30010 ms ), caller : clflush_one + 0x1c9 / 0x370 [ 30938.564843 ] mlx4_ib_handle_error_cqe syndrome 21 [ 30938.617988 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30938.672068 ] send request failed at connection 6 as 12 [ 30938.732389 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30938.786470 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30938.840551 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30938.894632 ] fit_poll_cq : failed status ( 5 ) for wr_id 1584 [ 30938.959112 ] fit_poll_cq : failed status ( 5 ) for wr_id 1585 [ 30939.023593 ] fit_poll_cq : connection 6 Recv weird event as -1 [ 30939.091194 ] fit_poll_cq : failed status ( 5 ) for wr_id 1586 [ 30939.155676 ] fit_poll_cq : connection 6 Recv weird event as -30704 [ 30939.227436 ] fit_poll_cq : failed status ( 5 ) for wr_id 1587 [ 30939.291917 ] fit_poll_cq : connection 6 Recv weird event as -30704 [ 30939.363678 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30939.417759 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30939.471839 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30939.525921 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30939.580002 ] fit_poll_cq : failed status ( 5 ) for wr_id 1588 [ 30939.644483 ] BUG : unable to handle kernel NULL pointer dereference at ( null ) [ 30939.738083 ] IP : [ < ffffffff81062fcd > ] fit_poll_cq + 0x4ad / 0x510 [ 30939.805684 ] PGD 0 [ 30939.829604 ] Oops : 0002 [ # 1 ] SMP PROCESSOR [ 30939.877445 ] CPU : 4 PID : 17 Comm : recvpollcq 4.0.0 - lego - ys + # 715 [ 30939.948166 ] RIP : 0010 : [ < ffffffff81062fcd > ] [ < ffffffff81062fcd > ] fit_poll_cq + 0x4ad / 0x510 fit_poll_cq at net / lego / fit_internal . c : 1734 memcpy (( void * ) ctx -> reply_ready_indicators [ reply_indicator_index ], & length , sizeof ( int )); M [ 30913.642698 ] mlx4_ib_handle_error_cqe syndrome 21 [ 30913.695839 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30913.749919 ] send request failed at connection 1 as 12 [ 30913.810236 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30913.864315 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30913.918395 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30913.972474 ] fit_poll_cq : failed status ( 5 ) for wr_id 305 [ 30914.035912 ] fit_poll_cq : failed status ( 5 ) for wr_id 306","title":"April 2018"},{"location":"lego/log/log-04-2018/#april-2018","text":"","title":"April 2018"},{"location":"lego/log/log-04-2018/#0504-fri","text":"We made it. We\u2019ve done our part, now, it depends on reviewers. Please, be mercy, our hardworking deserves something good.","title":"05/04 Fri"},{"location":"lego/log/log-04-2018/#0429-sun","text":"Rolling.","title":"04/29 Sun"},{"location":"lego/log/log-04-2018/#0426-thus","text":"Fix the victim pte_same issue in SMP race cases. SMP is really pain in the ass, how many times? But\u2026 another victim ref count bug show up in SMP. First log in 0426-w15-\u00bd 0426 - w15 -1 / 3 [ 206.381646 ] CPU12 PID28 victim : ffff88207ff69120 index : 4 refcount : 0 nr_fill : 0 locked : 0 flags :( 0x2e )( allocated | usable | hasdata | waitflush ) pcm : ( null ) pset : ffff88207ff72000 [ 206.416658 ] CPU12 PID28 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffd0000000 [ 206.433431 ] CPU12 PID28 victim : ffff88207ff69120 index : 4 refcount : 0 nr_fill : 0 locked : 0 flags :( 0x4e )( allocated | usable | hasdata | flushed ) pcm : ( null ) pset : ffff88207ff72000 [ 206.468429 ] CPU12 PID28 rmap to pset : ffff88207ff72000 set_idx : 0 nr_lru : 63 [ 206.484425 ] CPU12 PID28 victim dumped because : PCACHE_BUG_ON_VICTIM ( ! VictimAllocated ( v ) || ! VictimUsable ( v ) || ! VictimFlushed ( v ) || VictimWriteback ( v ) || VictimLocked ( v )) [ 206.543952 ] CPU : 12 PID : 28 Comm : python 4.0.0 - lego + # 274 [ 206.521849 ] WARNING : CPU : 12 PID : 28 at managers / processor / pcache / victim . c : 196 __put_victim_nolist + 0xa5 / 0xd0 [ 206.722631 ] [ < ffffffff8103b555 > ] __put_victim_nolist + 0xa5 / 0xd0 [ 206.729127 ] [ < ffffffff8103c419 > ] victim_try_fill_pcache + 0x2d9 / 0x460 [ 206.736107 ] [ < ffffffff8103b740 > ] ? victim_insert_hit_entry + 0x170 / 0x170 [ 206.743378 ] [ < ffffffff810371ea > ] pcache_handle_fault + 0x18a / 0x750 [ 206.399206 ] CPU8 PID19 victim : ffff88207ff69120 index : 4 refcount : 0 nr_fill : 0 locked : 0 flags :( 0x4e )( allocated | usable | hasdata | flushed ) pcm : ( null ) pset : ffff88207ff72000 [ 206.425092 ] CPU8 PID19 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffd0000000 [ 206.450977 ] CPU8 PID19 victim : ffff88207ff69120 index : 4 refcount : 0 nr_fill : 0 locked : 0 flags :( 0x4e )( allocated | usable | hasdata | flushed ) pcm : ( null ) pset : ffff88207ff72000 [ 206.476475 ] CPU8 PID19 rmap to pset : ffff88207ff72000 set_idx : 0 nr_lru : 63 [ 206.501779 ] CPU8 PID19 victim dumped because : PCACHE_BUG_ON_VICTIM ( victim_ref_count ( v ) == 0 ) [ 206.549963 ] CPU : 8 PID : 19 Comm : kvictim_flushd 4.0.0 - lego + # 274 [ 206.532803 ] WARNING : CPU : 8 PID : 19 at . / include / processor / pcache_victim . h : 119 __victim_flush_func + 0x1e4 / 0x1f0","title":"04/26 Thus"},{"location":"lego/log/log-04-2018/#0425","text":"Stay humble. Be real.","title":"04/25"},{"location":"lego/log/log-04-2018/#0422-sun","text":"Testing. Hardworking!","title":"04/22 Sun"},{"location":"lego/log/log-04-2018/#0421-sat","text":"Another major bug report in 0421-w15-19. Rmapped corrupted. lock issue? Fixed. It is handle_m2m_fork bug. pcache_miss_error + 0x20 Keep it going. I can not remember how many times I have seen this bug issue. And I have no idea. [ 714.144354 ] IP : [ < ffffffffffff8100 > ] 0xffffffffffff8100 [ 714.150171 ] PGD 115 c067 PUD 115e067 PMD 0 [ 714.154729 ] Oops : 0010 [ # 1 ] SMP PROCESSOR [ 714.159189 ] CPU : 0 PID : 15 Comm : ib_mad_completi 4.0.0 - lego + # 245 [ 714.165976 ] BUG : unable to handle kernel paging request at ffffffffffff8100 [ 714.173732 ] IP : [ < ffffffffffff8100 > ] 0xffffffffffff8100 [ 714.179549 ] PGD 115 c067 PUD 115e067 PMD 0 [ 714.184106 ] RIP : 0010 : [ < ffffffffffff8100 > ] [ < ffffffffffff8100 > ] 0xffffffffffff8100 [ 714.192638 ] RSP : 0000 : ffff88103e88fc80 EFLAGS : 00010046 [ 714.198552 ] RAX : 6e82000000000098 RBX : 7 b0bffffffffffff RCX : 0000000000000001 [ 714.206503 ] RDX : ffff88103e88fd28 RSI : 0000000000000000 RDI : 44 c0ffffffff8116 [ 714.214453 ] RBP : ffff88103e88fcd0 R08 : 000000000000001f R09 : ffff88103e8643c0 [ 714.222403 ] R10 : ffff88103e88fe68 R11 : 0000000000000001 R12 : a9670000018d71ba [ 714.230354 ] R13 : 0000000000000000 R14 : ffff88103e85d0f8 R15 : ffff88103dd58000 [ 714.238304 ] Oops : 0010 [ # 2 ] SMP PROCESSOR [ 714.242763 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc00000 ( 0000 ) knlGS : 0000000000000000 [ 714.251781 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 714.258180 ] CR2 : ffffffffffff8100 CR3 : 000000000115 9000 CR4 : 00000000000406 b0 [ 714.266130 ] CPU : 10 PID : 20 Comm : python 4.0.0 - lego + # 245 [ 714.272141 ] RIP : 0010 : [ < ffffffffffff8100 > ] [ < ffffffffffff8100 > ] 0xffffffffffff8100 [ 714.280673 ] RSP : 001 8 : ffff88103dd8fe10 EFLAGS : 00010202 [ 714.286588 ] RAX : ffff88101fa54270 RBX : 00000000000 c92a6 RCX : 0000000000000002 [ 714.294538 ] RDX : 00000000f fffffff RSI : 0000000000000000 RDI : 44 c0ffffffff8116 [ 714.302488 ] RBP : ffff88103dd8fe20 R08 : ffff88101fa6f000 R09 : ffff88101fa54400 [ 714.310439 ] R10 : ffff880000000000 R11 : 00000000407e9 c00 R12 : ffff88101fa54000 [ 714.318389 ] R13 : ffff88103dd68000 R14 : ffff88101fa60000 R15 : ffff88101fa54000 [ 714.326339 ] Stack : [ 714.328569 ] FS : 00007f fff7fdf740 ( 0000 ) GS : ffff88107fca0000 ( 0000 ) knlGS : 0000000000000000 [ 714.337585 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 714.343984 ] CR2 : ffffffffffff8100 CR3 : 000000103 dd9a000 CR4 : 00000000000406 a0 [ 714.351936 ] Stack : [ 714.354165 ] ffffffff810157f9 00000000003 d0f00 ffff88103dd8fec0 ffffffff8101dde5 [ 714.362309 ] ffff88103dd8fe68 ffffffff81036788 000000000000003 8 000000000000003 8 [ 714.370453 ] 00007f ffd89a79c0 ffff88101fa541c0 ffff88101fa54188 0000000000000000 [ 714.378598 ] 000000101f a60000 00007f ffd89a79d0 00007f ffd89a7700 0000000000000000 [ 714.386742 ] 00007f ffd89a6fb0 ffff88103dd8ff58 000000000000003 8 00000000003 d0f00 [ 714.394886 ] Call Trace : [ 714.397600 ] ffffffff81014f37 00000000000000 86 ffff88107fc05d80 ffff88103e864000 [ 714.405745 ] 0000000000000000 ffff88107fc04980 0000000000000000 0000000000000000 [ 714.413889 ] ffff88103e85d0f8 ffff88103dd58000 ffff88103e88fce8 ffffffff81016bb7 [ 714.422034 ] 000000007f c05d80 ffff88103e88fd10 ffffffff81006754 ffffffffffff0000 [ 714.430177 ] ffff88107fc05d80 ffff88103e864000 ffff88103e88fe00 ffffffff8100e4ea [ 714.438321 ] Call Trace : [ 714.441037 ] < TSK > [ 714.443169 ] [ < ffffffff810157f9 > ] ? ktime_get + 0x19 / 0x60 [ 714.448890 ] [ < ffffffff8101dde5 > ] copy_process + 0x2c5 / 0x1170 [ 714.454998 ] [ < ffffffff81036788 > ] ? strace_printflags + 0x88 / 0xc0 [ 714.461495 ] < TSK > [ 714.463627 ] [ < ffffffff81014f37 > ] ? update_wall_time + 0x47 / 0x6b0 [ 714.470123 ] [ < ffffffff81016bb7 > ] tick_handle_periodic + 0x67 / 0x70 [ 714.476716 ] [ < ffffffff81006754 > ] apic_timer_interrupt + 0x55 / 0x90 [ 714.483309 ] [ < ffffffff8101ecb6 > ] do_fork + 0x26 / 0x160 [ 714.488738 ] [ < ffffffff8101eea9 > ] sys_clone + 0x29 / 0x30 [ 714.494265 ] [ < ffffffff8100e8ad > ] do_syscall_64 + 0x3d / 0xd0 [ 714.500180 ] [ < ffffffff8100d7ac > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 714.507257 ] [ < ffffffff8100e4ea > ] smp__apic_timer_interrupt + 0x6a / 0x70 [ 714.514335 ] < EOT >","title":"04/21 Sat"},{"location":"lego/log/log-04-2018/#0420-fri","text":"Glad TF finally working now! Keep seeing this message from kernel. It have been many many times. Very deterministic. BUG : unable to handle kernel paging request at ffffffffffff8100","title":"04/20 Fri"},{"location":"lego/log/log-04-2018/#0419-thur","text":"Patched clflush to use tgid, n_nid directly without task_struct.","title":"04/19 Thur"},{"location":"lego/log/log-04-2018/#in-a-256m-excache-today-0419-w15-4-a-timeout-happen-first-which-will-be-handled-as-segfault-to-kill-all-threads-in-an-eviction-victim_prepare_hits-the-get_memory_nodes-encounter-the-null-again-looks-like-the-thread_group-mm-got-cleared-before","text":"","title":"In a 256M excache today (0419-w15-4), a timeout happen first, which will be handled as segfault to kill all threads. In an eviction-&gt;victim_prepare_hits, the get_memory_nodes() encounter the NULL again. Looks like the thread_group-&gt;mm got cleared before."},{"location":"lego/log/log-04-2018/#0418-wed","text":"Try best to fix the pipe bug. (I found it by using my old way of debugging. By writing a function that test if PTE is corrupted or not. I put that function around the sycall enter/exit. So it help to find which syscall corrupt memory. I have used this stupid technique to find so many hard-to-find memory corruption bugs.....) do_close_on_exec dup2 Re-read Yutong\u2019s patch again. It touches a lot handler code. This has to be verified before using any nowait reply. pipe\u2019s wakeup may have issue? 0418-w15-41. 39sec","title":"04/18 Wed"},{"location":"lego/log/log-04-2018/#0417-tue","text":"Checking list: -pcache: ibapi use va or pa, does it matter?- No, I change it to use the VA. Then we don\u2019t have the need to use PA reply any more. =ib_mad, does it really corrupt Memory= Still not sure. Should be something come from the ib_poll_cq . M side per PTE lock, check if the lock is really the same lock! -Mail I20. Check CPT.- Dist-VMA First make sure, TF+no-dist-vma work on my own setting. Though sometimes random bug happen (I doubt it is IB). Then turn on dist-vma w/wo zerofill w/wo kfree w/wo all-zero Debug. w/wo M side per PTE lock Change most handlers to use TX buffer. Reduce the random mismatched reply case. P side watchdog patch: what to print -It looks like it is more easier to have bug when I turn on those debug counter printing. I probably should check those buffer mgmt. All next test have zerofill:- w print F 0417-w15-2(rmap_walk list_for_each_entrry #GP) F 0417-w15-3(pcache_copy_page_range corrupted PTE) F 0417-w15-4(fit_poll_cq+0x39 ib_poll_cq() \u2026) F 0417-w15-5(pcache_copy_page_range corrupted PTE) wo strace exit: S 0417-w15-6(each 100 step take ~39s/ Linux is ~34s) S 0417-w15-7(filling shuffle data, that works) F 0417-w15-8(pcache_copy_page_range+0x5d1) F 0417-w15-9(rmap_walk+0x47 #GP) disable strace: F 0417-w15-10(pcache_copy_page_range+0x5d1) Conclusion it has nothing to do with the strace thing. most of them fail around nr_reqs=19103 Why the pcache_copy_page_range always happen, after some fork, execve. w strace (fork, vfork, clone, execve) F 0417-w15-11 (pcache_cp_pg_range). Understand its flow. Back to make sure P side per PTE lock is correct. If it is pcache_cp fault, it always fail at nr_reqs=19103 . And it is: 1) python fork, 2) execve sh. S 0417-w15-12. With global PTE lock. Passed the failed stage above. F 0417-W15-13. With global PTE lock. Failed at pcache_cp. Same place. (Since global PTE lock also fail, so it is not the lock issue. Still someone write to wrong memory.) F 0417-w15-14. With global PTE lock. Same place. Found that I printed a misleading debug info. Modified a little bit to print the actual pte content. Hope can get some valid info next round. F 0417-w15-15. Same place. copy: addr: 0x7fffdca07000, ptecont: 0x8800000000000 . zap: ptent: 0x340 address: 0x7fffdca08000 . F 0417-w15-16. Well. BUG in ib_mad_send handler. I add the same checking in ib_mad_receive. This is really just used to catch it. Not fixing it. F 0417-w15-17. Again, addr: 0x7fffdc207000, ptecont: 0x8800000000000 F 0417-w15-18. addr: 0x7fffdca07000, ptecont: 0x8800000000000 Conclusion Only these two addresses addr: 0x7fffdca07000, ptecont: 0x8800000000000 pte:ffff88103ea87038 (0x8800000000000) pfn:0x0 flags:(0x8800000000000) addr: 0x7fffdc207000, ptecont: 0x8800000000000 pte:ffff88103ea97038 (0x8800000000000) pfn:0x0 flags:(0x8800000000000) Bug found. In pipe_read/write. It somehow corrupted memory. Damn. -Another first thing, check this weird log.. : Hmm, this log should be fine. mad_post is after recv_done_handler. So even if we detect corrupted memory in handler, it has nothing to do with mad_post. The root cause should come from ib_poll_cq, that is where we pass wc to, and where the wc.wr_id was filled in.- [ 3850.911144 ] ib_mad_recv_done_handler () : c1 : 2060 c2 : 12 wc -> wr_id : 0xffff88103eea1398 [ 3850.921881 ] ib_mad_post_receive_mads () : c1 : 2060 c2 : 13 recv_wr . wr_id : 0xffff88103eea1008 recv_queue : ffff88103ee42520 [ 3850.933620 ] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 13 [ 3850.942346 ] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 14 [ 3850.951266 ] ib_mad_recv_done_handler () : c1 : 2061 c2 : 13 wc -> wr_id : 0xffff88103eea1560 [ 3850.961999 ] ib_mad_post_receive_mads () : c1 : 2061 c2 : 14 recv_wr . wr_id : 0xffff88103eea11d0 recv_queue : ffff88103ee42520 [ 3850.973737 ] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 14 [ 3851.257563 ] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 15 [ 3851.266295 ] ib_mad_recv_done_handler () : c1 : 2062 c2 : 14 wc -> wr_id : 0xffff88103eea1728 [ 3851.277029 ] ib_mad_post_receive_mads () : c1 : 2062 c2 : 15 recv_wr . wr_id : 0xffff88103eea1398 recv_queue : ffff88103ee42520 [ 3851.288767 ] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 15 [ 3851.297493 ] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 16 [ 3851.306413 ] ib_mad_recv_done_handler () : c1 : 2063 c2 : 15 wc -> wr_id : 0xffff88103eea18f0 [ 3851.317147 ] ib_mad_post_receive_mads () : c1 : 2063 c2 : 16 recv_wr . wr_id : 0xffff88103eea1560 recv_queue : ffff88103ee42520 [ 3851.328886 ] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 16 [ 3851.903180 ] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 17 [ 3851.911913 ] ib_mad_recv_done_handler () : c1 : 2064 c2 : 16 wc -> wr_id : 0xffff88103eea1ab8 [ 3851.922646 ] ib_mad_post_receive_mads () : c1 : 2064 c2 : 17 recv_wr . wr_id : 0xffff88103eea1728 recv_queue : ffff88103ee42520 [ 3851.934384 ] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 17 [ 3851.943110 ] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 18 [ 3851.952030 ] ib_mad_recv_done_handler () : c1 : 2065 c2 : 17 wc -> wr_id : 0xffff88103eea1c80 [ 3851.962764 ] ib_mad_post_receive_mads () : c1 : 2065 c2 : 18 recv_wr . wr_id : 0xffff88103eea18f0 recv_queue : ffff88103ee42520 [ 3851.974502 ] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 18 [ 3864.723128 ] *** FIT layer ready to go ! [ 3864.727206 ] *** [ 3867.339488 ] Processor LLC Configurations : [ 3867.343760 ] PhysStart : 0x100000000 [ 3867.348705 ] VirtStart : 0xffff880100000000 [ 3867.354329 ] Registered Size : 0x400000000 [ 3867.359274 ] Actual Used Size : 0x208000000 [ 3867.364219 ] NR cachelines : 2097152 [ 3867.368776 ] Associativity : 8 [ 3867.372751 ] NR Sets : 262144 [ 3867.377210 ] Cacheline size : 4096 B [ 3867.381672 ] Metadata size : 64 B [ 3867.385937 ] NR cacheline bits : 12 [ 0 - 11 ] 0x0000000000000fff [ 3867.392821 ] NR set - index bits : 18 [ 12 - 29 ] 0x000000003ffff000 [ 3867.399705 ] NR tag bits : 34 [ 30 - 63 ] 0xffffffffc0000000 [ 3867.406588 ] NR pages for data : 2097152 [ 3867.411147 ] NR pages for meta : 32768 [ 3867.415509 ] Cacheline ( pa ) range : [ 0x100000000 - 0x2ffffffff ] [ 3867.423848 ] Metadata ( pa ) range : [ 0x300000000 - 0x307ffffff ] [ 3867.432186 ] Cacheline ( va ) range : [ 0xffff880100000000 - 0xffff8802ffffffff ] [ 3867.440524 ] Metadata ( va ) range : [ ffff880300000000 - 0xffff880307ffffff ] [ 3867.448862 ] pcache_set_map ( 064 B ) : [ ffff88207ec00000 - 0xffff88207fbfffff ] [ 3867.457201 ] Way cache stride : 0x40000000 [ 3867.462048 ] Memmap $ semantic : memblock reserved [ 3867.468156 ] NR victim $ entries : 8 [ 3867.472725 ] newpid : 1 home : 1 replica : 1 [ 3867.476980 ] p2m_fork ( cpu0 ) : I cur : 1 - kernel_init new : 20 [ 3867.482718 ] p2m_fork ( cpu0 ) : O succeed cur : 1 - kernel_init new : 20 [ 3867.489197 ] Processor : Processor manager is running . [ 3867.494724 ] Online CPU : 0 , 2 , 4 , 6 , 8 , 10 , 12 , 14 , 16 , 18 , 20 , 22 [ 3867.500444 ] Active CPU : 0 , 2 , 6 , 10 , 12 , 14 , 16 , 18 , 20 , 22 [ 3867.505777 ] [ 0 ] Thread [ kvictim_flushd : 19 ] pinned at CPU 8 [ 3867.511982 ] [ 1 ] Thread [ recvpollcq : 17 ] pinned at CPU 4 [ 3867.539217 ] do_close_on_exec () : TODO , not implemented . [ 3867.549209 ] STDOUT : --- [ Before execv ^ V ] --- [ 3867.553870 ] STDOUT : --- [ e --- [ 3867.557880 ] newpid : 20 home : 1 replica : 1 [ 3867.562248 ] p2m_fork ( cpu10 ) : I cur : 20 - exe . o new : 21 [ 3867.567560 ] p2m_fork ( cpu10 ) : O succeed cur : 20 - exe . o new : 21 [ 3867.573670 ] CPU12 PID21 sys_execve [ 3867.578681 ] do_close_on_exec () : TODO , not implemented . [ 3867.584215 ] CPU12 PID21 sys_execve = 0 , 0x0 [ 3867.599867 ] BUG : unable to handle kernel paging request at 000000040 8446080 [ 3867.607436 ] IP : [ < ffffffff8101bbbf > ] task_tick_rt + 0x1f / 0xd0","title":"04/17 Tue"},{"location":"lego/log/log-04-2018/#0416-mon","text":"Make dist-vma work with TF first. Tough work. 0416-w14-7 : 1) do_wp_page triggered, 2) dealock on per pte lock. This really should not happen. It is single worker. Basically means the page->lock is not intialized. Probabaly our per PTE lock implementation is wrong. [ 5220.250552 ] hb : worker [ 0 ] CPU 4 stucked [ 5220.254819 ] hb : common_header [ op = 0x20000000 src_nid : 0 ] [ 5220.260734 ] hb : msg [ pid = 21 , tgid = 21 , flags = 0x51 , vaddr = 0x7fff7b7fdfb8 ] [ 5220.267911 ] CPU : 4 PID : 31 Comm : thpool - worker0 4.0.0 - lego - ys + # 237 [ 5220.274890 ] RIP : 0010 : [ < ffffffff81031aa3 > ] [ < ffffffff81031aa3 > ] handle_lego_mm_fault + 0x373 / 0x4f0 handle_lego_mm_fault + 0x373 / 0x4ee : arch_spin_lock at arch / x86 / include / asm / spinlock . h : 21 ( inlined by ) spin_lock at include / lego / spinlock . h : 72 ( inlined by ) do_anonymous_page at managers / memory / vm / fault . c : 115 ( inlined by ) handle_pte_fault at managers / memory / vm / fault . c : 142 ( inlined by ) handle_lego_mm_fault at managers / memory / vm / fault . c : 225 A IB bug during normal run (P M S TF), this is REALLY weird: [ 395.259560 ] CPU12 PID21 sys_execve [ 395.263345 ] BUG : unable to handle kernel NULL pointer dereference at 00000000000001 a0 [ 395.272068 ] IP : [ < ffffffff81064c09 > ] fit_poll_cq + 0x39 / 0x530 fit_poll_cq + 0x39 / 0x523 : git :( test_vma )] $ . / scripts / faddr2line vmImage fit_poll_cq + 0x39 ib_poll_cq at include / rdma / ib_verbs . h : 1614 ( inlined by ) fit_poll_cq at net / lego / fit_internal . c : 1671 Catch the ib_mad bug once.. and mlx4_error follows. I added more checking to where the mad_queue was assigned. [ 787.471385 ] ib_mad_completion_handler 2365 got successful recv cq op 128 mad_got_one 15 [ 787.480124 ] BUG ! mad_list : ffff88103eea1728 mad_queue : ( null ) [ 787.487491 ] ------------ [ cut here ] ------------ [ 787.492630 ] WARNING : CPU : 0 PID : 15 at drivers / infiniband / core / mad . c : 1909 ib_mad_completion_handler + 0xa56 / 0xab0","title":"04/16 Mon"},{"location":"lego/log/log-04-2018/#0415-sun","text":"Trying TF myself. Had a bug report on 0415-w15-5, on fork, execve etc. [ 317.436811 ] newpid : 22 home : 1 replica : 1 [ 317.477701 ] pte : ffff88103e94a038 pfn : 0x0 flags :() [ 317.482752 ] pte dumped because : corrupted [ 317.487213 ] ------------ [ cut here ] ------------ [ 317.492352 ] WARNING : CPU : 14 PID : 22 at managers / processor / pgtable . c : 365 pcache_copy_page_range + 0x5d1 / 0x6c0 [ 317.503213 ] CPU : 14 PID : 22 Comm : python 4.0.0 - lego + # 93 [ 317.552082 ] Call Trace : [ 317.554799 ] < TSK > [ 317.556930 ] [ < ffffffff810123a1 > ] __warn . constprop .0 + 0x91 / 0xd0 [ 317.563330 ] [ < ffffffff8101246f > ] warn_slowpath_null + 0xf / 0x20 [ 317.569634 ] [ < ffffffff8102d401 > ] pcache_copy_page_range + 0x5d1 / 0x6c0 [ 317.576615 ] [ < ffffffff81037ed7 > ] fork_dup_pcache + 0x27 / 0x30 [ 317.582723 ] [ < ffffffff8101e514 > ] copy_process + 0xcf4 / 0x1140 [ 317.588833 ] [ < ffffffff8101e986 > ] do_fork + 0x26 / 0x160 [ 317.594264 ] [ < ffffffff8101eb89 > ] sys_clone + 0x29 / 0x30 [ 317.599789 ] [ < ffffffff8100e66d > ] do_syscall_64 + 0x3d / 0xd0 [ 317.605705 ] [ < ffffffff8100d56c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 317.612782 ] < EOT > [ 317.614917 ] --- [ end trace 0000000000000000 ] --- [ 317.625561 ] p2m_fork ( cpu14 ) : I cur : 22 - python new : 36 [ 330.209312 ] p2m_fork ( cpu14 ) : O succeed cur : 22 - python new : 36 [ 330.310909 ] ------------ [ cut here ] ------------ [ 330.315864 ] BUG : failure at managers / processor / pcache / rmap . c : 804 / pcache_zap_pte () ! [ 330.324302 ] Kernel Panic - not syncing : BUG ! [ 330.329050 ] CPU : 0 PID : 36 Comm : python 4.0.0 - lego + # 93 [ 330.377824 ] Call Trace : [ 330.380540 ] < TSK > [ 330.382672 ] [ < ffffffff81026493 > ] panic + 0xc2 / 0x105 [ 330.387908 ] [ < ffffffff8101bbcc > ] ? task_tick_rt + 0x2c / 0xd0 [ 330.393920 ] [ < ffffffff81019245 > ] ? scheduler_tick + 0x55 / 0x60 [ 330.400126 ] [ < ffffffff810168f5 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 330.406913 ] [ < ffffffff81006684 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 330.413700 ] [ < ffffffff8100e2aa > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 330.420973 ] [ < ffffffff810125ad > ] ? printk + 0x11d / 0x1b0 [ 330.426597 ] [ < ffffffff810375bc > ] pcache_zap_pte + 0x14c / 0x190 [ 330.432802 ] [ < ffffffff81035db0 > ] ? __pcache_remove_rmap_one + 0x70 / 0x70 [ 330.439978 ] [ < ffffffff8102cd25 > ] unmap_page_range + 0x325 / 0x3f0 [ 330.446379 ] [ < ffffffff8102ce0e > ] release_pgtable + 0x1e / 0x40 [ 330.452487 ] [ < ffffffff81037ef8 > ] pcache_process_exit + 0x18 / 0x20 [ 330.458984 ] [ < ffffffff8101d3c4 > ] mmput + 0x34 / 0xb0 [ 330.464123 ] [ < ffffffff8102c38d > ] do_execve + 0x42d / 0x760 [ 330.469845 ] [ < ffffffff8102c6c9 > ] sys_execve + 0x9 / 0x10 [ 330.475371 ] [ < ffffffff8100e66d > ] do_syscall_64 + 0x3d / 0xd0 [ 330.481286 ] [ < ffffffff8100d56c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 [ 330.488364 ] < EOT > [ 330.490501 ] --- [ end Kernel panic - not syncing : BUG ! one more [ 369.223161] newpid: 22 home:1 replica: 1 [ 369.264307] pte:ffff88103ea41038 (0x0) pfn:0x0 flags:() [ 369.269938] pte dumped because: corrupted [ 369.274399] ------------[ cut here ]------------ [ 369.279538] WARNING: CPU: 14 PID: 22 at managers/processor/pgtable.c:365 pcache_copy_page_range+0x5d1/0x6c0 [ 369.290398] CPU: 14 PID: 22 Comm: python 4.0.0-lego+ #94 [ 369.296310] Stack: [ 369.341976] <TSK> [ 369.344107] [<ffffffff810123a1>] __warn.constprop.0+0x91/0xd0 [ 369.350508] [<ffffffff8101246f>] warn_slowpath_null+0xf/0x20 [ 369.356809] [<ffffffff8102d401>] pcache_copy_page_range+0x5d1/0x6c0 [ 369.363790] [<ffffffff81037f07>] fork_dup_pcache+0x27/0x30 [ 369.369897] [<ffffffff8101e514>] copy_process+0xcf4/0x1140 [ 369.376006] [<ffffffff8101e986>] do_fork+0x26/0x160 [ 369.381435] [<ffffffff8101eb89>] sys_clone+0x29/0x30 [ 369.386960] [<ffffffff8100e66d>] do_syscall_64+0x3d/0xd0 [ 369.392875] [<ffffffff8100d56c>] entry_SYSCALL64_slow_path+0x25/0x25 [ 369.399952] <EOT> [ 369.402086] ---[ end trace 0000000000000000 ]--- [ 369.412750] p2m_fork(cpu14): I cur:22-python new:36 [ 369.418215] p2m_fork(cpu14): O succeed cur:22-python new:36 [ 369.500829] ptent: 0x340 address: 0x7fffe2408000 [ 369.505783] pte:ffff88103dbe5040 (0x340) pfn:0x0 flags:(dirty|global|softw1) [ 369.513637] pte dumped because: corrupted [ 369.518095] ------------[ cut here ]------------ [ 369.523236] BUG: failure at managers/processor/pcache/rmap.c:808/pcache_zap_pte()! [ 369.531672] Kernel Panic - not syncing: BUG!","title":"04/15 Sun"},{"location":"lego/log/log-04-2018/#0414-sat","text":"Check if page table pages, page themselves are freed in munmap, at both P and M. Need to confirm. Will they do harm Implement replication Add IB counter","title":"04/14 Sat"},{"location":"lego/log/log-04-2018/#0413-fri","text":"Patched M side pgtable to use per PTE/PMD lock. So thpool in M will not be bottlnecked by the page_table_lock.","title":"04/13 Fri"},{"location":"lego/log/log-04-2018/#ib_mad_recv_done_handler-may-corrupt-memory-again","text":"Somehow, during testing of this patch. Running with MT-Phoenix 1GB, the P side has reported bad pgd entries. I\u2019m using fork+execve way. The child(phoenix) already exit. This msg is printed when parent exit_mm. The pgd table should either be 0, or valid pud va. Memory corruption happened\u2026 [ 2551.687806 ] Kernel strace [ 2551.690715 ] Task : 21 : 21 nr_accumulated_threads : 1 [ 2551.696327 ] % time seconds usecs / call calls errors syscall [ 2551.703704 ] ------ -------------- ----------- --------- --------- ---------------- [ 2551.712141 ] 98.63 66.942660568 66942661 1 0 sys_wait4 [ 2551.719898 ] 0.45 0.457060789 457061 1 0 sys_clone [ 2551.727654 ] 0.20 0.204320071 51081 4 0 sys_brk [ 2551.735216 ] 0.40 0.040378189 40379 1 0 sys_mmap [ 2551.742876 ] 0.13 0.013682424 4561 3 0 sys_write [ 2551.750633 ] 0.10 0.000001039 2 1 0 sys_newfstat [ 2551.758681 ] 0.88 0.000000888 1 2 0 sys_rt_sigaction [ 2551.767114 ] 0.79 0.000000792 1 2 0 sys_futex [ 2551.774871 ] 0.77 0.000000770 1 1 0 sys_rt_sigprocmask [ 2551.783501 ] 0.54 0.000000548 1 1 0 sys_arch_prctl [ 2551.791742 ] 0.49 0.000000499 1 1 0 sys_newuname [ 2551.799789 ] 0.46 0.000000469 1 1 0 sys_getrlimit [ 2551.807933 ] 0.19 0.000000195 1 1 0 sys_set_tid_address [ 2551.816659 ] 0.19 0.000000190 1 1 0 sys_set_robust_list [ 2551.825386 ] 0.18 0.000000181 1 1 0 sys_ioctl [ 2551.833143 ] ------ -------------- ----------- --------- --------- ---------------- [ 2551.841577 ] 100.00 67.658107612 22 0 total [ 2551.848945 ] [ 2551.850591 ] [ 2551.852240 ] Kernel Profile Points [ 2551.855924 ] status name total nr avg . ns [ 2551.865621 ] ------- -------------------- ---------------- ---------------- ---------------- [ 2551.875317 ] off flush_tlb_others 0.000204992 58 3535 [ 2551.885014 ] off __do_kmalloc_node 0.300783843 281501 1069 [ 2551.894709 ] off __pcache_zerofill 0.009844770 16558 595 [ 2551.904404 ] off pcache_miss 54.414457906 257869 211016 [ 2551.914100 ] off pcache_flush 0.000000000 0 0 [ 2551.923795 ] ------- -------------------- ---------------- ---------------- ---------------- [ 2551.933490 ] [ 2552.074985 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956028 ( ffffffff81146ca0 ) [ 2552.084206 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956030 ( ffff88103e956030 ) [ 2552.093611 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956038 ( ffff88103e956030 ) [ 2552.103016 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956048 ( ffff88103cc48740 ) [ 2552.112421 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956050 ( 00000000000001 c0 ) [ 2552.121825 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956058 ( ffff88103eea2008 ) [ 2552.131230 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956060 ( ffff88103eea17d8 ) [ 2552.140635 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956068 ( ffff88103ee42520 ) [ 2552.150040 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9560e8 ( 000000103e9560f 0 ) [ 2552.159444 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956118 ( 010200 8081018101 ) [ 2552.168849 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956120 ( 3 c010b0012000000 ) [ 2552.178254 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956128 ( 0000000000001100 ) [ 2552.187659 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956138 ( 00000000f fffffff ) [ 2552.197064 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956158 ( 0307 8 a2402010101 ) [ 2552.206467 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956160 ( 0307 8 a2453946600 ) [ 2552.215872 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956168 ( 0307 8 a2450946600 ) [ 2552.225277 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956170 ( 0310 800051946600 ) [ 2552.234682 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956178 ( c902000100000000 ) [ 2552.244088 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956198 ( bfd0cc054a122000 ) [ 2552.253492 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561a0 ( 0000000000 98 b9c8 ) [ 2552.262897 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561a8 ( bfe0fe0610914e01 ) [ 2552.272302 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561b0 ( 000000000050f 2 c7 ) [ 2552.281706 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561b8 ( bfd9a30000ec5100 ) [ 2552.291111 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561c0 ( bffc91d40f20f2c7 ) [ 2552.300516 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561c8 ( 0f 20 cd054a20f2c7 ) [ 2552.309920 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561d0 ( 1094 edcf0f60edcf ) [ 2552.319325 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e9561d8 ( 0000000000000100 ) [ 2552.328730 ] . / arch / x86 / include / asm / pgtable . h : 579 : bad pgd ffff88103e956218 ( 0000000000005 aa5 ) [ 2552.338151 ] nr_pgfault : 26 Second run, saw this invalid pointer deference again! Combined with the above log, I think ib_mad is definitely corrupting memory! I have to take a look. qp_info = mad_list->mad_queue->qp_info;","title":"ib_mad_recv_done_handler may corrupt memory, again."},{"location":"lego/log/log-04-2018/#patching-the-handlers-to-use-tx-buffer","text":"Patched. Once race condition: pcache_handle_miss use the page itself as the reply buffer. Assume later on, it changes to use nowait reply. When the reply is buffered in the queue and has not been sent. Another munmap comes in and invalidate this area, then the page will be freed. The data is invalidate. But this case seems abnormal. The application will not do so I guess.","title":"Patching the handlers to use tx buffer."},{"location":"lego/log/log-04-2018/#check-if-page-table-pages-page-themselves-are-freed-in-munmap-at-both-p-and-m-need-to-confirm","text":"","title":"Check if page table pages, page themselves are freed in munmap, at both P and M. Need to confirm."},{"location":"lego/log/log-04-2018/#tonight-task-think-about-how-to-do-the-vma-replication-how-to-combine-with-the-line-replicaiton","text":"","title":"Tonight task. Think about how to do the VMA replication, how to combine with the $ line replicaiton."},{"location":"lego/log/log-04-2018/#0412-thur","text":"Patched zerofill. All done. Testing new driver fix with Phoenix - 1 st run, the mismatch reply is still there. mmap() replied address is different from the one printed. So segfault follows. (0412-w15-4) - 2st run, 3st run, succeed. 0412-w15-9 0412-w14-9 First time testing phoenix with zerofill (no net). Somehow, P has pcache timeout, but M\u2019s watchdog show there is no pending requests. This happen once before I remember\u2026 0412-w15-10. Have not seen this ib mad thing for a long time. Indeed somewhere is wrong. [ 297.794969] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 15 [ 297.803706] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020 [ 297.812431] IP: [<ffffffff81058937>] ib_mad_completion_handler+0xc7/0x810 2","title":"04/12 Thur"},{"location":"lego/log/log-04-2018/#0411-wed","text":"Adding anon first touch opt. 0411-p/m-9 : this log indicate M does not have any unhandled requests, but P side has 1 __pcache_fill timeout. It seems the message is lost somewhere. 0411-p/m-11 : catch one with the debug msg Yiying added. She says the M side send queue has 2 reqs. But poll does not return any error. Weird. Help debugging IB issue.","title":"04/11 Wed"},{"location":"lego/log/log-04-2018/#0410-tue","text":"Found. IB stuck. Damn. [ 2240.294960] RIP: 0010:[<ffffffff8104a6d8>] [<ffffffff8104a6d8>] mlx4_ib_poll_cq+0x378/0x6a0 [ 2242.694733] RIP: 0010:[<ffffffff8104a6d8>] [<ffffffff8104a6d8>] mlx4_ib_poll_cq+0x378/0x6a0 [ 2245.094524] RIP: 0010:[<ffffffff8104a6e3>] [<ffffffff8104a6e3>] mlx4_ib_poll_cq+0x383/0x6a0 [ 2247.494306] RIP: 0010:[<ffffffff8104a6d8>] [<ffffffff8104a6d8>] mlx4_ib_poll_cq+0x378/0x6a0 [ 2249.894088] RIP: 0010:[<ffffffff8104a6d8>] [<ffffffff8104a6d8>] mlx4_ib_poll_cq+0x378/0x6a0 [ 2252.293870] RIP: 0010:[<ffffffff8104a6d8>] [<ffffffff8104a6d8>] mlx4_ib_poll_cq+0x378/0x6a0 [ 2254.693651] RIP: 0010:[<ffffffff8104a6d8>] [<ffffffff8104a6d8>] mlx4_ib_poll_cq+0x378/0x6a0 [ 2257.093431] RIP: 0010:[<ffffffff8104a6e3>] [<ffffffff8104a6e3>] mlx4_ib_poll_cq+0x383/0x6a0","title":"04/10 Tue"},{"location":"lego/log/log-04-2018/#0409-mon","text":"thpool testing. 4 workers. MT-phoenix: [ root @ wuklab05 ys ] # cat 040 9 - p | grep __munmap [ 227.054974 ] CPU14 PID22 strace__munmap ([ 0x7fffb0ba9000 - 0x7fffb4000000 ], 54882304 ) = 0 , 0x0 [ 227.093466 ] CPU16 PID23 strace__munmap ([ 0x7fffab7ff000 - 0x7fffac000000 ], 8392704 ) = 0 , 0x0 [ 227.102773 ] CPU14 PID22 strace__munmap ([ 0x7fffb8000000 - 0x7fffb8ba9000 ], 12226560 ) = 0 , 0x0 [ 227.141265 ] CPU18 PID24 strace__munmap ([ 0x7fffa8000000 - 0x7fffac000000 ], 67108864 ) = 0 , 0x0 [ 227.150669 ] CPU16 PID23 strace__munmap ([ 0x7fffb0000000 - 0x7fffb37ff000 ], 58716160 ) = 0 , 0x0 [ 227.218248 ] CPU22 PID26 strace__munmap ([ 0x7fffa0000000 - 0x7fffa4000000 ], 67108864 ) = 0 , 0x0 [ 227.285826 ] CPU2 PID28 strace__munmap ([ 0x7fff98000000 - 0x7fff9c000000 ], 67108864 ) = 0 , 0x0 [ 227.440567 ] CPU14 PID31 strace__munmap ([ 0x7fff8a7fd000 - 0x7fff8c000000 ], 25178112 ) = 0 , 0x0 [ 227.449972 ] CPU12 PID30 strace__munmap ([ 0x7fff88000000 - 0x7fff8c000000 ], 67108864 ) = 0 , 0x0 [ 227.459376 ] CPU14 PID31 strace__munmap ([ 0x7fff90000000 - 0x7fff927fd000 ], 41930752 ) = 0 , 0x0 [ 227.490109 ] CPU18 PID33 strace__munmap ([ 0x7fff80000000 - 0x7fff84000000 ], 67108864 ) = 0 , 0x0 [ 227.723140 ] word_count - pthr [ 29 ] : segfault at 0x4e842010 ip 0000000000420354 sp 00007f ffb17f9bc0 error 6 0x4e842010 Print mmap on M, if segfault. Printed, the 0x4e842010 is never a valid address. thpool makes Memory side SMP. Probably bring some issues. Found: P CPU22 PID26 strace__mmap(addr=0x0, len=0xfb000, prot(0x3)=PROT_READ|PROT_WRITE, flags(0x22)=MAP_PRIVATE|MAP_ANONYMOUS, fd=18446744073709551615( ), off=0x0) = 1317351432, 0x4e853008 word_count-pthr[26]: segfault at 0x4e853010 ip 0000000000420354 sp 00007fff972a8bc0 error 6 M [ 583.120615] 00400000-004d9000 r-xp 00000000 /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread [ 583.131578] 006d9000-006dc000 rw-p 000d9000 /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread [ 583.142729] 006dc000-00755000 rw-p 00000000 [heap] [ 583.148254] 7fff529c9000-7fffb93aa000 rw-p 00000000 [ 583.153974] 7fffb93aa000-7ffff7fff000 rw-p 00000000 /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_1GB.txt [ 583.167355] 7ffffffde000-7ffffffff000 rw-p 00000000 [stack] [ 583.173753] ------------[ cut here ]------------ [ 583.178892] WARNING: CPU: 4 PID: 31 at managers/memory/handle_pcache/fault.c:55 handle_p2m_pcache_miss+0x18e/0x1d0 [ 583.190430] src_nid:0,pid:21,vaddr:0x4e853010 [ 583.195279] CPU: 4 PID: 31 Comm: thpool-worker0 4.0.0-lego-ys+ #90 Confirmed. I printed added a number to mmap requests. And the compare the results of both P and M. The data is wrong. Btw, I\u2019m only running 1 worker thread at M, which makes it single thread handling. So, I\u2019m going to, 1) first use kmalloc to get the reply buffer, and 2) revert back the IB MAX_OUT config, remove the #ifdef COMP_MEMORY. See if it is this patch\u2019s issue. P : CPU18 PID24 strace__mmap ( 30 ..) = -1325940736 , 0x7fffb0f7c000 CPU22 PID26 strace__mmap ( 31 ..) = 2144269992 , 0x7fcef6a8 M : ... handle_p2m_mmap () : 30 7f ffb0f7c000 handle_p2m_mmap () : 31 7f ffb0efe000 ... Anyway, this is temporary fixed by using kmalloced reply buffer. Spent whole afternoon and whole night. Finally figure out why timeout happen in P. It is because somewhere in the middle, M has 1 or more requests stucked/unhandled. Deadlock happen in the middle. Like this one. 5 requests queued waiting, 1 is being handled. And that 1 handler stuck. And it is handle_pcache_miss. Now, I need to find out where it stuck! thpool-worker0 nr_queued: 5 1 Oh, I really hope we can have some soft/hw lockdep, watchdog stuff . This should make out life much much much much much easier!","title":"04/09 Mon"},{"location":"lego/log/log-04-2018/#0408-sun","text":"Trying the fit_nowait patch. First try fit_nowait patch, without any chanegs to other code. See if this patch can work. Second, modify pcache to use reply_message_nowait. See if this can work. and improve performance. Third, if 2) can improve, perf. Move on to modify thpool patch. 1 st , P fail at ib_mad, during boot: [ 349.239220 ] Online CPU : 0 , 2 , 4 , 6 , 8 , 10 , 12 , 14 , 16 , 18 , 20 , 22 [ 349.244940 ] Active CPU : 0 , 2 , 6 , 10 , 12 , 14 , 16 , 18 , 20 , 22 [ 349.250272 ] [ 0 ] Thread [ kvictim_flushd : 19 ] pinned at CPU 8 [ 349.256478 ] [ 1 ] Thread [ recvpollcq : 17 ] pinned at CPU 4 [ 356.188819 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 13 [ 356.197545 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000020 [ 356.206270 ] IP : [ < ffffffff81058287 > ] ib_mad_completion_handler + 0xc7 / 0x810 2st run, P side, config MAX_OUT to 1. Then single-thread pheonix with 1GB data finished. But forgot to turn on the profile point. Run one more time. 3st run. Same with 2st run setting. But with profile on. Bug shows. Ugh. I still think it is because of ib_mad_handler. It must write to wrong memory locations, and corrupt things randomly. [ 456.237913 ] do_close_on_exec () : TODO , not implemented . ... [ 456.263274 ] BUG : unable to handle kernel paging request at 00000002f 4 bfbf58 [ 456.270843 ] IP : [ < ffffffff8101bbff > ] task_tick_rt + 0x1f / 0xd0 [ 456.277048 ] PGD 0 [ 456.279279 ] Thread overran stack , or stack corrupted [ 456.284804 ] Oops : 0000 [ # 1 ] SMP PROCESSOR [ 456.289265 ] CPU : 10 PID : 20 Comm : kevict_sweepd 4.0.0 - lego + # 40 [ 456.295858 ] RIP : 0010 : [ < ffffffff8101bbff > ] [ < ffffffff8101bbff > ] task_tick_rt + 0x1f / 0xd0 4st run, succeed. But it looks like the perf is very bad. Oh. but 99% of the pcache miss are file-backed, which will go to storage. So the number is actually doubled. With fit_nowait patch : [ 308.660051 ] Kernel Profile Points [ 308.663734 ] status name total nr avg . ns [ 308.673431 ] ------- -------------------- ---------------- ---------------- ---------------- [ 308.683128 ] off flush_tlb_others 0.000130715 53 2467 [ 308.692824 ] off __do_kmalloc_node 0.097344056 265647 367 [ 308.702521 ] off pcache_miss 4.504660891 258211 17446 [ 308.712218 ] off pcache_flush 0.000000000 0 0 [ 308.721914 ] ------- -------------------- ---------------- ---------------- ---------------- 5st run. Just run large malloc test. Looks better than yesterday\u2019s result. But I\u2019m using 15 as P today, instead of 13. So, let me try one more time to see if it is the machine. With fit_nowait patch : [ 674.382592 ] Kernel Profile Points [ 674.386277 ] status name total nr avg . ns [ 674.395974 ] ------- -------------------- ---------------- ---------------- ---------------- [ 674.405670 ] off flush_tlb_others 0.000130838 53 2469 [ 674.415366 ] off __do_kmalloc_node 1.604700641 1584917 1013 [ 674.425062 ] off pcache_miss 6.467938547 786571 8223 [ 674.434758 ] off pcache_flush 3.342783614 262225 12748 [ 674.444455 ] ------- -------------------- ---------------- ---------------- ---------------- [ 674.554497 ] nr_pgfault : 786513 [ 674.557706 ] nr_clflush : 262225 [ 674.561099 ] nr_pgfault_wp : 0 [ 674.564299 ] nr_pgfault_wp_cow : 0 [ 674.567887 ] nr_pgfault_wp_reuse : 0 [ 674.571668 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 674.577195 ] nr_pcache_fill_from_memory : 786511 [ 674.582139 ] nr_pcache_fill_from_victim : 2 6st run. Looks like the above fit_nowait can have 400ns improvement. But how come? I did not even change the pcache handling to use ibapi_nowait!!! Maybe random variation. Let me run more. Without fit_nowait patches [ 428.546738 ] Kernel Profile Points [ 428.550424 ] status name total nr avg . ns [ 428.560119 ] ------- -------------------- ---------------- ---------------- ---------------- [ 428.569815 ] off flush_tlb_others 0.000131140 53 2475 [ 428.579510 ] off __do_kmalloc_node 1.758704197 1331927 1321 [ 428.589205 ] off pcache_miss 6.807601189 786575 8655 [ 428.598899 ] off pcache_flush 3.699044847 262227 14107 [ 428.608594 ] ------- -------------------- ---------------- ---------------- ---------------- [ 428.618289 ] [ 428.718670 ] nr_pgfault : 786515 [ 428.721878 ] nr_clflush : 262227 [ 428.725272 ] nr_pgfault_wp : 0 [ 428.728470 ] nr_pgfault_wp_cow : 0 [ 428.732058 ] nr_pgfault_wp_reuse : 0 [ 428.735840 ] nr_pgfault_due_to_concurrent_eviction : 0 [ 428.741365 ] nr_pcache_fill_from_memory : 786515 [ 428.746310 ] nr_pcache_fill_from_victim : 0 7 th run. without fit_nowait. without fit_nowait . [ 901.223090 ] Kernel Profile Points [ 901.226775 ] status name total nr avg . ns [ 901.236472 ] ------- -------------------- ---------------- ---------------- ---------------- [ 901.246168 ] off flush_tlb_others 0.000130802 53 2468 [ 901.255865 ] off __do_kmalloc_node 1.862575608 1331923 1399 [ 901.265560 ] off pcache_miss 6.814540477 786572 8664 [ 901.275257 ] off pcache_flush 3.699187003 262224 14107 [ 901.284953 ] ------- -------------------- ---------------- ---------------- ---------------- 8 th run. without fit_nowait. [ 321.514564 ] Kernel Profile Points [ 321.518250 ] status name total nr avg . ns [ 321.527945 ] ------- -------------------- ---------------- ---------------- ---------------- [ 321.537639 ] off flush_tlb_others 0.000130934 53 2471 [ 321.547335 ] off __do_kmalloc_node 2.216772665 1331939 1665 [ 321.557031 ] off pcache_miss 6.806060415 786573 8653 [ 321.566726 ] off pcache_flush 3.725455841 262231 14207 [ 321.576421 ] ------- -------------------- ---------------- ---------------- ---------------- 9 th run. with fit_nowait [ 374.847912 ] Kernel Profile Points [ 374.851597 ] status name total nr avg . ns [ 374.861293 ] ------- -------------------- ---------------- ---------------- ---------------- [ 374.870989 ] off flush_tlb_others 0.000130858 53 2470 [ 374.880684 ] off __do_kmalloc_node 1.485304454 1331934 1116 [ 374.890381 ] off pcache_miss 6.615317677 786582 8411 [ 374.900076 ] off pcache_flush 3.508328900 262234 13379 [ 374.909772 ] ------- -------------------- ---------------- ---------------- ---------------- 10 th run, with fit_nowait [ 225.211058] Kernel Profile Points [ 225.214743] status name total nr avg.ns [ 225.224440] ------- -------------------- ---------------- ---------------- ---------------- [ 225.234137] off flush_tlb_others 0.000131029 53 2473 [ 225.243833] off __do_kmalloc_node 1.211421872 1331984 910 [ 225.253529] off pcache_miss 6.583096125 786574 8370 [ 225.263226] off pcache_flush 3.464430818 262227 13212 [ 225.272922] ------- -------------------- ---------------- ---------------- ---------------- Sum: with fit_nowait: [ 225.253529] off pcache_miss 6.583096125 786574 8370 [ 225.263226] off pcache_flush 3.464430818 262227 13212 [ 374.890381] off pcache_miss 6.615317677 786582 8411 [ 374.900076] off pcache_flush 3.508328900 262234 13379 [ 674.425062] off pcache_miss 6.467938547 786571 8223 [ 674.434758] off pcache_flush 3.342783614 262225 12748 Without fit_nowait: [ 428.589205] off pcache_miss 6.807601189 786575 8655 [ 428.598899] off pcache_flush 3.699044847 262227 14107 [ 901.265560] off pcache_miss 6.814540477 786572 8664 [ 901.275257] off pcache_flush 3.699187003 262224 14107 [ 321.557031] off pcache_miss 6.806060415 786573 8653 [ 321.566726] off pcache_flush 3.725455841 262231 14207","title":"04/08 Sun"},{"location":"lego/log/log-04-2018/#0407-sat","text":"Well, now we finished all the profiling stuff. Continue on other work. Now I like listening Jazz while coding. Amazing Jazz, really good. Once again, ib_mad_completion_handler bug will happen. During application run, or even after application exit. [ 465.835447 ] nr_mremap_pset_diff : 0 [ 477.086886 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 21 [ 477.095620 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000020 [ 477.104345 ] IP : [ < ffffffff81058277 > ] ib_mad_completion_handler + 0xc7 / 0x810 ib_mad_completion_handler + 0xc7 / 0x808 : ib_mad_recv_done_handler at drivers / infiniband / core / mad . c : 1899 ( inlined by ) ib_mad_completion_handler at drivers / infiniband / core / mad . c : 2345 After remove net from pcache miss: [ 465.572131 ] Kernel Profile Points [ 465.575815 ] status name total nr avg . ns [ 465.585510 ] ------- -------------------- ---------------- ---------------- ---------------- [ 465.595206 ] off flush_tlb_others 0.000000000 0 0 [ 465.604901 ] off __do_kmalloc_node 0.656371295 1762220 373 [ 465.614597 ] off pcache_miss 7.172572671 786596 9119 [ 465.624291 ] off pcache_flush 3.698294960 262251 14103 [ 465.633987 ] ------- -------------------- ---------------- ---------------- ---------------- After remove net from pcache flush: [ 684.984000 ] Kernel Profile Points [ 684.987683 ] status name total nr avg . ns [ 684.997379 ] ------- -------------------- ---------------- ---------------- ---------------- [ 685.007074 ] off flush_tlb_others 0.000000000 0 0 [ 685.016770 ] off __do_kmalloc_node 0.627372836 1500543 419 [ 685.026464 ] off pcache_miss 7.128702028 786596 9063 [ 685.036159 ] off pcache_flush 3.660772506 262251 13960 [ 685.045855 ] ------- -------------------- ---------------- ---------------- ---------------- malloc, miss, flush are too slow. Especially the flush, how can it take 13.9us? It must be our handlers! lego_copy_to_user stuff.","title":"04/07 Sat"},{"location":"lego/log/log-04-2018/#0406-fri","text":"Well. Now we have in-kernel strace, in-kernel readprofile. Yummy.","title":"04/06 Fri"},{"location":"lego/log/log-04-2018/#0405-thur","text":"Discussion with Yilun. 1. munmap+nr_pgfault figure: count number of pgfaults between munmap, it should be an interesting figure. 2. track number of pgfault at: since there is no eviction, so any mmaped area at M should only have exactly one pcache fetch. 3. I probably want to use per-cpu counter. Anyway, continue strace work first. Finished.","title":"04/05 Thur"},{"location":"lego/log/log-04-2018/#0404-wed","text":"","title":"04/04 Wed"},{"location":"lego/log/log-04-2018/#strace-performance","text":"TF has very bad performance. It is either due to the syscall or pcache. Now I\u2019m adding facilities to track syscall activities, including average latency, total time. Basic utilities of strace are done. But I somehow need to change the design of multithread strace. Previously, I naively make the thread group keep some info, and let all other threads use that info to do bookkeeping. But this is really hard and not accurate. We first need to make sure we are running on a non-preemptable kernel, so the per-cpu time tracking will be accurate. Besides, we also need to make sure threads do not migrate because of syscalls such as sched_setaffinity. Oh, well, so I though I have to use per-thread strace_info. The first design I thought is: accumulating the counter of one thread to its thread group leader, when it exit. But this is slightly complex, and will affect the thread group leader runtime. So the second solution I came up is let all threads within a process, chain their straec_info together. And normal thread does not need to accumulate the counter. It can just exit. While the thread group leader exit, it walk through the chain to accumulate the counters. This is simpler. Besides, the strace_info of dead thread is safe. No one will touch it. Yeh! Let us do this tomorrow. We will have a robust kernel version strace.","title":"STRACE Performance"},{"location":"lego/log/log-04-2018/#sm-heartbeat","text":"Continue run some experiments on yesterday\u2019s case. One we sure is SM will keep sending requests to HCA. And it looks like it does not send in a very deterministic interval: [ 1224.034898 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 15 [ 1224.130616 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 15 [ 1224.222189 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 16 [ 1224.417181 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 16 [ 1393.159845 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 17 [ 1393.255546 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 17 [ 1393.347132 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 18 [ 1393.538972 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 18 [ 1449.437542 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 19 [ 1449.533248 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 19 [ 1449.624833 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 20 [ 1449.722512 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 20 [ 4322.423624 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 21 [ 4322.519328 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 21 [ 4322.610914 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 22 [ 4322.708594 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 22 [ 4350.750574 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 23 [ 4350.846278 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 23 [ 4350.937863 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 24 [ 4351.035543 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 24 [ 4519.690559 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 25 [ 4519.786262 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 25 [ 4519.877848 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 26 [ 4519.975527 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 26 [ 4576.396279 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 27 [ 4576.491979 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 27 [ 4576.583565 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 28 [ 4576.681245 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 28 [ 4942.886820 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 29 [ 4942.982523 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 29 [ 4943.074108 ] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 30 [ 4943.171789 ] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 30","title":"SM Heartbeat"},{"location":"lego/log/log-04-2018/#0403-tue","text":"","title":"04/03 Tue"},{"location":"lego/log/log-04-2018/#bug-bug-bug","text":"Finished basic replication mechanism last night. Today merged several patches. And both Yilun and I think there is something wrong with ib_mad_completion_handler . It seems it will break things behind our back. This is one bug catched today:","title":"BUG BUG BUG"},{"location":"lego/log/log-04-2018/#ib_mad_completion_handler","text":"At very early stage : [ 1174.406177 ] newpid : 20 home : 1 replica : 1 [ 1174.452983 ] p2m_fork ( cpu10 ) : I cur : 20 - exe . o new : 21 [ 1177.462795 ] ib_mad_completion_handler 2324 got successful recv cq op 128 mad_got_one 22 [ 1177.556502 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000020 [ 1177.650101 ] IP : [ < ffffffff81059104 > ] ib_mad_completion_handler + 0xb4 / 0x8a0 . / scripts / faddr2line vmImage ib_mad_completion_handler + 0xb4 ib_mad_completion_handler + 0xb4 / 0x899 : ib_mad_recv_done_handler at drivers / infiniband / core / mad . c : 1899 ( inlined by ) ib_mad_completion_handler at drivers / infiniband / core / mad . c : 2325 ib_mad_recv_done_handler () : 1899 : qp_info = mad_list -> mad_queue -> qp_info ; A more scared one after I changed ib_mad_completion_handler. Note that recvcq is the only thread running on cpu4: [ 863.887705 ] p2m_fork ( cpu10 ) : I cur : 20 - exe . o new : 21 [ 868.478424 ] p2m_fork ( cpu10 ) : O succeed cur : 20 - exe . o new : 21 [ 868.541991 ] BUG : unable to handle kernel NULL pointer dereference at 000000000000000 8 [ 868.635569 ] IP : [ < ffffffff810656d4 > ] __schedule + 0x94 / 0x1e0 [ 868.701090 ] PGD 0 [ 868.725010 ] general protection fault : 0000 [ # 1 ] SMP PROCESSOR [ 868.793651 ] CPU : 4 PID : 17 Comm : recvpollcq 4.0.0 - lego - ys + # 737 Source : clear_tsk_need_resched ( prev ); Even this one for Phoenix: [ 763.442043 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000010 [ 763.535636 ] IP : [ < ffffffff81018d6f > ] task_curr + 0xf / 0x30 [ 763.598035 ] PGD 103e956067 PUD 103e964067 PMD 0 [ 763.653154 ] Oops : 0000 [ # 1 ] SMP PROCESSOR [ 763.700992 ] CPU : 12 PID : 21 Comm : word_count - pthr 4.0.0 - lego - ys + # 740 [ 763.777950 ] RIP : 0010 : [ < ffffffff81018d6f > ] [ < ffffffff81018d6f > ] task_curr + 0xf / 0x30 This NEVER happen before. And this part of code should be correct. We\u2019ve ran a lot things.. I doubt if recent IB merge corrupt things.","title":"ib_mad_completion_handler"},{"location":"lego/log/log-04-2018/#fit_poll_cq","text":"Another one: [ 690.401626 ] stat : / root / ys / phoenix / phoenix -2.0 / tests / word_count / word_count_datafiles / word_1GB . txt [ 690.507742 ] SYSC_close () CPU12 PID : 21 [ fd : 4 ] -> [ / sys / devices / system / cpu / online ] [ 713.899884 ] ib_mad_completion_handler 2337 got successful recv cq op 128 mad_got_one 21 [ 713.995606 ] ib_mad_completion_handler 2331 got successful send cq op 0 mad_got_one 21 [ 714.087185 ] ib_mad_completion_handler 2337 got successful recv cq op 128 mad_got_one 22 [ 714.184871 ] ib_mad_completion_handler 2331 got successful send cq op 0 mad_got_one 22 [ 742.078102 ] ib_mad_completion_handler 2337 got successful recv cq op 128 mad_got_one 23 [ 742.173810 ] ib_mad_completion_handler 2331 got successful send cq op 0 mad_got_one 23 [ 742.265399 ] ib_mad_completion_handler 2337 got successful recv cq op 128 mad_got_one 24 [ 742.363085 ] ib_mad_completion_handler 2331 got successful send cq op 0 mad_got_one 24 [ 847.063372 ] mlx4_ib_handle_error_cqe syndrome 21 [ 847.116511 ] mlx4_ib_handle_error_cqe syndrome 5 [ 847.170590 ] send request failed at connection 7 as 12 [ 847.230909 ] mlx4_ib_handle_error_cqe syndrome 5 [ 847.284988 ] mlx4_ib_handle_error_cqe syndrome 5 [ 847.339067 ] mlx4_ib_handle_error_cqe syndrome 5 [ 847.393146 ] fit_poll_cq : failed status ( 5 ) for wr_id 1832 [ 847.457624 ] fit_poll_cq : failed status ( 5 ) for wr_id 1833 [ 847.522103 ] fit_poll_cq : connection 7 Recv weird event as -1 [ 847.589701 ] fit_poll_cq : failed status ( 5 ) for wr_id 1834 [ 847.654179 ] fit_poll_cq : connection 7 Recv weird event as -30704 [ 847.725938 ] fit_poll_cq : failed status ( 5 ) for wr_id 1835 [ 847.790416 ] fit_poll_cq : connection 7 Recv weird event as -30704 [ 847.862174 ] mlx4_ib_handle_error_cqe syndrome 5 [ 847.916252 ] mlx4_ib_handle_error_cqe syndrome 5 [ 847.970331 ] mlx4_ib_handle_error_cqe syndrome 5 [ 848.024410 ] mlx4_ib_handle_error_cqe syndrome 5 [ 848.078490 ] fit_poll_cq : failed status ( 5 ) for wr_id 1836 [ 848.142967 ] fit_poll_cq : failed status ( 5 ) for wr_id 1837 [ 848.207446 ] fit_poll_cq : connection 7 Recv weird event as -1 [ 848.275044 ] fit_poll_cq : failed status ( 5 ) for wr_id 1838 [ 848.339523 ] fit_poll_cq : connection 7 Recv weird event as -30704 [ 848.411281 ] fit_poll_cq : failed status ( 5 ) for wr_id 1839 [ 848.475760 ] fit_poll_cq : connection 7 Recv weird event as -30704 [ 848.547517 ] mlx4_ib_handle_error_cqe syndrome 5 [ 848.601596 ] mlx4_ib_handle_error_cqe syndrome 5 [ 848.655675 ] mlx4_ib_handle_error_cqe syndrome 5 [ 848.709753 ] mlx4_ib_handle_error_cqe syndrome 5 [ 848.763832 ] fit_poll_cq : failed status ( 5 ) for wr_id 1840 [ 848.828313 ] BUG : unable to handle kernel NULL pointer dereference at ( null ) [ 848.921908 ] IP : [ < ffffffff8106346d > ] fit_poll_cq + 0x4ad / 0x510 [ 848.989507 ] PGD 0 [ 849.013426 ] Oops : 0002 [ # 1 ] SMP PROCESSOR [ 849.061265 ] CPU : 4 PID : 17 Comm : recvpollcq 4.0.0 - lego - ys + # 744 [ 849.131983 ] RIP : 0010 : [ < ffffffff8106346d > ] [ < ffffffff8106346d > ] fit_poll_cq + 0x4ad / 0x510 [ 849.228700 ] RSP : 0000 : ffff88103e813d88 EFLAGS : 00010246 [ 849.292139 ] RAX : 000000000000100 8 RBX : ffff88103effbad0 RCX : 0000000000000000 [ 849.377418 ] RDX : 0000000000000000 RSI : ffffffff811d46e0 RDI : ffffffff811dbc08 [ 849.462695 ] RBP : ffff88103e813ea8 R08 : 0000000000000000 R09 : 0000000000000000 [ 849.547973 ] R10 : 0000000000000002 R11 : 0000000000000004 R12 : 0000000000000000 [ 849.633251 ] R13 : ffff88103e801008 R14 : 0000000000000004 R15 : ffff88103e813da0 [ 849.718529 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc40000 ( 0000 ) knlGS : 0000000000000000 [ 849.815246 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 849.883884 ] CR2 : 0000000000000000 CR3 : 000000000113 d000 CR4 : 00000000000406 a0 [ 849.969163 ] Stack : [ 849.993082 ] ffffffff81003299 000001 b03e813da0 0000000000000004 0000000000000730 [ 850.080440 ] 000000 8100000005 00001008000000f 9 ffff88103eff8c50 002 c222040000000 [ 850.167798 ] 0010004000000002 ffff88107fc20000 0000000000000731 ffffffff00000005 [ 850.255156 ] ffff8810000000f9 ffff88103eff8c50 0000000000000000 ffff88103e813e38 [ 850.342513 ] ffffffff81019854 0000000000000732 ffff881000000005 ffff8810000000f9 [ 850.429871 ] Call Trace : [ 850.458992 ] < TSK > [ 850.481870 ] [ < ffffffff81003299 > ] ? native_smp_send_reschedule + 0x39 / 0x50 [ 850.560909 ] [ < ffffffff81019854 > ] ? try_to_wake_up + 0xe4 / 0x1f0 [ 850.628506 ] [ < ffffffff81065708 > ] ? __schedule + 0xf8 / 0x1e0 [ 850.691945 ] [ < ffffffff810634d0 > ] ? fit_poll_cq + 0x510 / 0x510 [ 850.757464 ] [ < ffffffff810634e4 > ] fit_poll_cq_pass + 0x14 / 0x30 [ 850.824021 ] [ < ffffffff81020636 > ] kthread + 0xf6 / 0x120 [ 850.882260 ] [ < ffffffff81020540 > ] ? __kthread_parkme + 0x70 / 0x70 [ 850.950898 ] [ < ffffffff8100e572 > ] ret_from_fork + 0x22 / 0x30 /* handle normal reply */ ... memcpy (( void * ) ctx -> reply_ready_indicators [ reply_indicator_index ], & length , sizeof ( int )); ... ( This is a bad memcpy : reply_indicator_index , ctx , etc should be checked .)","title":"fit_poll_cq"},{"location":"lego/log/log-04-2018/#ib-spec-qp-cqe-wqe-send","text":"The channel adapter detects the WQE posting and accesses the WQE. The channel adapter interprets the command, validates the WQE\u2019s virtual 12 addresses, translates it to physical addresses, and accesses the data. The outgoing message buffer is split into one or more packets. To each packet the channel adapter adds a transport header (sequence numbers, opcode, etc.). If the destination resides on a remote subnet the channel adapter adds a network header (source & destination GIDs). The channel adapter then adds the local route header and calculates both the variant and invariant checksums. For a Send operation, the QP retrieves the address of the receive buffer from the next WQE on its receive queue, translates it to physical addresses, and accesses memory writing the data. If this is not the last packet of the message, the QP saves the current write location in 38 its context and waits for the next packet at which time it continues writing the receive buffer until it receives a packet that indicates it is the last packet of the operation. It then updates the receive WQE, retires it, and sends an acknowledge message to the originator. When the originator receives an acknowledgment, it creates a CQE on the 5 CQ and retires the WQE from the send queue. A QP can have multiple outstanding messages at any one time but the 8 target always acknowledges in the order sent, thus WQEs are retired in the order that they are posted.","title":"IB Spec: QP, CQE, WQE, SEND"},{"location":"lego/log/log-04-2018/#0402-mon","text":"Patching storage replica handler, able to finish today.","title":"04/02 Mon"},{"location":"lego/log/log-04-2018/#0401-sun","text":"Anyway. Summary of the day: replication at M almost done. Only flush part left. Storage also need a handler. But we still need code to recover. I\u2019m tired. :-( A month to go. Record a IB error. Using wuklab12 (P) and wuklab14(M+RAMFS), running usr/pcache_conflic.o: P [ 30801.296160 ] ibapi_send_reply () CPU : 8 PID : 19 timeout ( 30010 ms ), caller : clflush_one + 0x1c9 / 0x370 [ 30938.564843 ] mlx4_ib_handle_error_cqe syndrome 21 [ 30938.617988 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30938.672068 ] send request failed at connection 6 as 12 [ 30938.732389 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30938.786470 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30938.840551 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30938.894632 ] fit_poll_cq : failed status ( 5 ) for wr_id 1584 [ 30938.959112 ] fit_poll_cq : failed status ( 5 ) for wr_id 1585 [ 30939.023593 ] fit_poll_cq : connection 6 Recv weird event as -1 [ 30939.091194 ] fit_poll_cq : failed status ( 5 ) for wr_id 1586 [ 30939.155676 ] fit_poll_cq : connection 6 Recv weird event as -30704 [ 30939.227436 ] fit_poll_cq : failed status ( 5 ) for wr_id 1587 [ 30939.291917 ] fit_poll_cq : connection 6 Recv weird event as -30704 [ 30939.363678 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30939.417759 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30939.471839 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30939.525921 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30939.580002 ] fit_poll_cq : failed status ( 5 ) for wr_id 1588 [ 30939.644483 ] BUG : unable to handle kernel NULL pointer dereference at ( null ) [ 30939.738083 ] IP : [ < ffffffff81062fcd > ] fit_poll_cq + 0x4ad / 0x510 [ 30939.805684 ] PGD 0 [ 30939.829604 ] Oops : 0002 [ # 1 ] SMP PROCESSOR [ 30939.877445 ] CPU : 4 PID : 17 Comm : recvpollcq 4.0.0 - lego - ys + # 715 [ 30939.948166 ] RIP : 0010 : [ < ffffffff81062fcd > ] [ < ffffffff81062fcd > ] fit_poll_cq + 0x4ad / 0x510 fit_poll_cq at net / lego / fit_internal . c : 1734 memcpy (( void * ) ctx -> reply_ready_indicators [ reply_indicator_index ], & length , sizeof ( int )); M [ 30913.642698 ] mlx4_ib_handle_error_cqe syndrome 21 [ 30913.695839 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30913.749919 ] send request failed at connection 1 as 12 [ 30913.810236 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30913.864315 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30913.918395 ] mlx4_ib_handle_error_cqe syndrome 5 [ 30913.972474 ] fit_poll_cq : failed status ( 5 ) for wr_id 305 [ 30914.035912 ] fit_poll_cq : failed status ( 5 ) for wr_id 306","title":"04/01 Sun"},{"location":"lego/log/log-08-2018/","text":"Aug 2018 \u00b6 Aug 31 \u00b6 One major TODO \u00b6 Check do_handle_p2m_pcache_miss() . We MUST remove that mempcy, maybe by using another flag in thpool. This is just no acceptable. Ugh \u00b6 Fuck. Without debug_mm, there is still memory corruption. Try max_send_wr and number of QPs \u00b6 without lock_ib, with debug_mm. Change max_send_wr at all P M S. QP=4, max_send_wr = 1: always fail QP=4, max_send_wr = 256: always fail QP=24, max_send_wr = 1: succeed (0831-w14-18 0831-w14-20) QP=24, max_send_wr = 256: succeed (0831-w14-16 0831-w14-17) Pay attention to the 0831-w14-15 \uff1a something wrong with our timekeeping code? QP=24, max_send_wr = 1 case. After Victim bug fix \u00b6 MNIST 4 threads With lock_ib, debug_mm etc: 3 successful runs Only with debug_mm: Well fit failed. Lost CQE. Now the debug scope is limited. Let me try the micro test suite, to stress ibapi_send_reply itself. Potential: read/write buffer. Aug 30 \u00b6 Be humble. Identified victim bug. \u00b6 Finally. I thought it through, and with the help of this 0830-w14-12 . The bug is in victim_try_fill_pcache() , when there are multiple hits to the same victim. Since we released the usable_victim_lock after a hit. There might a be race case where: 1) CPU0 reached dec_and_test_filling , and passed to free the line. 2) CPU1 just got to the victim_check_hit , and increment the fill counter to 1 again. When CPU1 finished filling, and do dec_and_test_filling , it will do the free again!!! What a double free. Tomorrow, let me do the fix. Thought: adding more sync in victim_check_hit part. Basically we want to ensure only one CPU can do the final free. After adding pi_lock \u00b6 Okay. the pi_lock is added. Although it is mostly used by futex-pi and rt-mutex, we lego does not have these two guys. Therefore, it is only used by sched/core.c, exit.c, and kthread.c. 99% is in core.c The purpose of having this back is to have the spin_lock_irqsave(&p->pi_lock) back. Most scheduling code is not recursive, we have to disable interrupt. Of course we can use spin_lock_irqsave(&rq->lock) instead of spin_lock(&rq->lock) . But this is too dangerous at this stage. Porting based on Linux now is the fastest and safest way. The importance of disabling interrupt in some kernel path!! Good. Now I\u2019m seeing now debuggable victim issue. Classical deadlock catched. Now, only two victims. [ 2819.068997 ] CPU14 PID29 Abort victim alloc ( 20010 ms ) nr_usable_victims : 2. From pset_idx : 532 nr_lru : 63 fault_uva : 0x7fff98614000 [ 2819.094409 ] CPU14 PID29 -- Start Dump Victim Cache [ 0 ] total : 2 [ 2819.114188 ] CPU14 PID29 victim [ 0 ] : ffffffff810c2880 refcount : 2 nr_fill : 1 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2819.133289 ] CPU14 PID29 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffcc000000 [ 2819.141723 ] CPU14 PID29 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2819.149770 ] CPU14 PID29 victim [ 1 ] : ffffffff810c2900 refcount : 2 nr_fill : 1 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2819.168870 ] CPU14 PID29 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffb0000000 [ 2819.177306 ] CPU14 PID29 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2819.185352 ] CPU14 PID29 -- End Dump Victim Cache [ 0 ] [ 2819.081708 ] CPU16 PID30 Abort victim alloc ( 20010 ms ) nr_usable_victims : 2. From pset_idx : 0 nr_lru : 63 fault_uva : 0x7fffcc000024 [ 2819.209008 ] CPU16 PID30 -- Start Dump Victim Cache [ 1 ] total : 2 [ 2819.223358 ] CPU16 PID30 victim [ 0 ] : ffffffff810c2880 refcount : 2 nr_fill : 1 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2819.252443 ] CPU16 PID30 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffcc000000 [ 2819.260879 ] CPU16 PID30 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2819.268926 ] CPU16 PID30 victim [ 1 ] : ffffffff810c2900 refcount : 2 nr_fill : 1 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2819.288026 ] CPU16 PID30 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffb0000000 [ 2819.296461 ] CPU16 PID30 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2819.304508 ] CPU16 PID30 -- End Dump Victim Cache [ 1 ] [ 2819.101391 ] CPU18 PID31 Abort victim alloc ( 20010 ms ) nr_usable_victims : 2. From pset_idx : 15 nr_lru : 63 fault_uva : 0x7fff98c0f000 [ 2819.328165 ] CPU18 PID31 -- Start Dump Victim Cache [ 2 ] total : 2 [ 2819.335146 ] CPU18 PID31 victim [ 0 ] : ffffffff810c2880 refcount : 1 nr_fill : 0 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2819.354246 ] CPU18 PID31 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffcc000000 [ 2819.362680 ] CPU18 PID31 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2819.370728 ] CPU18 PID31 victim [ 1 ] : ffffffff810c2900 refcount : 2 nr_fill : 1 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2819.389828 ] CPU18 PID31 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffb0000000 [ 2819.398262 ] CPU18 PID31 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2819.406310 ] CPU18 PID31 -- End Dump Victim Cache [ 2 ] # # This guy grabbed the fill counter right before the first timout # That's why the above three timeout happen. And this one is 20s later # which equals to the timeout second. # [ 2839.327457 ] CPU12 PID28 Abort victim alloc ( 20010 ms ) nr_usable_victims : 2. From pset_idx : 0 nr_lru : 63 fault_uva : 0x7fffb0000f00 [ 2839.339964 ] CPU12 PID28 -- Start Dump Victim Cache [ 3 ] total : 2 [ 2839.346945 ] CPU12 PID28 victim [ 0 ] : ffffffff810c2880 refcount : 1 nr_fill : 0 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2839.366046 ] CPU12 PID28 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffcc000000 [ 2839.374480 ] CPU12 PID28 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2839.382527 ] CPU12 PID28 victim [ 1 ] : ffffffff810c2900 refcount : 2 nr_fill : 1 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2839.401628 ] CPU12 PID28 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffb0000000 [ 2839.410062 ] CPU12 PID28 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2839.418109 ] CPU12 PID28 -- End Dump Victim Cache [ 3 ] rq->lock deadlock \u00b6 Alright. We had rq->lock deadlock issue. Basically, we missed the part of disabling interrupt. A timer interrupt will try to acquire the lock again. Then, bang we have a deadlock. Digging into the code, you will be able to find the cause easily. The root cause we removed all the pi_lock stuff, which actually have a lot irqsave usages\u2026 Oh man, maybe it\u2019s time to add it back. [ 3367.835389] ------------------- cut here ------------------- [ 3367.841504] Possible deadlock happend locker_cpu: 0 [ 3367.846934] Current call stack: [ 3367.850425] CPU: 0 PID: 1 Comm: kernel_init 4.0.0-lego+ #437 [ 3367.856726] Stack: [ 3367.858957] ffff88107ff0fa58 ffffffff8101f4b6 ffff88107fc05e00 00000004a817c800 [ 3367.867101] ffff88107ff0fa80 ffffffff8101f52e ffff88107fc05e00 ffff88107ffb4000 [ 3367.875246] 0000000000000000 ffff88107ff0faa0 ffffffff8101b1ae ffff88107fc04980 [ 3367.883390] 0000000000000000 ffff88107ff0fab8 ffffffff810174f5 0000000000000286 [ 3367.891535] ffff88107ff0fae0 ffffffff81006774 ffff88107ffb9000 ffff88107fc05e00 [ 3367.899680] Call Trace: [ 3367.902396] <TSK> [ 3367.904528] [<ffffffff8101f4c2>] report_deadlock+0x62/0x80 [ 3367.910637] [<ffffffff8101f52e>] debug_spin_lock+0x4e/0x60 [ 3367.916745] [<ffffffff8101b1ae>] scheduler_tick+0x2e/0x60 [ 3367.922756] [<ffffffff810174f5>] tick_handle_periodic+0x45/0x70 [ 3367.929350] [<ffffffff81006774>] apic_timer_interrupt+0x54/0x90 [ 3367.935943] [<ffffffff8100e8aa>] smp__apic_timer_interrupt+0x6a/0x70 [ 3367.943021] [<ffffffff8101db99>] ? enqueue_task_rt+0x149/0x250 [ 3367.949518] [<ffffffff8105908a>] ? __mlx4_write_mtt+0xea/0x140 [ 3367.956014] [<ffffffff8101ad34>] activate_task+0x44/0x50 [ 3367.961929] [<ffffffff8101b667>] ttwu_do_activate+0x27/0x50 [ 3367.968134] [<ffffffff8101b89c>] try_to_wake_up+0xdc/0x1f0 [ 3367.974243] [<ffffffff8106cc20>] ? ib_mad_send_done_handler.isra.22+0x4d0/0x4d0 [ 3367.982388] [<ffffffff8101ba80>] wake_up_process+0x10/0x20 [ 3367.988497] [<ffffffff81023116>] __kthread_create_on_node+0x146/0x230 [ 3367.995671] [<ffffffff8102329f>] kthread_create_on_node+0x2f/0x40 [ 3368.002459] [<ffffffff81066873>] ? ib_create_cq+0x23/0x60 [ 3368.008470] [<ffffffff810695e1>] ib_mad_init_device+0x1f1/0x7b0 [ 3368.015064] [<ffffffff81067246>] ib_register_device+0x5d6/0x690 [ 3368.021657] [<ffffffff8105e9d3>] mlx4_ib_add+0x653/0x780 [ 3368.027571] [<ffffffff8105147d>] mlx4_add_device+0x8d/0x130 [ 3368.033777] [<ffffffff8105158c>] mlx4_register_interface+0x6c/0xa0 [ 3368.040661] [<ffffffff811dc660>] mlx4_ib_init+0x10/0x20 [ 3368.046478] [<ffffffff811dc619>] mlx4_init+0x19/0x50 [ 3368.052005] [<ffffffff811dc68d>] ib_core_init+0x1d/0x30 [ 3368.057823] [<ffffffff811db7f9>] device_init+0x9/0x10 [ 3368.063447] [<ffffffff8100030b>] kernel_init+0x4b/0xc0 [ 3368.069168] [<ffffffff8101b0ea>] ? schedule_tail+0xa/0x40 [ 3368.075178] [<ffffffff810002c0>] ? 0xffffffff810002c0 [ 3368.080803] [<ffffffff8100eb32>] ret_from_fork+0x22/0x30 [ 3368.086718] <EOT> 0830-w14-1: I really don\u2019t know how this happen. The refcounter and fill counter should be enough to serialize.. [37722.177024] CPU20 PID31 victim:ffffffff810c2880 index:0 refcount:0 nr_fill:0 max_fill:4 locked:0 flags:(0x12e)(allocated|usable|hasdata|waitflush|fillfree) pcm: (null) pset:ffff88207ff5b980 [37722.196623] CPU20 PID31 hit[0] owner:22 m_nid:1 rep_nid:1 addr: 0x2c33000 [37722.204572] CPU20 PID31 victim:ffffffff810c2880 index:0 refcount:0 nr_fill:0 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm: (null) pset:ffff88207ff5b980 [37722.224154] CPU20 PID31 rmap to pset:ffff88207ff5b980 set_idx: 51 nr_lru:63 [37722.232299] CPU20 PID31 victim dumped because: PCACHE_BUG_ON_VICTIM(!VictimAllocated(v) || !VictimUsable(v) || !VictimFlushed(v) || VictimWriteback(v) || VictimLocked(v)) [37722.254790] WARNING: CPU: 20 PID: 31 at managers/processor/pcache/victim.c:196 __put_victim_nolist+0xb8/0x140 ffffffff8103e170[37722.453632] [<ffffffff8103c9c8>] __put_victim_nolist+0xb8/0x140 0000000000000000[37722.461873] [<ffffffff8103db18>] victim_try_fill_pcache+0x2f8/0x440 [37722.265842] CPU10 PID20 victim:ffffffff810c2880 index:0 refcount:0 nr_fill:0 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm: (null) pset:ffff88207ff5b980 [37722.291438] CPU10 PID20 hit[0] owner:22 m_nid:1 rep_nid:1 addr: 0x2c33000 [37722.301616] CPU10 PID20 victim:ffffffff810c2880 index:0 refcount:0 nr_fill:0 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm: (null) pset:ffff88207ff5b980 [37722.324206] CPU10 PID20 rmap to pset:ffff88207ff5b980 set_idx: 51 nr_lru:63 [37722.332349] CPU10 PID20 victim dumped because: PCACHE_BUG_ON_VICTIM(victim_ref_count(v) == 0) [37722.350673] WARNING: CPU: 10 PID: 20 at ./include/processor/pcache_victim.h:127 __victim_flush_func+0x232/0x250 [37722.363568] CPU: 10 PID: 20 Comm: kvictim_flushd 4.0.0-lego+ #435 [37722.534003] [<ffffffff8103e152>] __victim_flush_func+0x232/0x250 [37722.547577] [<ffffffff8103e1d9>] victim_flush_async+0x69/0xb0 [37722.553975] [<ffffffff81022ec1>] kthread+0x111/0x130 [37722.565900] [<ffffffff8100eb32>] ret_from_fork+0x22/0x30 Aug 29 \u00b6 The only thing left about core_IB is: ib_sa_query, which will be invoked when there is a mlx4 interrupts. Not sure if this is important. Anyway. Testing TF 4 threads MNIST again. When I enable SEQ_IBAPI\uff1a 0829-w14-11 (0829-w09-11) succeed 0829-w14-12: P side seems have deadlock. Let me enable DEBUG_SPINLOCK. 0829-w14-13: SEQ_IBAPI, DEBUG_SPINLOCK, this is a very useful log: [ 531.495545 ] STDOUT : --- [ INFO : tensorflow : loss = 0.5256375 , step = 101 ( 25.166 sec ) ] --- [ 531.624474 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000064 [ 531.633016 ] IP : [ < ffffffff8103b60e > ] __put_victim_nolist + 0xe / 0xa0 [ 531.639803 ] PGD 0 [ 531.642032 ] Oops : 0002 [ # 1 ] SMP PROCESSOR [ 531.646493 ] CPU : 10 PID : 20 Comm : kvictim_flushd 4.0.0 - lego + # 426 [ 531.653279 ] RIP : 0010 : [ < ffffffff8103b60e > ] [ < ffffffff8103b60e > ] __put_victim_nolist + 0xe / 0xa0 [ 531.662781 ] RSP : 0000 : ffff880fe392fde0 EFLAGS : 00010006 [ 531.668696 ] RAX : 0000000000000000 RBX : ffffffff810c2b00 RCX : ffffffff810c2b70 [ 531.676646 ] RDX : ffffffff810c2b70 RSI : 0000007 aea3f42fa RDI : ffffffff810c2b00 [ 531.684597 ] RBP : ffff880fe392fdf0 R08 : 000000000000001f R09 : 0000000000000002 [ 531.692548 ] R10 : 00000000 80000000 R11 : 00000000000664 c3 R12 : ffff88207ff57000 [ 531.700498 ] R13 : ffffffff810c2b60 R14 : ffff880a72555000 R15 : ffffffff810c2b48 [ 531.708449 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fca0000 ( 0000 ) knlGS : 0000000000000000 [ 531.717466 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 531.723865 ] CR2 : 0000000000000064 CR3 : 00000000011 b9000 CR4 : 00000000000406 a0 [ 531.731816 ] Stack : [ 531.734046 ] ffffffff810c2b00 ffff88207ff57000 ffff880fe392fe08 ffffffff8103bbea [ 531.742190 ] ffffffff810c2b00 ffff880fe392fe48 ffffffff8103c729 00000000 8103 d7c2 [ 531.750335 ] ffff880a72555060 ffff88107ff0fdc8 0000000000000000 ffffffff8103c780 [ 531.758479 ] 0000000000000000 ffff880fe392fe60 ffffffff8103c7e6 ffff880fe391c000 [ 531.766623 ] ffff880fe392ff48 ffffffff81022e81 0000000000000000 0000000000000000 [ 531.774768 ] Call Trace : [ 531.777483 ] < TSK > [ 531.779617 ] [ < ffffffff8103bbea > ] __put_victim + 0x4a / 0x50 [ 531.785433 ] [ < ffffffff8103c729 > ] __victim_flush_func + 0xb9 / 0x110 [ 531.792027 ] [ < ffffffff8103c780 > ] ? __victim_flush_func + 0x110 / 0x110 [ 531.798911 ] [ < ffffffff8103c7e6 > ] victim_flush_async + 0x66 / 0x90 [ 531.805310 ] [ < ffffffff81022e81 > ] kthread + 0x111 / 0x130 [ 531.810836 ] [ < ffffffff81022d70 > ] ? __kthread_parkme + 0x70 / 0x70 [ 531.817236 ] [ < ffffffff8100eb32 > ] ret_from_fork + 0x22 / 0x30 [ 531.823151 ] < EOT > 0829-w14-14: this looks like a double free, or concurrent eviction. But if you look into the evict code, we will check the Flushed flag. It means another eviction routine should have skipped this line, and will not pick this line to do eviction. Some other possibilities? check until 0829-w14-18 [ 1671.661424 ] ------------ [ cut here ] ------------ [ 1671.666378 ] BUG : failure at managers / processor / pcache / victim . c : 610 / victim_finish_insert () ! [ 1671.675591 ] Kernel Panic - not syncing : BUG ! [ 1671.680339 ] CPU : 20 PID : 31 Comm : python 4.0.0 - lego + # 426 [ 1671.686351 ] Stack : [ 1671.688581 ] ffff880fbe76fda0 ffffffff810289b7 ffffffff00000008 ffff880fbe76fdb0 [ 1671.696725 ] ffff880fbe76fd68 ffffff0021475542 ffff88107fd45e00 ffff880fbe753000 [ 1671.704870 ] 0000000000000000 0000000000000001 ffff880fbe76f9b0 ffffffff8101b1b7 [ 1671.713015 ] ffff88107fd44980 ffff880fbe76f9d8 ffffffff8101405f 0000000000000000 [ 1671.721160 ] 0000000000000001 ffff880ff992a000 0000000000000001 ffff880fbe76f9f0 [ 1671.729304 ] Call Trace : [ 1671.732019 ] < TSK > [ 1671.734153 ] [ < ffffffff810289c3 > ] panic + 0xc2 / 0x10a [ 1671.739388 ] [ < ffffffff8101b1b7 > ] ? scheduler_tick + 0x57 / 0x60 [ 1671.745593 ] [ < ffffffff8101405f > ] ? generic_smp_call_function_single_interrupt + 0x8f / 0x160 [ 1671.754611 ] [ < ffffffff8100339e > ] ? call_function_interrupt + 0x2e / 0x40 [ 1671.761688 ] [ < ffffffff8100e9fa > ] ? smp__call_function_interrupt + 0x6a / 0x70 [ 1671.769251 ] [ < ffffffff8101f4bb > ] ? debug_spin_lock + 0x1b / 0x50 [ 1671.775555 ] [ < ffffffff81075efc > ] ? fit_internal_poll_sendcq + 0x6c / 0x140 [ 1671.782826 ] [ < ffffffff81042039 > ] ? find_next_bit + 0x19 / 0x20 [ 1671.788934 ] [ < ffffffff8101f4bb > ] ? debug_spin_lock + 0x1b / 0x50 [ 1671.795236 ] [ < ffffffff8101dcac > ] ? task_tick_rt + 0x2c / 0xd0 [ 1671.801248 ] [ < ffffffff8101b1b7 > ] ? scheduler_tick + 0x57 / 0x60 [ 1671.807453 ] [ < ffffffff810174d5 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 1671.814240 ] [ < ffffffff81006774 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 1671.821029 ] [ < ffffffff8100e8aa > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 1671.828300 ] [ < ffffffff81012bc8 > ] ? printk + 0x118 / 0x1b0 [ 1671.833924 ] [ < ffffffff8103c161 > ] victim_finish_insert + 0x171 / 0x180 [ 1671.840711 ] [ < ffffffff8103b2a2 > ] pcache_evict_line + 0xf2 / 0x2e0 [ 1671.847110 ] [ < ffffffff81038d7c > ] pcache_alloc + 0x1ac / 0x380 [ 1671.853122 ] [ < ffffffff8103a10c > ] ? pcache_add_rmap + 0x7c / 0x260 [ 1671.859521 ] [ < ffffffff810382bb > ] common_do_fill_page + 0x2b / 0x1e0 [ 1671.866114 ] [ < ffffffff81038631 > ] pcache_handle_fault + 0x1c1 / 0x620 [ 1671.872804 ] [ < ffffffff81037fc0 > ] ? pcache_meta_to_kva + 0x30 / 0x30 [ 1671.879398 ] [ < ffffffff8101006f > ] do_page_fault + 0xaf / 0x1c0 [ 1671.885410 ] [ < ffffffff8100dedf > ] page_fault + 0x1f / 0x30 0829-w14-16: we got this by having debug_spinlock, and seq_ibapi. This is interesting and serious. I think our general C code is fine.. Should I go check the assembly part? This is the rq->lock? come on\u2026 [ 683.748135 ] ------------------- cut here ------------------- [ 683.754252 ] Possible deadlock happend [ 683.758323 ] Current call stack : [ 683.761815 ] CPU : 4 PID : 39 Comm : python 4.0.0 - lego + # 428 [ 683.767728 ] Stack : [ 683.769959 ] ffff880fc1c1fc38 ffffffff8101f48c ffff88107fc45e00 ffff880fc1c1fc60 [ 683.778103 ] ffffffff8101f4e4 ffff88107fc45e00 ffff880fc23fb000 0000000000000000 [ 683.786247 ] ffff880fc1c1fc80 ffffffff8101b18e ffff88107fc44980 0000000000000004 [ 683.794391 ] ffff880fc1c1fc98 ffffffff810174d5 ffffffff8101dddb ffff880fc1c1fcc0 [ 683.802537 ] ffffffff81006774 ffff88107fc45e00 00000004 a817c800 000000 9 a8a78c5e7 [ 683.810680 ] Call Trace : [ 683.813396 ] < TSK > [ 683.815528 ] [ < ffffffff8101f498 > ] report_deadlock + 0x58 / 0x60 [ 683.821637 ] [ < ffffffff8101f4e4 > ] debug_spin_lock + 0x44 / 0x50 [ 683.827745 ] [ < ffffffff8101b18e > ] scheduler_tick + 0x2e / 0x60 [ 683.833758 ] [ < ffffffff810174d5 > ] tick_handle_periodic + 0x45 / 0x70 [ 683.840351 ] [ < ffffffff8101dddb > ] ? dequeue_task_rt + 0x1b / 0x180 [ 683.846750 ] [ < ffffffff81006774 > ] apic_timer_interrupt + 0x54 / 0x90 [ 683.853343 ] [ < ffffffff8100e8aa > ] smp__apic_timer_interrupt + 0x6a / 0x70 [ 683.860421 ] [ < ffffffff8101f4d1 > ] ? debug_spin_lock + 0x31 / 0x50 [ 683.866723 ] [ < ffffffff8101b86e > ] try_to_wake_up + 0xce / 0x1f0 [ 683.872832 ] [ < ffffffff8101b9e4 > ] wake_up_q + 0x54 / 0xc0 [ 683.878358 ] [ < ffffffff81028487 > ] do_futex + 0x407 / 0x620 [ 683.883982 ] [ < ffffffff8103a941 > ] ? pcache_add_rmap + 0xb1 / 0x600 [ 683.890381 ] [ < ffffffff8102870c > ] sys_futex + 0x6c / 0x130 [ 683.896005 ] [ < ffffffff8100ec66 > ] do_syscall_64 + 0x36 / 0xc0 [ 683.901919 ] [ < ffffffff8100db6c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25 Aug 27 \u00b6 There a lot lost CQE cases. This one is about P->M->S. And M lost the CQE for the WQE sent to S. 0827 - w9 -5 [ 963.304865 ] watchdog : worker [ 0 ] CPU10 stucked [ 963.309712 ] watchdog : common_header [ op = 0x20000000 src_nid : 0 ] [ 963.316210 ] CPU : 10 PID : 20 Comm : thpool - worker0 4.0.0 - lego + # 43 [ 963.322899 ] RIP : 0010 : [ < ffffffff8106ad51 > ] [ < ffffffff8106ad51 > ] fit_send_reply_with_rdma_write_with_imm + 0x2a1 / 0x3a0 [ 963.334632 ] RSP : 0000 : ffff88103ef3fc20 EFLAGS : 000002 87 [ 963.340547 ] RAX : 00000000f fffb6d4 RBX : 000000000000000 b RCX : 0000000000001770 [ 963.348498 ] RDX : 00000000f fffa70d RSI : fffffffffffff039 RDI : 0000000000000000 [ 963.356450 ] RBP : ffff88103ef3fcc0 R08 : 000000000000001f R09 : 0000000000000002 [ 963.364400 ] R10 : 00000000 80000000 R11 : 000077f f80000000 R12 : 0000000000000000 [ 963.372352 ] R13 : ffff88103ef26738 R14 : 00000000000 b3d54 R15 : ffff88103ef25008 [ 963.380303 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fca0000 ( 0000 ) knlGS : 0000000000000000 [ 963.389320 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 963.395720 ] CR2 : 0000000000000000 CR3 : 000000000116 a000 CR4 : 00000000000406 a0 [ 963.403671 ] Stack : [ 963.405901 ] 00007f ff000b3d54 ffffffff800b3d54 ffff881000000004 ffff88103ef3fc78 [ 963.414045 ] 0000000 900000000 ffff881000000000 0000100 800000001 ffff88103d216000 [ 963.422191 ] ffff88103eebae48 800 b3d540000011c ffffff9b00000246 ffffea0000000001 [ 963.430337 ] 000000103 d216000 0000000000010 c00 000000000000011 c 000000000000100 8 [ 963.438481 ] 000000000000011 c 000000000000100 8 ffff88103eebae48 ffff88103ef3fd70 [ 963.446626 ] Call Trace : [ 963.449342 ] < TSK > [ 963.451475 ] [ < ffffffff81067c80 > ] ibapi_send_reply_imm + 0x50 / 0xd0 [ 963.458068 ] [ < ffffffff8102e953 > ] ? __storage_read + 0xc3 / 0x120 [ 963.464371 ] [ < ffffffff8102e953 > ] __storage_read + 0xc3 / 0x120 [ 963.470480 ] [ < ffffffff8102e9bf > ] storage_read + 0xf / 0x50 [ 963.476201 ] [ < ffffffff8102eab7 > ] storage_vma_fault + 0xb7 / 0x130 [ 963.482600 ] [ < ffffffff8103262f > ] handle_lego_mm_fault + 0x13f / 0x4a0 [ 963.489389 ] [ < ffffffff8102ecf4 > ] common_handle_p2m_miss . isra .1 + 0x54 / 0xc0 [ 963.496855 ] [ < ffffffff8102edc7 > ] handle_p2m_pcache_miss + 0x67 / 0x2d0 [ 963.503739 ] [ < ffffffff8102bf96 > ] thpool_worker_func + 0x296 / 0x3a0 [ 963.510332 ] [ < ffffffff8102bd00 > ] ? handle_bad_request + 0x40 / 0x40 [ 963.516926 ] [ < ffffffff81020ca6 > ] kthread + 0xf6 / 0x120 [ 963.522357 ] [ < ffffffff81020bb0 > ] ? __kthread_parkme + 0x70 / 0x70 [ 963.528756 ] [ < ffffffff8100e632 > ] ret_from_fork + 0x22 / 0x30 hmm, another on lost CQE happen at P. Today is weird, why we happen to have so many lost CQE today? Think about why CQE is not generated? 0827 - w14 -6 [ 1185.835707 ] ***** ***** Fail to to get the CQE from send_cq after 20 seconds ! ***** This means the packet was lost and something went wrong ***** with your NIC ... ***** connection_id : 7 dest node : 1 ***** [ 1185.856465 ] IB Stats : [ 1185.858985 ] nr_ib_send_reply : 3452 [ 1185.864221 ] nr_bytes_tx : 506507 [ 1185.869456 ] nr_bytes_rx : 8981004 [ 1185.874692 ] ------------ [ cut here ] ------------ [ 1185.879829 ] WARNING : CPU : 14 PID : 22 at net / lego / fit_internal . c : 1108 fit_internal_poll_sendcq + 0xe5 / 0x140 [ 1185.890399 ] CPU : 14 PID : 22 Comm : python 4.0.0 - lego + # 356 [ 1185.896410 ] Stack : [ 1185.898640 ] ffff88103c49fb30 ffffffff810126f5 ffff88103cb22000 00000004 a817c800 [ 1185.906784 ] 0000010f7139214f 0000000000000007 ffff88103c49fb40 ffffffff810127cf [ 1185.914927 ] ffff88103c49fbf0 ffffffff810724b5 000000023 cb2c280 ffff88103cb2c1f8 [ 1185.923072 ] 00000000000002 86 ffff88103c49fc18 ffff88103cb06000 ffff88103cb2c150 [ 1185.931217 ] 000000000000024 b ffff88108101c7dc ffff88107fce5d80 ffff88103c46f000 [ 1185.939360 ] Call Trace : [ 1185.942075 ] < TSK > [ 1185.944209 ] [ < ffffffff81012701 > ] __warn . constprop .1 + 0x91 / 0xd0 [ 1185.950607 ] [ < ffffffff810127cf > ] warn_slowpath_null + 0xf / 0x20 [ 1185.956909 ] [ < ffffffff810724b5 > ] fit_internal_poll_sendcq + 0xe5 / 0x140 [ 1185.963987 ] [ < ffffffff81019dd5 > ] ? scheduler_tick + 0x55 / 0x60 [ 1185.970192 ] [ < ffffffff81072662 > ] fit_send_message_with_rdma_write_with_imm_request + 0x152 / 0x350 [ 1185.979791 ] [ < ffffffff810741ff > ] fit_send_reply_with_rdma_write_with_imm + 0x25f / 0x3a0 [ 1185.988420 ] [ < ffffffff810368c2 > ] ? __pcache_do_fill_page + 0xc2 / 0x1d0 [ 1185.995401 ] [ < ffffffff810701e9 > ] ibapi_send_reply_timeout + 0x79 / 0x120 [ 1186.002479 ] [ < ffffffff810368c2 > ] ? __pcache_do_fill_page + 0xc2 / 0x1d0 [ 1186.009459 ] [ < ffffffff810368c2 > ] __pcache_do_fill_page + 0xc2 / 0x1d0 [ 1186.016245 ] [ < ffffffff81036ac4 > ] common_do_fill_page + 0xf4 / 0x1f0 [ 1186.022839 ] [ < ffffffff81036d80 > ] pcache_handle_fault + 0x1c0 / 0x610 [ 1186.029528 ] [ < ffffffff81036800 > ] ? __pcache_do_zerofill_page + 0x100 / 0x100 [ 1186.036995 ] [ < ffffffff8100fdff > ] do_page_fault + 0xaf / 0x1c0 [ 1186.043005 ] [ < ffffffff8100dc1f > ] page_fault + 0x1f / 0x30 Aug 26 \u00b6 Oh well. I saw the same damn lost packet issue again. The issue can be desribed as: P use lite rpc to send a request to M. M processed the handled, and called rpc reply to sent back to P. M need to poll send_cq to poll completion. But M fail to get the CQE for the should-be-sent-out WQE. This is tested with M\u2019s CONFIG_FIT_NOWAIT optimization, which is basically an optimization that M will not poll cq every time a reply was sent out, instead, do batch polling. The following stack dump was reported by M side watchdog. It is not necessary mlx4_poll_cq\u2019s issue, since there is a while (1) loop at fit code. Oh well. Log name : 0826 - w9 -1 [ 187736.669027 ] watchdog : worker [ 0 ] CPU10 stucked [ 187736.673972 ] watchdog : common_header [ op = 0x30000000 src_nid : 0 ] [ 187736.680566 ] CPU : 10 PID : 20 Comm : thpool - worker0 4.0.0 - lego + # 26 [ 187736.687351 ] RIP : 0010 : [ < ffffffff810522c3 > ] [ < ffffffff810522c3 > ] mlx4_ib_poll_cq + 0x1d3 / 0x850 [ 187736.696854 ] RSP : 0000 : ffff88103ef3f750 EFLAGS : 000002 86 [ 187736.702865 ] RAX : 00000000f ffffff5 RBX : 0000000000000000 RCX : ffff88103ed6b050 [ 187736.710913 ] RDX : 00000000 80630000 RSI : 0000000000000001 RDI : ffff88103edb0bf0 [ 187736.718961 ] RBP : ffff88103ef3f7b8 R08 : 0000000000000020 R09 : 0000000000000002 [ 187736.727007 ] R10 : 0000000f fc53fddc R11 : 0000000040 bf1040 R12 : ffff88103ef3f7c8 [ 187736.735055 ] R13 : 0000000000000000 R14 : 0000000000000000 R15 : ffff88103edb0bf0 [ 187736.743104 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fca0000 ( 0000 ) knlGS : 0000000000000000 [ 187736.752218 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 187736.758714 ] CR2 : 0000000000000000 CR3 : 000000000116 a000 CR4 : 00000000000406 a0 [ 187736.766762 ] Stack : [ 187736.769089 ] 0000000f fc53fddc 0000000000000002 0000000000000020 ffff88103edb0c98 [ 187736.777331 ] 00000000000002 86 00000000 80630000 ffff88103ef3f7d0 000063 8000000018 [ 187736.785572 ] ffff88103edb0bf0 0000000000000001 ffff88103ef25008 0000000000000003 [ 187736.793813 ] 000000000000000 c ffff88103ef3fd30 ffffffff8106920c ffff88103ef3fd54 [ 187736.802054 ] 0000000100000000 0000000100000000 ffff88103edb07b0 ffff88103e81b008 [ 187736.810296 ] Call Trace : [ 187736.813108 ] < TSK > [ 187736.815338 ] [ < ffffffff8106920c > ] fit_internal_poll_sendcq + 0x6c / 0xe0 [ 187736.822416 ] [ < ffffffff8106ab2f > ] ? fit_send_reply_with_rdma_write_with_imm + 0x25f / 0x3a0 [ 187736.831336 ] [ < ffffffff81033ff0 > ] ? _lego_copy_to_user + 0x110 / 0x250 [ 187736.838220 ] [ < ffffffff81028d65 > ] ? __free_pages + 0x25 / 0x30 [ 187736.844329 ] [ < ffffffff8102e981 > ] ? __storage_read + 0xf1 / 0x120 [ 187736.850728 ] [ < ffffffff81019865 > ] ? scheduler_tick + 0x55 / 0x60 [ 187736.857031 ] [ < ffffffff810693d2 > ] ? fit_send_message_with_rdma_write_with_imm_request + 0x152 / 0x350 [ 187736.866920 ] [ < ffffffff810693d2 > ] ? fit_send_message_with_rdma_write_with_imm_request + 0x152 / 0x350 [ 187736.876810 ] [ < ffffffff8103043f > ] ? __vma_adjust + 0x38f / 0x550 [ 187736.883113 ] [ < ffffffff81030944 > ] ? vma_merge + 0x1a4 / 0x280 [ 187736.889123 ] [ < ffffffff81030f20 > ] ? arch_get_unmapped_area_topdown + 0xe0 / 0x220 [ 187736.897075 ] [ < ffffffff810693d2 > ] fit_send_message_with_rdma_write_with_imm_request + 0x152 / 0x350 [ 187736.906771 ] [ < ffffffff81069ab5 > ] fit_ack_reply_callback + 0x185 / 0x1e0 [ 187736.913848 ] [ < ffffffff8102f129 > ] ? handle_p2m_flush_one + 0x69 / 0x160 [ 187736.920830 ] [ < ffffffff8102bde0 > ] thpool_worker_func + 0xe0 / 0x3a0 [ 187736.927424 ] [ < ffffffff8102bd00 > ] ? handle_bad_request + 0x40 / 0x40 [ 187736.934113 ] [ < ffffffff81020ca6 > ] kthread + 0xf6 / 0x120 [ 187736.939639 ] [ < ffffffff81020bb0 > ] ? __kthread_parkme + 0x70 / 0x70 [ 187736.946137 ] [ < ffffffff8100e632 > ] ret_from_fork + 0x22 / 0x30 Aug 22 \u00b6 Damn it!!! After so much effort verifying we had a solid IB stack, we still has memory corruption and deadlock issues. Fuck! One thing at a time, simple stuff first. Okay, tomorrow first add DEBUG_SPINLOCK to detect possible deadlocks. This, could help to identify some buggy code. After this, I will spend some time looking into the LITE, it\u2019s fucking HEAVY. I do found a lot issues during summer. Personally, I\u2019m not feeling good this days. I treat someone with love and respect, but there is not too much in return. Yeahyeahyeah, I know how this works. It\u2019s just sad that sometimes you just have a BAD timing. I\u2019ve went through too much things in 2018, good and bad. I care sooo much about the people I love, family and others. I feel this is good, of course. Anyway, it is supposed to be a Lego dump, that no one probably interested in.","title":"Aug 2018"},{"location":"lego/log/log-08-2018/#aug-2018","text":"","title":"Aug 2018"},{"location":"lego/log/log-08-2018/#aug-31","text":"","title":"Aug 31"},{"location":"lego/log/log-08-2018/#one-major-todo","text":"Check do_handle_p2m_pcache_miss() . We MUST remove that mempcy, maybe by using another flag in thpool. This is just no acceptable.","title":"One major TODO"},{"location":"lego/log/log-08-2018/#ugh","text":"Fuck. Without debug_mm, there is still memory corruption.","title":"Ugh"},{"location":"lego/log/log-08-2018/#try-max_send_wr-and-number-of-qps","text":"without lock_ib, with debug_mm. Change max_send_wr at all P M S. QP=4, max_send_wr = 1: always fail QP=4, max_send_wr = 256: always fail QP=24, max_send_wr = 1: succeed (0831-w14-18 0831-w14-20) QP=24, max_send_wr = 256: succeed (0831-w14-16 0831-w14-17) Pay attention to the 0831-w14-15 \uff1a something wrong with our timekeeping code? QP=24, max_send_wr = 1 case.","title":"Try max_send_wr and number of QPs"},{"location":"lego/log/log-08-2018/#after-victim-bug-fix","text":"MNIST 4 threads With lock_ib, debug_mm etc: 3 successful runs Only with debug_mm: Well fit failed. Lost CQE. Now the debug scope is limited. Let me try the micro test suite, to stress ibapi_send_reply itself. Potential: read/write buffer.","title":"After Victim bug fix"},{"location":"lego/log/log-08-2018/#aug-30","text":"Be humble.","title":"Aug 30"},{"location":"lego/log/log-08-2018/#identified-victim-bug","text":"Finally. I thought it through, and with the help of this 0830-w14-12 . The bug is in victim_try_fill_pcache() , when there are multiple hits to the same victim. Since we released the usable_victim_lock after a hit. There might a be race case where: 1) CPU0 reached dec_and_test_filling , and passed to free the line. 2) CPU1 just got to the victim_check_hit , and increment the fill counter to 1 again. When CPU1 finished filling, and do dec_and_test_filling , it will do the free again!!! What a double free. Tomorrow, let me do the fix. Thought: adding more sync in victim_check_hit part. Basically we want to ensure only one CPU can do the final free.","title":"Identified victim bug."},{"location":"lego/log/log-08-2018/#after-adding-pi_lock","text":"Okay. the pi_lock is added. Although it is mostly used by futex-pi and rt-mutex, we lego does not have these two guys. Therefore, it is only used by sched/core.c, exit.c, and kthread.c. 99% is in core.c The purpose of having this back is to have the spin_lock_irqsave(&p->pi_lock) back. Most scheduling code is not recursive, we have to disable interrupt. Of course we can use spin_lock_irqsave(&rq->lock) instead of spin_lock(&rq->lock) . But this is too dangerous at this stage. Porting based on Linux now is the fastest and safest way. The importance of disabling interrupt in some kernel path!! Good. Now I\u2019m seeing now debuggable victim issue. Classical deadlock catched. Now, only two victims. [ 2819.068997 ] CPU14 PID29 Abort victim alloc ( 20010 ms ) nr_usable_victims : 2. From pset_idx : 532 nr_lru : 63 fault_uva : 0x7fff98614000 [ 2819.094409 ] CPU14 PID29 -- Start Dump Victim Cache [ 0 ] total : 2 [ 2819.114188 ] CPU14 PID29 victim [ 0 ] : ffffffff810c2880 refcount : 2 nr_fill : 1 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2819.133289 ] CPU14 PID29 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffcc000000 [ 2819.141723 ] CPU14 PID29 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2819.149770 ] CPU14 PID29 victim [ 1 ] : ffffffff810c2900 refcount : 2 nr_fill : 1 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2819.168870 ] CPU14 PID29 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffb0000000 [ 2819.177306 ] CPU14 PID29 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2819.185352 ] CPU14 PID29 -- End Dump Victim Cache [ 0 ] [ 2819.081708 ] CPU16 PID30 Abort victim alloc ( 20010 ms ) nr_usable_victims : 2. From pset_idx : 0 nr_lru : 63 fault_uva : 0x7fffcc000024 [ 2819.209008 ] CPU16 PID30 -- Start Dump Victim Cache [ 1 ] total : 2 [ 2819.223358 ] CPU16 PID30 victim [ 0 ] : ffffffff810c2880 refcount : 2 nr_fill : 1 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2819.252443 ] CPU16 PID30 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffcc000000 [ 2819.260879 ] CPU16 PID30 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2819.268926 ] CPU16 PID30 victim [ 1 ] : ffffffff810c2900 refcount : 2 nr_fill : 1 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2819.288026 ] CPU16 PID30 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffb0000000 [ 2819.296461 ] CPU16 PID30 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2819.304508 ] CPU16 PID30 -- End Dump Victim Cache [ 1 ] [ 2819.101391 ] CPU18 PID31 Abort victim alloc ( 20010 ms ) nr_usable_victims : 2. From pset_idx : 15 nr_lru : 63 fault_uva : 0x7fff98c0f000 [ 2819.328165 ] CPU18 PID31 -- Start Dump Victim Cache [ 2 ] total : 2 [ 2819.335146 ] CPU18 PID31 victim [ 0 ] : ffffffff810c2880 refcount : 1 nr_fill : 0 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2819.354246 ] CPU18 PID31 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffcc000000 [ 2819.362680 ] CPU18 PID31 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2819.370728 ] CPU18 PID31 victim [ 1 ] : ffffffff810c2900 refcount : 2 nr_fill : 1 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2819.389828 ] CPU18 PID31 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffb0000000 [ 2819.398262 ] CPU18 PID31 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2819.406310 ] CPU18 PID31 -- End Dump Victim Cache [ 2 ] # # This guy grabbed the fill counter right before the first timout # That's why the above three timeout happen. And this one is 20s later # which equals to the timeout second. # [ 2839.327457 ] CPU12 PID28 Abort victim alloc ( 20010 ms ) nr_usable_victims : 2. From pset_idx : 0 nr_lru : 63 fault_uva : 0x7fffb0000f00 [ 2839.339964 ] CPU12 PID28 -- Start Dump Victim Cache [ 3 ] total : 2 [ 2839.346945 ] CPU12 PID28 victim [ 0 ] : ffffffff810c2880 refcount : 1 nr_fill : 0 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2839.366046 ] CPU12 PID28 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffcc000000 [ 2839.374480 ] CPU12 PID28 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2839.382527 ] CPU12 PID28 victim [ 1 ] : ffffffff810c2900 refcount : 2 nr_fill : 1 max_fill : 4 locked : 0 flags :( 0x14e )( allocated | usable | hasdata | flushed | fillfree ) pcm : ( null ) pset : ffff88207ff5a000 [ 2839.401628 ] CPU12 PID28 hit [ 0 ] owner : 21 m_nid : 1 rep_nid : 1 addr : 0x7fffb0000000 [ 2839.410062 ] CPU12 PID28 rmap to pset : ffff88207ff5a000 set_idx : 0 nr_lru : 63 [ 2839.418109 ] CPU12 PID28 -- End Dump Victim Cache [ 3 ]","title":"After adding pi_lock"},{"location":"lego/log/log-08-2018/#rq-lock-deadlock","text":"Alright. We had rq->lock deadlock issue. Basically, we missed the part of disabling interrupt. A timer interrupt will try to acquire the lock again. Then, bang we have a deadlock. Digging into the code, you will be able to find the cause easily. The root cause we removed all the pi_lock stuff, which actually have a lot irqsave usages\u2026 Oh man, maybe it\u2019s time to add it back. [ 3367.835389] ------------------- cut here ------------------- [ 3367.841504] Possible deadlock happend locker_cpu: 0 [ 3367.846934] Current call stack: [ 3367.850425] CPU: 0 PID: 1 Comm: kernel_init 4.0.0-lego+ #437 [ 3367.856726] Stack: [ 3367.858957] ffff88107ff0fa58 ffffffff8101f4b6 ffff88107fc05e00 00000004a817c800 [ 3367.867101] ffff88107ff0fa80 ffffffff8101f52e ffff88107fc05e00 ffff88107ffb4000 [ 3367.875246] 0000000000000000 ffff88107ff0faa0 ffffffff8101b1ae ffff88107fc04980 [ 3367.883390] 0000000000000000 ffff88107ff0fab8 ffffffff810174f5 0000000000000286 [ 3367.891535] ffff88107ff0fae0 ffffffff81006774 ffff88107ffb9000 ffff88107fc05e00 [ 3367.899680] Call Trace: [ 3367.902396] <TSK> [ 3367.904528] [<ffffffff8101f4c2>] report_deadlock+0x62/0x80 [ 3367.910637] [<ffffffff8101f52e>] debug_spin_lock+0x4e/0x60 [ 3367.916745] [<ffffffff8101b1ae>] scheduler_tick+0x2e/0x60 [ 3367.922756] [<ffffffff810174f5>] tick_handle_periodic+0x45/0x70 [ 3367.929350] [<ffffffff81006774>] apic_timer_interrupt+0x54/0x90 [ 3367.935943] [<ffffffff8100e8aa>] smp__apic_timer_interrupt+0x6a/0x70 [ 3367.943021] [<ffffffff8101db99>] ? enqueue_task_rt+0x149/0x250 [ 3367.949518] [<ffffffff8105908a>] ? __mlx4_write_mtt+0xea/0x140 [ 3367.956014] [<ffffffff8101ad34>] activate_task+0x44/0x50 [ 3367.961929] [<ffffffff8101b667>] ttwu_do_activate+0x27/0x50 [ 3367.968134] [<ffffffff8101b89c>] try_to_wake_up+0xdc/0x1f0 [ 3367.974243] [<ffffffff8106cc20>] ? ib_mad_send_done_handler.isra.22+0x4d0/0x4d0 [ 3367.982388] [<ffffffff8101ba80>] wake_up_process+0x10/0x20 [ 3367.988497] [<ffffffff81023116>] __kthread_create_on_node+0x146/0x230 [ 3367.995671] [<ffffffff8102329f>] kthread_create_on_node+0x2f/0x40 [ 3368.002459] [<ffffffff81066873>] ? ib_create_cq+0x23/0x60 [ 3368.008470] [<ffffffff810695e1>] ib_mad_init_device+0x1f1/0x7b0 [ 3368.015064] [<ffffffff81067246>] ib_register_device+0x5d6/0x690 [ 3368.021657] [<ffffffff8105e9d3>] mlx4_ib_add+0x653/0x780 [ 3368.027571] [<ffffffff8105147d>] mlx4_add_device+0x8d/0x130 [ 3368.033777] [<ffffffff8105158c>] mlx4_register_interface+0x6c/0xa0 [ 3368.040661] [<ffffffff811dc660>] mlx4_ib_init+0x10/0x20 [ 3368.046478] [<ffffffff811dc619>] mlx4_init+0x19/0x50 [ 3368.052005] [<ffffffff811dc68d>] ib_core_init+0x1d/0x30 [ 3368.057823] [<ffffffff811db7f9>] device_init+0x9/0x10 [ 3368.063447] [<ffffffff8100030b>] kernel_init+0x4b/0xc0 [ 3368.069168] [<ffffffff8101b0ea>] ? schedule_tail+0xa/0x40 [ 3368.075178] [<ffffffff810002c0>] ? 0xffffffff810002c0 [ 3368.080803] [<ffffffff8100eb32>] ret_from_fork+0x22/0x30 [ 3368.086718] <EOT> 0830-w14-1: I really don\u2019t know how this happen. The refcounter and fill counter should be enough to serialize.. [37722.177024] CPU20 PID31 victim:ffffffff810c2880 index:0 refcount:0 nr_fill:0 max_fill:4 locked:0 flags:(0x12e)(allocated|usable|hasdata|waitflush|fillfree) pcm: (null) pset:ffff88207ff5b980 [37722.196623] CPU20 PID31 hit[0] owner:22 m_nid:1 rep_nid:1 addr: 0x2c33000 [37722.204572] CPU20 PID31 victim:ffffffff810c2880 index:0 refcount:0 nr_fill:0 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm: (null) pset:ffff88207ff5b980 [37722.224154] CPU20 PID31 rmap to pset:ffff88207ff5b980 set_idx: 51 nr_lru:63 [37722.232299] CPU20 PID31 victim dumped because: PCACHE_BUG_ON_VICTIM(!VictimAllocated(v) || !VictimUsable(v) || !VictimFlushed(v) || VictimWriteback(v) || VictimLocked(v)) [37722.254790] WARNING: CPU: 20 PID: 31 at managers/processor/pcache/victim.c:196 __put_victim_nolist+0xb8/0x140 ffffffff8103e170[37722.453632] [<ffffffff8103c9c8>] __put_victim_nolist+0xb8/0x140 0000000000000000[37722.461873] [<ffffffff8103db18>] victim_try_fill_pcache+0x2f8/0x440 [37722.265842] CPU10 PID20 victim:ffffffff810c2880 index:0 refcount:0 nr_fill:0 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm: (null) pset:ffff88207ff5b980 [37722.291438] CPU10 PID20 hit[0] owner:22 m_nid:1 rep_nid:1 addr: 0x2c33000 [37722.301616] CPU10 PID20 victim:ffffffff810c2880 index:0 refcount:0 nr_fill:0 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm: (null) pset:ffff88207ff5b980 [37722.324206] CPU10 PID20 rmap to pset:ffff88207ff5b980 set_idx: 51 nr_lru:63 [37722.332349] CPU10 PID20 victim dumped because: PCACHE_BUG_ON_VICTIM(victim_ref_count(v) == 0) [37722.350673] WARNING: CPU: 10 PID: 20 at ./include/processor/pcache_victim.h:127 __victim_flush_func+0x232/0x250 [37722.363568] CPU: 10 PID: 20 Comm: kvictim_flushd 4.0.0-lego+ #435 [37722.534003] [<ffffffff8103e152>] __victim_flush_func+0x232/0x250 [37722.547577] [<ffffffff8103e1d9>] victim_flush_async+0x69/0xb0 [37722.553975] [<ffffffff81022ec1>] kthread+0x111/0x130 [37722.565900] [<ffffffff8100eb32>] ret_from_fork+0x22/0x30","title":"rq-&gt;lock deadlock"},{"location":"lego/log/log-08-2018/#aug-29","text":"The only thing left about core_IB is: ib_sa_query, which will be invoked when there is a mlx4 interrupts. Not sure if this is important. Anyway. Testing TF 4 threads MNIST again. When I enable SEQ_IBAPI\uff1a 0829-w14-11 (0829-w09-11) succeed 0829-w14-12: P side seems have deadlock. Let me enable DEBUG_SPINLOCK. 0829-w14-13: SEQ_IBAPI, DEBUG_SPINLOCK, this is a very useful log: [ 531.495545 ] STDOUT : --- [ INFO : tensorflow : loss = 0.5256375 , step = 101 ( 25.166 sec ) ] --- [ 531.624474 ] BUG : unable to handle kernel NULL pointer dereference at 0000000000000064 [ 531.633016 ] IP : [ < ffffffff8103b60e > ] __put_victim_nolist + 0xe / 0xa0 [ 531.639803 ] PGD 0 [ 531.642032 ] Oops : 0002 [ # 1 ] SMP PROCESSOR [ 531.646493 ] CPU : 10 PID : 20 Comm : kvictim_flushd 4.0.0 - lego + # 426 [ 531.653279 ] RIP : 0010 : [ < ffffffff8103b60e > ] [ < ffffffff8103b60e > ] __put_victim_nolist + 0xe / 0xa0 [ 531.662781 ] RSP : 0000 : ffff880fe392fde0 EFLAGS : 00010006 [ 531.668696 ] RAX : 0000000000000000 RBX : ffffffff810c2b00 RCX : ffffffff810c2b70 [ 531.676646 ] RDX : ffffffff810c2b70 RSI : 0000007 aea3f42fa RDI : ffffffff810c2b00 [ 531.684597 ] RBP : ffff880fe392fdf0 R08 : 000000000000001f R09 : 0000000000000002 [ 531.692548 ] R10 : 00000000 80000000 R11 : 00000000000664 c3 R12 : ffff88207ff57000 [ 531.700498 ] R13 : ffffffff810c2b60 R14 : ffff880a72555000 R15 : ffffffff810c2b48 [ 531.708449 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fca0000 ( 0000 ) knlGS : 0000000000000000 [ 531.717466 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 531.723865 ] CR2 : 0000000000000064 CR3 : 00000000011 b9000 CR4 : 00000000000406 a0 [ 531.731816 ] Stack : [ 531.734046 ] ffffffff810c2b00 ffff88207ff57000 ffff880fe392fe08 ffffffff8103bbea [ 531.742190 ] ffffffff810c2b00 ffff880fe392fe48 ffffffff8103c729 00000000 8103 d7c2 [ 531.750335 ] ffff880a72555060 ffff88107ff0fdc8 0000000000000000 ffffffff8103c780 [ 531.758479 ] 0000000000000000 ffff880fe392fe60 ffffffff8103c7e6 ffff880fe391c000 [ 531.766623 ] ffff880fe392ff48 ffffffff81022e81 0000000000000000 0000000000000000 [ 531.774768 ] Call Trace : [ 531.777483 ] < TSK > [ 531.779617 ] [ < ffffffff8103bbea > ] __put_victim + 0x4a / 0x50 [ 531.785433 ] [ < ffffffff8103c729 > ] __victim_flush_func + 0xb9 / 0x110 [ 531.792027 ] [ < ffffffff8103c780 > ] ? __victim_flush_func + 0x110 / 0x110 [ 531.798911 ] [ < ffffffff8103c7e6 > ] victim_flush_async + 0x66 / 0x90 [ 531.805310 ] [ < ffffffff81022e81 > ] kthread + 0x111 / 0x130 [ 531.810836 ] [ < ffffffff81022d70 > ] ? __kthread_parkme + 0x70 / 0x70 [ 531.817236 ] [ < ffffffff8100eb32 > ] ret_from_fork + 0x22 / 0x30 [ 531.823151 ] < EOT > 0829-w14-14: this looks like a double free, or concurrent eviction. But if you look into the evict code, we will check the Flushed flag. It means another eviction routine should have skipped this line, and will not pick this line to do eviction. Some other possibilities? check until 0829-w14-18 [ 1671.661424 ] ------------ [ cut here ] ------------ [ 1671.666378 ] BUG : failure at managers / processor / pcache / victim . c : 610 / victim_finish_insert () ! [ 1671.675591 ] Kernel Panic - not syncing : BUG ! [ 1671.680339 ] CPU : 20 PID : 31 Comm : python 4.0.0 - lego + # 426 [ 1671.686351 ] Stack : [ 1671.688581 ] ffff880fbe76fda0 ffffffff810289b7 ffffffff00000008 ffff880fbe76fdb0 [ 1671.696725 ] ffff880fbe76fd68 ffffff0021475542 ffff88107fd45e00 ffff880fbe753000 [ 1671.704870 ] 0000000000000000 0000000000000001 ffff880fbe76f9b0 ffffffff8101b1b7 [ 1671.713015 ] ffff88107fd44980 ffff880fbe76f9d8 ffffffff8101405f 0000000000000000 [ 1671.721160 ] 0000000000000001 ffff880ff992a000 0000000000000001 ffff880fbe76f9f0 [ 1671.729304 ] Call Trace : [ 1671.732019 ] < TSK > [ 1671.734153 ] [ < ffffffff810289c3 > ] panic + 0xc2 / 0x10a [ 1671.739388 ] [ < ffffffff8101b1b7 > ] ? scheduler_tick + 0x57 / 0x60 [ 1671.745593 ] [ < ffffffff8101405f > ] ? generic_smp_call_function_single_interrupt + 0x8f / 0x160 [ 1671.754611 ] [ < ffffffff8100339e > ] ? call_function_interrupt + 0x2e / 0x40 [ 1671.761688 ] [ < ffffffff8100e9fa > ] ? smp__call_function_interrupt + 0x6a / 0x70 [ 1671.769251 ] [ < ffffffff8101f4bb > ] ? debug_spin_lock + 0x1b / 0x50 [ 1671.775555 ] [ < ffffffff81075efc > ] ? fit_internal_poll_sendcq + 0x6c / 0x140 [ 1671.782826 ] [ < ffffffff81042039 > ] ? find_next_bit + 0x19 / 0x20 [ 1671.788934 ] [ < ffffffff8101f4bb > ] ? debug_spin_lock + 0x1b / 0x50 [ 1671.795236 ] [ < ffffffff8101dcac > ] ? task_tick_rt + 0x2c / 0xd0 [ 1671.801248 ] [ < ffffffff8101b1b7 > ] ? scheduler_tick + 0x57 / 0x60 [ 1671.807453 ] [ < ffffffff810174d5 > ] ? tick_handle_periodic + 0x45 / 0x70 [ 1671.814240 ] [ < ffffffff81006774 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 1671.821029 ] [ < ffffffff8100e8aa > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 1671.828300 ] [ < ffffffff81012bc8 > ] ? printk + 0x118 / 0x1b0 [ 1671.833924 ] [ < ffffffff8103c161 > ] victim_finish_insert + 0x171 / 0x180 [ 1671.840711 ] [ < ffffffff8103b2a2 > ] pcache_evict_line + 0xf2 / 0x2e0 [ 1671.847110 ] [ < ffffffff81038d7c > ] pcache_alloc + 0x1ac / 0x380 [ 1671.853122 ] [ < ffffffff8103a10c > ] ? pcache_add_rmap + 0x7c / 0x260 [ 1671.859521 ] [ < ffffffff810382bb > ] common_do_fill_page + 0x2b / 0x1e0 [ 1671.866114 ] [ < ffffffff81038631 > ] pcache_handle_fault + 0x1c1 / 0x620 [ 1671.872804 ] [ < ffffffff81037fc0 > ] ? pcache_meta_to_kva + 0x30 / 0x30 [ 1671.879398 ] [ < ffffffff8101006f > ] do_page_fault + 0xaf / 0x1c0 [ 1671.885410 ] [ < ffffffff8100dedf > ] page_fault + 0x1f / 0x30 0829-w14-16: we got this by having debug_spinlock, and seq_ibapi. This is interesting and serious. I think our general C code is fine.. Should I go check the assembly part? This is the rq->lock? come on\u2026 [ 683.748135 ] ------------------- cut here ------------------- [ 683.754252 ] Possible deadlock happend [ 683.758323 ] Current call stack : [ 683.761815 ] CPU : 4 PID : 39 Comm : python 4.0.0 - lego + # 428 [ 683.767728 ] Stack : [ 683.769959 ] ffff880fc1c1fc38 ffffffff8101f48c ffff88107fc45e00 ffff880fc1c1fc60 [ 683.778103 ] ffffffff8101f4e4 ffff88107fc45e00 ffff880fc23fb000 0000000000000000 [ 683.786247 ] ffff880fc1c1fc80 ffffffff8101b18e ffff88107fc44980 0000000000000004 [ 683.794391 ] ffff880fc1c1fc98 ffffffff810174d5 ffffffff8101dddb ffff880fc1c1fcc0 [ 683.802537 ] ffffffff81006774 ffff88107fc45e00 00000004 a817c800 000000 9 a8a78c5e7 [ 683.810680 ] Call Trace : [ 683.813396 ] < TSK > [ 683.815528 ] [ < ffffffff8101f498 > ] report_deadlock + 0x58 / 0x60 [ 683.821637 ] [ < ffffffff8101f4e4 > ] debug_spin_lock + 0x44 / 0x50 [ 683.827745 ] [ < ffffffff8101b18e > ] scheduler_tick + 0x2e / 0x60 [ 683.833758 ] [ < ffffffff810174d5 > ] tick_handle_periodic + 0x45 / 0x70 [ 683.840351 ] [ < ffffffff8101dddb > ] ? dequeue_task_rt + 0x1b / 0x180 [ 683.846750 ] [ < ffffffff81006774 > ] apic_timer_interrupt + 0x54 / 0x90 [ 683.853343 ] [ < ffffffff8100e8aa > ] smp__apic_timer_interrupt + 0x6a / 0x70 [ 683.860421 ] [ < ffffffff8101f4d1 > ] ? debug_spin_lock + 0x31 / 0x50 [ 683.866723 ] [ < ffffffff8101b86e > ] try_to_wake_up + 0xce / 0x1f0 [ 683.872832 ] [ < ffffffff8101b9e4 > ] wake_up_q + 0x54 / 0xc0 [ 683.878358 ] [ < ffffffff81028487 > ] do_futex + 0x407 / 0x620 [ 683.883982 ] [ < ffffffff8103a941 > ] ? pcache_add_rmap + 0xb1 / 0x600 [ 683.890381 ] [ < ffffffff8102870c > ] sys_futex + 0x6c / 0x130 [ 683.896005 ] [ < ffffffff8100ec66 > ] do_syscall_64 + 0x36 / 0xc0 [ 683.901919 ] [ < ffffffff8100db6c > ] entry_SYSCALL64_slow_path + 0x25 / 0x25","title":"Aug 29"},{"location":"lego/log/log-08-2018/#aug-27","text":"There a lot lost CQE cases. This one is about P->M->S. And M lost the CQE for the WQE sent to S. 0827 - w9 -5 [ 963.304865 ] watchdog : worker [ 0 ] CPU10 stucked [ 963.309712 ] watchdog : common_header [ op = 0x20000000 src_nid : 0 ] [ 963.316210 ] CPU : 10 PID : 20 Comm : thpool - worker0 4.0.0 - lego + # 43 [ 963.322899 ] RIP : 0010 : [ < ffffffff8106ad51 > ] [ < ffffffff8106ad51 > ] fit_send_reply_with_rdma_write_with_imm + 0x2a1 / 0x3a0 [ 963.334632 ] RSP : 0000 : ffff88103ef3fc20 EFLAGS : 000002 87 [ 963.340547 ] RAX : 00000000f fffb6d4 RBX : 000000000000000 b RCX : 0000000000001770 [ 963.348498 ] RDX : 00000000f fffa70d RSI : fffffffffffff039 RDI : 0000000000000000 [ 963.356450 ] RBP : ffff88103ef3fcc0 R08 : 000000000000001f R09 : 0000000000000002 [ 963.364400 ] R10 : 00000000 80000000 R11 : 000077f f80000000 R12 : 0000000000000000 [ 963.372352 ] R13 : ffff88103ef26738 R14 : 00000000000 b3d54 R15 : ffff88103ef25008 [ 963.380303 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fca0000 ( 0000 ) knlGS : 0000000000000000 [ 963.389320 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 963.395720 ] CR2 : 0000000000000000 CR3 : 000000000116 a000 CR4 : 00000000000406 a0 [ 963.403671 ] Stack : [ 963.405901 ] 00007f ff000b3d54 ffffffff800b3d54 ffff881000000004 ffff88103ef3fc78 [ 963.414045 ] 0000000 900000000 ffff881000000000 0000100 800000001 ffff88103d216000 [ 963.422191 ] ffff88103eebae48 800 b3d540000011c ffffff9b00000246 ffffea0000000001 [ 963.430337 ] 000000103 d216000 0000000000010 c00 000000000000011 c 000000000000100 8 [ 963.438481 ] 000000000000011 c 000000000000100 8 ffff88103eebae48 ffff88103ef3fd70 [ 963.446626 ] Call Trace : [ 963.449342 ] < TSK > [ 963.451475 ] [ < ffffffff81067c80 > ] ibapi_send_reply_imm + 0x50 / 0xd0 [ 963.458068 ] [ < ffffffff8102e953 > ] ? __storage_read + 0xc3 / 0x120 [ 963.464371 ] [ < ffffffff8102e953 > ] __storage_read + 0xc3 / 0x120 [ 963.470480 ] [ < ffffffff8102e9bf > ] storage_read + 0xf / 0x50 [ 963.476201 ] [ < ffffffff8102eab7 > ] storage_vma_fault + 0xb7 / 0x130 [ 963.482600 ] [ < ffffffff8103262f > ] handle_lego_mm_fault + 0x13f / 0x4a0 [ 963.489389 ] [ < ffffffff8102ecf4 > ] common_handle_p2m_miss . isra .1 + 0x54 / 0xc0 [ 963.496855 ] [ < ffffffff8102edc7 > ] handle_p2m_pcache_miss + 0x67 / 0x2d0 [ 963.503739 ] [ < ffffffff8102bf96 > ] thpool_worker_func + 0x296 / 0x3a0 [ 963.510332 ] [ < ffffffff8102bd00 > ] ? handle_bad_request + 0x40 / 0x40 [ 963.516926 ] [ < ffffffff81020ca6 > ] kthread + 0xf6 / 0x120 [ 963.522357 ] [ < ffffffff81020bb0 > ] ? __kthread_parkme + 0x70 / 0x70 [ 963.528756 ] [ < ffffffff8100e632 > ] ret_from_fork + 0x22 / 0x30 hmm, another on lost CQE happen at P. Today is weird, why we happen to have so many lost CQE today? Think about why CQE is not generated? 0827 - w14 -6 [ 1185.835707 ] ***** ***** Fail to to get the CQE from send_cq after 20 seconds ! ***** This means the packet was lost and something went wrong ***** with your NIC ... ***** connection_id : 7 dest node : 1 ***** [ 1185.856465 ] IB Stats : [ 1185.858985 ] nr_ib_send_reply : 3452 [ 1185.864221 ] nr_bytes_tx : 506507 [ 1185.869456 ] nr_bytes_rx : 8981004 [ 1185.874692 ] ------------ [ cut here ] ------------ [ 1185.879829 ] WARNING : CPU : 14 PID : 22 at net / lego / fit_internal . c : 1108 fit_internal_poll_sendcq + 0xe5 / 0x140 [ 1185.890399 ] CPU : 14 PID : 22 Comm : python 4.0.0 - lego + # 356 [ 1185.896410 ] Stack : [ 1185.898640 ] ffff88103c49fb30 ffffffff810126f5 ffff88103cb22000 00000004 a817c800 [ 1185.906784 ] 0000010f7139214f 0000000000000007 ffff88103c49fb40 ffffffff810127cf [ 1185.914927 ] ffff88103c49fbf0 ffffffff810724b5 000000023 cb2c280 ffff88103cb2c1f8 [ 1185.923072 ] 00000000000002 86 ffff88103c49fc18 ffff88103cb06000 ffff88103cb2c150 [ 1185.931217 ] 000000000000024 b ffff88108101c7dc ffff88107fce5d80 ffff88103c46f000 [ 1185.939360 ] Call Trace : [ 1185.942075 ] < TSK > [ 1185.944209 ] [ < ffffffff81012701 > ] __warn . constprop .1 + 0x91 / 0xd0 [ 1185.950607 ] [ < ffffffff810127cf > ] warn_slowpath_null + 0xf / 0x20 [ 1185.956909 ] [ < ffffffff810724b5 > ] fit_internal_poll_sendcq + 0xe5 / 0x140 [ 1185.963987 ] [ < ffffffff81019dd5 > ] ? scheduler_tick + 0x55 / 0x60 [ 1185.970192 ] [ < ffffffff81072662 > ] fit_send_message_with_rdma_write_with_imm_request + 0x152 / 0x350 [ 1185.979791 ] [ < ffffffff810741ff > ] fit_send_reply_with_rdma_write_with_imm + 0x25f / 0x3a0 [ 1185.988420 ] [ < ffffffff810368c2 > ] ? __pcache_do_fill_page + 0xc2 / 0x1d0 [ 1185.995401 ] [ < ffffffff810701e9 > ] ibapi_send_reply_timeout + 0x79 / 0x120 [ 1186.002479 ] [ < ffffffff810368c2 > ] ? __pcache_do_fill_page + 0xc2 / 0x1d0 [ 1186.009459 ] [ < ffffffff810368c2 > ] __pcache_do_fill_page + 0xc2 / 0x1d0 [ 1186.016245 ] [ < ffffffff81036ac4 > ] common_do_fill_page + 0xf4 / 0x1f0 [ 1186.022839 ] [ < ffffffff81036d80 > ] pcache_handle_fault + 0x1c0 / 0x610 [ 1186.029528 ] [ < ffffffff81036800 > ] ? __pcache_do_zerofill_page + 0x100 / 0x100 [ 1186.036995 ] [ < ffffffff8100fdff > ] do_page_fault + 0xaf / 0x1c0 [ 1186.043005 ] [ < ffffffff8100dc1f > ] page_fault + 0x1f / 0x30","title":"Aug 27"},{"location":"lego/log/log-08-2018/#aug-26","text":"Oh well. I saw the same damn lost packet issue again. The issue can be desribed as: P use lite rpc to send a request to M. M processed the handled, and called rpc reply to sent back to P. M need to poll send_cq to poll completion. But M fail to get the CQE for the should-be-sent-out WQE. This is tested with M\u2019s CONFIG_FIT_NOWAIT optimization, which is basically an optimization that M will not poll cq every time a reply was sent out, instead, do batch polling. The following stack dump was reported by M side watchdog. It is not necessary mlx4_poll_cq\u2019s issue, since there is a while (1) loop at fit code. Oh well. Log name : 0826 - w9 -1 [ 187736.669027 ] watchdog : worker [ 0 ] CPU10 stucked [ 187736.673972 ] watchdog : common_header [ op = 0x30000000 src_nid : 0 ] [ 187736.680566 ] CPU : 10 PID : 20 Comm : thpool - worker0 4.0.0 - lego + # 26 [ 187736.687351 ] RIP : 0010 : [ < ffffffff810522c3 > ] [ < ffffffff810522c3 > ] mlx4_ib_poll_cq + 0x1d3 / 0x850 [ 187736.696854 ] RSP : 0000 : ffff88103ef3f750 EFLAGS : 000002 86 [ 187736.702865 ] RAX : 00000000f ffffff5 RBX : 0000000000000000 RCX : ffff88103ed6b050 [ 187736.710913 ] RDX : 00000000 80630000 RSI : 0000000000000001 RDI : ffff88103edb0bf0 [ 187736.718961 ] RBP : ffff88103ef3f7b8 R08 : 0000000000000020 R09 : 0000000000000002 [ 187736.727007 ] R10 : 0000000f fc53fddc R11 : 0000000040 bf1040 R12 : ffff88103ef3f7c8 [ 187736.735055 ] R13 : 0000000000000000 R14 : 0000000000000000 R15 : ffff88103edb0bf0 [ 187736.743104 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fca0000 ( 0000 ) knlGS : 0000000000000000 [ 187736.752218 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 187736.758714 ] CR2 : 0000000000000000 CR3 : 000000000116 a000 CR4 : 00000000000406 a0 [ 187736.766762 ] Stack : [ 187736.769089 ] 0000000f fc53fddc 0000000000000002 0000000000000020 ffff88103edb0c98 [ 187736.777331 ] 00000000000002 86 00000000 80630000 ffff88103ef3f7d0 000063 8000000018 [ 187736.785572 ] ffff88103edb0bf0 0000000000000001 ffff88103ef25008 0000000000000003 [ 187736.793813 ] 000000000000000 c ffff88103ef3fd30 ffffffff8106920c ffff88103ef3fd54 [ 187736.802054 ] 0000000100000000 0000000100000000 ffff88103edb07b0 ffff88103e81b008 [ 187736.810296 ] Call Trace : [ 187736.813108 ] < TSK > [ 187736.815338 ] [ < ffffffff8106920c > ] fit_internal_poll_sendcq + 0x6c / 0xe0 [ 187736.822416 ] [ < ffffffff8106ab2f > ] ? fit_send_reply_with_rdma_write_with_imm + 0x25f / 0x3a0 [ 187736.831336 ] [ < ffffffff81033ff0 > ] ? _lego_copy_to_user + 0x110 / 0x250 [ 187736.838220 ] [ < ffffffff81028d65 > ] ? __free_pages + 0x25 / 0x30 [ 187736.844329 ] [ < ffffffff8102e981 > ] ? __storage_read + 0xf1 / 0x120 [ 187736.850728 ] [ < ffffffff81019865 > ] ? scheduler_tick + 0x55 / 0x60 [ 187736.857031 ] [ < ffffffff810693d2 > ] ? fit_send_message_with_rdma_write_with_imm_request + 0x152 / 0x350 [ 187736.866920 ] [ < ffffffff810693d2 > ] ? fit_send_message_with_rdma_write_with_imm_request + 0x152 / 0x350 [ 187736.876810 ] [ < ffffffff8103043f > ] ? __vma_adjust + 0x38f / 0x550 [ 187736.883113 ] [ < ffffffff81030944 > ] ? vma_merge + 0x1a4 / 0x280 [ 187736.889123 ] [ < ffffffff81030f20 > ] ? arch_get_unmapped_area_topdown + 0xe0 / 0x220 [ 187736.897075 ] [ < ffffffff810693d2 > ] fit_send_message_with_rdma_write_with_imm_request + 0x152 / 0x350 [ 187736.906771 ] [ < ffffffff81069ab5 > ] fit_ack_reply_callback + 0x185 / 0x1e0 [ 187736.913848 ] [ < ffffffff8102f129 > ] ? handle_p2m_flush_one + 0x69 / 0x160 [ 187736.920830 ] [ < ffffffff8102bde0 > ] thpool_worker_func + 0xe0 / 0x3a0 [ 187736.927424 ] [ < ffffffff8102bd00 > ] ? handle_bad_request + 0x40 / 0x40 [ 187736.934113 ] [ < ffffffff81020ca6 > ] kthread + 0xf6 / 0x120 [ 187736.939639 ] [ < ffffffff81020bb0 > ] ? __kthread_parkme + 0x70 / 0x70 [ 187736.946137 ] [ < ffffffff8100e632 > ] ret_from_fork + 0x22 / 0x30","title":"Aug 26"},{"location":"lego/log/log-08-2018/#aug-22","text":"Damn it!!! After so much effort verifying we had a solid IB stack, we still has memory corruption and deadlock issues. Fuck! One thing at a time, simple stuff first. Okay, tomorrow first add DEBUG_SPINLOCK to detect possible deadlocks. This, could help to identify some buggy code. After this, I will spend some time looking into the LITE, it\u2019s fucking HEAVY. I do found a lot issues during summer. Personally, I\u2019m not feeling good this days. I treat someone with love and respect, but there is not too much in return. Yeahyeahyeah, I know how this works. It\u2019s just sad that sometimes you just have a BAD timing. I\u2019ve went through too much things in 2018, good and bad. I care sooo much about the people I love, family and others. I feel this is good, of course. Anyway, it is supposed to be a Lego dump, that no one probably interested in.","title":"Aug 22"},{"location":"lego/log/log-09-2018/","text":"Sep 2018 \u00b6 Sep 20 \u00b6 [ 54.602054 ] nr_pcache_pee_free : 0 [ 54.602537 ] nr_pcache_pee_free_kmalloc : 0 [ 1468.765410 ] mlx4_msi_x_interrupt () : IRQ : 27 CPU : 1 [ 1468.766956 ] event PORT_MNG_CHG arrived [ 1468.768193 ] < mlx4_ib > handle_port_mgmt_change_event : rereg [ 1468.813660 ] ib_cache : ib_cache_update () : Updated port 1 of dev 0000 : 00 : 08.0 [ 1468.815097 ] ib_sa_event () : TODO [ 1479.178651 ] mlx4_msi_x_interrupt () : IRQ : 27 CPU : 1 [ 1479.180201 ] event PORT_MNG_CHG arrived [ 1479.181430 ] < mlx4_ib > handle_port_mgmt_change_event : rereg [ 1479.190813 ] bad : scheduling from the idle thread ! [ 1479.192158 ] CPU : 1 PID : 0 Comm : swapper / 1 4.0.0 - lego + # 146 [ 1479.193622 ] Stack : [ 1479.194408 ] ffff88083fddf980 ffffffff8101eefc ffff88083fc45d80 ffff88083fc45d80 [ 1479.196826 ] ffff88083fddf9a8 ffffffff8101ace4 00000001 810067 d4 ffff88083fe43000 [ 1479.199226 ] ffffffffffff0000 ffff88083fddf9e0 ffffffff81078bf6 ffffffff8100e8ea [ 1479.203615 ] ffffffffffff0000 0000000000000000 ffff88083fe43000 ffff88083fe43000 [ 1479.206532 ] ffff88083fddf9f8 ffffffff81078ca3 7f ffffffffffffff ffff88083fddfa68 [ 1479.208791 ] Call Trace : [ 1479.209606 ] < TSK > [ 1479.210322 ] [ < ffffffff8101ef08 > ] dequeue_task_idle + 0x48 / 0x60 [ 1479.211726 ] [ < ffffffff8101ace4 > ] deactivate_task + 0x44 / 0x50 [ 1479.213092 ] [ < ffffffff81078bf6 > ] __schedule + 0x146 / 0x1e0 [ 1479.214410 ] [ < ffffffff8100e8ea > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 1479.215960 ] [ < ffffffff81078ca3 > ] schedule + 0x13 / 0x30 [ 1479.217211 ] [ < ffffffff810789da > ] schedule_timeout + 0x12a / 0x1a0 [ 1479.218625 ] [ < ffffffff81079e54 > ] __down_common + 0xaa / 0x103 [ 1479.219904 ] [ < ffffffff81079ec5 > ] __down + 0x18 / 0x1a [ 1479.221046 ] [ < ffffffff8101f24c > ] down + 0x3c / 0x40 [ 1479.222163 ] [ < ffffffff8104dba7 > ] __mlx4_cmd + 0x1d7 / 0x3c0 [ 1479.223397 ] [ < ffffffff810619de > ] mlx4_MAD_IFC + 0x22e / 0x490 [ 1479.224666 ] [ < ffffffff8105d321 > ] __mlx4_ib_query_pkey + 0x181 / 0x240 [ 1479.226045 ] [ < ffffffff8105d3f3 > ] mlx4_ib_query_pkey + 0x13 / 0x20 [ 1479.227365 ] [ < ffffffff81064cb4 > ] ib_query_pkey + 0x14 / 0x20 [ 1479.228617 ] [ < ffffffff810651a7 > ] ib_cache_update + 0x237 / 0x480 [ 1479.229862 ] [ < ffffffff810657f8 > ] ib_cache_event + 0x28 / 0x30 [ 1479.231026 ] [ < ffffffff81064bf0 > ] ib_dispatch_event + 0x40 / 0x70 [ 1479.232222 ] [ < ffffffff810627c8 > ] handle_port_mgmt_change_event + 0x158 / 0x1c0 [ 1479.233602 ] [ < ffffffff8105b5ac > ] mlx4_ib_event + 0x7c / 0xa0 [ 1479.234744 ] [ < ffffffff8104ee55 > ] mlx4_dispatch_event + 0x65 / 0x90 [ 1479.235968 ] [ < ffffffff8104f2c3 > ] mlx4_eq_int + 0x273 / 0x4f0 [ 1479.237113 ] [ < ffffffff8104f616 > ] mlx4_msi_x_interrupt + 0x36 / 0x40 [ 1479.238352 ] [ < ffffffff81017894 > ] handle_irq_event_percpu + 0x24 / 0xa0 [ 1479.239584 ] [ < ffffffff81017938 > ] handle_irq_event + 0x28 / 0x50 [ 1479.240696 ] [ < ffffffff810180fe > ] handle_edge_irq + 0x5e / 0xc0 [ 1479.241794 ] [ < ffffffff810054c3 > ] do_IRQ + 0x43 / 0xd0 [ 1479.242779 ] [ < ffffffff810067d4 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 1479.243971 ] [ < ffffffff8100e0aa > ] common_interrupt + 0x6a / 0x6a [ 1479.245084 ] [ < ffffffff8101c6b0 > ] ? cpu_idle + 0x10 / 0x30 [ 1479.246123 ] [ < ffffffff81003425 > ] start_secondary_cpu + 0x55 / 0x60 [ 1479.247278 ] < EOT > Sep 17 \u00b6 Can not believe I\u2019m wasting time on this crap X again. Sep 16 \u00b6 Tests done today: Setting Log nr_workers Tracing (strace/counter/profiling) Runtime (s) pcache_flush_net (us) TF-MNIST, Linux 13.2s TF4-MNIST, 128MB 0916-w14-1 1 ON avg 48.5s 9891 TF4-MNIST, 128MB 0916-w14-2 1 OFF (46.1+44.6+45.5+45.7+44)/5 = 45.2s N/A TF4-MNIST, 128MB 0916-w14-4 4 ON (43.4+44+43.9+42.6+42.1)/5=43.2 8351 TF4-MNIST, 128MB 0916-w14-3 4 OFF (40.1+42.1+42.0+41.7+42.1)/5 = 41.6 N/A TF4-Cifar, Linux 235.5s TF4-Cifar, 128MB 0916-w14-5 4 OFF (636.2+635.0+636.8+637.2+634.1)/5=635.8 N/A TF4-Cifar, 128MB 0916-w14-6 1 OFF (660.2+662.2+662.8+663.8+661+5)/5=663s N/A TF4-Cifar, 256MB 0916-w14-7 1 OFF 486s N/A Sep 15 \u00b6 DAMN. Let us summarize today. Okay. Fixed the double-post-cqe issue. Hehe. The post part is the only fucking left code that I did not look into at fit_poll_recv_cq. And, ironically, there is no error checking for ib_post_recv(), which won\u2019t generate any error/warning. error checking error checking\u2026 Anyway fuck it. Today I created a new tag v0.0.9, hope we have a stable net. The RPC profile code is very stressing, and fit survived. The following wanring is fixed by post rx_depth/2. [ 1812.017204 ] fit : To align first QPN , we skipped : # 72 # 72 # 73 # 74 # 75 # 76 # 77 # 78 # 79 [ 1812.157570 ] fit : fit_post_receives_message () -628 CPU 2 Fail to post recv conn_id : 12 [ 1812.166013 ] ------------ [ cut here ] ------------ [ 1812.171152 ] WARNING : CPU : 2 PID : 16 at net / lego / fit_internal . c : 629 fit_post_receives_message . isra .7 + 0xce / 0x100 [ 1812.182302 ] CPU : 2 PID : 16 Comm : ib - initd 4.0.0 - lego + # 95 [ 1812.188314 ] Stack : [ 1812.190544 ] ffff880ff98bfd50 ffffffff8101299b 0000000000000 cff 0000000000000060 [ 1812.198689 ] 0000000000000 d00 0000000000000100 ffff880ff98dc030 ffff880ff98bfd60 [ 1812.206834 ] ffffffff81012a8f ffff880ff98bfdc8 ffffffff810743de fffffff4fffffff4 [ 1812.214978 ] ffff880ff98bfd80 0000000000000000 0000000000000 cff 0000000000000000 [ 1812.223124 ] 0000000000000000 ffff880ff98dc000 0000000000000000 000000000000000 c [ 1812.231269 ] Call Trace : [ 1812.233984 ] < TSK > [ 1812.236116 ] [ < ffffffff810129a7 > ] __warn . constprop .0 + 0xa7 / 0x100 [ 1812.242613 ] [ < ffffffff81012a8f > ] warn_slowpath_null + 0xf / 0x20 [ 1812.248915 ] [ < ffffffff810743de > ] fit_post_receives_message . isra .7 + 0xce / 0x100 [ 1812.256770 ] [ < ffffffff81076a1a > ] fit_add_newnode + 0xca / 0x170 [ 1812.262974 ] [ < ffffffff81079d10 > ] fit_establish_conn + 0x7b0 / 0xaa0 [ 1812.269568 ] [ < ffffffff81073ce8 > ] ? ibv_add_one + 0x98 / 0x120 [ 1812.275580 ] [ < ffffffff810741f0 > ] ? ibapi_get_node_id + 0x20 / 0x20 [ 1812.282076 ] [ < ffffffff81074258 > ] lego_ib_init + 0x68 / 0xf0 [ 1812.287893 ] [ < ffffffff81023261 > ] kthread + 0x111 / 0x130 [ 1812.293421 ] [ < ffffffff81023150 > ] ? __kthread_parkme + 0x70 / 0x70 [ 1812.299820 ] [ < ffffffff8100eaf2 > ] ret_from_fork + 0x22 / 0x30 [ 1812.305735 ] < EOT > [ 1812.307868 ] --- [ end trace 0000000000000000 ] --- Sep 11 \u00b6 Got this log, 5 machine, p2s_open, S side has this issue. Damn. [ 1672.962279 ] ***** ***** Fail to to get the CQE from send_cq after 20 seconds ! ***** This means the packet was lost and something went wrong ***** with your NIC ... ***** connection_id : 11 dest node : 0 ***** [ 1673.061668 ] ------------ [ cut here ] ------------ [ 1673.074937 ] WARNING : CPU : 10 PID : 4624 at / root / ys / LegoOS_2M / linux - modules / fit / fit_internal . c : 956 fit_internal_poll_sendcq + 0xda / 0x130 [ fit ]() [ 1673.101557 ] Modules linked in : storage ( OF ) fit ( OF ) xt_CHECKSUM iptable_mangle ipt_MASQUERADE iptable_nat nf_nat_ipv4 nf_nat nf_conntrack_ipv4 nf_defrag_ipv4 xt_conntrack nf_conntrack ipt_REJECT tun bridge stp llc ebtable_filter ebtable s ip6table_filter ip6_tables iptable_filter xprtrdma sunrpc ib_isert iscsi_target_mod ib_iser libiscsi scsi_transport_iscsi ib_srpt target_core_mod ib_srp scsi_transport_srp scsi_tgt ib_ipoib rdma_ucm ib_ucm ib_uverbs ib_umad rdma_cm ib_c m iw_cm ib_addr x86_pkg_temp_thermal coretemp kvm_intel kvm crc32_pclmul ghash_clmulni_intel aesni_intel lrw gf128mul glue_helper ipmi_devintf ablk_helper cryptd ipmi_si iTCO_wdt ipmi_msghandler iTCO_vendor_support dcdbas sg pcspkr shpchp acpi_power_meter lpc_ich mfd_core wmi mperf uinput binfmt_misc ip_tables ext4 mbcache jbd2 mlx4_ib [ 1673.182609 ] ib_sa ib_mad ib_core mlx4_en sd_mod crc_t10dif mgag200 syscopyarea sysfillrect sysimgblt i2c_algo_bit drm_kms_helper ttm drm ahci crc32c_intel libahci mlx4_core libata tg3 nvme megaraid_sas ptp i2c_core pps_core dm_mirror dm_region_hash dm_log dm_mod [ 1673.222604 ] CPU : 10 PID : 4624 Comm : lego - storaged Tainted : GF W O 3.11.1 - vanilla # 1 [ 1673.235825 ] Hardware name : Dell Inc . PowerEdge R730 / 05 99 V5 , BIOS 1.5.4 10 / 002 / 2015 [ 1673.248883 ] 000000000000000 9 ffff88102186b9f8 ffffffff8159a5a4 0000000000000000 [ 1673.261795 ] ffff88102186ba30 ffffffff810641bd ffff882027180400 00000004 a817c800 [ 1673.274499 ] 000001 80 dc3abde5 0000000000000000 0000000000000000 ffff88102186ba40 [ 1673.287034 ] Call Trace : [ 1673.299259 ] [ < ffffffff8159a5a4 > ] dump_stack + 0x45 / 0x56 [ 1673.311371 ] [ < ffffffff810641bd > ] warn_slowpath_common + 0x7d / 0xa0 [ 1673.323268 ] [ < ffffffff8106429a > ] warn_slowpath_null + 0x1a / 0x20 [ 1673.334892 ] [ < ffffffffa063669a > ] fit_internal_poll_sendcq + 0xda / 0x130 [ fit ] [ 1673.346348 ] [ < ffffffff81093e25 > ] ? check_preempt_curr + 0x85 / 0xa0 [ 1673.357575 ] [ < ffffffffa06367f7 > ] fit_send_message_with_rdma_write_with_imm_request + 0x107 / 0x3f0 [ fit ] [ 1673.368777 ] [ < ffffffff8107bde4 > ] ? wake_up_worker + 0x24 / 0x30 [ 1673.379741 ] [ < ffffffffa0636ee9 > ] fit_reply_message + 0x89 / 0xa0 [ fit ] [ 1673.390497 ] [ < ffffffffa063507b > ] ibapi_reply_message + 0x1b / 0x20 [ fit ] [ 1673.401039 ] [ < ffffffffa0646785 > ] handle_open_request + 0xa5 / 0xe0 [ storage ] [ 1673.411367 ] [ < ffffffffa0646106 > ] storage_manager + 0x106 / 0x300 [ storage ] [ 1673.421470 ] [ < ffffffffa0646000 > ] ? 0xffffffffa0645fff [ 1673.431297 ] [ < ffffffffa0646000 > ] ? 0xffffffffa0645fff [ 1673.440797 ] [ < ffffffff81085ec0 > ] kthread + 0xc0 / 0xd0 [ 1673.450034 ] [ < ffffffff81085e00 > ] ? insert_kthread_work + 0x40 / 0x40 [ 1673.459063 ] [ < ffffffff815a94ac > ] ret_from_fork + 0x7c / 0xb0 [ 1673.467837 ] [ < ffffffff81085e00 > ] ? insert_kthread_work + 0x40 / 0x40 [ 1673.476400 ] --- [ end trace f9b19a31d409f910 ] --- [ 1695.867276 ] storage_self_monitor () : in_handler = 1 [ 1695.875906 ] handle_replica_flush : 0 [ 1695.884613 ] handle_replica_vma : 0 [ 1695.893265 ] handle_replica_read : 12740 [ 1695.901920 ] handle_replica_write : 0 [ 1713.012565 ] INFO : rcu_sched self - detected stall on CPU { 10 } ( t = 60001 jiffies g = 7646 c = 7645 q = 0 ) [ 1713.013339 ] sending NMI to all CPUs : [ 1713.013573 ] INFO : rcu_sched detected stalls on CPUs / tasks : { 10 } ( detected by 15 , t = 60002 jiffies , g = 7646 , c = 7645 , q = 0 ) [ 1713.014807 ] NMI backtrace for cpu 0 [ 1713.015685 ] CPU : 0 PID : 4591 Comm : wq_handler Tainted : GF W O 3.11.1 - vanilla # 1 [ 1713.016624 ] Hardware name : Dell Inc . PowerEdge R730 / 05 99 V5 , BIOS 1.5.4 10 / 002 / 2015 [ 1713.017575 ] task : ffff88201f193b40 ti : ffff88101a34a000 task . ti : ffff88101a34a000 [ 1713.018530 ] RIP : 0010 : [ < ffffffffa0636b55 > ] [ < ffffffffa0636b55 > ] waiting_queue_handler + 0x75 / 0x140 [ fit ] [ 1713.018530 ] RIP : 0010 : [ < ffffffffa0636b55 > ] [ < ffffffffa0636b55 > ] waiting_queue_handler + 0x75 / 0x140 [ fit ] [ 1713.019512 ] RSP : 001 8 : ffff88101a34be78 EFLAGS : 000002 96 [ 1713.020444 ] RAX : 00000000000 80080 RBX : ffff8820200253f0 RCX : ffff88201f193b40 [ 1713.021364 ] RDX : 0000000000000001 RSI : ffff88103f414760 RDI : ffff88103f4146c0 [ 1713.022260 ] RBP : ffff88101a34bec8 R08 : 0000000000000000 R09 : 0000000000000001 [ 1713.023138 ] R10 : 0000000000000001 R11 : ffffffffa0636b55 R12 : ffff8820200253c0 [ 1713.024000 ] R13 : ffff881022005000 R14 : ffffffffa063b8e4 R15 : ffffffffa063b8e4 [ 1713.024839 ] FS : 0000000000000000 ( 0000 ) GS : ffff88103f400000 ( 0000 ) knlGS : 0000000000000000 [ 1713.025676 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 1713.026481 ] CR2 : 00007f d77ef46000 CR3 : 0000000001 876000 CR4 : 00000000001407f 0 [ 1713.027273 ] Stack : [ 1713.028035 ] ffff881000000000 ffff881000300660 ffff882000000003 0000000000000000 [ 1713.028818 ] ffff881000000000 ffff881021eafc38 ffff881022005000 ffffffffa0636ae0 [ 1713.029585 ] 0000000000000000 0000000000000000 ffff88101a34bf48 ffffffff81085ec0 [ 1713.030350 ] Call Trace : [ 1713.031098 ] [ < ffffffffa0636ae0 > ] ? fit_send_message_with_rdma_write_with_imm_request + 0x3f0 / 0x3f0 [ fit ] [ 1713.031875 ] [ < ffffffff81085ec0 > ] kthread + 0xc0 / 0xd0 [ 1713.032641 ] [ < ffffffff81085e00 > ] ? insert_kthread_work + 0x40 / 0x40 [ 1713.033407 ] [ < ffffffff815a94ac > ] ret_from_fork + 0x7c / 0xb0 [ 1713.034171 ] [ < ffffffff81085e00 > ] ? insert_kthread_work + 0x40 / 0x40 Sep 08 \u00b6 Check this log out: ]--- [ 427.218569] STDOUT: ---[ INFO:tensorflow:Graph was finalized. ]--- [ 427.416043] BUG: unable to handle kernel NULL pointer dereference at (null) [ 427.424583] IP: [<ffffffff810748fb>] fit_poll_recv_cq+0x5cb/0x860 [ 427.431370] mlx4_msi_x_interrupt(): IRQ: 27 CPU: 0 [ 427.436702] PGD 0 [ 427.438932] CQ_ERROR CQ overrun on CQN 000082 [ 427.443780] Oops: 0002 [#1] SMP PROCESSOR [ 427.448240] event qp_event arrived [ 427.452022] CPU: 6 PID: 18 Comm: FIT_RecvCQ-0 4.0.0-lego+ #23 [ 427.458421] event qp_event arrived [ 427.462203] RIP: 0010:[<ffffffff810748fb>] [<ffffffff810748fb>] fit_poll_recv_cq+0x5cb/0x860 [ 427.471704] RSP: 0000:ffff881023e3fe60 EFLAGS: 00010287 [ 427.477618] RAX: 0000000000000000 RBX: 000000002aaaaaab RCX: 0000000000000004 [ 427.485570] RDX: 0000000000000000 RSI: 0000000000000053 RDI: 0000000000000000 [ 427.493520] RBP: ffff881023e3fec0 R08: 0000000000000001 R09: ffff881039900000 [ 427.501470] R10: 0000000000000000 R11: ffff881039918000 R12: ffff8810398f2000 [ 427.509421] R13: 0000000000000000 R14: 0000000000000001 R15: ffff881023e25008 [ 427.517371] event qp_event arrived [ 427.521153] FS: 0000000000000000(0000) GS:ffff88107fc60000(0000) knlGS:0000000000000000 [ 427.530169] CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [ 427.536569] CR2: 0000000000000000 CR3: 000000000117a000 CR4: 00000000000406a0 [ 427.544519] event qp_event arrived Trying to tune FIT\u2019s number polling threads. This could be the throughput/latency killer. 128M P num_polling M worker M num_polling Runtime (s) 1 1 1 46.8s 1 4 1 Sep 07 \u00b6 Set up Infiniswap again. What a fucking crap code, and crash the kernel out of nowhere. crap crap crap. Hmm, Linux will tune the CPU freq during runtime, will be higher than 2.4GHz. So disable it, make it a fair comparison with Lego. intel_pstate=disable. Sep 06 \u00b6 Did two optimizations on pcache, both are buffer management. Especially the pcache rmap case. In both opts, we kind of use static/pre-allocated array to serve dynamic allocation. This is a better solution than using kmem_cache, faster. kmem_cache will be a more general solution here. kmem_cache, FIFO queue (thpool buffer), static preallocated array (rmap, clflush)\u2026 Buffer management is really a very important thing in system building. I should be aware at the beginning next time. These changes are in commits: 6e0cf6c5c64edbe445a27cf55f86ac51f8a897b3 73377cafce95ffa0cfb155f77cac97456a5e4a71 Sep 05 \u00b6 Alright. Besides some flaws/bugs in some kfree stuff, LegoOS now actually is very robust! Ran a quick git summary: project : LegoOS repo age : 1 year, 11 months active : 358 days commits : 1540 files : 1161 authors : 1317 Yizhou Shan 85.5% 120 root 7.8% 36 hythzz 2.3% 27 yilun 1.8% 16 Yutong Huang 1.0% 10 Build Android 0.6% 8 Yiying Zhang 0.5% 4 sumukh1991 0.3% 1 Yizhou SHan 0.1% 1 Sumukh Hallymysore Ravindra 0.1% Of course, there are still PLENY room for improvement, and I know where. At this time, I really think we need something like kmem_cache, which is so fucking useful. It can probably further reduce much overhead. Sep 04 \u00b6 Trying the perset eviction list mechanism, instead of victim cache. The benefit of using this is: we will no longer be bottelnecked by victim cache anymore. Each faulting thread will do eviction/flush within its own context. For 4 threads MNIST, I saw 3 seconds reduction. Removed the bitmap, use per pcache set counter for quick reference. Sep 03 \u00b6 With DEBUG_MM, try enable HAVE_FREE directory by directory - \u00b6 - update_wall_time+0x44 is where we call tsc_read. And this has been called many times (HZ per second). All of a sudden, the pointer got crashed. Who wrote to this code memory?? Remote RDMA? [ 1052.470714 ] general protection fault : 0000 [ # 1 ] SMP PROCESSOR [ 1052.477113 ] CPU : 0 PID : 15 Comm : ib_mad1 4.0.0 - lego + # 509 [ 1052.483125 ] RIP : 0010 : [ < ffffffff81015764 > ] [ < ffffffff81015764 > ] update_wall_time + 0x44 / 0x6f0 [ 1052.492530 ] RSP : 0000 : ffff88103ad9fc88 EFLAGS : 00010046 [ 1052.498445 ] RAX : 4510f fffffff8118 RBX : 0380f fffffffffff RCX : 0000000000000001 [ 1052.506396 ] RDX : ffff88103ad9fd28 RSI : 0000000000000000 RDI : 4510f fffffff8118 [ 1052.514346 ] RBP : ffff88103ad9fcd0 R08 : 000000000000001f R09 : 0000000000000000 [ 1052.522298 ] R10 : 000000000000002 9 R11 : ffff881013f8e130 R12 : aaff0000024a2677 [ 1052.530248 ] R13 : 0000000000000000 R14 : ffff88103ad85228 R15 : ffff88103ae0c000 [ 1052.538199 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc00000 ( 0000 ) knlGS : 0000000000000000 [ 1052.547216 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 1052.553616 ] CR2 : 0000000000000000 CR3 : 000000000117 b000 CR4 : 00000000000406 b0 [ 1052.561567 ] Stack : [ 1052.563797 ] 00000000000000 86 ffff88107fc05d80 ffff88103ad85000 0000000000000000 [ 1052.571941 ] ffff88107fc04980 0000000000000000 0000000000000000 ffff88103ad85228 [ 1052.580085 ] ffff88103ae0c000 ffff88103ad9fce8 ffffffff81017557 000000003 ad9fe10 [ 1052.588230 ] ffff88103ad9fd10 ffffffff810067a4 ffffffff81088040 ffff88107fc05d80 [ 1052.596375 ] ffff88103ad85000 ffff88103ad9fdf8 ffffffff8100e8ea ffff88103ad9fd28 [ 1052.604520 ] Call Trace : [ 1052.607236 ] < TSK > [ 1052.609368 ] [ < ffffffff81017557 > ] tick_handle_periodic + 0x67 / 0x70 [ 1052.615961 ] [ < ffffffff810067a4 > ] apic_timer_interrupt + 0x54 / 0x90 [ 1052.622555 ] [ < ffffffff8100e8ea > ] smp__apic_timer_interrupt + 0x6a / 0x70 [ 1052.629633 ] [ < ffffffff8107b488 > ] ? __schedule + 0xf8 / 0x1e0 [ 1052.635548 ] [ < ffffffff8107b583 > ] schedule + 0x13 / 0x30 [ 1052.640978 ] [ < ffffffff8106c98e > ] ib_mad_completion_handler + 0x5de / 0xc20 [ 1052.648250 ] [ < ffffffff8101de3b > ] ? dequeue_task_rt + 0x1b / 0x180 [ 1052.654648 ] [ < ffffffff8106c3b0 > ] ? ib_mad_send_done_handler . isra .22 + 0x4e0 / 0x4e0 [ 1052.662793 ] [ < ffffffff81022af6 > ] kthread + 0xf6 / 0x110 [ 1052.668223 ] [ < ffffffff81022a00 > ] ? __kthread_parkme + 0x70 / 0x70 [ 1052.674622 ] [ < ffffffff8100eb72 > ] ret_from_fork + 0x22 / 0x30 [ 1052.680538 ] < EOT > [ 1052.682670 ] Code : db e4 16 00 79 0 d f3 90 80 3 d d0 e4 16 00 00 7 e f5 eb ea 48 8 b 1 d fd fa 1f 00 48 8 b 05 e6 fa 1f 00 4 c 8 b 25 f7 fa 1f 00 48 89 c7 < ff > 50 28 49 89 c7 48 89 d8 4 d 29 e7 48 d1 e8 49 21 df 48 f7 d0 [ 1052.703711 ] RIP [ < ffffffff81015764 > ] update_wall_time + 0x44 / 0x6f0 [ 1052.710498 ] RSP < ffff88103ad9fc88 >","title":"Sep 2018"},{"location":"lego/log/log-09-2018/#sep-2018","text":"","title":"Sep 2018"},{"location":"lego/log/log-09-2018/#sep-20","text":"[ 54.602054 ] nr_pcache_pee_free : 0 [ 54.602537 ] nr_pcache_pee_free_kmalloc : 0 [ 1468.765410 ] mlx4_msi_x_interrupt () : IRQ : 27 CPU : 1 [ 1468.766956 ] event PORT_MNG_CHG arrived [ 1468.768193 ] < mlx4_ib > handle_port_mgmt_change_event : rereg [ 1468.813660 ] ib_cache : ib_cache_update () : Updated port 1 of dev 0000 : 00 : 08.0 [ 1468.815097 ] ib_sa_event () : TODO [ 1479.178651 ] mlx4_msi_x_interrupt () : IRQ : 27 CPU : 1 [ 1479.180201 ] event PORT_MNG_CHG arrived [ 1479.181430 ] < mlx4_ib > handle_port_mgmt_change_event : rereg [ 1479.190813 ] bad : scheduling from the idle thread ! [ 1479.192158 ] CPU : 1 PID : 0 Comm : swapper / 1 4.0.0 - lego + # 146 [ 1479.193622 ] Stack : [ 1479.194408 ] ffff88083fddf980 ffffffff8101eefc ffff88083fc45d80 ffff88083fc45d80 [ 1479.196826 ] ffff88083fddf9a8 ffffffff8101ace4 00000001 810067 d4 ffff88083fe43000 [ 1479.199226 ] ffffffffffff0000 ffff88083fddf9e0 ffffffff81078bf6 ffffffff8100e8ea [ 1479.203615 ] ffffffffffff0000 0000000000000000 ffff88083fe43000 ffff88083fe43000 [ 1479.206532 ] ffff88083fddf9f8 ffffffff81078ca3 7f ffffffffffffff ffff88083fddfa68 [ 1479.208791 ] Call Trace : [ 1479.209606 ] < TSK > [ 1479.210322 ] [ < ffffffff8101ef08 > ] dequeue_task_idle + 0x48 / 0x60 [ 1479.211726 ] [ < ffffffff8101ace4 > ] deactivate_task + 0x44 / 0x50 [ 1479.213092 ] [ < ffffffff81078bf6 > ] __schedule + 0x146 / 0x1e0 [ 1479.214410 ] [ < ffffffff8100e8ea > ] ? smp__apic_timer_interrupt + 0x6a / 0x70 [ 1479.215960 ] [ < ffffffff81078ca3 > ] schedule + 0x13 / 0x30 [ 1479.217211 ] [ < ffffffff810789da > ] schedule_timeout + 0x12a / 0x1a0 [ 1479.218625 ] [ < ffffffff81079e54 > ] __down_common + 0xaa / 0x103 [ 1479.219904 ] [ < ffffffff81079ec5 > ] __down + 0x18 / 0x1a [ 1479.221046 ] [ < ffffffff8101f24c > ] down + 0x3c / 0x40 [ 1479.222163 ] [ < ffffffff8104dba7 > ] __mlx4_cmd + 0x1d7 / 0x3c0 [ 1479.223397 ] [ < ffffffff810619de > ] mlx4_MAD_IFC + 0x22e / 0x490 [ 1479.224666 ] [ < ffffffff8105d321 > ] __mlx4_ib_query_pkey + 0x181 / 0x240 [ 1479.226045 ] [ < ffffffff8105d3f3 > ] mlx4_ib_query_pkey + 0x13 / 0x20 [ 1479.227365 ] [ < ffffffff81064cb4 > ] ib_query_pkey + 0x14 / 0x20 [ 1479.228617 ] [ < ffffffff810651a7 > ] ib_cache_update + 0x237 / 0x480 [ 1479.229862 ] [ < ffffffff810657f8 > ] ib_cache_event + 0x28 / 0x30 [ 1479.231026 ] [ < ffffffff81064bf0 > ] ib_dispatch_event + 0x40 / 0x70 [ 1479.232222 ] [ < ffffffff810627c8 > ] handle_port_mgmt_change_event + 0x158 / 0x1c0 [ 1479.233602 ] [ < ffffffff8105b5ac > ] mlx4_ib_event + 0x7c / 0xa0 [ 1479.234744 ] [ < ffffffff8104ee55 > ] mlx4_dispatch_event + 0x65 / 0x90 [ 1479.235968 ] [ < ffffffff8104f2c3 > ] mlx4_eq_int + 0x273 / 0x4f0 [ 1479.237113 ] [ < ffffffff8104f616 > ] mlx4_msi_x_interrupt + 0x36 / 0x40 [ 1479.238352 ] [ < ffffffff81017894 > ] handle_irq_event_percpu + 0x24 / 0xa0 [ 1479.239584 ] [ < ffffffff81017938 > ] handle_irq_event + 0x28 / 0x50 [ 1479.240696 ] [ < ffffffff810180fe > ] handle_edge_irq + 0x5e / 0xc0 [ 1479.241794 ] [ < ffffffff810054c3 > ] do_IRQ + 0x43 / 0xd0 [ 1479.242779 ] [ < ffffffff810067d4 > ] ? apic_timer_interrupt + 0x54 / 0x90 [ 1479.243971 ] [ < ffffffff8100e0aa > ] common_interrupt + 0x6a / 0x6a [ 1479.245084 ] [ < ffffffff8101c6b0 > ] ? cpu_idle + 0x10 / 0x30 [ 1479.246123 ] [ < ffffffff81003425 > ] start_secondary_cpu + 0x55 / 0x60 [ 1479.247278 ] < EOT >","title":"Sep 20"},{"location":"lego/log/log-09-2018/#sep-17","text":"Can not believe I\u2019m wasting time on this crap X again.","title":"Sep 17"},{"location":"lego/log/log-09-2018/#sep-16","text":"Tests done today: Setting Log nr_workers Tracing (strace/counter/profiling) Runtime (s) pcache_flush_net (us) TF-MNIST, Linux 13.2s TF4-MNIST, 128MB 0916-w14-1 1 ON avg 48.5s 9891 TF4-MNIST, 128MB 0916-w14-2 1 OFF (46.1+44.6+45.5+45.7+44)/5 = 45.2s N/A TF4-MNIST, 128MB 0916-w14-4 4 ON (43.4+44+43.9+42.6+42.1)/5=43.2 8351 TF4-MNIST, 128MB 0916-w14-3 4 OFF (40.1+42.1+42.0+41.7+42.1)/5 = 41.6 N/A TF4-Cifar, Linux 235.5s TF4-Cifar, 128MB 0916-w14-5 4 OFF (636.2+635.0+636.8+637.2+634.1)/5=635.8 N/A TF4-Cifar, 128MB 0916-w14-6 1 OFF (660.2+662.2+662.8+663.8+661+5)/5=663s N/A TF4-Cifar, 256MB 0916-w14-7 1 OFF 486s N/A","title":"Sep 16"},{"location":"lego/log/log-09-2018/#sep-15","text":"DAMN. Let us summarize today. Okay. Fixed the double-post-cqe issue. Hehe. The post part is the only fucking left code that I did not look into at fit_poll_recv_cq. And, ironically, there is no error checking for ib_post_recv(), which won\u2019t generate any error/warning. error checking error checking\u2026 Anyway fuck it. Today I created a new tag v0.0.9, hope we have a stable net. The RPC profile code is very stressing, and fit survived. The following wanring is fixed by post rx_depth/2. [ 1812.017204 ] fit : To align first QPN , we skipped : # 72 # 72 # 73 # 74 # 75 # 76 # 77 # 78 # 79 [ 1812.157570 ] fit : fit_post_receives_message () -628 CPU 2 Fail to post recv conn_id : 12 [ 1812.166013 ] ------------ [ cut here ] ------------ [ 1812.171152 ] WARNING : CPU : 2 PID : 16 at net / lego / fit_internal . c : 629 fit_post_receives_message . isra .7 + 0xce / 0x100 [ 1812.182302 ] CPU : 2 PID : 16 Comm : ib - initd 4.0.0 - lego + # 95 [ 1812.188314 ] Stack : [ 1812.190544 ] ffff880ff98bfd50 ffffffff8101299b 0000000000000 cff 0000000000000060 [ 1812.198689 ] 0000000000000 d00 0000000000000100 ffff880ff98dc030 ffff880ff98bfd60 [ 1812.206834 ] ffffffff81012a8f ffff880ff98bfdc8 ffffffff810743de fffffff4fffffff4 [ 1812.214978 ] ffff880ff98bfd80 0000000000000000 0000000000000 cff 0000000000000000 [ 1812.223124 ] 0000000000000000 ffff880ff98dc000 0000000000000000 000000000000000 c [ 1812.231269 ] Call Trace : [ 1812.233984 ] < TSK > [ 1812.236116 ] [ < ffffffff810129a7 > ] __warn . constprop .0 + 0xa7 / 0x100 [ 1812.242613 ] [ < ffffffff81012a8f > ] warn_slowpath_null + 0xf / 0x20 [ 1812.248915 ] [ < ffffffff810743de > ] fit_post_receives_message . isra .7 + 0xce / 0x100 [ 1812.256770 ] [ < ffffffff81076a1a > ] fit_add_newnode + 0xca / 0x170 [ 1812.262974 ] [ < ffffffff81079d10 > ] fit_establish_conn + 0x7b0 / 0xaa0 [ 1812.269568 ] [ < ffffffff81073ce8 > ] ? ibv_add_one + 0x98 / 0x120 [ 1812.275580 ] [ < ffffffff810741f0 > ] ? ibapi_get_node_id + 0x20 / 0x20 [ 1812.282076 ] [ < ffffffff81074258 > ] lego_ib_init + 0x68 / 0xf0 [ 1812.287893 ] [ < ffffffff81023261 > ] kthread + 0x111 / 0x130 [ 1812.293421 ] [ < ffffffff81023150 > ] ? __kthread_parkme + 0x70 / 0x70 [ 1812.299820 ] [ < ffffffff8100eaf2 > ] ret_from_fork + 0x22 / 0x30 [ 1812.305735 ] < EOT > [ 1812.307868 ] --- [ end trace 0000000000000000 ] ---","title":"Sep 15"},{"location":"lego/log/log-09-2018/#sep-11","text":"Got this log, 5 machine, p2s_open, S side has this issue. Damn. [ 1672.962279 ] ***** ***** Fail to to get the CQE from send_cq after 20 seconds ! ***** This means the packet was lost and something went wrong ***** with your NIC ... ***** connection_id : 11 dest node : 0 ***** [ 1673.061668 ] ------------ [ cut here ] ------------ [ 1673.074937 ] WARNING : CPU : 10 PID : 4624 at / root / ys / LegoOS_2M / linux - modules / fit / fit_internal . c : 956 fit_internal_poll_sendcq + 0xda / 0x130 [ fit ]() [ 1673.101557 ] Modules linked in : storage ( OF ) fit ( OF ) xt_CHECKSUM iptable_mangle ipt_MASQUERADE iptable_nat nf_nat_ipv4 nf_nat nf_conntrack_ipv4 nf_defrag_ipv4 xt_conntrack nf_conntrack ipt_REJECT tun bridge stp llc ebtable_filter ebtable s ip6table_filter ip6_tables iptable_filter xprtrdma sunrpc ib_isert iscsi_target_mod ib_iser libiscsi scsi_transport_iscsi ib_srpt target_core_mod ib_srp scsi_transport_srp scsi_tgt ib_ipoib rdma_ucm ib_ucm ib_uverbs ib_umad rdma_cm ib_c m iw_cm ib_addr x86_pkg_temp_thermal coretemp kvm_intel kvm crc32_pclmul ghash_clmulni_intel aesni_intel lrw gf128mul glue_helper ipmi_devintf ablk_helper cryptd ipmi_si iTCO_wdt ipmi_msghandler iTCO_vendor_support dcdbas sg pcspkr shpchp acpi_power_meter lpc_ich mfd_core wmi mperf uinput binfmt_misc ip_tables ext4 mbcache jbd2 mlx4_ib [ 1673.182609 ] ib_sa ib_mad ib_core mlx4_en sd_mod crc_t10dif mgag200 syscopyarea sysfillrect sysimgblt i2c_algo_bit drm_kms_helper ttm drm ahci crc32c_intel libahci mlx4_core libata tg3 nvme megaraid_sas ptp i2c_core pps_core dm_mirror dm_region_hash dm_log dm_mod [ 1673.222604 ] CPU : 10 PID : 4624 Comm : lego - storaged Tainted : GF W O 3.11.1 - vanilla # 1 [ 1673.235825 ] Hardware name : Dell Inc . PowerEdge R730 / 05 99 V5 , BIOS 1.5.4 10 / 002 / 2015 [ 1673.248883 ] 000000000000000 9 ffff88102186b9f8 ffffffff8159a5a4 0000000000000000 [ 1673.261795 ] ffff88102186ba30 ffffffff810641bd ffff882027180400 00000004 a817c800 [ 1673.274499 ] 000001 80 dc3abde5 0000000000000000 0000000000000000 ffff88102186ba40 [ 1673.287034 ] Call Trace : [ 1673.299259 ] [ < ffffffff8159a5a4 > ] dump_stack + 0x45 / 0x56 [ 1673.311371 ] [ < ffffffff810641bd > ] warn_slowpath_common + 0x7d / 0xa0 [ 1673.323268 ] [ < ffffffff8106429a > ] warn_slowpath_null + 0x1a / 0x20 [ 1673.334892 ] [ < ffffffffa063669a > ] fit_internal_poll_sendcq + 0xda / 0x130 [ fit ] [ 1673.346348 ] [ < ffffffff81093e25 > ] ? check_preempt_curr + 0x85 / 0xa0 [ 1673.357575 ] [ < ffffffffa06367f7 > ] fit_send_message_with_rdma_write_with_imm_request + 0x107 / 0x3f0 [ fit ] [ 1673.368777 ] [ < ffffffff8107bde4 > ] ? wake_up_worker + 0x24 / 0x30 [ 1673.379741 ] [ < ffffffffa0636ee9 > ] fit_reply_message + 0x89 / 0xa0 [ fit ] [ 1673.390497 ] [ < ffffffffa063507b > ] ibapi_reply_message + 0x1b / 0x20 [ fit ] [ 1673.401039 ] [ < ffffffffa0646785 > ] handle_open_request + 0xa5 / 0xe0 [ storage ] [ 1673.411367 ] [ < ffffffffa0646106 > ] storage_manager + 0x106 / 0x300 [ storage ] [ 1673.421470 ] [ < ffffffffa0646000 > ] ? 0xffffffffa0645fff [ 1673.431297 ] [ < ffffffffa0646000 > ] ? 0xffffffffa0645fff [ 1673.440797 ] [ < ffffffff81085ec0 > ] kthread + 0xc0 / 0xd0 [ 1673.450034 ] [ < ffffffff81085e00 > ] ? insert_kthread_work + 0x40 / 0x40 [ 1673.459063 ] [ < ffffffff815a94ac > ] ret_from_fork + 0x7c / 0xb0 [ 1673.467837 ] [ < ffffffff81085e00 > ] ? insert_kthread_work + 0x40 / 0x40 [ 1673.476400 ] --- [ end trace f9b19a31d409f910 ] --- [ 1695.867276 ] storage_self_monitor () : in_handler = 1 [ 1695.875906 ] handle_replica_flush : 0 [ 1695.884613 ] handle_replica_vma : 0 [ 1695.893265 ] handle_replica_read : 12740 [ 1695.901920 ] handle_replica_write : 0 [ 1713.012565 ] INFO : rcu_sched self - detected stall on CPU { 10 } ( t = 60001 jiffies g = 7646 c = 7645 q = 0 ) [ 1713.013339 ] sending NMI to all CPUs : [ 1713.013573 ] INFO : rcu_sched detected stalls on CPUs / tasks : { 10 } ( detected by 15 , t = 60002 jiffies , g = 7646 , c = 7645 , q = 0 ) [ 1713.014807 ] NMI backtrace for cpu 0 [ 1713.015685 ] CPU : 0 PID : 4591 Comm : wq_handler Tainted : GF W O 3.11.1 - vanilla # 1 [ 1713.016624 ] Hardware name : Dell Inc . PowerEdge R730 / 05 99 V5 , BIOS 1.5.4 10 / 002 / 2015 [ 1713.017575 ] task : ffff88201f193b40 ti : ffff88101a34a000 task . ti : ffff88101a34a000 [ 1713.018530 ] RIP : 0010 : [ < ffffffffa0636b55 > ] [ < ffffffffa0636b55 > ] waiting_queue_handler + 0x75 / 0x140 [ fit ] [ 1713.018530 ] RIP : 0010 : [ < ffffffffa0636b55 > ] [ < ffffffffa0636b55 > ] waiting_queue_handler + 0x75 / 0x140 [ fit ] [ 1713.019512 ] RSP : 001 8 : ffff88101a34be78 EFLAGS : 000002 96 [ 1713.020444 ] RAX : 00000000000 80080 RBX : ffff8820200253f0 RCX : ffff88201f193b40 [ 1713.021364 ] RDX : 0000000000000001 RSI : ffff88103f414760 RDI : ffff88103f4146c0 [ 1713.022260 ] RBP : ffff88101a34bec8 R08 : 0000000000000000 R09 : 0000000000000001 [ 1713.023138 ] R10 : 0000000000000001 R11 : ffffffffa0636b55 R12 : ffff8820200253c0 [ 1713.024000 ] R13 : ffff881022005000 R14 : ffffffffa063b8e4 R15 : ffffffffa063b8e4 [ 1713.024839 ] FS : 0000000000000000 ( 0000 ) GS : ffff88103f400000 ( 0000 ) knlGS : 0000000000000000 [ 1713.025676 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 1713.026481 ] CR2 : 00007f d77ef46000 CR3 : 0000000001 876000 CR4 : 00000000001407f 0 [ 1713.027273 ] Stack : [ 1713.028035 ] ffff881000000000 ffff881000300660 ffff882000000003 0000000000000000 [ 1713.028818 ] ffff881000000000 ffff881021eafc38 ffff881022005000 ffffffffa0636ae0 [ 1713.029585 ] 0000000000000000 0000000000000000 ffff88101a34bf48 ffffffff81085ec0 [ 1713.030350 ] Call Trace : [ 1713.031098 ] [ < ffffffffa0636ae0 > ] ? fit_send_message_with_rdma_write_with_imm_request + 0x3f0 / 0x3f0 [ fit ] [ 1713.031875 ] [ < ffffffff81085ec0 > ] kthread + 0xc0 / 0xd0 [ 1713.032641 ] [ < ffffffff81085e00 > ] ? insert_kthread_work + 0x40 / 0x40 [ 1713.033407 ] [ < ffffffff815a94ac > ] ret_from_fork + 0x7c / 0xb0 [ 1713.034171 ] [ < ffffffff81085e00 > ] ? insert_kthread_work + 0x40 / 0x40","title":"Sep 11"},{"location":"lego/log/log-09-2018/#sep-08","text":"Check this log out: ]--- [ 427.218569] STDOUT: ---[ INFO:tensorflow:Graph was finalized. ]--- [ 427.416043] BUG: unable to handle kernel NULL pointer dereference at (null) [ 427.424583] IP: [<ffffffff810748fb>] fit_poll_recv_cq+0x5cb/0x860 [ 427.431370] mlx4_msi_x_interrupt(): IRQ: 27 CPU: 0 [ 427.436702] PGD 0 [ 427.438932] CQ_ERROR CQ overrun on CQN 000082 [ 427.443780] Oops: 0002 [#1] SMP PROCESSOR [ 427.448240] event qp_event arrived [ 427.452022] CPU: 6 PID: 18 Comm: FIT_RecvCQ-0 4.0.0-lego+ #23 [ 427.458421] event qp_event arrived [ 427.462203] RIP: 0010:[<ffffffff810748fb>] [<ffffffff810748fb>] fit_poll_recv_cq+0x5cb/0x860 [ 427.471704] RSP: 0000:ffff881023e3fe60 EFLAGS: 00010287 [ 427.477618] RAX: 0000000000000000 RBX: 000000002aaaaaab RCX: 0000000000000004 [ 427.485570] RDX: 0000000000000000 RSI: 0000000000000053 RDI: 0000000000000000 [ 427.493520] RBP: ffff881023e3fec0 R08: 0000000000000001 R09: ffff881039900000 [ 427.501470] R10: 0000000000000000 R11: ffff881039918000 R12: ffff8810398f2000 [ 427.509421] R13: 0000000000000000 R14: 0000000000000001 R15: ffff881023e25008 [ 427.517371] event qp_event arrived [ 427.521153] FS: 0000000000000000(0000) GS:ffff88107fc60000(0000) knlGS:0000000000000000 [ 427.530169] CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [ 427.536569] CR2: 0000000000000000 CR3: 000000000117a000 CR4: 00000000000406a0 [ 427.544519] event qp_event arrived Trying to tune FIT\u2019s number polling threads. This could be the throughput/latency killer. 128M P num_polling M worker M num_polling Runtime (s) 1 1 1 46.8s 1 4 1","title":"Sep 08"},{"location":"lego/log/log-09-2018/#sep-07","text":"Set up Infiniswap again. What a fucking crap code, and crash the kernel out of nowhere. crap crap crap. Hmm, Linux will tune the CPU freq during runtime, will be higher than 2.4GHz. So disable it, make it a fair comparison with Lego. intel_pstate=disable.","title":"Sep 07"},{"location":"lego/log/log-09-2018/#sep-06","text":"Did two optimizations on pcache, both are buffer management. Especially the pcache rmap case. In both opts, we kind of use static/pre-allocated array to serve dynamic allocation. This is a better solution than using kmem_cache, faster. kmem_cache will be a more general solution here. kmem_cache, FIFO queue (thpool buffer), static preallocated array (rmap, clflush)\u2026 Buffer management is really a very important thing in system building. I should be aware at the beginning next time. These changes are in commits: 6e0cf6c5c64edbe445a27cf55f86ac51f8a897b3 73377cafce95ffa0cfb155f77cac97456a5e4a71","title":"Sep 06"},{"location":"lego/log/log-09-2018/#sep-05","text":"Alright. Besides some flaws/bugs in some kfree stuff, LegoOS now actually is very robust! Ran a quick git summary: project : LegoOS repo age : 1 year, 11 months active : 358 days commits : 1540 files : 1161 authors : 1317 Yizhou Shan 85.5% 120 root 7.8% 36 hythzz 2.3% 27 yilun 1.8% 16 Yutong Huang 1.0% 10 Build Android 0.6% 8 Yiying Zhang 0.5% 4 sumukh1991 0.3% 1 Yizhou SHan 0.1% 1 Sumukh Hallymysore Ravindra 0.1% Of course, there are still PLENY room for improvement, and I know where. At this time, I really think we need something like kmem_cache, which is so fucking useful. It can probably further reduce much overhead.","title":"Sep 05"},{"location":"lego/log/log-09-2018/#sep-04","text":"Trying the perset eviction list mechanism, instead of victim cache. The benefit of using this is: we will no longer be bottelnecked by victim cache anymore. Each faulting thread will do eviction/flush within its own context. For 4 threads MNIST, I saw 3 seconds reduction. Removed the bitmap, use per pcache set counter for quick reference.","title":"Sep 04"},{"location":"lego/log/log-09-2018/#sep-03","text":"With DEBUG_MM, try enable HAVE_FREE directory by directory","title":"Sep 03"},{"location":"lego/log/log-09-2018/#-","text":"- update_wall_time+0x44 is where we call tsc_read. And this has been called many times (HZ per second). All of a sudden, the pointer got crashed. Who wrote to this code memory?? Remote RDMA? [ 1052.470714 ] general protection fault : 0000 [ # 1 ] SMP PROCESSOR [ 1052.477113 ] CPU : 0 PID : 15 Comm : ib_mad1 4.0.0 - lego + # 509 [ 1052.483125 ] RIP : 0010 : [ < ffffffff81015764 > ] [ < ffffffff81015764 > ] update_wall_time + 0x44 / 0x6f0 [ 1052.492530 ] RSP : 0000 : ffff88103ad9fc88 EFLAGS : 00010046 [ 1052.498445 ] RAX : 4510f fffffff8118 RBX : 0380f fffffffffff RCX : 0000000000000001 [ 1052.506396 ] RDX : ffff88103ad9fd28 RSI : 0000000000000000 RDI : 4510f fffffff8118 [ 1052.514346 ] RBP : ffff88103ad9fcd0 R08 : 000000000000001f R09 : 0000000000000000 [ 1052.522298 ] R10 : 000000000000002 9 R11 : ffff881013f8e130 R12 : aaff0000024a2677 [ 1052.530248 ] R13 : 0000000000000000 R14 : ffff88103ad85228 R15 : ffff88103ae0c000 [ 1052.538199 ] FS : 0000000000000000 ( 0000 ) GS : ffff88107fc00000 ( 0000 ) knlGS : 0000000000000000 [ 1052.547216 ] CS : 0010 DS : 0000 ES : 0000 CR0 : 00000000 80050033 [ 1052.553616 ] CR2 : 0000000000000000 CR3 : 000000000117 b000 CR4 : 00000000000406 b0 [ 1052.561567 ] Stack : [ 1052.563797 ] 00000000000000 86 ffff88107fc05d80 ffff88103ad85000 0000000000000000 [ 1052.571941 ] ffff88107fc04980 0000000000000000 0000000000000000 ffff88103ad85228 [ 1052.580085 ] ffff88103ae0c000 ffff88103ad9fce8 ffffffff81017557 000000003 ad9fe10 [ 1052.588230 ] ffff88103ad9fd10 ffffffff810067a4 ffffffff81088040 ffff88107fc05d80 [ 1052.596375 ] ffff88103ad85000 ffff88103ad9fdf8 ffffffff8100e8ea ffff88103ad9fd28 [ 1052.604520 ] Call Trace : [ 1052.607236 ] < TSK > [ 1052.609368 ] [ < ffffffff81017557 > ] tick_handle_periodic + 0x67 / 0x70 [ 1052.615961 ] [ < ffffffff810067a4 > ] apic_timer_interrupt + 0x54 / 0x90 [ 1052.622555 ] [ < ffffffff8100e8ea > ] smp__apic_timer_interrupt + 0x6a / 0x70 [ 1052.629633 ] [ < ffffffff8107b488 > ] ? __schedule + 0xf8 / 0x1e0 [ 1052.635548 ] [ < ffffffff8107b583 > ] schedule + 0x13 / 0x30 [ 1052.640978 ] [ < ffffffff8106c98e > ] ib_mad_completion_handler + 0x5de / 0xc20 [ 1052.648250 ] [ < ffffffff8101de3b > ] ? dequeue_task_rt + 0x1b / 0x180 [ 1052.654648 ] [ < ffffffff8106c3b0 > ] ? ib_mad_send_done_handler . isra .22 + 0x4e0 / 0x4e0 [ 1052.662793 ] [ < ffffffff81022af6 > ] kthread + 0xf6 / 0x110 [ 1052.668223 ] [ < ffffffff81022a00 > ] ? __kthread_parkme + 0x70 / 0x70 [ 1052.674622 ] [ < ffffffff8100eb72 > ] ret_from_fork + 0x22 / 0x30 [ 1052.680538 ] < EOT > [ 1052.682670 ] Code : db e4 16 00 79 0 d f3 90 80 3 d d0 e4 16 00 00 7 e f5 eb ea 48 8 b 1 d fd fa 1f 00 48 8 b 05 e6 fa 1f 00 4 c 8 b 25 f7 fa 1f 00 48 89 c7 < ff > 50 28 49 89 c7 48 89 d8 4 d 29 e7 48 d1 e8 49 21 df 48 f7 d0 [ 1052.703711 ] RIP [ < ffffffff81015764 > ] update_wall_time + 0x44 / 0x6f0 [ 1052.710498 ] RSP < ffff88103ad9fc88 >","title":"-"},{"location":"lego/log/misc/","text":"MISC \u00b6 /etc/ld.so.preload : GLIBC uses access() to check if this file exist (normally it does not exist) 1 . This is something related to LD_PRELOAD : If both LD_PRELOAD and /etc/ld.so.preload are employed, the libraries specified by LD_PRELOAD are preloaded first. / etc/ld.so.preload has a system-wide effect, causing the specified libraries to be preloaded for all programs that are executed on the system 2 . I was reading a FAST18 paper (Fail-Slow Datacenter). I found it quite interesting and some suggestions are very useful for all system designers. Especially: Make implicit error-masking explicit. DO NOT FAIL SILENTLY . Since this is not a fail-stop ( binary ) issue, normally system designers will not raise exceptions. System designers should be aware of uncommon situations, raise explicit exceptions to convert a fail-slow ( non-binary ) case to a fail-stop ( binary ) case .Actually, this also reminds the email by Linus Torvards on BUG_ON usage 3 . Exposing performance statistic information for all-level (device, firmware, system software, application) . However, based on my own experience, do not generate too much useless logs, it will just help to hide the root cause. Testing of applications is often done on a testing environment, smaller in size (perhaps only a single server) and less loaded than the \u201clive\u201d environment. The replication behavior of such an installation may differ from a live environment in ways that mean that replication lag is unlikely to be observed in testing - masking replication-sensitive bugs. mmap PROT_NONE is really used by applications, or library. They have their special usage. etc/ld.so.preload \u21a9 ld.so.8.html \u21a9 LKML:BUG_ON \u21a9","title":"MISC"},{"location":"lego/log/misc/#misc","text":"/etc/ld.so.preload : GLIBC uses access() to check if this file exist (normally it does not exist) 1 . This is something related to LD_PRELOAD : If both LD_PRELOAD and /etc/ld.so.preload are employed, the libraries specified by LD_PRELOAD are preloaded first. / etc/ld.so.preload has a system-wide effect, causing the specified libraries to be preloaded for all programs that are executed on the system 2 . I was reading a FAST18 paper (Fail-Slow Datacenter). I found it quite interesting and some suggestions are very useful for all system designers. Especially: Make implicit error-masking explicit. DO NOT FAIL SILENTLY . Since this is not a fail-stop ( binary ) issue, normally system designers will not raise exceptions. System designers should be aware of uncommon situations, raise explicit exceptions to convert a fail-slow ( non-binary ) case to a fail-stop ( binary ) case .Actually, this also reminds the email by Linus Torvards on BUG_ON usage 3 . Exposing performance statistic information for all-level (device, firmware, system software, application) . However, based on my own experience, do not generate too much useless logs, it will just help to hide the root cause. Testing of applications is often done on a testing environment, smaller in size (perhaps only a single server) and less loaded than the \u201clive\u201d environment. The replication behavior of such an installation may differ from a live environment in ways that mean that replication lag is unlikely to be observed in testing - masking replication-sensitive bugs. mmap PROT_NONE is really used by applications, or library. They have their special usage. etc/ld.so.preload \u21a9 ld.so.8.html \u21a9 LKML:BUG_ON \u21a9","title":"MISC"},{"location":"lego/log/test-note/","text":"Scripts \u00b6 Scripts used to run OSDI\u201818 LegoOS experiments. CPU Freq \u00b6 For fair comparision, we disable cpu freq tuning (because lego does not have it. shame!): Add this to boot kernel command parameter: intel_pstate=disable swap-to-ssd \u00b6 Please remember to clear the page cache! echo 3 > /proc/sys/vm/drop_caches rm -rf /tmp/mnist_model/ lxc-execute -n test -s lxc.cgroup.memory.limit_in_bytes=128M -- python mnist.py swap-to-ramdisk \u00b6 Please note we are using BLK_DEV_RAM, a block device based on RAM. We are NOT using tmpfs or ramfs. The difference is:. modprobe brd rd_size=16777216 dd if=/dev/zero of=/dev/ram0 bs=4K mkswap /dev/ram0 swapon /dev/ram0 swapoff others Accelio and nbdX \u00b6 Follow this , and this . Tested with CentOS 7.2 kernel 3.13.1 wuklab14, wuklab18 Side notes Server side, the block device created for client, can not be raw disk/SSD. I created a file from SSD Stick with 3.13 at both client and server. Client with 3.19 will crash Server: touch /mnt/ssd/swap truncate -s +4G /mnt/ssd/swap raio_server -a 10.0.0.X -p 5555 -t rdma -f 0 Client: modprobe xio_rdma; modprobe xio_tcp modprobe nbdx nbdxadm -o create_host -i 0 -p \"10.0.0.X:5555\" nbdxadm -o create_device -i 0 -d 0 -f \"/mnt/ssd/swap\" nbdxadm -o show_all_devices mkswap /dev/nbdx0 swapon /dev/nbdx0 swapoff others Infiniswap \u00b6 Tested with CentOS 7.2 MLNX_OFED_LINUX-3.3-1.0.4.0-rhel7.2-x86_64 kernel 3.13.1 Note 1. At server side, use server ib0\u2019s IP address: # ifconfig ib0 : flags = 4163 < UP , BROADCAST , RUNNING , MULTICAST > mtu 2044 inet 10.0.0.67 netmask 255.255.255.0 broadcast 10.0.0.255 . / infiniswap - daemon 10.0.0.67 9400 At client side, use server ib0\u2019s IP in portal.list: 1 10.0.0.67:9400 2. At client side, change the BACKUP_DISK to an unused disk, and use a CORRECT one! Otherwise, wait for kernel panic, ugh. Use HDD such as /dev/sdb A SSD will kill Infiniswap. 3. Also, looks like we need to remove memmap from kernel parameter.","title":"Test Script"},{"location":"lego/log/test-note/#scripts","text":"Scripts used to run OSDI\u201818 LegoOS experiments.","title":"Scripts"},{"location":"lego/log/test-note/#cpu-freq","text":"For fair comparision, we disable cpu freq tuning (because lego does not have it. shame!): Add this to boot kernel command parameter: intel_pstate=disable","title":"CPU Freq"},{"location":"lego/log/test-note/#swap-to-ssd","text":"Please remember to clear the page cache! echo 3 > /proc/sys/vm/drop_caches rm -rf /tmp/mnist_model/ lxc-execute -n test -s lxc.cgroup.memory.limit_in_bytes=128M -- python mnist.py","title":"swap-to-ssd"},{"location":"lego/log/test-note/#swap-to-ramdisk","text":"Please note we are using BLK_DEV_RAM, a block device based on RAM. We are NOT using tmpfs or ramfs. The difference is:. modprobe brd rd_size=16777216 dd if=/dev/zero of=/dev/ram0 bs=4K mkswap /dev/ram0 swapon /dev/ram0 swapoff others","title":"swap-to-ramdisk"},{"location":"lego/log/test-note/#accelio-and-nbdx","text":"Follow this , and this . Tested with CentOS 7.2 kernel 3.13.1 wuklab14, wuklab18 Side notes Server side, the block device created for client, can not be raw disk/SSD. I created a file from SSD Stick with 3.13 at both client and server. Client with 3.19 will crash Server: touch /mnt/ssd/swap truncate -s +4G /mnt/ssd/swap raio_server -a 10.0.0.X -p 5555 -t rdma -f 0 Client: modprobe xio_rdma; modprobe xio_tcp modprobe nbdx nbdxadm -o create_host -i 0 -p \"10.0.0.X:5555\" nbdxadm -o create_device -i 0 -d 0 -f \"/mnt/ssd/swap\" nbdxadm -o show_all_devices mkswap /dev/nbdx0 swapon /dev/nbdx0 swapoff others","title":"Accelio and nbdX"},{"location":"lego/log/test-note/#infiniswap","text":"Tested with CentOS 7.2 MLNX_OFED_LINUX-3.3-1.0.4.0-rhel7.2-x86_64 kernel 3.13.1 Note 1. At server side, use server ib0\u2019s IP address: # ifconfig ib0 : flags = 4163 < UP , BROADCAST , RUNNING , MULTICAST > mtu 2044 inet 10.0.0.67 netmask 255.255.255.0 broadcast 10.0.0.255 . / infiniswap - daemon 10.0.0.67 9400 At client side, use server ib0\u2019s IP in portal.list: 1 10.0.0.67:9400 2. At client side, change the BACKUP_DISK to an unused disk, and use a CORRECT one! Otherwise, wait for kernel panic, ugh. Use HDD such as /dev/sdb A SSD will kill Infiniswap. 3. Also, looks like we need to remove memmap from kernel parameter.","title":"Infiniswap"},{"location":"lego/paper/genz/","text":"Interconnect Technology Comparison \u00b6 Interconnect Technology Products or Vendor Physical Domain Cache Coherent Access Semantic Maximum Bandwidth Medium Latency Gen-Z 7 8 N/A Cross components Memory 32 GBps ~ 400+ GBps Unidirectional <100ns OpenCAPI 7 IBM Power9 Motherboard Memory 50 GBps per lane Bidirectional ? CCIX 7 N/A Motherboard Memory 32/40/50 GBps/lane Bidirectional ? OmniPath 9 10 Intel KnightsLanding Cross networrk Network 25 GBps/port Bidirectional ? PCIe 3.0 A Lot Motherboard PCIe ~1GBps/lane 12 4B Read ~756ns 11 PCIe 4.0 Soon Motherboard PCIe ~2GBps/lane ? IB EDR Mellanox ConnectX4,X5 Cross network Network 100Gbps 0.5us IB HDR Mellanox ConnectX6 Cross network Network 200Gbps <0.5us HyperTransport 4 AMD Motherboard Memory 51.2 GBps per link Bidirectional ? NVLink 2 NVIDIA V100 IBM Power9 Motherboard Memory 50GBps per link Bidirectional ? QPI 5 6 Intel Motherboard Memory ? ? Intel Main Memory Bus Intel Processor Memory E7-8894 v4 85 GB/s E5-2620 v3 59 GB/s ? Ethernet 3 A Lot Motherboard Network Mellanox 200Gbps Cisco ASR 100 Gbps 1 ? POWER9, NVLink 2.0, 300GB/s \u2013 Created: Feb 28, 2018 Last Updated: March 01, 2018 Ethernet Cisco ASR 9000 Series 4-Port 100-Gigabit Ethernet \u21a9 Terabit Ethernet https://en.wikipedia.org/wiki/NVLink \u21a9 NVLink \u21a9 HyperTransport \u21a9 https://en.wikipedia.org/wiki/Intel_QuickPath_Interconnect \u21a9 https://communities.intel.com/thread/21872 \u21a9 https://www.openfabrics.org/images/eventpresos/2017presentations/213_CCIXGen-Z_BBenton.pdf \u21a9 \u21a9 \u21a9 Gen-Z Overview \u21a9 http://www.hoti.org/hoti23/slides/rimmer.pdf \u21a9 https://www.intel.com/content/www/us/en/products/network-io/high-performance-fabrics/omni-path-edge-switch-100-series.html \u21a9 https://forum.stanford.edu/events/posterslides/LowLatencyNetworkInterfaces.pdf \u21a9 https://www.xilinx.com/support/documentation/white_papers/wp350.pdf \u21a9","title":"Gen-Z"},{"location":"lego/paper/genz/#interconnect-technology-comparison","text":"Interconnect Technology Products or Vendor Physical Domain Cache Coherent Access Semantic Maximum Bandwidth Medium Latency Gen-Z 7 8 N/A Cross components Memory 32 GBps ~ 400+ GBps Unidirectional <100ns OpenCAPI 7 IBM Power9 Motherboard Memory 50 GBps per lane Bidirectional ? CCIX 7 N/A Motherboard Memory 32/40/50 GBps/lane Bidirectional ? OmniPath 9 10 Intel KnightsLanding Cross networrk Network 25 GBps/port Bidirectional ? PCIe 3.0 A Lot Motherboard PCIe ~1GBps/lane 12 4B Read ~756ns 11 PCIe 4.0 Soon Motherboard PCIe ~2GBps/lane ? IB EDR Mellanox ConnectX4,X5 Cross network Network 100Gbps 0.5us IB HDR Mellanox ConnectX6 Cross network Network 200Gbps <0.5us HyperTransport 4 AMD Motherboard Memory 51.2 GBps per link Bidirectional ? NVLink 2 NVIDIA V100 IBM Power9 Motherboard Memory 50GBps per link Bidirectional ? QPI 5 6 Intel Motherboard Memory ? ? Intel Main Memory Bus Intel Processor Memory E7-8894 v4 85 GB/s E5-2620 v3 59 GB/s ? Ethernet 3 A Lot Motherboard Network Mellanox 200Gbps Cisco ASR 100 Gbps 1 ? POWER9, NVLink 2.0, 300GB/s \u2013 Created: Feb 28, 2018 Last Updated: March 01, 2018 Ethernet Cisco ASR 9000 Series 4-Port 100-Gigabit Ethernet \u21a9 Terabit Ethernet https://en.wikipedia.org/wiki/NVLink \u21a9 NVLink \u21a9 HyperTransport \u21a9 https://en.wikipedia.org/wiki/Intel_QuickPath_Interconnect \u21a9 https://communities.intel.com/thread/21872 \u21a9 https://www.openfabrics.org/images/eventpresos/2017presentations/213_CCIXGen-Z_BBenton.pdf \u21a9 \u21a9 \u21a9 Gen-Z Overview \u21a9 http://www.hoti.org/hoti23/slides/rimmer.pdf \u21a9 https://www.intel.com/content/www/us/en/products/network-io/high-performance-fabrics/omni-path-edge-switch-100-series.html \u21a9 https://forum.stanford.edu/events/posterslides/LowLatencyNetworkInterfaces.pdf \u21a9 https://www.xilinx.com/support/documentation/white_papers/wp350.pdf \u21a9","title":"Interconnect Technology Comparison"},{"location":"lego/paper/nmp/","text":"Near Memory Processing \u00b6 NMP: Near Memory Processing NDC: Near Data Computing PRIME: A Novel Processing-in-memory Architecture for Neural Network Computation in ReRAM-based Main Memory, ISCA'16 High-performance acceleration of NN requires high memory bandwidth since the PUs are hungry for fetching the synaptic weights [17] . To address this challenge, recent special-purpose chip designs have adopted large on-chip memory to store the synaptic weights. For example, DaDianNao [18] employed a large on-chip eDRAM for both high bandwidth and data locality; TrueNorth utilized an SRAM crossbar memory for synapses in each core [19]. DianNao and DaDianNao \u2026 memory bandwidth requirements of two important layer types: convolutional layers with private kernels (used in DNNs) and classifier layers used in both CNNs and DNNs. For these types of layers, the total number of required synapses can be massive, in the millions of parameters, or even tens or hundreds thereof. providing sufficient eDRAM capacity to hold all synapse on the combined eDRAM of all chips will save on off-chip DRAM accesses , which are particularly costly energy-wise Synapses . In a perceptron layer, all synapses are usually unique, and thus there is no reuse within the layer. On the other hand, the synapses are reused across network invocations, i.e., for each new input data (also called \u201cinput row\u201d) presented to the neural network. So a sufficiently large L2 could store all network synapses and take advantage of that locality. For DNNs with private kernels, this is not possible as the total number of synapses are in the tens or hundreds of millions (the largest network to date has a billion synapses [26]). However, for both CNNs and DNNs with shared kernels, the total number of synapses range in the millions, which is within the reach of an L2 cache. In Figure 6, see CLASS1 - Tiled+L2, we emulate the case where reuse across network invocations is possible by considering only the perceptron layer; as a result, the total bandwidth requirements are now drastically reduced. So, ML workloads do need large memory bandwidth, and need a lot memory. But how about temporary working set size ? It\u2019s the best if it has a reasonable working set size that can fit the cache. TPU Each model needs between 5M and 100M weights (9 th column of Table 1), which can take a lot of time and energy to access. To amortize the access costs, the same weights are reused across a batch of independent examples during inference or training , which improves performance. The weights for the matrix unit are staged through an onchip Weight FIFO that reads from an off-chip 8 GiB DRAM called Weight Memory (for inference, weights are read-only; 8 GiB supports many simultaneously active models). The weight FIFO is four tiles deep. The intermediate results are held in the 24 MiB on-chip Unified Buffer , which can serve as inputs to the Matrix Unit. In virtual cache model, we actually can assign those weights to some designated sets, thus avoid conflicting with other data, which means we can sustain those weights in cache! To conclude: a) ML needs to use weight/synapses during computation, and those data will be reused repeatly across different stages. Besides, output from last stage serves the input of next stage, so buffering the intermediate data is important. Most ML accelerators use some kind of on-chip memory ( Weighted FIFO, Unified Cache in TPU ) to buffer those data. This fits the HBM+Disaggregated Memory model: HBM is the on-chip memory, while disaggregated memory is the off-chip memory. b) Combined with virtual cache, we could assign special virtual addresses to weight data, so they stay in some designated cache sets. Kernel can avoid allocating conflict virtual addresses later. Thus we can retain these weight data in virtual cache easily.","title":"NMP"},{"location":"lego/paper/nmp/#near-memory-processing","text":"NMP: Near Memory Processing NDC: Near Data Computing PRIME: A Novel Processing-in-memory Architecture for Neural Network Computation in ReRAM-based Main Memory, ISCA'16 High-performance acceleration of NN requires high memory bandwidth since the PUs are hungry for fetching the synaptic weights [17] . To address this challenge, recent special-purpose chip designs have adopted large on-chip memory to store the synaptic weights. For example, DaDianNao [18] employed a large on-chip eDRAM for both high bandwidth and data locality; TrueNorth utilized an SRAM crossbar memory for synapses in each core [19]. DianNao and DaDianNao \u2026 memory bandwidth requirements of two important layer types: convolutional layers with private kernels (used in DNNs) and classifier layers used in both CNNs and DNNs. For these types of layers, the total number of required synapses can be massive, in the millions of parameters, or even tens or hundreds thereof. providing sufficient eDRAM capacity to hold all synapse on the combined eDRAM of all chips will save on off-chip DRAM accesses , which are particularly costly energy-wise Synapses . In a perceptron layer, all synapses are usually unique, and thus there is no reuse within the layer. On the other hand, the synapses are reused across network invocations, i.e., for each new input data (also called \u201cinput row\u201d) presented to the neural network. So a sufficiently large L2 could store all network synapses and take advantage of that locality. For DNNs with private kernels, this is not possible as the total number of synapses are in the tens or hundreds of millions (the largest network to date has a billion synapses [26]). However, for both CNNs and DNNs with shared kernels, the total number of synapses range in the millions, which is within the reach of an L2 cache. In Figure 6, see CLASS1 - Tiled+L2, we emulate the case where reuse across network invocations is possible by considering only the perceptron layer; as a result, the total bandwidth requirements are now drastically reduced. So, ML workloads do need large memory bandwidth, and need a lot memory. But how about temporary working set size ? It\u2019s the best if it has a reasonable working set size that can fit the cache. TPU Each model needs between 5M and 100M weights (9 th column of Table 1), which can take a lot of time and energy to access. To amortize the access costs, the same weights are reused across a batch of independent examples during inference or training , which improves performance. The weights for the matrix unit are staged through an onchip Weight FIFO that reads from an off-chip 8 GiB DRAM called Weight Memory (for inference, weights are read-only; 8 GiB supports many simultaneously active models). The weight FIFO is four tiles deep. The intermediate results are held in the 24 MiB on-chip Unified Buffer , which can serve as inputs to the Matrix Unit. In virtual cache model, we actually can assign those weights to some designated sets, thus avoid conflicting with other data, which means we can sustain those weights in cache! To conclude: a) ML needs to use weight/synapses during computation, and those data will be reused repeatly across different stages. Besides, output from last stage serves the input of next stage, so buffering the intermediate data is important. Most ML accelerators use some kind of on-chip memory ( Weighted FIFO, Unified Cache in TPU ) to buffer those data. This fits the HBM+Disaggregated Memory model: HBM is the on-chip memory, while disaggregated memory is the off-chip memory. b) Combined with virtual cache, we could assign special virtual addresses to weight data, so they stay in some designated cache sets. Kernel can avoid allocating conflict virtual addresses later. Thus we can retain these weight data in virtual cache easily.","title":"Near Memory Processing"},{"location":"lego/paper/os/","text":"Operating System \u00b6 Multics Hydra (operating system), CMU 70\u2019s Firefly DEC, 80\u2019s HIVE Disco IBM K42 Tessellation, UCB Akaros, UCB Amoeba The Amoeba distributed operating system Amoeba A Distributed Operating System for the 1990s Corey Corey: An Operating System for Many Cores Barrelfish Decoupling Cores, Kernels, and Operating Systems The Multikernel: A new OS architecture for scalable multicore systems Drawbridge Graphene L4 FOS An Operating System for Multicore and Clouds: Mechanisms and Implementation","title":"Operating System"},{"location":"lego/paper/os/#operating-system","text":"Multics Hydra (operating system), CMU 70\u2019s Firefly DEC, 80\u2019s HIVE Disco IBM K42 Tessellation, UCB Akaros, UCB Amoeba The Amoeba distributed operating system Amoeba A Distributed Operating System for the 1990s Corey Corey: An Operating System for Many Cores Barrelfish Decoupling Cores, Kernels, and Operating Systems The Multikernel: A new OS architecture for scalable multicore systems Drawbridge Graphene L4 FOS An Operating System for Multicore and Clouds: Mechanisms and Implementation","title":"Operating System"},{"location":"lego/paper/processor_oom/","text":"Process/Memory Kernel Memory \u00b6 This document is based on discussion with Yiying, about how to deal with processor or memory component\u2019s out-of-kernel-memory situation. It mainly bothers processor component, which has a small kernel memory while needs to support all running user threads. Process\u2019s local kernel memory is limited by design. There are several major users: 1) pcache\u2019s rmap, which is propotional to pcache size. 2) IB, which depends on concurrent outgoing messages. 3) running threads. For each thread at processor, Lego needs to allocate some kernel memory for it, e.g, kernel stack , task_strcut , and so on. Both 1) and 2) are fine, they can be easily controlled. However we can not limit how many threads user can create, thus 3) becomes the critical criminal of oom. When processor is running out of kernel memory, Lego needs to deal with it. Currently, we propose three different solutions: s1) Swap kernel memory to remote memory component s2) Kill some threads to have some usable memory (OOM killer) s3) Migrate , or checkpoint , threads to processors that have usable kernel memory For solution 3), there is a case where all processors are running out of memory. Then we have to use solution 1) or 2). \u2013 Yizhou Shan Feb 17, 2018","title":"Processor OOM"},{"location":"lego/paper/processor_oom/#processmemory-kernel-memory","text":"This document is based on discussion with Yiying, about how to deal with processor or memory component\u2019s out-of-kernel-memory situation. It mainly bothers processor component, which has a small kernel memory while needs to support all running user threads. Process\u2019s local kernel memory is limited by design. There are several major users: 1) pcache\u2019s rmap, which is propotional to pcache size. 2) IB, which depends on concurrent outgoing messages. 3) running threads. For each thread at processor, Lego needs to allocate some kernel memory for it, e.g, kernel stack , task_strcut , and so on. Both 1) and 2) are fine, they can be easily controlled. However we can not limit how many threads user can create, thus 3) becomes the critical criminal of oom. When processor is running out of kernel memory, Lego needs to deal with it. Currently, we propose three different solutions: s1) Swap kernel memory to remote memory component s2) Kill some threads to have some usable memory (OOM killer) s3) Migrate , or checkpoint , threads to processors that have usable kernel memory For solution 3), there is a case where all processors are running out of memory. Then we have to use solution 1) or 2). \u2013 Yizhou Shan Feb 17, 2018","title":"Process/Memory Kernel Memory"},{"location":"lego/paper/related/","text":"dRedBox \u00b6 news IBM Advancing cloud with memory disaggregation [Slides: Open Source Cloud Ecosystem for Next-Gen Disaggregated Datacenters] ( https://schd.ws/hosted_files/osseu17/60/dReDBox.CloudOpen2017.talk.pdf ) Slides: Demo","title":"Related"},{"location":"lego/paper/related/#dredbox","text":"news IBM Advancing cloud with memory disaggregation [Slides: Open Source Cloud Ecosystem for Next-Gen Disaggregated Datacenters] ( https://schd.ws/hosted_files/osseu17/60/dReDBox.CloudOpen2017.talk.pdf ) Slides: Demo","title":"dRedBox"},{"location":"lego/paper/replication/","text":"Replication, Checkpoint, Logging, and Recovery \u00b6 Discussion \u00b6 03/25/18: Revisit RAMCloud, which has a very similar goal with Lego. It keeps a full copy of data in DRAM, use disk to ensure crash consistency. The key assumption of RAMCloud is the battery-backed DRAM or PM on its disk side. We don\u2019t need to provide a 100% recoverable model. Our goal here is to reduce the failure probabilities introduced by more components. Let us say Lego do the persist in a batching fashion, instead of per-page. We are not able to recover if and only if failure happen while we do the batch persist. But we are safe if failure happen between batched persist. That actually also means we need to checkpoint process state in Processor side. We have to save all the process context along with the persisted memory log! Otherwise, the memory content is useless, we don\u2019t know the exact IP and other things. I\u2019m wrong. :-) 03/20/18: when memory is enough, use pessimistic replication, when demand is high, use optimistic to save memory components. Replication \u00b6 Before started, I spent some time recap, and found Wiki pages 1 2 3 are actually very good. Two main approaches: Optimistic (Lazy, Passive) Replication 4 , in which replicas are allowed to diverge Eventual consistency 5 6 7 , meaning that replicas are guaranteed to converge only when the system has been quiesced for a period of time Pessimistic (Active, Multi-master 8 ) Replication , tries to guarantee from the beginning that all of the replicas are identical to each other, as if there was only a single copy of the data all along. Lego is more towards memory replication, not storage replication. We may want to conduct some ideas from DSM replication (MRSW, MRMW), or in-memory DB such as RAMCloud, VoltDB? Checkpointing \u00b6 Some nice reading 9 . Application types: Long-running v.s. Short-lived Built-in checkpoint/journaling v.s. no built-in checkpoint/journaling Two main approaches: Coordinated 2PC Un-coordinated Domino effect We should favor [Long-running && no built-in checkpoint/journaling] applications. Normally they are not distributed systems, right? Even it is, it might be running as a single-node version. Based on this, I think we should favor coordinated checkpointing. HPC community 10 11 12 has a lot publications on checkpoint/recovery (e.g., Lawrence National Laboratory). MISC \u00b6 Some other interesting topics: Erasure Coding Less space overhead Parity Calculation is CPU-intensive Increased latency \u2013 Yizhou Shan Created: Mar 19, 2018 Last Updated: Mar 19, 2018 Wiki: Replication \u21a9 Wiki: High-availability_cluster \u21a9 Wiki: Virtual synchrony \u21a9 Wiki: Optimistic Replication \u21a9 Wiki: Quiesce \u21a9 Wiki: Eventual Consistency \u21a9 Wiki: CAP Theorem \u21a9 Wiki: Multi-master replication \u21a9 Wiki: Application Checkpointing \u21a9 Paper: A Survey of Checkpoint/Restart Implementations \u21a9 Paper: The Design and Implementation of Berkeley Lab\u2019s Linux Checkpoint/Restart \u21a9 Berkeley Lab Checkpoint/Restart (BLCR) for LINUX \u21a9","title":"Replication"},{"location":"lego/paper/replication/#replication-checkpoint-logging-and-recovery","text":"","title":"Replication, Checkpoint, Logging, and Recovery"},{"location":"lego/paper/replication/#discussion","text":"03/25/18: Revisit RAMCloud, which has a very similar goal with Lego. It keeps a full copy of data in DRAM, use disk to ensure crash consistency. The key assumption of RAMCloud is the battery-backed DRAM or PM on its disk side. We don\u2019t need to provide a 100% recoverable model. Our goal here is to reduce the failure probabilities introduced by more components. Let us say Lego do the persist in a batching fashion, instead of per-page. We are not able to recover if and only if failure happen while we do the batch persist. But we are safe if failure happen between batched persist. That actually also means we need to checkpoint process state in Processor side. We have to save all the process context along with the persisted memory log! Otherwise, the memory content is useless, we don\u2019t know the exact IP and other things. I\u2019m wrong. :-) 03/20/18: when memory is enough, use pessimistic replication, when demand is high, use optimistic to save memory components.","title":"Discussion"},{"location":"lego/paper/replication/#replication","text":"Before started, I spent some time recap, and found Wiki pages 1 2 3 are actually very good. Two main approaches: Optimistic (Lazy, Passive) Replication 4 , in which replicas are allowed to diverge Eventual consistency 5 6 7 , meaning that replicas are guaranteed to converge only when the system has been quiesced for a period of time Pessimistic (Active, Multi-master 8 ) Replication , tries to guarantee from the beginning that all of the replicas are identical to each other, as if there was only a single copy of the data all along. Lego is more towards memory replication, not storage replication. We may want to conduct some ideas from DSM replication (MRSW, MRMW), or in-memory DB such as RAMCloud, VoltDB?","title":"Replication"},{"location":"lego/paper/replication/#checkpointing","text":"Some nice reading 9 . Application types: Long-running v.s. Short-lived Built-in checkpoint/journaling v.s. no built-in checkpoint/journaling Two main approaches: Coordinated 2PC Un-coordinated Domino effect We should favor [Long-running && no built-in checkpoint/journaling] applications. Normally they are not distributed systems, right? Even it is, it might be running as a single-node version. Based on this, I think we should favor coordinated checkpointing. HPC community 10 11 12 has a lot publications on checkpoint/recovery (e.g., Lawrence National Laboratory).","title":"Checkpointing"},{"location":"lego/paper/replication/#misc","text":"Some other interesting topics: Erasure Coding Less space overhead Parity Calculation is CPU-intensive Increased latency \u2013 Yizhou Shan Created: Mar 19, 2018 Last Updated: Mar 19, 2018 Wiki: Replication \u21a9 Wiki: High-availability_cluster \u21a9 Wiki: Virtual synchrony \u21a9 Wiki: Optimistic Replication \u21a9 Wiki: Quiesce \u21a9 Wiki: Eventual Consistency \u21a9 Wiki: CAP Theorem \u21a9 Wiki: Multi-master replication \u21a9 Wiki: Application Checkpointing \u21a9 Paper: A Survey of Checkpoint/Restart Implementations \u21a9 Paper: The Design and Implementation of Berkeley Lab\u2019s Linux Checkpoint/Restart \u21a9 Berkeley Lab Checkpoint/Restart (BLCR) for LINUX \u21a9","title":"MISC"},{"location":"lego/pcache/config/","text":"Pcache Configuration \u00b6 This doc explains what configuration options pcache has, and how to config them properly. Pcache is only enabled in Lego\u2019s processor manager and currently it uses DRAM to emulate the last-level cache (or, L4). Kconfig \u00b6 CONFIG_MEMMAP_MEMBLOCK_RESERVED \u00b6 DEFAULT: Y By default, boot command line option memmap $ will reserve a range of physical memory. This reserved memory will be marked reserved in e820 table, which means this range will not be registered into memblock . Only memory that has been registered into memblock will be assigned struct page with it (both memblock.memory and memblock.reserve will have). And do note that this part of reserved memory can be mapped as 1GB page at boot time. In other words, by default (the linux semantic), users need to ioremap the memmap $ reserved physical memory, and use the returned kernel virtual address afterwards. And do note that the ioremap() only support 4KB mapping. In Lego, if this option is enabled, the memory marked by memmap $ will NOT be marked reserved into e820 table, instead, it will be pushed into memblock , which means it is mapped into kernel direct mapping and has struct page . For those who have done DAX, or NVM related stuff, you must have struggled with memmap $ , and complained why it does not have struct page , I guess? So here is the simple code to do so: if ( * p == '@' ) { start_at = memparse ( p + 1 , & p ); e820_add_region ( start_at , mem_size , E820_RAM ); } else if ( * p == '#' ) { start_at = memparse ( p + 1 , & p ); e820_add_region ( start_at , mem_size , E820_ACPI ); } else if ( * p == '$' ) { start_at = memparse ( p + 1 , & p ); #ifdef CONFIG_MEMMAP_MEMBLOCK_RESERVED memblock_reserve ( start_at , mem_size ); #else e820_add_region ( start_at , mem_size , E820_RESERVED ); #endif But why we are having this? Because I think the direct 1GB mapping may have better performance: huge page mapping can truly save us a lot TLB misses. However, the real performance number is unknown. If unsure, say Y . \u2013 Yizhou Shan Created: Feb 01, 2018 Last Updated: Feb 01, 2018","title":"Config"},{"location":"lego/pcache/config/#pcache-configuration","text":"This doc explains what configuration options pcache has, and how to config them properly. Pcache is only enabled in Lego\u2019s processor manager and currently it uses DRAM to emulate the last-level cache (or, L4).","title":"Pcache Configuration"},{"location":"lego/pcache/config/#kconfig","text":"","title":"Kconfig"},{"location":"lego/pcache/config/#config_memmap_memblock_reserved","text":"DEFAULT: Y By default, boot command line option memmap $ will reserve a range of physical memory. This reserved memory will be marked reserved in e820 table, which means this range will not be registered into memblock . Only memory that has been registered into memblock will be assigned struct page with it (both memblock.memory and memblock.reserve will have). And do note that this part of reserved memory can be mapped as 1GB page at boot time. In other words, by default (the linux semantic), users need to ioremap the memmap $ reserved physical memory, and use the returned kernel virtual address afterwards. And do note that the ioremap() only support 4KB mapping. In Lego, if this option is enabled, the memory marked by memmap $ will NOT be marked reserved into e820 table, instead, it will be pushed into memblock , which means it is mapped into kernel direct mapping and has struct page . For those who have done DAX, or NVM related stuff, you must have struggled with memmap $ , and complained why it does not have struct page , I guess? So here is the simple code to do so: if ( * p == '@' ) { start_at = memparse ( p + 1 , & p ); e820_add_region ( start_at , mem_size , E820_RAM ); } else if ( * p == '#' ) { start_at = memparse ( p + 1 , & p ); e820_add_region ( start_at , mem_size , E820_ACPI ); } else if ( * p == '$' ) { start_at = memparse ( p + 1 , & p ); #ifdef CONFIG_MEMMAP_MEMBLOCK_RESERVED memblock_reserve ( start_at , mem_size ); #else e820_add_region ( start_at , mem_size , E820_RESERVED ); #endif But why we are having this? Because I think the direct 1GB mapping may have better performance: huge page mapping can truly save us a lot TLB misses. However, the real performance number is unknown. If unsure, say Y . \u2013 Yizhou Shan Created: Feb 01, 2018 Last Updated: Feb 01, 2018","title":"CONFIG_MEMMAP_MEMBLOCK_RESERVED"},{"location":"lego/pcache/evict_and_ref/","text":"Mumble pcache eviction and refcount \u00b6 This is about how Lego is doing eviction against live references of pcache. Unlike the garbage collection where it only reclaims object that has no references, pcache eviction may try to evict a pcache that is currently being used by another thread. Both parties need to be very careful. A tricky business. To describe the issue in a high-level, let us consider this case: the system now has two threads running on two different cores. The first thread try to evict a pcache line, and it truly find a candidate and prepare to evict. Meanwhile, the other thread is currently using this pcache line to do some operations such as zap_rmap() . If the first thread evict the pcache line without synchronization with the second thread, oops, the second thread is playing with a wrong pcache. The textbook idea is adding refcount. However, this is not enough in C. Because: There is no way to prevent the second thread from getting the pointer to that pcm. A simple inc_refcount() from the second thread can happen anytime in the middle of first thread\u2019s eviction. Solutions: To actually prevent the second thread from getting the pointer, we should think about how it get the pointer? Luckily, in Lego, there is only one entry point, which is from pte to pcm (aka. pcache_meta). So to synchronize pte change becomes very important. Luckily, we are doing pte_lock before getting the pcm. So this simple pte lock ensures the second thread a safe, will-not-be-evicted pcm (of course, with some other checkings). This idea can also be generalized to any data structures that need pointer references: protect your pointer ! Refcount checking is also necessary. In the eviction routine, we need to use atomic_xchg to reset the refcount. If this fails, it means someone else is using it. Do note, this atomic_xchg is carried out with pcm locked. Thus the ordering of locking, get/put matters in the code. The code itself tells a much more complete story, I strongly recommend you read the code if you are interested. Here I will list the most interesting part. For the other users except eviction, they need to do this: pcm = pte_to_pcache_meta ( ptent ); /* * We have a strict lock ordering everyone should obey: * lock pcache * lock pte * The caller already locked pte, thus we should avoid deadlock here * by droping pte lock first and then acquire both of them in order. */ if ( unlikely ( ! trylock_pcache ( pcm ))) { /* in case it got evicted and @pcm becomes invalid */ get_pcache ( pcm ); /* * Once we release the pte lock, this pcm may be * unmapped by another thread who is doing eviction. * Since we have grabbed one extra ref above, so even * it is unmapped, eviction thread will not fail to free it. */ spin_unlock ( ptl ); lock_pcache ( pcm ); spin_lock ( ptl ); /* * Since we dropped the lock, the pcache line might * be got evicted in the middle. */ if ( ! pte_same ( * pte , ptent )) { unlock_pcache ( pcm ); /* * This put maybe decreases the ref to 0 * and eventually free the pcache line. * This happens if the @pcm was selected * to be evicted at the same time. */ put_pcache ( pcm ); return - EAGAIN ; } put_pcache ( pcm ); } As for the eviction thread, it needs to make sure it is the last user using this pcm: /* * Each rmap counts one refcount, plus the one grabbed * during evict_find_line(), we should have (nr_mapped + 1) * here if there are no any other users. * * Furthurmore, others can not go from munmap/mremap/wp to * put_pcache() within pcache_zap_pte(), pcache_move_pte() * or pcache_do_wp_page(). Thus the refcount must larger or * equal to (nr_mapped + 1). * * But if there truly other users (refcount > nr_mapped + 1), * then we should manually sub the refcount. The other users * which are currently holding the ref, will free the pcache * once it call put_pcache. */ PCACHE_BUG_ON_PCM ( pcache_ref_count ( pcm ) < nr_mapped + 1 , pcm ); if ( unlikely ( ! pcache_ref_freeze ( pcm , nr_mapped + 1 ))) { if ( unlikely ( pcache_ref_sub_and_test ( pcm , nr_mapped + 1 ))) { pr_info ( \"BUG: pcm refcount, nr_mapped: %d \\n \" , nr_mapped ); dump_pcache_meta ( pcm , \"ref error\" ); BUG (); } ClearPcacheReclaim ( pcm ); add_to_lru_list ( pcm , pset ); unlock_pcache ( pcm ); inc_pcache_event ( PCACHE_EVICTION_EAGAIN_CONCURRENT ); return PCACHE_EVICT_EAGAIN_CONCURRENT ; } My personal thought: live eviction against live objects/references is very hard. You first need to use refcount to ensure a correct ordering. You also need to have a way to prevent others from using the going-to-be-evicted pointer, or have a way to detect a under-use pointer. In this Lego pcache case, we use the combination of pte lock, pcache lock, and pcache refcount, to ensure everyone is safe. And all these is quite similar to Linux page operations. I learned a lot from its code. But I still not fully understand how it ensures the page is not used by others, it has way more parties than lego that can use the page at the same time of eviction. Magic kernel folks. \u2013 Yizhou Shan Created: Mar 15, 2018 Last Updated: Mar 16, 2018","title":"Evict and Refcount"},{"location":"lego/pcache/evict_and_ref/#mumble-pcache-eviction-and-refcount","text":"This is about how Lego is doing eviction against live references of pcache. Unlike the garbage collection where it only reclaims object that has no references, pcache eviction may try to evict a pcache that is currently being used by another thread. Both parties need to be very careful. A tricky business. To describe the issue in a high-level, let us consider this case: the system now has two threads running on two different cores. The first thread try to evict a pcache line, and it truly find a candidate and prepare to evict. Meanwhile, the other thread is currently using this pcache line to do some operations such as zap_rmap() . If the first thread evict the pcache line without synchronization with the second thread, oops, the second thread is playing with a wrong pcache. The textbook idea is adding refcount. However, this is not enough in C. Because: There is no way to prevent the second thread from getting the pointer to that pcm. A simple inc_refcount() from the second thread can happen anytime in the middle of first thread\u2019s eviction. Solutions: To actually prevent the second thread from getting the pointer, we should think about how it get the pointer? Luckily, in Lego, there is only one entry point, which is from pte to pcm (aka. pcache_meta). So to synchronize pte change becomes very important. Luckily, we are doing pte_lock before getting the pcm. So this simple pte lock ensures the second thread a safe, will-not-be-evicted pcm (of course, with some other checkings). This idea can also be generalized to any data structures that need pointer references: protect your pointer ! Refcount checking is also necessary. In the eviction routine, we need to use atomic_xchg to reset the refcount. If this fails, it means someone else is using it. Do note, this atomic_xchg is carried out with pcm locked. Thus the ordering of locking, get/put matters in the code. The code itself tells a much more complete story, I strongly recommend you read the code if you are interested. Here I will list the most interesting part. For the other users except eviction, they need to do this: pcm = pte_to_pcache_meta ( ptent ); /* * We have a strict lock ordering everyone should obey: * lock pcache * lock pte * The caller already locked pte, thus we should avoid deadlock here * by droping pte lock first and then acquire both of them in order. */ if ( unlikely ( ! trylock_pcache ( pcm ))) { /* in case it got evicted and @pcm becomes invalid */ get_pcache ( pcm ); /* * Once we release the pte lock, this pcm may be * unmapped by another thread who is doing eviction. * Since we have grabbed one extra ref above, so even * it is unmapped, eviction thread will not fail to free it. */ spin_unlock ( ptl ); lock_pcache ( pcm ); spin_lock ( ptl ); /* * Since we dropped the lock, the pcache line might * be got evicted in the middle. */ if ( ! pte_same ( * pte , ptent )) { unlock_pcache ( pcm ); /* * This put maybe decreases the ref to 0 * and eventually free the pcache line. * This happens if the @pcm was selected * to be evicted at the same time. */ put_pcache ( pcm ); return - EAGAIN ; } put_pcache ( pcm ); } As for the eviction thread, it needs to make sure it is the last user using this pcm: /* * Each rmap counts one refcount, plus the one grabbed * during evict_find_line(), we should have (nr_mapped + 1) * here if there are no any other users. * * Furthurmore, others can not go from munmap/mremap/wp to * put_pcache() within pcache_zap_pte(), pcache_move_pte() * or pcache_do_wp_page(). Thus the refcount must larger or * equal to (nr_mapped + 1). * * But if there truly other users (refcount > nr_mapped + 1), * then we should manually sub the refcount. The other users * which are currently holding the ref, will free the pcache * once it call put_pcache. */ PCACHE_BUG_ON_PCM ( pcache_ref_count ( pcm ) < nr_mapped + 1 , pcm ); if ( unlikely ( ! pcache_ref_freeze ( pcm , nr_mapped + 1 ))) { if ( unlikely ( pcache_ref_sub_and_test ( pcm , nr_mapped + 1 ))) { pr_info ( \"BUG: pcm refcount, nr_mapped: %d \\n \" , nr_mapped ); dump_pcache_meta ( pcm , \"ref error\" ); BUG (); } ClearPcacheReclaim ( pcm ); add_to_lru_list ( pcm , pset ); unlock_pcache ( pcm ); inc_pcache_event ( PCACHE_EVICTION_EAGAIN_CONCURRENT ); return PCACHE_EVICT_EAGAIN_CONCURRENT ; } My personal thought: live eviction against live objects/references is very hard. You first need to use refcount to ensure a correct ordering. You also need to have a way to prevent others from using the going-to-be-evicted pointer, or have a way to detect a under-use pointer. In this Lego pcache case, we use the combination of pte lock, pcache lock, and pcache refcount, to ensure everyone is safe. And all these is quite similar to Linux page operations. I learned a lot from its code. But I still not fully understand how it ensures the page is not used by others, it has way more parties than lego that can use the page at the same time of eviction. Magic kernel folks. \u2013 Yizhou Shan Created: Mar 15, 2018 Last Updated: Mar 16, 2018","title":"Mumble pcache eviction and refcount"},{"location":"lego/pcache/pgtable-lock/","text":"Fine-grain Page Table Lock \u00b6 In old Linux or previous Lego, user page table operations, such as set, clear, are protected by mm->page_table_lock . This one single lock prohibits a lot parallelisms on big SMP machines. An ideal solution is to have finer-granularity locks, so that faults on different parts of the user address space can be handled with less contention. But finer-granularity locks means you need more memory for the locks. This is a simple trade-off. Lego currently mimic the Linux x86 default setting 1 , where each PMD and PTE page table pages has their own lock. The lock is a spinlock embedded in the struct page . As illustrated below: Both Processor and Memory managers are using the same mechanism to increase parallelism. And it is something that can improve performance a lot . \u2013 Yizhou Shan Created: Mar 22, 2018 Last Updated: April 13, 2018 Split page table locks \u21a9","title":"PageTable Lock"},{"location":"lego/pcache/pgtable-lock/#fine-grain-page-table-lock","text":"In old Linux or previous Lego, user page table operations, such as set, clear, are protected by mm->page_table_lock . This one single lock prohibits a lot parallelisms on big SMP machines. An ideal solution is to have finer-granularity locks, so that faults on different parts of the user address space can be handled with less contention. But finer-granularity locks means you need more memory for the locks. This is a simple trade-off. Lego currently mimic the Linux x86 default setting 1 , where each PMD and PTE page table pages has their own lock. The lock is a spinlock embedded in the struct page . As illustrated below: Both Processor and Memory managers are using the same mechanism to increase parallelism. And it is something that can improve performance a lot . \u2013 Yizhou Shan Created: Mar 22, 2018 Last Updated: April 13, 2018 Split page table locks \u21a9","title":"Fine-grain Page Table Lock"},{"location":"lego/pcache/replication/","text":"Memory Replication \u00b6 Keep a single copy of each page in DRAM, with redundant copies on secondary storage such as disk or flash. This makes replication nearly free in terms of cost, and energy usage. But we should consider the extra network cost. RAMCloud has two components running on a single machine: master , and backup . In lego, master is the handler running on Memory , backup is the handler running on Storage . Because of dual-Memory solution , we don\u2019t need a hash table from <pid, user_vaddr> to objects in log: M1 has its own <VA-PA> mapping table, and it will not be updated on replication. M2 does not need to look up. RAMCloud use 8MB segment. Logs are first appended within each segment. Each log has different size, depends on the objects being written. Lego is different. Replication is triggered by pcache/victim flush, which means the data is always the size of a pcache line (4KB now). This make things somehow simpler. But other general rules still apply. \u2013 Yizhou Shan Created: Mar 31, 2018 Last Updated: Mar 31, 2018","title":"Replication"},{"location":"lego/pcache/replication/#memory-replication","text":"Keep a single copy of each page in DRAM, with redundant copies on secondary storage such as disk or flash. This makes replication nearly free in terms of cost, and energy usage. But we should consider the extra network cost. RAMCloud has two components running on a single machine: master , and backup . In lego, master is the handler running on Memory , backup is the handler running on Storage . Because of dual-Memory solution , we don\u2019t need a hash table from <pid, user_vaddr> to objects in log: M1 has its own <VA-PA> mapping table, and it will not be updated on replication. M2 does not need to look up. RAMCloud use 8MB segment. Logs are first appended within each segment. Each log has different size, depends on the objects being written. Lego is different. Replication is triggered by pcache/victim flush, which means the data is always the size of a pcache line (4KB now). This make things somehow simpler. But other general rules still apply. \u2013 Yizhou Shan Created: Mar 31, 2018 Last Updated: Mar 31, 2018","title":"Memory Replication"},{"location":"lego/pcache/rmap/","text":"Reverse Mapping of Pcache \u00b6 This document explains Lego\u2019s reverse mapping design for pcache. We also present Lego internal functions that eventually manipulate rmap data structures. For readers who are not familiar with reverse mapping, I recommend you search what is rmap in Linux first. Design \u00b6 The reverse mapping, or rmap, of our pcache is implemented in a very basic and straightforward way: pointing back to all page table entries (ptes) directly. Shared pcache lines will have a list of ptes that point to this pcache line. We also did this way in Hotpot. rmap is used by 1) a bunch of syscalls, such as fork() , execv() , mmap() , munmap() , mremap() , brk() . 2) page reclaim, which needs to unmap all ptes for a given swapped page. Other than fork() and execv() , other vm related syscalls are invoked very frequently for a typical datacenter application. Moreover, page reclaim and swap also run concurrently to gain exclusive access to rmap. So, rmap operations have to be fast. Directly pointing to pte seems the best solution here. However, this fine-granularity design will consume a lot memory for the per-pte list. Furthermore, vma creation, deletion, split and merge happen frequently, the overhead to manage rmap is quite high. No wonder Linux choses another object-based way to do so, which leverages vma itself to take a longer path towards pte. The important question is: does this naive solution fit current Lego? Yes, it fits, for several reasons. 1) Current Lego run static-linked ELF binary only, thus there will not be any shared hot library pages, which implies rmap list maintenance is simplified. 2) Our targeted applications mostly are single process. Even for multiple process ones, the number of processes stay stable and fork() happen at early init time. 3) major users of rmap such as mremap() and munmap() perform rmap operation explicitly, mmap() perform rmap implicitly via pgfault (or pcache miss), pcache reclaim perform sweep async. All of them, combined with 1) and 2), most of the time will perform rmap operation on a single pte. Internal \u00b6 The following table describes different contexts that manipulate rmap data structures. Currently, rmap only has four possible operations. The context field describes the large context that trigger such rmap operation. The related functions and pcache callback field lists functions that actually did the dirty work. rmap operation Context Related functions and pcache callback Add fork() pgfault copy_pte_range() -> pcache_copy_pte() pcache_add_rmap() Remove munmap() exit_mmap() write_protected zap_pte_range() -> pcache_zap_pte() pcache_do_wp -> pcache_remove_rmap Update mremap() move_ptes() -> pcache_move_pte() Lookup pcache eviction sweep, etc. pcache_referenced() , pcache_wrprotect() pcache_try_to_unmap() Each rmap holds one refcount of pcache. The refcount is increased after pcache_add_rmap , and must be decreased after removing pcache rmap, can from pcache_remove_rmap , pcache_zap_pte or pcache_move_pte_slowpath . Thought \u00b6 One function I personally love the most is rmap_walk() , whose name pretty much tells the story. To use rmap_walk() , caller passes a struct rmap_walk_control , which including caller specific callback for each rmap. This function also isolates the specific data structures used by rmap from various callers. In Lego, a lot pcache functions are built upon rmap_walk() . struct rmap_walk_control , or struct scan_control , or struct something_control are used a lot by Linux kernel. Personally I do love this way of doing data structure walk, or reuse functions. However, even this way can greatly reduce duplicated code size, it will make the code unnecessary complex. As a system developer, no more expects to see a function longer than 100 lines. People love saying: Do one thing and do it better , while it not always works that perfectly. Coding is nothing different life, it is all about trade-off. \u2013 Yizhou Shan Created: Feb 02, 2018 Last Updated: Mar 10, 2018","title":"Reverse Mapping"},{"location":"lego/pcache/rmap/#reverse-mapping-of-pcache","text":"This document explains Lego\u2019s reverse mapping design for pcache. We also present Lego internal functions that eventually manipulate rmap data structures. For readers who are not familiar with reverse mapping, I recommend you search what is rmap in Linux first.","title":"Reverse Mapping of Pcache"},{"location":"lego/pcache/rmap/#design","text":"The reverse mapping, or rmap, of our pcache is implemented in a very basic and straightforward way: pointing back to all page table entries (ptes) directly. Shared pcache lines will have a list of ptes that point to this pcache line. We also did this way in Hotpot. rmap is used by 1) a bunch of syscalls, such as fork() , execv() , mmap() , munmap() , mremap() , brk() . 2) page reclaim, which needs to unmap all ptes for a given swapped page. Other than fork() and execv() , other vm related syscalls are invoked very frequently for a typical datacenter application. Moreover, page reclaim and swap also run concurrently to gain exclusive access to rmap. So, rmap operations have to be fast. Directly pointing to pte seems the best solution here. However, this fine-granularity design will consume a lot memory for the per-pte list. Furthermore, vma creation, deletion, split and merge happen frequently, the overhead to manage rmap is quite high. No wonder Linux choses another object-based way to do so, which leverages vma itself to take a longer path towards pte. The important question is: does this naive solution fit current Lego? Yes, it fits, for several reasons. 1) Current Lego run static-linked ELF binary only, thus there will not be any shared hot library pages, which implies rmap list maintenance is simplified. 2) Our targeted applications mostly are single process. Even for multiple process ones, the number of processes stay stable and fork() happen at early init time. 3) major users of rmap such as mremap() and munmap() perform rmap operation explicitly, mmap() perform rmap implicitly via pgfault (or pcache miss), pcache reclaim perform sweep async. All of them, combined with 1) and 2), most of the time will perform rmap operation on a single pte.","title":"Design"},{"location":"lego/pcache/rmap/#internal","text":"The following table describes different contexts that manipulate rmap data structures. Currently, rmap only has four possible operations. The context field describes the large context that trigger such rmap operation. The related functions and pcache callback field lists functions that actually did the dirty work. rmap operation Context Related functions and pcache callback Add fork() pgfault copy_pte_range() -> pcache_copy_pte() pcache_add_rmap() Remove munmap() exit_mmap() write_protected zap_pte_range() -> pcache_zap_pte() pcache_do_wp -> pcache_remove_rmap Update mremap() move_ptes() -> pcache_move_pte() Lookup pcache eviction sweep, etc. pcache_referenced() , pcache_wrprotect() pcache_try_to_unmap() Each rmap holds one refcount of pcache. The refcount is increased after pcache_add_rmap , and must be decreased after removing pcache rmap, can from pcache_remove_rmap , pcache_zap_pte or pcache_move_pte_slowpath .","title":"Internal"},{"location":"lego/pcache/rmap/#thought","text":"One function I personally love the most is rmap_walk() , whose name pretty much tells the story. To use rmap_walk() , caller passes a struct rmap_walk_control , which including caller specific callback for each rmap. This function also isolates the specific data structures used by rmap from various callers. In Lego, a lot pcache functions are built upon rmap_walk() . struct rmap_walk_control , or struct scan_control , or struct something_control are used a lot by Linux kernel. Personally I do love this way of doing data structure walk, or reuse functions. However, even this way can greatly reduce duplicated code size, it will make the code unnecessary complex. As a system developer, no more expects to see a function longer than 100 lines. People love saying: Do one thing and do it better , while it not always works that perfectly. Coding is nothing different life, it is all about trade-off. \u2013 Yizhou Shan Created: Feb 02, 2018 Last Updated: Mar 10, 2018","title":"Thought"},{"location":"lego/pcache/smp_design/","text":"SMP Design Thought \u00b6 Coding pcache is nothing different from coding mm code. It is the same with your familiar mixed pgfault, LRU, page cache and writeback code. Each pcache line can be involved with multiple activities at the same time. We have to use different states to synchronize among them. If you have ever read linux mm code, you will know that sometimes, comment is literally more than code. SMP pain in ass. I don\u2019t think this document is well written. It is just some random thoughts I wrote down while coding. Some of them might be wrong. But it is still worth looking back. Pcache and Victim Cache Organization \u00b6 Our pcache and victim cache are allocated and arranged as a big array. As for pcache we look at it in a cache set view , which means consecutive pcache lines are not relevant in natual. As for victim cache, we simply treat it as a big array and walk through it one by one. Allocation/Eviction SMP Consideration \u00b6 The alloc/free of both pcache and victim cache are simple: each pcache line or victim cache line has a Allocated bit to indicate if this line is free or not. The Allocated bit is manipulated by atomic bit operations, thus SMP safe. This further implies that we do not need another spinlock to guard allocation. However, other activities such as explict eviction, background sweep may walk through the cache lines at the same time of cache allocation, a single Allocated bit is not enough. Because an allocated cache line will need some initial setup, such as reset refcount, clear flags (prep_new_pcache), thus there is a small time gap between Allocated bit being set and the cache line being truly safe to use. Other activities must wait the cache line to be usable, and then they can do further operations on this cache line. To solve this race condition, there two possible solutions: 1) Add another bit: Usable , which is set once initial setup is done. In this case, functions excluding alloction code should always check if the Usable bit is set or not. a) If it is set, this means the cache line is safe for further operations b) If not, and Allocated bit is set, this means the cache line is under setup in another core, We should skip it. c) If not, and Allocated bit is not set, this means this cache line is simply free. We should skip it. 2) Add allocated cache lines to a list (such as LRU list), and functions excluding allocation code will only look into cache lines within this list. In other words, others will only look into surely usable cache lines. Both solutions try to avoid others looking into un-mature cache lines in SMP envorinment. The rule is simple: function should NOT look into data that is not supposed to be seen. The cache line that has Allocated bit set but under setup is a typical case. As an example, the physical page allocator, page reclaim, page cache in Linux are implemented with the second solution. Pages freshly allocated will be added a LRU list or page cache own list. And page reclaim code will only look into pages within the LRU list, it will not go through all physical pages to do so. The reason for Linux to do so is simple: kernel can not scan the whole physical pages to find out pages to operate. Pcache: When it comes to pcache, we use both. In our envision, pcache will have high-associativity such as 64 or 128. It will have very bad performance if our eviction algorithm or sweep thread need to go through every cache lines within a set to find out candidates, while there might be only 1 or 2 allocated lines. However, additional Usable bit is added for debug purpose. Victim Cache: When it comes to victim cache, the first solution seems a better choice. Because victim cache only a few cache lines, e.g., 8 or 16. This means a whole victim cache line walk is fast. While the list deletion and addition seem may introduce some unnecessary overhead. It is all about trade-off. These choices affect the usage of pcache and victim cache, mostly the eviction code. More on above two solutions \u00b6 The first solution is used if evict_random is configured. The second solution is used when evict_lru is configured. I do not have any doubt about second solution, it works, though with a lot SMP pain in ass. But I do have more to say about the first solution, which is adding another usable bit. The Usable bit only ensures other threads will not use unmature pcache, but it can not prevent other threads seeing a going-to-be-freed pcache. What is this going-to-be-freed asshole? Let us consider this case: CPU0 is doing eviction and checked the Usable bit, which is set. Then CPU0 thought this cache line is all set, ready to be torqued. Before doing all the dirty work, CPU0 will get_pcache_unless_zero() first to make sure the pcache will not go away in the middle. However, meanwhile, CPU1 did a put_pcache() and a consecutive pcache_alloc() right before CPU0 did called get_pcache_unless_zero() . Bang! CPU0 may use an mature pcache line, cause CPU1\u2019s pcache_init_ref_count() may come before CPU1\u2019s get_pcache_unless_zero() ! How to solve this? CPU0 need to add additional checking after get_pcache_unless_zero() . For more details, please check the code in pcache/evcit_random.c , which has more pretty explanation. \u2013 Yizhou Shan Jan 31, 2018","title":"SMP Design"},{"location":"lego/pcache/smp_design/#smp-design-thought","text":"Coding pcache is nothing different from coding mm code. It is the same with your familiar mixed pgfault, LRU, page cache and writeback code. Each pcache line can be involved with multiple activities at the same time. We have to use different states to synchronize among them. If you have ever read linux mm code, you will know that sometimes, comment is literally more than code. SMP pain in ass. I don\u2019t think this document is well written. It is just some random thoughts I wrote down while coding. Some of them might be wrong. But it is still worth looking back.","title":"SMP Design Thought"},{"location":"lego/pcache/smp_design/#pcache-and-victim-cache-organization","text":"Our pcache and victim cache are allocated and arranged as a big array. As for pcache we look at it in a cache set view , which means consecutive pcache lines are not relevant in natual. As for victim cache, we simply treat it as a big array and walk through it one by one.","title":"Pcache and Victim Cache Organization"},{"location":"lego/pcache/smp_design/#allocationeviction-smp-consideration","text":"The alloc/free of both pcache and victim cache are simple: each pcache line or victim cache line has a Allocated bit to indicate if this line is free or not. The Allocated bit is manipulated by atomic bit operations, thus SMP safe. This further implies that we do not need another spinlock to guard allocation. However, other activities such as explict eviction, background sweep may walk through the cache lines at the same time of cache allocation, a single Allocated bit is not enough. Because an allocated cache line will need some initial setup, such as reset refcount, clear flags (prep_new_pcache), thus there is a small time gap between Allocated bit being set and the cache line being truly safe to use. Other activities must wait the cache line to be usable, and then they can do further operations on this cache line. To solve this race condition, there two possible solutions: 1) Add another bit: Usable , which is set once initial setup is done. In this case, functions excluding alloction code should always check if the Usable bit is set or not. a) If it is set, this means the cache line is safe for further operations b) If not, and Allocated bit is set, this means the cache line is under setup in another core, We should skip it. c) If not, and Allocated bit is not set, this means this cache line is simply free. We should skip it. 2) Add allocated cache lines to a list (such as LRU list), and functions excluding allocation code will only look into cache lines within this list. In other words, others will only look into surely usable cache lines. Both solutions try to avoid others looking into un-mature cache lines in SMP envorinment. The rule is simple: function should NOT look into data that is not supposed to be seen. The cache line that has Allocated bit set but under setup is a typical case. As an example, the physical page allocator, page reclaim, page cache in Linux are implemented with the second solution. Pages freshly allocated will be added a LRU list or page cache own list. And page reclaim code will only look into pages within the LRU list, it will not go through all physical pages to do so. The reason for Linux to do so is simple: kernel can not scan the whole physical pages to find out pages to operate. Pcache: When it comes to pcache, we use both. In our envision, pcache will have high-associativity such as 64 or 128. It will have very bad performance if our eviction algorithm or sweep thread need to go through every cache lines within a set to find out candidates, while there might be only 1 or 2 allocated lines. However, additional Usable bit is added for debug purpose. Victim Cache: When it comes to victim cache, the first solution seems a better choice. Because victim cache only a few cache lines, e.g., 8 or 16. This means a whole victim cache line walk is fast. While the list deletion and addition seem may introduce some unnecessary overhead. It is all about trade-off. These choices affect the usage of pcache and victim cache, mostly the eviction code.","title":"Allocation/Eviction SMP Consideration"},{"location":"lego/pcache/smp_design/#more-on-above-two-solutions","text":"The first solution is used if evict_random is configured. The second solution is used when evict_lru is configured. I do not have any doubt about second solution, it works, though with a lot SMP pain in ass. But I do have more to say about the first solution, which is adding another usable bit. The Usable bit only ensures other threads will not use unmature pcache, but it can not prevent other threads seeing a going-to-be-freed pcache. What is this going-to-be-freed asshole? Let us consider this case: CPU0 is doing eviction and checked the Usable bit, which is set. Then CPU0 thought this cache line is all set, ready to be torqued. Before doing all the dirty work, CPU0 will get_pcache_unless_zero() first to make sure the pcache will not go away in the middle. However, meanwhile, CPU1 did a put_pcache() and a consecutive pcache_alloc() right before CPU0 did called get_pcache_unless_zero() . Bang! CPU0 may use an mature pcache line, cause CPU1\u2019s pcache_init_ref_count() may come before CPU1\u2019s get_pcache_unless_zero() ! How to solve this? CPU0 need to add additional checking after get_pcache_unless_zero() . For more details, please check the code in pcache/evcit_random.c , which has more pretty explanation. \u2013 Yizhou Shan Jan 31, 2018","title":"More on above two solutions"},{"location":"lego/pcache/sweep/","text":"Pcache Sweep \u00b6 Some notes while coding pcache sweep thread. The sweep thread wants to detect the hotness of pages, and then adjust LRU list accordingly. Data Worth a Billion \u00b6 Pcache-reclaim, or any other object reclaim, need some data to algorithm about. So specific algorithm can select the best candidate to reclaim. In reality, algorithms are designed quite well, but how to get the data part becomes extremely hard. I think this applies to many different systems. For example, to select the hot pages in x86 is notorious hard because x86 hardware only provides a Referenced bit for system software to reason about. To make it worse, Referenced bit is cached in TLB, which means CPU will NOT set the Referenced bit even you reset in PTE, because CPU think the bit is already set. In order to get an accurate hot pages tracking, you probably need a TLB flush after reset Referenced bit. But, are you kidding me, a TLB flush after each reset? We have to say NO here. The Linux code explains it well: static inline int ptep_clear_flush_young ( pte_t * ptep ) { /* * On x86 CPUs, clearing the accessed bit without a TLB flush * doesn't cause data corruption. [ It could cause incorrect * page aging and the (mistaken) reclaim of hot pages, but the * chance of that should be relatively low. ] * * So as a performance optimization don't flush the TLB when * clearing the accessed bit, it will eventually be flushed by * a context switch or a VM operation anyway. [ In the rare * event of it not getting flushed for a long time the delay * shouldn't really matter because there's no real memory * pressure for swapout to react to. ] */ return ptep_test_and_clear_young ( ptep ); } Aggressiveness \u00b6 An aggressive sweep algorithm will disturb the normal operations a lot. In Lego, there 4 main factors that define the aggressiveness: Time interval between each run Number of sets to look at during each run Skip if it is not full Skip if it is under eviction Number of lines to look at for each set Smaller or equal to associativity Number of lines to adjust for each set Smaller or equal to lines to look at \u2013 Yizhou Shan Created: Mar 18, 2018 Last Updated: Mar 18, 2018","title":"Sweep"},{"location":"lego/pcache/sweep/#pcache-sweep","text":"Some notes while coding pcache sweep thread. The sweep thread wants to detect the hotness of pages, and then adjust LRU list accordingly.","title":"Pcache Sweep"},{"location":"lego/pcache/sweep/#data-worth-a-billion","text":"Pcache-reclaim, or any other object reclaim, need some data to algorithm about. So specific algorithm can select the best candidate to reclaim. In reality, algorithms are designed quite well, but how to get the data part becomes extremely hard. I think this applies to many different systems. For example, to select the hot pages in x86 is notorious hard because x86 hardware only provides a Referenced bit for system software to reason about. To make it worse, Referenced bit is cached in TLB, which means CPU will NOT set the Referenced bit even you reset in PTE, because CPU think the bit is already set. In order to get an accurate hot pages tracking, you probably need a TLB flush after reset Referenced bit. But, are you kidding me, a TLB flush after each reset? We have to say NO here. The Linux code explains it well: static inline int ptep_clear_flush_young ( pte_t * ptep ) { /* * On x86 CPUs, clearing the accessed bit without a TLB flush * doesn't cause data corruption. [ It could cause incorrect * page aging and the (mistaken) reclaim of hot pages, but the * chance of that should be relatively low. ] * * So as a performance optimization don't flush the TLB when * clearing the accessed bit, it will eventually be flushed by * a context switch or a VM operation anyway. [ In the rare * event of it not getting flushed for a long time the delay * shouldn't really matter because there's no real memory * pressure for swapout to react to. ] */ return ptep_test_and_clear_young ( ptep ); }","title":"Data Worth a Billion"},{"location":"lego/pcache/sweep/#aggressiveness","text":"An aggressive sweep algorithm will disturb the normal operations a lot. In Lego, there 4 main factors that define the aggressiveness: Time interval between each run Number of sets to look at during each run Skip if it is not full Skip if it is under eviction Number of lines to look at for each set Smaller or equal to associativity Number of lines to adjust for each set Smaller or equal to lines to look at \u2013 Yizhou Shan Created: Mar 18, 2018 Last Updated: Mar 18, 2018","title":"Aggressiveness"},{"location":"lego/pcache/tlb/","text":"TLB Coherence \u00b6 x86 does not keep TLB coherent across cores, nor with in-memory page table. And that is why we need explicit TLB flush when some PTE modifications happen (e.g. downgrade RW to RO, clear PTE, etc.). Besides, TLB flush is very important and affect application correctness. I\u2019ve had some really awful debugging experience which was eventually introduced by missed TLB flush. Below is a list of operations that should have TLB flush followed: munmap (optional, can be optimized by holding the old VA range) mremap (required) fork (RW->RO) (required) CoW (RO->RW) (required) mprotect (required) migration (required) Unfortunately, TLB flush is costly, especially if we need to shootdown TLB entries on remote core. TLB shootdown 1 2 3 is performed by sending IPI to remote core, and remote core will flush local TLB entries within its handler. Linux optimize this by batching TLB flush until context switch happens. Lego currently does not have this nice feature, we flush TLB one by one for each PTE change (listed as TODO ). \u2013 Yizhou Shan Created: Mar 19, 2018 Last Updated: Mar 19, 2018 Optimizing the TLB Shootdown Algorithm with Page Access Tracking, ATC\u201818 \u21a9 LATR: Lazy Translation Coherence, ASPLOS\u201818 \u21a9 Hardware Translation Coherence for Virtualized Systems, ISCA\u201817 \u21a9","title":"TLB Coherence"},{"location":"lego/pcache/tlb/#tlb-coherence","text":"x86 does not keep TLB coherent across cores, nor with in-memory page table. And that is why we need explicit TLB flush when some PTE modifications happen (e.g. downgrade RW to RO, clear PTE, etc.). Besides, TLB flush is very important and affect application correctness. I\u2019ve had some really awful debugging experience which was eventually introduced by missed TLB flush. Below is a list of operations that should have TLB flush followed: munmap (optional, can be optimized by holding the old VA range) mremap (required) fork (RW->RO) (required) CoW (RO->RW) (required) mprotect (required) migration (required) Unfortunately, TLB flush is costly, especially if we need to shootdown TLB entries on remote core. TLB shootdown 1 2 3 is performed by sending IPI to remote core, and remote core will flush local TLB entries within its handler. Linux optimize this by batching TLB flush until context switch happens. Lego currently does not have this nice feature, we flush TLB one by one for each PTE change (listed as TODO ). \u2013 Yizhou Shan Created: Mar 19, 2018 Last Updated: Mar 19, 2018 Optimizing the TLB Shootdown Algorithm with Page Access Tracking, ATC\u201818 \u21a9 LATR: Lazy Translation Coherence, ASPLOS\u201818 \u21a9 Hardware Translation Coherence for Virtualized Systems, ISCA\u201817 \u21a9","title":"TLB Coherence"},{"location":"lego/pcache/victim/","text":"Victim Cache \u00b6 \u2013 Yizhou Shan Created: Mar 12, 2018 Last Updated: Mar 12, 2018","title":"Victim Cache"},{"location":"lego/pcache/victim/#victim-cache","text":"\u2013 Yizhou Shan Created: Mar 12, 2018 Last Updated: Mar 12, 2018","title":"Victim Cache"},{"location":"lego/pcache/virtual_cache/","text":"Virtual Cache \u00b6 Synonymous impact Cache coherence impact TLB shootdown The good thing is, synonymous actually happen very rare in really workload. But when OS is invoked, it actually creates a lot synonymous. Because the physical page is mapped both low user virtual address and high kernel virtual address. What is this? What is bad about this? When does this happen? (All cases: kernel, shared vma mapping) How to solve this? Software solution: OS level detection, global virtual address, identical virtual address etc. Hardware solution: detect and manage at runtime. Back pointer, Dynamic synonymous remapping, reverse mapping. Similar ideas. A nice summary can be found on A new perspective for efficient virtual-cache coherence, ISCA'13 . Let me share my reading list. I think I\u2019ve collected most of the important virtual cache papers: TLB and cache line lifetime: Enigma, ISC'10 : For each case where valid data exists in the cache hierarchy without a corresponding valid translation entry, systems with physically-tagged caches have to resolve the translation miss. Only after the page table has been \u201cwalked\u201d and a valid translation entry installed can the already cache-resident data be provided to the processing core. Especially in the faster levels of cache, the additional page table walk can add significant latency to what otherwise would have been a low-latency cache hit. GPU virtual cache, ASPLOS'18 : We notice that the per-CU TLB miss ratio is high; however, many TLB misses hit in the GPU caches. Only 34% of references that miss in the 32-entry per-CU L1 TLB are also L2 cache misses and access main memory (blue bars). An average of 31% of total per-CU TLB misses find the corresponding data in private L1 caches (black bars), and an additional 35% of the total misses hit in a shared L2 virtual cache (red bars). These hits occur because blocks in the cache hierarchy are likely to reside longer than the lifetime of the corresponding per-CU TLB entries Reading the GPU virtual cache ASPLOS'18 paper today. I mostly interested in how they handle synonymous and mremap issue. Synonymous: Their solution for synonymous is quite simple (not sure if practical or effective): use a leading virtual address, which is the first VA that has the virtual cache miss. Subsequent misses that from different VA will not have the their cache lines filled, instead, they will make subsequent VA forever miss, and fetch the content from the leading VA cache line (they call it replay). In all, synonymous is solved by only having one cache line, and does not fill other VA cache lines. mremap: They did not mention mremap. But I guess they do not need to care this. When remap happens, the original PTE is invalidated first, and TLB shootdown follows, all they need to do is to invalidate the virtual cache line (need to be flushed back to memory if dirty). When the new VA mapping established and accessed, it will be a normal virtual cache miss OVC also does not need to care about this because they are doing a similar way (I guess). Lego need to handle mremap differently. Because we don\u2019t want to flush the dirty line back to memory, to save 1) one clflush, 2) another pcache miss. This means Lego wants to keep the content in Pcache. So the set_index of new VA and old VA matters in our case. \u2013 Yizhou Shan Created: Mar 28, 2018 Last Updated: Mar 29, 2018","title":"Virtual Cache"},{"location":"lego/pcache/virtual_cache/#virtual-cache","text":"Synonymous impact Cache coherence impact TLB shootdown The good thing is, synonymous actually happen very rare in really workload. But when OS is invoked, it actually creates a lot synonymous. Because the physical page is mapped both low user virtual address and high kernel virtual address. What is this? What is bad about this? When does this happen? (All cases: kernel, shared vma mapping) How to solve this? Software solution: OS level detection, global virtual address, identical virtual address etc. Hardware solution: detect and manage at runtime. Back pointer, Dynamic synonymous remapping, reverse mapping. Similar ideas. A nice summary can be found on A new perspective for efficient virtual-cache coherence, ISCA'13 . Let me share my reading list. I think I\u2019ve collected most of the important virtual cache papers: TLB and cache line lifetime: Enigma, ISC'10 : For each case where valid data exists in the cache hierarchy without a corresponding valid translation entry, systems with physically-tagged caches have to resolve the translation miss. Only after the page table has been \u201cwalked\u201d and a valid translation entry installed can the already cache-resident data be provided to the processing core. Especially in the faster levels of cache, the additional page table walk can add significant latency to what otherwise would have been a low-latency cache hit. GPU virtual cache, ASPLOS'18 : We notice that the per-CU TLB miss ratio is high; however, many TLB misses hit in the GPU caches. Only 34% of references that miss in the 32-entry per-CU L1 TLB are also L2 cache misses and access main memory (blue bars). An average of 31% of total per-CU TLB misses find the corresponding data in private L1 caches (black bars), and an additional 35% of the total misses hit in a shared L2 virtual cache (red bars). These hits occur because blocks in the cache hierarchy are likely to reside longer than the lifetime of the corresponding per-CU TLB entries Reading the GPU virtual cache ASPLOS'18 paper today. I mostly interested in how they handle synonymous and mremap issue. Synonymous: Their solution for synonymous is quite simple (not sure if practical or effective): use a leading virtual address, which is the first VA that has the virtual cache miss. Subsequent misses that from different VA will not have the their cache lines filled, instead, they will make subsequent VA forever miss, and fetch the content from the leading VA cache line (they call it replay). In all, synonymous is solved by only having one cache line, and does not fill other VA cache lines. mremap: They did not mention mremap. But I guess they do not need to care this. When remap happens, the original PTE is invalidated first, and TLB shootdown follows, all they need to do is to invalidate the virtual cache line (need to be flushed back to memory if dirty). When the new VA mapping established and accessed, it will be a normal virtual cache miss OVC also does not need to care about this because they are doing a similar way (I guess). Lego need to handle mremap differently. Because we don\u2019t want to flush the dirty line back to memory, to save 1) one clflush, 2) another pcache miss. This means Lego wants to keep the content in Pcache. So the set_index of new VA and old VA matters in our case. \u2013 Yizhou Shan Created: Mar 28, 2018 Last Updated: Mar 29, 2018","title":"Virtual Cache"},{"location":"lego/syscall/compat/","text":"Compat SYSCALL in Lego \u00b6 Lego does not support compatible syscalls, where one is able to run 32-bit image on 64-bit OS. However, the ugly FPU code and signal part in Linux is heavily hacked with the assumption that compat syscall is supported. We are no expert in this FPU thing, just to make sure we don\u2019t break this FPU evil, Lego adds the fake compat syscall support. Fake means whenever a 32-bit syscall is issued, Lego will just panic. Kconfig \u00b6 If one compiles a x86_64 Linux kernel, compat syscalls are supported by default. Everything related to compat syscalls are controlled by the following two Kconfig options. Lego may want to support compat syscalls in the future, thus we add these two Kconfigs to avoid future mess: CONFIG_COMPAT CONFIG_IA32_EMULATION Internal \u00b6 Entry Points \u00b6 The assembly entry points are defined in entry/entry_64_compat.S : ENTRY ( entry_SYSENTER_compat ) ... call do_fast_syscall_32 GLOBAL ( __end_entry_SYSENTER_compat ) ENDPROC ( entry_SYSENTER_compat ) ENTRY ( entry_SYSCALL_compat ) ... call do_fast_syscall_32 END ( entry_SYSCALL_compat ) ENTRY ( entry_INT80_compat ) ... call do_int80_syscall_32 END ( entry_INT80_compat ) Entry Points Setup \u00b6 The assembly entry points are filled to system registers and IDT table. So users can actually issue those calls, Lego is able to catch them: static void syscall_init ( void ) { wrmsr ( MSR_STAR , 0 , ( __USER32_CS << 16 ) | __KERNEL_CS ); wrmsrl ( MSR_LSTAR , ( unsigned long ) entry_SYSCALL_64 ); #ifdef CONFIG_IA32_EMULATION wrmsrl ( MSR_CSTAR , ( unsigned long ) entry_SYSCALL_compat ); /* * This only works on Intel CPUs. * On AMD CPUs these MSRs are 32-bit, CPU truncates MSR_IA32_SYSENTER_EIP. * This does not cause SYSENTER to jump to the wrong location, because * AMD doesn't allow SYSENTER in long mode (either 32- or 64-bit). */ wrmsrl_safe ( MSR_IA32_SYSENTER_CS , ( u64 ) __KERNEL_CS ); wrmsrl_safe ( MSR_IA32_SYSENTER_ESP , 0ULL ); wrmsrl_safe ( MSR_IA32_SYSENTER_EIP , ( u64 ) entry_SYSENTER_compat ); #else wrmsrl ( MSR_CSTAR , ( unsigned long ) ignore_sysret ); wrmsrl_safe ( MSR_IA32_SYSENTER_CS , ( u64 ) GDT_ENTRY_INVALID_SEG ); wrmsrl_safe ( MSR_IA32_SYSENTER_ESP , 0ULL ); wrmsrl_safe ( MSR_IA32_SYSENTER_EIP , 0ULL ); #endif /* Flags to clear on syscall */ wrmsrl ( MSR_SYSCALL_MASK , X86_EFLAGS_TF | X86_EFLAGS_DF | X86_EFLAGS_IF | X86_EFLAGS_IOPL | X86_EFLAGS_AC | X86_EFLAGS_NT ); } arch / x86 / kernel / cpu / common . c void __init trap_init ( void ) { ... #ifdef CONFIG_IA32_EMULATION set_system_intr_gate ( IA32_SYSCALL_VECTOR , entry_INT80_compat ); set_bit ( IA32_SYSCALL_VECTOR , used_vectors ); #endif ... } arch / x86 / kernel / traps . c C code \u00b6 The actual C code is in entry/common.c : #if defined(CONFIG_X86_32) || defined(CONFIG_IA32_EMULATION) static __always_inline void do_syscall_32_irqs_on ( struct pt_regs * regs ) { #ifdef CONFIG_IA32_EMULATION current -> thread . status |= TS_COMPAT ; #endif BUG (); } /* Handles int $0x80 */ __visible void do_int80_syscall_32 ( struct pt_regs * regs ) { BUG (); } /* Returns 0 to return using IRET or 1 to return using SYSEXIT/SYSRETL. */ __visible long do_fast_syscall_32 ( struct pt_regs * regs ) { BUG (); } #endif \u2013 Yizhou Shan Created: Feb 22, 2018 Last Updated: Feb 22, 2018","title":"compat"},{"location":"lego/syscall/compat/#compat-syscall-in-lego","text":"Lego does not support compatible syscalls, where one is able to run 32-bit image on 64-bit OS. However, the ugly FPU code and signal part in Linux is heavily hacked with the assumption that compat syscall is supported. We are no expert in this FPU thing, just to make sure we don\u2019t break this FPU evil, Lego adds the fake compat syscall support. Fake means whenever a 32-bit syscall is issued, Lego will just panic.","title":"Compat SYSCALL in Lego"},{"location":"lego/syscall/compat/#kconfig","text":"If one compiles a x86_64 Linux kernel, compat syscalls are supported by default. Everything related to compat syscalls are controlled by the following two Kconfig options. Lego may want to support compat syscalls in the future, thus we add these two Kconfigs to avoid future mess: CONFIG_COMPAT CONFIG_IA32_EMULATION","title":"Kconfig"},{"location":"lego/syscall/compat/#internal","text":"","title":"Internal"},{"location":"lego/syscall/compat/#entry-points","text":"The assembly entry points are defined in entry/entry_64_compat.S : ENTRY ( entry_SYSENTER_compat ) ... call do_fast_syscall_32 GLOBAL ( __end_entry_SYSENTER_compat ) ENDPROC ( entry_SYSENTER_compat ) ENTRY ( entry_SYSCALL_compat ) ... call do_fast_syscall_32 END ( entry_SYSCALL_compat ) ENTRY ( entry_INT80_compat ) ... call do_int80_syscall_32 END ( entry_INT80_compat )","title":"Entry Points"},{"location":"lego/syscall/compat/#entry-points-setup","text":"The assembly entry points are filled to system registers and IDT table. So users can actually issue those calls, Lego is able to catch them: static void syscall_init ( void ) { wrmsr ( MSR_STAR , 0 , ( __USER32_CS << 16 ) | __KERNEL_CS ); wrmsrl ( MSR_LSTAR , ( unsigned long ) entry_SYSCALL_64 ); #ifdef CONFIG_IA32_EMULATION wrmsrl ( MSR_CSTAR , ( unsigned long ) entry_SYSCALL_compat ); /* * This only works on Intel CPUs. * On AMD CPUs these MSRs are 32-bit, CPU truncates MSR_IA32_SYSENTER_EIP. * This does not cause SYSENTER to jump to the wrong location, because * AMD doesn't allow SYSENTER in long mode (either 32- or 64-bit). */ wrmsrl_safe ( MSR_IA32_SYSENTER_CS , ( u64 ) __KERNEL_CS ); wrmsrl_safe ( MSR_IA32_SYSENTER_ESP , 0ULL ); wrmsrl_safe ( MSR_IA32_SYSENTER_EIP , ( u64 ) entry_SYSENTER_compat ); #else wrmsrl ( MSR_CSTAR , ( unsigned long ) ignore_sysret ); wrmsrl_safe ( MSR_IA32_SYSENTER_CS , ( u64 ) GDT_ENTRY_INVALID_SEG ); wrmsrl_safe ( MSR_IA32_SYSENTER_ESP , 0ULL ); wrmsrl_safe ( MSR_IA32_SYSENTER_EIP , 0ULL ); #endif /* Flags to clear on syscall */ wrmsrl ( MSR_SYSCALL_MASK , X86_EFLAGS_TF | X86_EFLAGS_DF | X86_EFLAGS_IF | X86_EFLAGS_IOPL | X86_EFLAGS_AC | X86_EFLAGS_NT ); } arch / x86 / kernel / cpu / common . c void __init trap_init ( void ) { ... #ifdef CONFIG_IA32_EMULATION set_system_intr_gate ( IA32_SYSCALL_VECTOR , entry_INT80_compat ); set_bit ( IA32_SYSCALL_VECTOR , used_vectors ); #endif ... } arch / x86 / kernel / traps . c","title":"Entry Points Setup"},{"location":"lego/syscall/compat/#c-code","text":"The actual C code is in entry/common.c : #if defined(CONFIG_X86_32) || defined(CONFIG_IA32_EMULATION) static __always_inline void do_syscall_32_irqs_on ( struct pt_regs * regs ) { #ifdef CONFIG_IA32_EMULATION current -> thread . status |= TS_COMPAT ; #endif BUG (); } /* Handles int $0x80 */ __visible void do_int80_syscall_32 ( struct pt_regs * regs ) { BUG (); } /* Returns 0 to return using IRET or 1 to return using SYSEXIT/SYSRETL. */ __visible long do_fast_syscall_32 ( struct pt_regs * regs ) { BUG (); } #endif \u2013 Yizhou Shan Created: Feb 22, 2018 Last Updated: Feb 22, 2018","title":"C code"},{"location":"lego/syscall/facts/","text":"Lego SYSCALL Facts \u00b6 This document is about the general concepts of Lego syscall implementation. If you are developing syscall, please read this document first. Interrupts Enabled \u00b6 Each syscall is invoked with interrupts enabled. Also, it must return with interrupts enabled as well. Any buggy syscall implementation will be catched by syscall_return_slowpath() : void syscall_return_slowpath ( struct pt_regs * regs ) { if ( WARN ( irqs_disabled (), \"syscall %ld left IRQs disabled\" , regs -> orig_ax )) local_irq_enable (); local_irq_disable (); prepare_exit_to_usermode ( regs ); } void do_syscall_64 ( struct pt_regs * regs ) { .. local_irq_enable (); if ( likely ( nr < NR_syscalls )) { regs -> ax = sys_call_table [ nr ]( regs -> di , regs -> si , regs -> dx , regs -> r10 , regs -> r8 , regs -> r9 ); } syscall_return_slowpath ( regs ); .. } Get User Entry pt_regs \u00b6 The macro task_pt_regs() always return the pt_regs , that saves the user context when it issued the syscall, no matter how many levels interrupts are nested when you call task_pt_regs() . This is based on the fact that kernel stack is empty at syscall entry, thus this user pt_regs was saved at the top of kernel stack: #define task_pt_regs(tsk) ((struct pt_regs *)(tsk)->thread.sp0 - 1) ENTRY ( entry_SYSCALL_64 ) SWAPGS /* * SYSCALL does not change rsp for us! * Save the previous rsp and load the top of kernel stack. * It must be the top of kernel stack, since we came here * from *userspace*. */ movq %rsp , PER_CPU_VAR ( rsp_scratch ) movq PER_CPU_VAR ( cpu_current_top_of_stack ), %rsp /* * Construct struct pt_regs on stack * * In any syscall handler, you can use * current_pt_regs() * to get these registers. */ pushq $__USER_DS /* pt_regs->ss */ pushq PER_CPU_VAR ( rsp_scratch ) /* pt_regs->sp */ pushq %r11 /* pt_regs->flags */ pushq $__USER_CS /* pt_regs->cs */ pushq %rcx /* pt_regs->ip */ pushq %rax /* pt_regs->orig_ax */ pushq %rdi /* pt_regs->di */ pushq %rsi /* pt_regs->si */ pushq %rdx /* pt_regs->dx */ pushq %rcx /* pt_regs->cx */ pushq $-ENOSYS /* pt_regs->ax */ pushq %r8 /* pt_regs->r8 */ pushq %r9 /* pt_regs->r9 */ pushq %r10 /* pt_regs->r10 */ pushq %r11 /* pt_regs->r11 */ sub $ ( 6 * 8 ), %rsp /* pt_regs->bp, bx, r12-15 */ .... \u2013 Yizhou Shan Created: Feb 22, 2018 Last Updated: Feb 22, 2018","title":"Facts"},{"location":"lego/syscall/facts/#lego-syscall-facts","text":"This document is about the general concepts of Lego syscall implementation. If you are developing syscall, please read this document first.","title":"Lego SYSCALL Facts"},{"location":"lego/syscall/facts/#interrupts-enabled","text":"Each syscall is invoked with interrupts enabled. Also, it must return with interrupts enabled as well. Any buggy syscall implementation will be catched by syscall_return_slowpath() : void syscall_return_slowpath ( struct pt_regs * regs ) { if ( WARN ( irqs_disabled (), \"syscall %ld left IRQs disabled\" , regs -> orig_ax )) local_irq_enable (); local_irq_disable (); prepare_exit_to_usermode ( regs ); } void do_syscall_64 ( struct pt_regs * regs ) { .. local_irq_enable (); if ( likely ( nr < NR_syscalls )) { regs -> ax = sys_call_table [ nr ]( regs -> di , regs -> si , regs -> dx , regs -> r10 , regs -> r8 , regs -> r9 ); } syscall_return_slowpath ( regs ); .. }","title":"Interrupts Enabled"},{"location":"lego/syscall/facts/#get-user-entry-pt_regs","text":"The macro task_pt_regs() always return the pt_regs , that saves the user context when it issued the syscall, no matter how many levels interrupts are nested when you call task_pt_regs() . This is based on the fact that kernel stack is empty at syscall entry, thus this user pt_regs was saved at the top of kernel stack: #define task_pt_regs(tsk) ((struct pt_regs *)(tsk)->thread.sp0 - 1) ENTRY ( entry_SYSCALL_64 ) SWAPGS /* * SYSCALL does not change rsp for us! * Save the previous rsp and load the top of kernel stack. * It must be the top of kernel stack, since we came here * from *userspace*. */ movq %rsp , PER_CPU_VAR ( rsp_scratch ) movq PER_CPU_VAR ( cpu_current_top_of_stack ), %rsp /* * Construct struct pt_regs on stack * * In any syscall handler, you can use * current_pt_regs() * to get these registers. */ pushq $__USER_DS /* pt_regs->ss */ pushq PER_CPU_VAR ( rsp_scratch ) /* pt_regs->sp */ pushq %r11 /* pt_regs->flags */ pushq $__USER_CS /* pt_regs->cs */ pushq %rcx /* pt_regs->ip */ pushq %rax /* pt_regs->orig_ax */ pushq %rdi /* pt_regs->di */ pushq %rsi /* pt_regs->si */ pushq %rdx /* pt_regs->dx */ pushq %rcx /* pt_regs->cx */ pushq $-ENOSYS /* pt_regs->ax */ pushq %r8 /* pt_regs->r8 */ pushq %r9 /* pt_regs->r9 */ pushq %r10 /* pt_regs->r10 */ pushq %r11 /* pt_regs->r11 */ sub $ ( 6 * 8 ), %rsp /* pt_regs->bp, bx, r12-15 */ .... \u2013 Yizhou Shan Created: Feb 22, 2018 Last Updated: Feb 22, 2018","title":"Get User Entry pt_regs"},{"location":"lego/syscall/fork/","text":"fork() \u00b6 Memory Manager \u00b6 We need to duplicate the address space in the memory manager side. Follow the traditional fork() semantic, both the existing and newly created address space will be write-protected. Since we have the flexibility to implement any VM organization, we should be careful while duplicating the address space. Currently, we are using page-based VM, thus the duplicating is basically creating a new pgd and copy existing pgtables, and further downgrade permission to read-only. This is now performed by lego_copy_page_range() . The final write-protect is performed by lego_copy_one_pte() : static inline int lego_copy_one_pte (..) { .. /* * If it's a COW mapping, write protect it both * in the parent and the child */ if ( is_cow_mapping ( vm_flags )) { ptep_set_wrprotect ( src_pte ); pte = pte_wrprotect ( pte ); } ... } Duplicate VM Free Pool \u00b6 TODO Yutong Processor Manager \u00b6 Boring implementation details in the processor manager side. Entry Points \u00b6 fork() vfork() clone() kernel_thread() All of them land on do_fork() , which is Lego\u2019s main fork function. do_fork() \u00b6 There are mainly three parts within do_fork() : 1) copy_process() , which duplicates a new task based on current , including allocate new kernel stack, new task_struct, increase mm reference counter, etc. 2) If we are creating a new process, then tell global monitor or memory manager to let them update bookkeeping and create corresponding data structures. 3) wake_up_new_task() , which gives away the newly created task to local scheduler. copy_process() \u00b6 The routine is kind of boring. It do a lot dirty work to copy information from calling thread to new thread. The most important data structures of course are task_struct , mm_sturct , sighand , and so on. This section only talks about few of them, and leave others to readers who are interested. Sanity Checking \u00b6 Mainly check if clone_flags are passed properly. For example, if user is creating a new thread, that implies certain data structures are shared, cause new thread belongs to the same process with the calling thread. If CLONE_THREAD is passed, then CLONE_SIGHAND , CLONE_VM , and so on must be set as well. /* * Thread groups must share signals as well, and detached threads * can only be started up within the thread group. */ if (( clone_flags & CLONE_THREAD ) && ! ( clone_flags & CLONE_SIGHAND )) return ERR_PTR ( - EINVAL ); /* * Shared signal handlers imply shared VM. By way of the above, * thread groups also imply shared VM. Blocking this case allows * for various simplifications in other code. */ if (( clone_flags & CLONE_SIGHAND ) && ! ( clone_flags & CLONE_VM )) return ERR_PTR ( - EINVAL ); dup_task_struct() \u00b6 Two main things: 1) duplicate a new task_struct , 2) duplicate a new kernel stack. x86 is just a weird architecture, the size of task_struct depends on the size of fpu. So the allocation and duplication need to callback to x86-specific code to duplicate the task_struct and fpu info. int arch_dup_task_struct ( struct task_struct * dst , struct task_struct * src ) { memcpy ( dst , src , arch_task_struct_size ); return fpu__copy ( & dst -> thread . fpu , & src -> thread . fpu ); } The stack duplication is fairly simple, just copy everything from the old stack to new stack. Of course, it needs to setup the thread_info to points to this new thread, so the current macro will work. static void setup_thread_stack ( struct task_struct * p , struct task_struct * org ) { /* Duplicate whole stack! */ * task_thread_info ( p ) = * task_thread_info ( org ); /* Make the `current' macro work */ task_thread_info ( p ) -> task = p ; } copy_mm() \u00b6 This is where threads within a process will share the virtual address space happens. If we are creating a new process, then this function will create a new mm_struct , and also a new pgd : /* * pgd_alloc() will duplicate the identity kernel mapping * but leaves other entries empty: */ mm -> pgd = pgd_alloc ( mm ); if ( unlikely ( ! mm -> pgd )) { kfree ( mm ); return NULL ; } Duplicate pcache data \u00b6 TODO TODO: hook with pcache We need to duplicate the pcache vm_range array, once Yutong finished the code. setup_sched_fork() \u00b6 Callback to scheduler to setup this new task. It may reset all scheduler related information. Here we also have a chance to change this task\u2019s scheduler class: int setup_sched_fork ( unsigned long clone_flags , struct task_struct * p ) { int cpu = get_cpu (); __sched_fork ( clone_flags , p ); p -> state = TASK_NEW ; ... if ( unlikely ( p -> sched_reset_on_fork )) { if ( task_has_rt_policy ( p )) { p -> policy = SCHED_NORMAL ; p -> static_prio = NICE_TO_PRIO ( 0 ); p -> rt_priority = 0 ; } else if ( PRIO_TO_NICE ( p -> static_prio ) < 0 ) p -> static_prio = NICE_TO_PRIO ( 0 ); p -> prio = p -> normal_prio = __normal_prio ( p ); set_load_weight ( p ); ... } if ( rt_prio ( p -> prio )) p -> sched_class = & rt_sched_class ; else { p -> sched_class = & fair_sched_class ; set_load_weight ( p ); } __set_task_cpu ( p , cpu ); if ( p -> sched_class -> task_fork ) p -> sched_class -> task_fork ( p ); ... } Allocate new pid \u00b6 In both Lego and Linux, we don\u2019t allocate new pid for a new thread, if that thread is an idle thread . So callers of do_fork needs to pass something to let do_fork know. In Linux, they use struct pid, init_struct_pid to check. In Lego, we introduce an new clone_flag CLONE_IDLE_THREAD . If that flag is set, do_fork() will try to allocate a new pid for the new thread. Otherwise, it will be 0: /* clone idle thread, whose pid is 0 */ if ( ! ( clone_flags & CLONE_IDLE_THREAD )) { pid = alloc_pid ( p ); if ( ! pid ) goto out_cleanup_thread ; } So, only the init_idle() function can pass this CLONE_IDLE_THREAD down. All other usages are wrong and should be reported. In order to avoid conflict with Linux clone_flag, we define it as: #define CLONE_IDLE_THREAD 0x100000000 SETTID/CLEARTID \u00b6 These are some futex related stuff. I will cover these stuff in futex document: p -> set_child_tid = ( clone_flags & CLONE_CHILD_SETTID ) ? child_tidptr : NULL ; /* * Clear TID on mm_release()? */ p -> clear_child_tid = ( clone_flags & CLONE_CHILD_CLEARTID ) ? child_tidptr : NULL ; #ifdef CONFIG_FUTEX p -> robust_list = NULL ; #endif copy_thread_tls() \u00b6 This is the most interesting function. Cover later. p2m_fork() \u00b6 In order to track user activities, we need to know when user are going to create new process. Fork is the best time and the only time we kernel know. So, Lego adds this special hook to tell remote global monitor or memory manager that there is a new process going to be created. Upon receiving this message, remote monitor will update its bookkeeping for this specific user/vNode. /* Tell remote memory component */ #ifdef CONFIG_COMP_PROCESSOR if ( clone_flags & CLONE_GLOBAL_THREAD ) { ... p2m_fork ( p , clone_flags ); ... } #endif The CLONE_GLOBAL_THREAD should only be set, if the following cases happen: fork() vfork() clone(), without CLONE_THREAD being set In order to avoid conflict with Linux clone_flag, we define it as: #define CLONE_GLOBAL_THREAD 0x200000000 wake_up_new_task() \u00b6 The last step of do_fork is waking up the new thread or process, which is performed by wake_up_new_task() function. The first question this function will ask is: which cpu to land? The answer comes from select_task_rq() : static inline int select_task_rq ( struct task_struct * p , int cpu , int sd_flags , int wake_flags ) { if ( p -> nr_cpus_allowed > 1 ) cpu = p -> sched_class -> select_task_rq ( p , cpu , sd_flags , wake_flags ); else cpu = cpumask_any ( & p -> cpus_allowed ); ... } Clearly, this is determined by cpus_allowed , which is the same with its parent at this point. That being said, if the parent is only able to run on one specific CPU, then all its children will end up running on the same CPU when they wake up (they could change their affinity later). This is also the default on Linux: A child created via fork(2) inherits its parent's CPU affinity mask. The affinity mask is preserved across an execve(2). After landing CPU is selected, following operation is simple: just enqueue this task into landing CPU\u2019s runqueue, and we are done: void wake_up_new_task ( struct task_struct * p ) { ... /* Select a CPU for new thread to run */ #ifdef CONFIG_SMP /* * Fork balancing, do it here and not earlier because: * - cpus_allowed can change in the fork path * - any previously selected cpu might disappear through hotplug */ set_task_cpu ( p , select_task_rq ( p , task_cpu ( p ), SD_BALANCE_FORK , 0 )); #endif rq = __task_rq_lock ( p ); activate_task ( rq , p , 0 ); p -> on_rq = TASK_ON_RQ_QUEUED ; ... } \u2013 Yizhou Shan Created: Feb 11, 2018 Last Updated: Feb 27, 2018","title":"fork()"},{"location":"lego/syscall/fork/#fork","text":"","title":"fork()"},{"location":"lego/syscall/fork/#memory-manager","text":"We need to duplicate the address space in the memory manager side. Follow the traditional fork() semantic, both the existing and newly created address space will be write-protected. Since we have the flexibility to implement any VM organization, we should be careful while duplicating the address space. Currently, we are using page-based VM, thus the duplicating is basically creating a new pgd and copy existing pgtables, and further downgrade permission to read-only. This is now performed by lego_copy_page_range() . The final write-protect is performed by lego_copy_one_pte() : static inline int lego_copy_one_pte (..) { .. /* * If it's a COW mapping, write protect it both * in the parent and the child */ if ( is_cow_mapping ( vm_flags )) { ptep_set_wrprotect ( src_pte ); pte = pte_wrprotect ( pte ); } ... }","title":"Memory Manager"},{"location":"lego/syscall/fork/#duplicate-vm-free-pool","text":"TODO Yutong","title":"Duplicate VM Free Pool"},{"location":"lego/syscall/fork/#processor-manager","text":"Boring implementation details in the processor manager side.","title":"Processor Manager"},{"location":"lego/syscall/fork/#entry-points","text":"fork() vfork() clone() kernel_thread() All of them land on do_fork() , which is Lego\u2019s main fork function.","title":"Entry Points"},{"location":"lego/syscall/fork/#do_fork","text":"There are mainly three parts within do_fork() : 1) copy_process() , which duplicates a new task based on current , including allocate new kernel stack, new task_struct, increase mm reference counter, etc. 2) If we are creating a new process, then tell global monitor or memory manager to let them update bookkeeping and create corresponding data structures. 3) wake_up_new_task() , which gives away the newly created task to local scheduler.","title":"do_fork()"},{"location":"lego/syscall/fork/#copy_process","text":"The routine is kind of boring. It do a lot dirty work to copy information from calling thread to new thread. The most important data structures of course are task_struct , mm_sturct , sighand , and so on. This section only talks about few of them, and leave others to readers who are interested.","title":"copy_process()"},{"location":"lego/syscall/fork/#sanity-checking","text":"Mainly check if clone_flags are passed properly. For example, if user is creating a new thread, that implies certain data structures are shared, cause new thread belongs to the same process with the calling thread. If CLONE_THREAD is passed, then CLONE_SIGHAND , CLONE_VM , and so on must be set as well. /* * Thread groups must share signals as well, and detached threads * can only be started up within the thread group. */ if (( clone_flags & CLONE_THREAD ) && ! ( clone_flags & CLONE_SIGHAND )) return ERR_PTR ( - EINVAL ); /* * Shared signal handlers imply shared VM. By way of the above, * thread groups also imply shared VM. Blocking this case allows * for various simplifications in other code. */ if (( clone_flags & CLONE_SIGHAND ) && ! ( clone_flags & CLONE_VM )) return ERR_PTR ( - EINVAL );","title":"Sanity Checking"},{"location":"lego/syscall/fork/#dup_task_struct","text":"Two main things: 1) duplicate a new task_struct , 2) duplicate a new kernel stack. x86 is just a weird architecture, the size of task_struct depends on the size of fpu. So the allocation and duplication need to callback to x86-specific code to duplicate the task_struct and fpu info. int arch_dup_task_struct ( struct task_struct * dst , struct task_struct * src ) { memcpy ( dst , src , arch_task_struct_size ); return fpu__copy ( & dst -> thread . fpu , & src -> thread . fpu ); } The stack duplication is fairly simple, just copy everything from the old stack to new stack. Of course, it needs to setup the thread_info to points to this new thread, so the current macro will work. static void setup_thread_stack ( struct task_struct * p , struct task_struct * org ) { /* Duplicate whole stack! */ * task_thread_info ( p ) = * task_thread_info ( org ); /* Make the `current' macro work */ task_thread_info ( p ) -> task = p ; }","title":"dup_task_struct()"},{"location":"lego/syscall/fork/#copy_mm","text":"This is where threads within a process will share the virtual address space happens. If we are creating a new process, then this function will create a new mm_struct , and also a new pgd : /* * pgd_alloc() will duplicate the identity kernel mapping * but leaves other entries empty: */ mm -> pgd = pgd_alloc ( mm ); if ( unlikely ( ! mm -> pgd )) { kfree ( mm ); return NULL ; }","title":"copy_mm()"},{"location":"lego/syscall/fork/#duplicate-pcache-data","text":"TODO TODO: hook with pcache We need to duplicate the pcache vm_range array, once Yutong finished the code.","title":"Duplicate pcache data"},{"location":"lego/syscall/fork/#setup_sched_fork","text":"Callback to scheduler to setup this new task. It may reset all scheduler related information. Here we also have a chance to change this task\u2019s scheduler class: int setup_sched_fork ( unsigned long clone_flags , struct task_struct * p ) { int cpu = get_cpu (); __sched_fork ( clone_flags , p ); p -> state = TASK_NEW ; ... if ( unlikely ( p -> sched_reset_on_fork )) { if ( task_has_rt_policy ( p )) { p -> policy = SCHED_NORMAL ; p -> static_prio = NICE_TO_PRIO ( 0 ); p -> rt_priority = 0 ; } else if ( PRIO_TO_NICE ( p -> static_prio ) < 0 ) p -> static_prio = NICE_TO_PRIO ( 0 ); p -> prio = p -> normal_prio = __normal_prio ( p ); set_load_weight ( p ); ... } if ( rt_prio ( p -> prio )) p -> sched_class = & rt_sched_class ; else { p -> sched_class = & fair_sched_class ; set_load_weight ( p ); } __set_task_cpu ( p , cpu ); if ( p -> sched_class -> task_fork ) p -> sched_class -> task_fork ( p ); ... }","title":"setup_sched_fork()"},{"location":"lego/syscall/fork/#allocate-new-pid","text":"In both Lego and Linux, we don\u2019t allocate new pid for a new thread, if that thread is an idle thread . So callers of do_fork needs to pass something to let do_fork know. In Linux, they use struct pid, init_struct_pid to check. In Lego, we introduce an new clone_flag CLONE_IDLE_THREAD . If that flag is set, do_fork() will try to allocate a new pid for the new thread. Otherwise, it will be 0: /* clone idle thread, whose pid is 0 */ if ( ! ( clone_flags & CLONE_IDLE_THREAD )) { pid = alloc_pid ( p ); if ( ! pid ) goto out_cleanup_thread ; } So, only the init_idle() function can pass this CLONE_IDLE_THREAD down. All other usages are wrong and should be reported. In order to avoid conflict with Linux clone_flag, we define it as: #define CLONE_IDLE_THREAD 0x100000000","title":"Allocate new pid"},{"location":"lego/syscall/fork/#settidcleartid","text":"These are some futex related stuff. I will cover these stuff in futex document: p -> set_child_tid = ( clone_flags & CLONE_CHILD_SETTID ) ? child_tidptr : NULL ; /* * Clear TID on mm_release()? */ p -> clear_child_tid = ( clone_flags & CLONE_CHILD_CLEARTID ) ? child_tidptr : NULL ; #ifdef CONFIG_FUTEX p -> robust_list = NULL ; #endif","title":"SETTID/CLEARTID"},{"location":"lego/syscall/fork/#copy_thread_tls","text":"This is the most interesting function. Cover later.","title":"copy_thread_tls()"},{"location":"lego/syscall/fork/#p2m_fork","text":"In order to track user activities, we need to know when user are going to create new process. Fork is the best time and the only time we kernel know. So, Lego adds this special hook to tell remote global monitor or memory manager that there is a new process going to be created. Upon receiving this message, remote monitor will update its bookkeeping for this specific user/vNode. /* Tell remote memory component */ #ifdef CONFIG_COMP_PROCESSOR if ( clone_flags & CLONE_GLOBAL_THREAD ) { ... p2m_fork ( p , clone_flags ); ... } #endif The CLONE_GLOBAL_THREAD should only be set, if the following cases happen: fork() vfork() clone(), without CLONE_THREAD being set In order to avoid conflict with Linux clone_flag, we define it as: #define CLONE_GLOBAL_THREAD 0x200000000","title":"p2m_fork()"},{"location":"lego/syscall/fork/#wake_up_new_task","text":"The last step of do_fork is waking up the new thread or process, which is performed by wake_up_new_task() function. The first question this function will ask is: which cpu to land? The answer comes from select_task_rq() : static inline int select_task_rq ( struct task_struct * p , int cpu , int sd_flags , int wake_flags ) { if ( p -> nr_cpus_allowed > 1 ) cpu = p -> sched_class -> select_task_rq ( p , cpu , sd_flags , wake_flags ); else cpu = cpumask_any ( & p -> cpus_allowed ); ... } Clearly, this is determined by cpus_allowed , which is the same with its parent at this point. That being said, if the parent is only able to run on one specific CPU, then all its children will end up running on the same CPU when they wake up (they could change their affinity later). This is also the default on Linux: A child created via fork(2) inherits its parent's CPU affinity mask. The affinity mask is preserved across an execve(2). After landing CPU is selected, following operation is simple: just enqueue this task into landing CPU\u2019s runqueue, and we are done: void wake_up_new_task ( struct task_struct * p ) { ... /* Select a CPU for new thread to run */ #ifdef CONFIG_SMP /* * Fork balancing, do it here and not earlier because: * - cpus_allowed can change in the fork path * - any previously selected cpu might disappear through hotplug */ set_task_cpu ( p , select_task_rq ( p , task_cpu ( p ), SD_BALANCE_FORK , 0 )); #endif rq = __task_rq_lock ( p ); activate_task ( rq , p , 0 ); p -> on_rq = TASK_ON_RQ_QUEUED ; ... } \u2013 Yizhou Shan Created: Feb 11, 2018 Last Updated: Feb 27, 2018","title":"wake_up_new_task()"},{"location":"lego/syscall/getrusage/","text":"getrusage \u00b6 The syscall getrusage is used to get user program resource usage. It is a nice syscall. But only nice if kernel has all the nice bookkeeping. It is a luxury for us to have all the counting. The syscall is added recently due to wait family syscalls, which use and bookkeep some of rusage . As on the last updated date (Mar 7), the syscall in Lego only reports number of context switches and a few others. \u2013 Yizhou Shan Created: Mar 7, 2018 Last Updated: Mar 7, 2018","title":"getrusage()"},{"location":"lego/syscall/getrusage/#getrusage","text":"The syscall getrusage is used to get user program resource usage. It is a nice syscall. But only nice if kernel has all the nice bookkeeping. It is a luxury for us to have all the counting. The syscall is added recently due to wait family syscalls, which use and bookkeep some of rusage . As on the last updated date (Mar 7), the syscall in Lego only reports number of context switches and a few others. \u2013 Yizhou Shan Created: Mar 7, 2018 Last Updated: Mar 7, 2018","title":"getrusage"},{"location":"lego/syscall/mremap/","text":"mremap() \u00b6","title":"mremap()"},{"location":"lego/syscall/mremap/#mremap","text":"","title":"mremap()"},{"location":"lego/syscall/msync/","text":"msync() \u00b6 The document is a summary I wrote after reading Failure-atomic msync() paper, which help me understand several questions related to msync() . msync() is not atomic. During msync(), pages are being written back to disk one by one (or batched): few pages have been flushed back, but few pages are still in the memory. This premature writeback is not atomic and will be affected by failure. msync() need concurrency control . This actually is the issue I asked before. With a multi-threaded application, does msync() provide the synchronization semantic? The answer is no. Other threads within the same process are able to write to pages under msync(). This implies, application need to handle concurrency by themselves, e.g., rwlocks. At the very beginning, I thought msync() provide this semantic. The only way to implement this should be: kernel make all pages\u2019 PTE read-only, and then perform flush back. If any other threads does a write during flush, they will have a page fault. And in the pgfault function, we hold the threads until the pages are written back. Probably some nice reading. fsync, fdatasync 1 . \u2013 Yizhou Shan Created: Feb 01, 2018 Last Updated: Mar 23, 2018 RFLUSH: Rethink the Flush \u21a9","title":"msync()"},{"location":"lego/syscall/msync/#msync","text":"The document is a summary I wrote after reading Failure-atomic msync() paper, which help me understand several questions related to msync() . msync() is not atomic. During msync(), pages are being written back to disk one by one (or batched): few pages have been flushed back, but few pages are still in the memory. This premature writeback is not atomic and will be affected by failure. msync() need concurrency control . This actually is the issue I asked before. With a multi-threaded application, does msync() provide the synchronization semantic? The answer is no. Other threads within the same process are able to write to pages under msync(). This implies, application need to handle concurrency by themselves, e.g., rwlocks. At the very beginning, I thought msync() provide this semantic. The only way to implement this should be: kernel make all pages\u2019 PTE read-only, and then perform flush back. If any other threads does a write during flush, they will have a page fault. And in the pgfault function, we hold the threads until the pages are written back. Probably some nice reading. fsync, fdatasync 1 . \u2013 Yizhou Shan Created: Feb 01, 2018 Last Updated: Mar 23, 2018 RFLUSH: Rethink the Flush \u21a9","title":"msync()"},{"location":"lego/syscall/wait_and_exit/","text":"wait4(), waitid(), and exit() \u00b6 Lego supports wait4() and waitid() syscalls, and they are compatible with Linux programs. These two syscalls rely on exit_notify() function when a thread exit() . Basically, when a thread exit, it will notify its parent, and reparent 3 its children if necessary. Facts in Lego: Lego does not have process group and session 2 concept. Each process is within its own process group and session. This implies Lego will not have Orphaned Process Group 1 when a process exit. Orphan process 3 is adopted by init process (pid 1) if its father is a single-thread process, otherwise it will be adopted by other thread within its father\u2019s process. This is performed by function forget_original_parent() . wait, signal, exec, fork are close related. \u2013 Yizhou Shan Created: Mar 8, 2018 Last Updated: Mar 10, 2018 Orphaned Process Groups \u21a9 Process Group \u21a9 Orphan Process \u21a9 \u21a9","title":"wait4 and exit()"},{"location":"lego/syscall/wait_and_exit/#wait4-waitid-and-exit","text":"Lego supports wait4() and waitid() syscalls, and they are compatible with Linux programs. These two syscalls rely on exit_notify() function when a thread exit() . Basically, when a thread exit, it will notify its parent, and reparent 3 its children if necessary. Facts in Lego: Lego does not have process group and session 2 concept. Each process is within its own process group and session. This implies Lego will not have Orphaned Process Group 1 when a process exit. Orphan process 3 is adopted by init process (pid 1) if its father is a single-thread process, otherwise it will be adopted by other thread within its father\u2019s process. This is performed by function forget_original_parent() . wait, signal, exec, fork are close related. \u2013 Yizhou Shan Created: Mar 8, 2018 Last Updated: Mar 10, 2018 Orphaned Process Groups \u21a9 Process Group \u21a9 Orphan Process \u21a9 \u21a9","title":"wait4(), waitid(), and exit()"},{"location":"misc/cheatsheet/","text":"Cheatsheet \u00b6 Python \u00b6 f'{0x0c180606:032b}' VNC \u00b6 Server side: Start server on certain port with certain geometry: vncserver :66 -geometry 1920x1080 Client side: for safety, use SSH tunnel. -p 22 : ssh port is 22 -L 7777:localhost:5966 : Forward localhost\u2019s 7777 to server\u2019s 5966 Step 1) ssh -p 22 -v -C -L 7777:localhost:5966 root@yourserver.com Step 2) Use VNC client to establish connection with localhost:7777 virsh \u00b6 Pass commands to QEMU in the virsh bash: # qemu-monitor-command guest_os_id --hmp \"info cpus\" Markdown \u00b6 Emoji cheatsheet tmux \u00b6 Install tmux-plugins , it makes your terminal bling bling. bash \u00b6 Show current git branch in PS1: parse_git_branch () { git branch 2 > /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/ git:(\\1)/' } PS1 = \"\\[\\e[32m\\][\\u@\\h: \\W\\e[33m\\]\\$(parse_git_branch)\\[\\033[32m\\]]\\[\\e[00m\\] $ \" Forward man pages to vim : vman () { man $* | col -b | vim -c 'set ft=man nomod nolist' - ; } alias man = \"vman\" Git \u00b6 git log --pretty=\"%C(Yellow)%h %C(auto)%d (%C(Green)%cr%C(reset))%x09 %C(Cyan)%an: %C(reset)%s\" --date=short --graph QEMU \u00b6 Run standalone kernel: # Create a new directory to store the serial output from printk(). OUTPUT_DIR = \"test-output\" if [ -e $OUTPUT_DIR ] ; then if [ -f $OUTPUT_DIR ] ; then echo \"ERROR: $OUTPUT_DIR is not a directly\" exit 1 fi else mkdir -p $OUTPUT_DIR fi KERNEL = \"arch/x86_64/boot/bzImage\" KERNEL_PARAM = \"console=ttyS0 earlyprintk=serial,ttyS0,115200\" SERIAL = \"-serial file: $OUTPUT_DIR /ttyS0 -serial file: $OUTPUT_DIR /ttyS1\" # -cpu Haswell,+tsc,+sse,+xsave,+aes,+avx,+erms,+pdpe1gb,+pge \\ # Above -cpu option may not work with some kernels. qemu-system-x86_64 -s \\ -nographic \\ -kernel $KERNEL -append \" $KERNEL_PARAM \" \\ -no-reboot \\ -d int,cpu_reset -D $OUTPUT_DIR /qemu.log \\ $SERIAL \\ -m 16G \\ -monitor stdio \\ -smp cpus = 24 ,cores = 12 ,threads = 2 ,sockets = 2 \\ -numa node,cpus = 0 -11,mem = 8G,nodeid = 0 \\ -numa node,cpus = 12 -23,mem = 8G,nodeid = 1 Install CentOS on Dell PowerEdge \u00b6 Enable SR-IOV for future usage Press F11 Boot Manager during boot Find Integrated Devices Enable SR-IOV Global Enable Partition /boot : e.g, 50GB swap : e.g, 4G / : all left Don\u2019t forget to enable Network during installation. Change SSH port Disable firewalld systemctl stop firewalld systemctl disable firewalld If SELinux is enabled yum install policycoreutils-python semanage port -a -t ssh_port_t -p tcp #PORTNUMBER Change /etc/ssh/sshd_config systemctl restart sshd Avoid Typing SSH Password \u00b6 Generate keys: ssh-keygen -t rsa Copy to remote: ssh-copy-id -i ~/.ssh/id_rsa.pub username@remotehost -p 22 GRUB2 on Ubuntu \u00b6 Nothing like grubby?! Shame on you. Step I: cat /boot/grub/grub.cfg | grep menuentry menuentry 'Ubuntu, with Linux 4.16.0' --class ubuntu ... menuentry 'Ubuntu, with Linux 4.9.92' --class ubuntu ... Step II: Open /etc/default/grub , change GRUB_DEFAULT=\u201dAdvanced options for Ubuntu>Ubuntu, with Linux 4.16.0\u201d GRUB_DEFAULT=\u201dAdvanced options for Ubuntu>Ubuntu, with Linux 4.9.92\u201d Step III: sudo update-grub Migrate to Ubuntu From MacOS \u00b6 Disable [Super+p] . This is my tmux prefix somehow. xmodmap to switch Super and CTRL. 1","title":"Cheatsheet"},{"location":"misc/cheatsheet/#cheatsheet","text":"","title":"Cheatsheet"},{"location":"misc/cheatsheet/#python","text":"f'{0x0c180606:032b}'","title":"Python"},{"location":"misc/cheatsheet/#vnc","text":"Server side: Start server on certain port with certain geometry: vncserver :66 -geometry 1920x1080 Client side: for safety, use SSH tunnel. -p 22 : ssh port is 22 -L 7777:localhost:5966 : Forward localhost\u2019s 7777 to server\u2019s 5966 Step 1) ssh -p 22 -v -C -L 7777:localhost:5966 root@yourserver.com Step 2) Use VNC client to establish connection with localhost:7777","title":"VNC"},{"location":"misc/cheatsheet/#virsh","text":"Pass commands to QEMU in the virsh bash: # qemu-monitor-command guest_os_id --hmp \"info cpus\"","title":"virsh"},{"location":"misc/cheatsheet/#markdown","text":"Emoji cheatsheet","title":"Markdown"},{"location":"misc/cheatsheet/#tmux","text":"Install tmux-plugins , it makes your terminal bling bling.","title":"tmux"},{"location":"misc/cheatsheet/#bash","text":"Show current git branch in PS1: parse_git_branch () { git branch 2 > /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/ git:(\\1)/' } PS1 = \"\\[\\e[32m\\][\\u@\\h: \\W\\e[33m\\]\\$(parse_git_branch)\\[\\033[32m\\]]\\[\\e[00m\\] $ \" Forward man pages to vim : vman () { man $* | col -b | vim -c 'set ft=man nomod nolist' - ; } alias man = \"vman\"","title":"bash"},{"location":"misc/cheatsheet/#git","text":"git log --pretty=\"%C(Yellow)%h %C(auto)%d (%C(Green)%cr%C(reset))%x09 %C(Cyan)%an: %C(reset)%s\" --date=short --graph","title":"Git"},{"location":"misc/cheatsheet/#qemu","text":"Run standalone kernel: # Create a new directory to store the serial output from printk(). OUTPUT_DIR = \"test-output\" if [ -e $OUTPUT_DIR ] ; then if [ -f $OUTPUT_DIR ] ; then echo \"ERROR: $OUTPUT_DIR is not a directly\" exit 1 fi else mkdir -p $OUTPUT_DIR fi KERNEL = \"arch/x86_64/boot/bzImage\" KERNEL_PARAM = \"console=ttyS0 earlyprintk=serial,ttyS0,115200\" SERIAL = \"-serial file: $OUTPUT_DIR /ttyS0 -serial file: $OUTPUT_DIR /ttyS1\" # -cpu Haswell,+tsc,+sse,+xsave,+aes,+avx,+erms,+pdpe1gb,+pge \\ # Above -cpu option may not work with some kernels. qemu-system-x86_64 -s \\ -nographic \\ -kernel $KERNEL -append \" $KERNEL_PARAM \" \\ -no-reboot \\ -d int,cpu_reset -D $OUTPUT_DIR /qemu.log \\ $SERIAL \\ -m 16G \\ -monitor stdio \\ -smp cpus = 24 ,cores = 12 ,threads = 2 ,sockets = 2 \\ -numa node,cpus = 0 -11,mem = 8G,nodeid = 0 \\ -numa node,cpus = 12 -23,mem = 8G,nodeid = 1","title":"QEMU"},{"location":"misc/cheatsheet/#install-centos-on-dell-poweredge","text":"Enable SR-IOV for future usage Press F11 Boot Manager during boot Find Integrated Devices Enable SR-IOV Global Enable Partition /boot : e.g, 50GB swap : e.g, 4G / : all left Don\u2019t forget to enable Network during installation. Change SSH port Disable firewalld systemctl stop firewalld systemctl disable firewalld If SELinux is enabled yum install policycoreutils-python semanage port -a -t ssh_port_t -p tcp #PORTNUMBER Change /etc/ssh/sshd_config systemctl restart sshd","title":"Install CentOS on Dell PowerEdge"},{"location":"misc/cheatsheet/#avoid-typing-ssh-password","text":"Generate keys: ssh-keygen -t rsa Copy to remote: ssh-copy-id -i ~/.ssh/id_rsa.pub username@remotehost -p 22","title":"Avoid Typing SSH Password"},{"location":"misc/cheatsheet/#grub2-on-ubuntu","text":"Nothing like grubby?! Shame on you. Step I: cat /boot/grub/grub.cfg | grep menuentry menuentry 'Ubuntu, with Linux 4.16.0' --class ubuntu ... menuentry 'Ubuntu, with Linux 4.9.92' --class ubuntu ... Step II: Open /etc/default/grub , change GRUB_DEFAULT=\u201dAdvanced options for Ubuntu>Ubuntu, with Linux 4.16.0\u201d GRUB_DEFAULT=\u201dAdvanced options for Ubuntu>Ubuntu, with Linux 4.9.92\u201d Step III: sudo update-grub","title":"GRUB2 on Ubuntu"},{"location":"misc/cheatsheet/#migrate-to-ubuntu-from-macos","text":"Disable [Super+p] . This is my tmux prefix somehow. xmodmap to switch Super and CTRL. 1","title":"Migrate to Ubuntu From MacOS"},{"location":"misc/essential/","text":"System Developing Essentials \u00b6 Misc Advice \u00b6 Elevator Pitches, John Wilkes Creating an effective poster, John Wilkes How to Get a Paper Accepted at OOPSLA Tools \u00b6 Stack and Register Dumper NMI and software Watchdog Tracepoint and Ring Buffer Profilers Counters Whiskey and Luck Keep in mind \u00b6 Stress your system Every single critical subsystem Confident with your base subsystem Fix bug/Improve perf at early stage Plan ahead Single thread, or thread pool? How to avoid using lock ? What lock to use? How to reduce lock contention ? Does this data structure need reference counter ? Should I use per-cpu data structures? Should I pad this lock $-line aligned to avoid pingpong? Decent Cleanup I\u2019m fucking hate a crap kernel module just kill my machine, either stuck or bug. Free buffer/structure Remove the pointer from friends\u2019 list/tree. If you forgot to do so, mostly you will have some silent memory corruption. So be kind, cleanup what you have done during intilization. Report error. Do not be SILENT. Clever Buffer Management kmem_cache? static pre-allocated array? Ring buffer? Other than kmem_cache, I used other two solutions to optimize various dynamic allocation in LegoOS. The motivation is very simple: some data structures will be allocated/free very very frequently at runtime. So we want to speed it up! System Building Advice \u00b6 John Ousterhout If you don\u2019t know what the problem was, you haven\u2019t fixed it If it hasn\u2019t been used, it doesn\u2019t work","title":"Essential"},{"location":"misc/essential/#system-developing-essentials","text":"","title":"System Developing Essentials"},{"location":"misc/essential/#misc-advice","text":"Elevator Pitches, John Wilkes Creating an effective poster, John Wilkes How to Get a Paper Accepted at OOPSLA","title":"Misc Advice"},{"location":"misc/essential/#tools","text":"Stack and Register Dumper NMI and software Watchdog Tracepoint and Ring Buffer Profilers Counters Whiskey and Luck","title":"Tools"},{"location":"misc/essential/#keep-in-mind","text":"Stress your system Every single critical subsystem Confident with your base subsystem Fix bug/Improve perf at early stage Plan ahead Single thread, or thread pool? How to avoid using lock ? What lock to use? How to reduce lock contention ? Does this data structure need reference counter ? Should I use per-cpu data structures? Should I pad this lock $-line aligned to avoid pingpong? Decent Cleanup I\u2019m fucking hate a crap kernel module just kill my machine, either stuck or bug. Free buffer/structure Remove the pointer from friends\u2019 list/tree. If you forgot to do so, mostly you will have some silent memory corruption. So be kind, cleanup what you have done during intilization. Report error. Do not be SILENT. Clever Buffer Management kmem_cache? static pre-allocated array? Ring buffer? Other than kmem_cache, I used other two solutions to optimize various dynamic allocation in LegoOS. The motivation is very simple: some data structures will be allocated/free very very frequently at runtime. So we want to speed it up!","title":"Keep in mind"},{"location":"misc/essential/#system-building-advice","text":"John Ousterhout If you don\u2019t know what the problem was, you haven\u2019t fixed it If it hasn\u2019t been used, it doesn\u2019t work","title":"System Building Advice"},{"location":"misc/jasmine/","text":"Cool and good-to-know stuff: GigaIO RSS (Receiver Side Scaling) Intel Flow Director E2, ClickOS, NetVM, and Metron. AutoML What is \u2018Site Reliability Engineering\u2019? Deduplication: Content Based Page Sharing (CBPS) + COW Linux\u2019s Kernel Same-page Merging (KSM) Multi-Queue SSD, MQ-SSD 2 Write Anywhere File Layout, WAFL . NetApp Paper 1 . Journaling Shadow Paging Soft Updates Shared-nothing architecture -> no single point of contention ZeptoOS Tail-tolerant Distributed Systems S.M.A.R.T (Self-Monitoring, Analysis, and Reporting Technology) linux-mm . Actually, not that interesting. Serveless AWS Lambda Google Cloud Function Azure Functions SDS TidalScale ScaleMP Apache Crail Redis Lab Journaling of journal Concurrent Data Structures NUMA-aware data structures linearizability lock-free skip list blog WAFL Iron: Repairing Live Enterprise File Systems, FAST\u201818 \u21a9 Linux Block IO: Introducing Multi-queue SSD Access on Multi-core Systems, SYSTOR\u201813 \u21a9","title":"Jasmine"},{"location":"misc/talk/","text":"DASH dynamic ad over HTTP (video) rate adaption algorithm: estimate net bw? Multipath TCP https://www.multipath-tcp.org/ cost/byte, perf/$","title":"Talk"},{"location":"notes/CXL/","text":"What is up with CXL? \u00b6 Version History Date Description Nov 15, 2022 Small fixes Jul 17, 2022 Initial Intro \u00b6 Is CXL just another NUMA? You probably have heared about CXL many times. And you\u2019ve probably wondered, what is it, exactly? And why folks are so excited about it? This (short) note explains CXL from my own pespective. In particular, what is it, how to use it, what\u2019s the current status, and what\u2019s next. DISCLAIMER: I\u2019m no expert in the CXL protocol itself. I\u2019m just a systems researcher who may need to compare my systems against CXL-enabled ones. Hence my thoughts and views could be biased and wrong. If you are looking for serious CXL specification stuff, please check out the official CXL site . Without further ado, let\u2019s get started. What is CXL? \u00b6 CXL is short for Compute Express Link. It has 3 types. I will focus on CXL type 3 device, the one used for memory expansion . The CXL hereafter refers to type 3. Originally CXL was proposed to tame DRAM/PM heterogeneity and has a framework to maintain cache coherence among accelerators. CXL is now mainly used in the disaggregated memory scenario. But was CXL originally designed with the disaggregated memory setting in mind? I doubt that. Hence it is interesting to think why CXL has such a successful spin-off. My take: because CXL was designed for heterogeenous DRAM technologies, one of its core design principle is to work with different kinds of memory. Using memory usually requires extremely low latency. As such, CXL requires a low latency interconnection between a processing unit (e.g., CPU) and a CXL controller (the one right before memory chips). This pursuit eventually brings a CPU closer to a device (CXL controller) that is capable of accessing external resources. It calls for something better/faster than the long-standing PCIe. And this subsequently enables the disaggregated memory usage. How to use CXL? \u00b6 I think there are two ways to look at CXL, one from the traditional server angel, and the other from resource disaggregation. Either way, CXL enables disaggregated memory with extrmely low latency. From the traditional server angle : CXL allows the CPUs to access remote memory (i.e., memory resides outside the server box) at extremely low-latency, very much like accessing a NUMA node (could be ~100ns, see the MS arXiv paper). Since the remote memory is provisioned separately from the servers, you basically enjoys memory expansive \u201cfree\u201d. Of course not exactly free, but it is relatable to NUMA system tuning. From the disaggregated memory angle : CXL enables another design spectrum in disaggregated memory (DM) systems. Usually, DM systems access remote memory over RDMA with a few software tricks at the client side. The tricks include explicit APIs (AIFM, OSDI\u201820), runtime (Semeru, OSDI\u201820), kernel paging (InfiniSwap, NSDI\u201817). No matter what software is used, the overhead of accessing disaggregated memory is usually larger than 2-4 us. The overhead comes from software cost, DMA to RDMA NIC cost, RDMA NIC cost, etc. CXL brings something new to the table. At its core, CXL claims a PCIe bus address and allows CPUs to access remote memory using LD/ST, bypassing all the software and NIC overheads. The DirectCXL, ATC\u201822 paper has a nice breakdown. What\u2019s the status of CXL? \u00b6 CXL is taking off. Cloud vendors are pushing it. Microsoft and Meta have released papers on their in-houst CXL platforms. Though no hardware is actually evaluated, they are building it. I remember Meta has CXL FPGAs long time ago. The whole industry is pushing it. There are numerous summits hosting CXL tutorials. The latest being OCP Global Summit 2022 . What\u2019s next for CXL? \u00b6 I think there are A LOT to explore. Research wise. Like concurrency. Readings \u00b6 First-Gen CXL, arXiv\u201822. Two contributions. Azure memory standing analysis, and a CXL prototype description. Works for opaque VM. The system is intergrated with cluster-side VM scheduler. No page migration, but VM migration. Has ML-based VM memory usage prediction And runtime QoS monitoring based on PMU countes The paper is accepted to ASPLOS\u201823 and renamed to Pond. TPP, arXiv\u201822. Two contribtions. Workloads analysis and an enhanced paging system. Works within a normal linux kernel (has user space parts), various improvements on LRU lists etc. Both the MS and TPP paper assume accessing to remote CXL memory is like accessing NUMA nodes, latency runs at around 100ns. Crazy numbers. DirectCXL, ATC\u201822 First FPGA prototype. Since they don\u2019t have CXL-enabled x86, they use RISC-V. The latency is around 300ns?","title":"What is CXL?"},{"location":"notes/CXL/#what-is-up-with-cxl","text":"Version History Date Description Nov 15, 2022 Small fixes Jul 17, 2022 Initial","title":"What is up with CXL?"},{"location":"notes/CXL/#intro","text":"Is CXL just another NUMA? You probably have heared about CXL many times. And you\u2019ve probably wondered, what is it, exactly? And why folks are so excited about it? This (short) note explains CXL from my own pespective. In particular, what is it, how to use it, what\u2019s the current status, and what\u2019s next. DISCLAIMER: I\u2019m no expert in the CXL protocol itself. I\u2019m just a systems researcher who may need to compare my systems against CXL-enabled ones. Hence my thoughts and views could be biased and wrong. If you are looking for serious CXL specification stuff, please check out the official CXL site . Without further ado, let\u2019s get started.","title":"Intro"},{"location":"notes/CXL/#what-is-cxl","text":"CXL is short for Compute Express Link. It has 3 types. I will focus on CXL type 3 device, the one used for memory expansion . The CXL hereafter refers to type 3. Originally CXL was proposed to tame DRAM/PM heterogeneity and has a framework to maintain cache coherence among accelerators. CXL is now mainly used in the disaggregated memory scenario. But was CXL originally designed with the disaggregated memory setting in mind? I doubt that. Hence it is interesting to think why CXL has such a successful spin-off. My take: because CXL was designed for heterogeenous DRAM technologies, one of its core design principle is to work with different kinds of memory. Using memory usually requires extremely low latency. As such, CXL requires a low latency interconnection between a processing unit (e.g., CPU) and a CXL controller (the one right before memory chips). This pursuit eventually brings a CPU closer to a device (CXL controller) that is capable of accessing external resources. It calls for something better/faster than the long-standing PCIe. And this subsequently enables the disaggregated memory usage.","title":"What is CXL?"},{"location":"notes/CXL/#how-to-use-cxl","text":"I think there are two ways to look at CXL, one from the traditional server angel, and the other from resource disaggregation. Either way, CXL enables disaggregated memory with extrmely low latency. From the traditional server angle : CXL allows the CPUs to access remote memory (i.e., memory resides outside the server box) at extremely low-latency, very much like accessing a NUMA node (could be ~100ns, see the MS arXiv paper). Since the remote memory is provisioned separately from the servers, you basically enjoys memory expansive \u201cfree\u201d. Of course not exactly free, but it is relatable to NUMA system tuning. From the disaggregated memory angle : CXL enables another design spectrum in disaggregated memory (DM) systems. Usually, DM systems access remote memory over RDMA with a few software tricks at the client side. The tricks include explicit APIs (AIFM, OSDI\u201820), runtime (Semeru, OSDI\u201820), kernel paging (InfiniSwap, NSDI\u201817). No matter what software is used, the overhead of accessing disaggregated memory is usually larger than 2-4 us. The overhead comes from software cost, DMA to RDMA NIC cost, RDMA NIC cost, etc. CXL brings something new to the table. At its core, CXL claims a PCIe bus address and allows CPUs to access remote memory using LD/ST, bypassing all the software and NIC overheads. The DirectCXL, ATC\u201822 paper has a nice breakdown.","title":"How to use CXL?"},{"location":"notes/CXL/#whats-the-status-of-cxl","text":"CXL is taking off. Cloud vendors are pushing it. Microsoft and Meta have released papers on their in-houst CXL platforms. Though no hardware is actually evaluated, they are building it. I remember Meta has CXL FPGAs long time ago. The whole industry is pushing it. There are numerous summits hosting CXL tutorials. The latest being OCP Global Summit 2022 .","title":"What's the status of CXL?"},{"location":"notes/CXL/#whats-next-for-cxl","text":"I think there are A LOT to explore. Research wise. Like concurrency.","title":"What's next for CXL?"},{"location":"notes/CXL/#readings","text":"First-Gen CXL, arXiv\u201822. Two contributions. Azure memory standing analysis, and a CXL prototype description. Works for opaque VM. The system is intergrated with cluster-side VM scheduler. No page migration, but VM migration. Has ML-based VM memory usage prediction And runtime QoS monitoring based on PMU countes The paper is accepted to ASPLOS\u201823 and renamed to Pond. TPP, arXiv\u201822. Two contribtions. Workloads analysis and an enhanced paging system. Works within a normal linux kernel (has user space parts), various improvements on LRU lists etc. Both the MS and TPP paper assume accessing to remote CXL memory is like accessing NUMA nodes, latency runs at around 100ns. Crazy numbers. DirectCXL, ATC\u201822 First FPGA prototype. Since they don\u2019t have CXL-enabled x86, they use RISC-V. The latency is around 300ns?","title":"Readings"},{"location":"notes/MLIR/","text":"MLIR \u00b6 Version History Date Description Jul 3, 2022 Add Pathways Apr 2, 2022 Ported from Craft. Recently, I switched to Craft for technical writing. I\u2019m very happy I made that transition. Craft is great at exporting things to Markdown format. This document is organized as follows. MLIR at 10,000 feet - an overview. Why MLIR was created? - a study of the original MLIR paper. How MLIR is used in the wild? - case studies. Without further ado, let\u2019s get started. MLIR At 10,000 Feet \u00b6 MLIR is short for Multi-Level Intermediate Representation. MLIR helps to build reusage compiler infrastructure and reduce duplicate codes. I draw the following figure to show MLIR\u2019s workflow at a very high level. In specific: MLIR\u2019s input: applications, compilers, C program, etc Within MLIR, we can implement multiple Dialects for distinct inputs. For instance, we could use a Dialect to deal with tensors. Further, we can deploy a shared optimization layer to unify things. Once we have an optimal IR, MLIR can now lower it onto the backends such as LLVM for CPUs, CIRCT for FPGAs. If you are targeting specialized hardware such as FPGA or TPU, you still need vendor-tools for final compilation (e.g., use Vivado to synthesis Verilog). Resources \u00b6 I have found several excellent primer readings. LLVM Paper from Google, 2020 . This paper describes the rationale behind MLIR. Chris L is one of the authord. LLVM MLIR Tutorial I didn\u2019t understand this image when I first read it. But now it all makes sense. MLIR is something that lies across language AST and LLVM IR. ScaleHLS, HPCA\u201822 can compile HLS C/C++ or PyTorch model to optimized HLS C/C++ using MLIR. Motivation from the Google MLIR Paper \u00b6 This is a really nice Intro , pay close attention to how they lay out the storyline. If you are new to PL just like me, I strongly recommend going through the MLIR Toy Example (covered below ) for a better understanding, and then come back, read through this again. A common characteristic of popular ML systems is their \u201cone size \ufb01ts all\u201d approach\u2014a single abstraction level to interface with the system: the LLVM Intermediate Representation (IR) is roughly \u201cC with vectors\u201d, and JVM provides an \u201cobject-oriented type system with a garbage collector\u201d abstraction. This \u201cone size \ufb01ts all\u201d approach is incredibly valuable\u2014and in practice, the mapping to these domains from ubiquitous source languages (C/C++ and Java respectively) is straightforward. ( Praise the unified LLVM IR ) At the same time, many problems are better modeled at a higher- or lower-level abstraction, e.g. source-level analysis of C++ code is very dif\ufb01cult on LLVM IR. We observe that many languages (including e.g. Swift, Rust, Julia, Fortran) develop their own IR in order to solve domain-speci\ufb01c problems, like language/library-speci\ufb01c optimizations, \ufb02ow-sensitive type checking. Similarly, machine learning systems typically use \u201cML graphs\u201d as a domain-speci\ufb01c abstraction in the same way. ( Point out the issues about LLVM IR ) While the development of domain speci\ufb01c IRs is a well studied art, their engineering and implementation cost remains high. \u2026 this can lead to lower quality compiler systems. ( Point out that developing customized IR framework is challenging ) The MLIR project aims to directly tackle these programming language design and implementation challenges\u2014by making it very cheap to de\ufb01ne and introduce new abstraction levels, and provide \u201cin the box\u201d infrastructure to solve common compiler engineering problems. MLIR does this by standardizing the Static Single Assignment (SSA)-based IR data structures providing a declarative system for de\ufb01ning IR dialects (demonstrated below using the Toy example) providing a wide range of common infrastructure (including documentation, parsing and printing logic, location tracking, multithreaded compilation support, pass management, etc). This image shows that most high-level languages have their own AST and associated infrastructure for transforming etc. Though language-specific, these are modules doing similar things. MLIR is a general framework to facilitate the development of such language-specific modules. It allows developers to use a unified codebase/framework to do their optimizations and develop some common, shared optimizations for multiple inputs. I recommend reading Toy Example Tutorial for a deep understanding. This image is MLIR\u2019s original motivation. They found that ML graphs have a lot of different compilers. The compilation process is fragmented and some compilers are not following the best practices. Case Studies \u00b6 Example 1: MLIR Toy Example \u00b6 While reading through its documentation, I\u2019m starting to get a sense of what problem MLIR is trying to solve. The MLIR paper for sure describes the problem at a high level, but being able to read through the code example and its documentation helps a lot. The following quote is the same motivation described in the MLIR paper. Other compilers, like LLVM (see the Kaleidoscope tutorial ), offer a fixed set of predefined types and (usually low-level / RISC-like) instructions. It is up to the frontend for a given language to perform any language-specific type-checking, analysis, or transformation before emitting LLVM IR. <- also mentioned in the MLIR paper. For example, Clang will use its AST to perform not only static analysis but also transformations, such as C++ template instantiation through AST cloning and rewrite. Finally, languages with construction at a higher level than C/C++ may require non-trivial lowering from their AST to generate LLVM IR . Consequently, multiple frontends end up reimplementing significant pieces of infrastructure to support the need for these analyses and transformations . MLIR addresses this issue by being designed for extensibility. There are few pre-defined instructions ( operations in MLIR terminology) or types. Like C, Swift, Rust, etc., each language has its own AST optimizers that do some language-specific transformations and analysis. This is quite tedious to do. So: MLIR is designed to allow all IR elements, such as attributes, operations, and types, to be customized. At the same time, IR elements can always be reduced to the above fundamental concepts. This allows MLIR to parse, represent, and round-trip ** IR for any operation.** This is EXACTLY what I want to say for the APSys submission. Through dialects, MLIR allows for the representation of many different levels of abstraction; the Toy dialect that we have previously defined is one such example. Though these different dialects may represent different abstractions, there is often a set of common transformations and analyses that we would like to perform. The blog builds the Toy Example following these steps : It first defines the semantics of this toy language and some simple operations. It then defines an IR for the Toy language in an MLIR dialect. MLIR can transform the source code into its internal IR using the above dialect. It then performs \u201c High-level Language-Specific Analysis and Transformation \u201d and other optimizations on the generated IR within MLIR. The transformations are pretty straightforward, such as eliminating duplicated ops. These optimizations, however, would be difficult for LLVM to carry out. It then discussed an MLIR internal interface infrastructure that facilitates the above transformations. The rationale is that most transformations used by distinct languages are similar, hence a framework can reduce code duplication and also allow developers to design a set of shared common optimizations/passes. Then, the interesting part. It converts this Dialect into other MLIR built-in dialects (e.g., affine, arithmetic), thereby lowering the toy Dialect into more concrete memory accesses, and arithmetic ops, etc. Finally, it again lowers the above partially-lowered IR onto the LLVM IR. Once we are here, we can invoke LLVM to generate code (e.g., for x86 or ARM CPUs) or run with the LLVM JIT. Of course, instead of lowering it onto the LLVM IR, one can also lower it onto another IR, e.g., TPU IR (what TensorFlow does). My understanding MLIR is a generic framework that allows you to define your customized IR using MLIR\u2019s generic primitives (i.e., an indirection layer). From MLIR\u2019s perspective, your IR is just one of the many dialects it supports. More importantly, a dialect can fully or partially convert into other dialects. For instance, if you convert your IR into the LLVM IR, you can immediately take advantage of the LLVM\u2019s code-generation framework for CPUs. If you convert your IR into the TPU IR, you can then generate code running on TPUs. Say I want to build some P4 or FPGA stuff using MLIR, I would do : I would first define a language model together with a new IR using MLIR primitives. Then, within MLIR, I would do all sorts of language-specific optimizations, transformations, etc. I can also do some conversions among other dialects. After all that, say I\u2019ve got an optimized IR. What should I do next? I cannot fully lower it to the LLVM IR, because there is no P4/FPGA backend in the LLVM framework. If I target FPGA, I could generate FIRRTL, which is the input of CIRCIT or Chisel . If I target P4, I could generate the MLIR IR into something like a P4 IR/backend, which then will do vendor-specific compilation into deployable binaries. Is this P4 IR thing already part of the p4 compiler chain? If so, why should I go through all this trouble adding a new MLIR dialect, why not directly use the p4 compile chain? What benefits are we getting out of MLIR though? Answer: we will benefit from MLIR only if we are targeting multiple backends at the same time, thus we can share the same optimization infrastructure. In specific, one piece of code can run on top of a set of heterogeneous devices. All the optimizations are nicely done within the MLIR layer. Example 2: Google IREE \u00b6 IREE IREE (**I**ntermediate **R**epresentation **E**xecution **E**nvironment 1 ) is an MLIR -based end-to-end compiler and runtime that lowers Machine Learning (ML) models to a unified IR I\u2019m not exactly sure what IREE is doing. Overall, it takes an ML program and tries to transform it into scheduling and computation modules run on various hardware components. The bottom right part is interesting. You can see that it can lower onto the LLVM IR, further generating codes for various CPUs; it can also lower onto SPIR-V IR, a special IR defined for GPUs. I\u2019m not sure what VMVX is. Example 3: LLVM CIRCT \u00b6 CIRCT\u2019s inputs: Chisel\u2019s FIRRTL MLIR\u2019s output CIRCT\u2019s outputs: Verilog C++? TCL? CIRCT Charter - CIRCT https://llvm.org/devmtg/2021-11/slides/2021-CIRCT-LiftingHardwareDevOutOfThe20thCentury.pdf CIRCT implements its own FIRRTL parser, so it can take an FIR file to generate RTL Other than that, CIRCT could also take MLIR outputs to generate RTL. Apparently, CIRCT also uses the Dialects concepts. Example 4: TensorFlow/PyTorch with MLIR \u00b6 Torch-MLIR: https://github.com/llvm/torch-mlir It compiles some Torch operations into a newly defined torch-dialect in MLIR. Within MLIR, the torch-dialect is further lowered onto built-in dialects such as affine https://github.com/llvm/torch-mlir/blob/main/Torch-MLIR.png Example 5: ScaleHLS, HPCA\u201922 \u00b6 https://github.com/hanchenye/scalehls https://raw.githubusercontent.com/hanchenye/scalehls/master/docs/ScaleHLS.svg The whole system is implemented on top of MLIR. They introduced a new HLSCPP dialect. They take HLS C programs, or TORCH/ONNX graph-level programs, then produce highly-optimized HLS C/C++ programs. It is a very interesting read. The following image shows its workflow. My thought: I think we will continue seeing more MLIR-based solutions to help DSA development. It\u2019ll be interesting to see some higher-level, or higher-order primitives constructed in MLIR to help, say, FPGA-based SQL develpoment (or rather, any types of FPGA-based computations). In general, MLIR helps to raise the abstrantion, hence we are able to raise the programmability futher. Example 6: EQueue, HPCA\u201822 \u00b6 Compiler-Driven Simulation of Reconfigurable Hardware Accelerators, HPCA\u201822. The goal is to help simulation. Add a new dialect in MLIR to model different accelerators. There are two general approaches to do simulation: 1) use RTL-level, which is very precise and also very slow. 2) use high-level simulators, sth like gem5. Fast, but is far away from hardware. The goal of this paper is to use MLIR to build sth in the middle. It introduces a new dialect IR, which can describe various accelerator structure (e.g., how many processors, memory, DMA engines etc). Since MLIR can lower IR, their system can model the accelerator at different levels. On one extreme, they can do very high-level simulation (probably just use their new IR). On the other extreme, they can lower their IR to be close to actual hardware. Check their Fig3-Fig5 to understand how they can model different accelerators! Example 7: Pathways, Google \u00b6 The paper is Pathways: Asynchronous Distributed Dataflow For ML, arXiv\u201822 From the paper: \u201cSec 4.2: The client then constructs a device location-agnostic PATHWAYS intermediate representation (IR) for the program, expressed as a custom MLIR (Lattner et al., 2021) dialect. The IR is progressively \u201clowered\u201d via a series of standard compiler passes, which eventually output a low-level representation that includes the physical device locations. This low-level program takes into account the network connectivity between physical devices and includes operations to transfer outputs from a source computation shard to the locations of its destination shards, including scatter and gather operations when a data exchange is required.\u201d Misc \u00b6 Alpa, arXiv\u201821 proposes a set of methods to partition an ML training process to best utilize pipeline, data, model parallelism. This seems to be the first one doing all 3 at once. There are, of course, similar papers in the past doing 2 out of 3 (a paper from the Stanford folks). TVM IP stuff is also highly related. General PL Related Readings \u00b6 Saw this paper on twitter today (03/25/2022). It won the ICSE influential award. https://people.inf.ethz.ch/suz/publications/natural.pdf","title":"What is MLIR?"},{"location":"notes/MLIR/#mlir","text":"Version History Date Description Jul 3, 2022 Add Pathways Apr 2, 2022 Ported from Craft. Recently, I switched to Craft for technical writing. I\u2019m very happy I made that transition. Craft is great at exporting things to Markdown format. This document is organized as follows. MLIR at 10,000 feet - an overview. Why MLIR was created? - a study of the original MLIR paper. How MLIR is used in the wild? - case studies. Without further ado, let\u2019s get started.","title":"MLIR"},{"location":"notes/MLIR/#mlir-at-10000-feet","text":"MLIR is short for Multi-Level Intermediate Representation. MLIR helps to build reusage compiler infrastructure and reduce duplicate codes. I draw the following figure to show MLIR\u2019s workflow at a very high level. In specific: MLIR\u2019s input: applications, compilers, C program, etc Within MLIR, we can implement multiple Dialects for distinct inputs. For instance, we could use a Dialect to deal with tensors. Further, we can deploy a shared optimization layer to unify things. Once we have an optimal IR, MLIR can now lower it onto the backends such as LLVM for CPUs, CIRCT for FPGAs. If you are targeting specialized hardware such as FPGA or TPU, you still need vendor-tools for final compilation (e.g., use Vivado to synthesis Verilog).","title":"MLIR At 10,000 Feet"},{"location":"notes/MLIR/#resources","text":"I have found several excellent primer readings. LLVM Paper from Google, 2020 . This paper describes the rationale behind MLIR. Chris L is one of the authord. LLVM MLIR Tutorial I didn\u2019t understand this image when I first read it. But now it all makes sense. MLIR is something that lies across language AST and LLVM IR. ScaleHLS, HPCA\u201822 can compile HLS C/C++ or PyTorch model to optimized HLS C/C++ using MLIR.","title":"Resources"},{"location":"notes/MLIR/#motivation-from-the-google-mlir-paper","text":"This is a really nice Intro , pay close attention to how they lay out the storyline. If you are new to PL just like me, I strongly recommend going through the MLIR Toy Example (covered below ) for a better understanding, and then come back, read through this again. A common characteristic of popular ML systems is their \u201cone size \ufb01ts all\u201d approach\u2014a single abstraction level to interface with the system: the LLVM Intermediate Representation (IR) is roughly \u201cC with vectors\u201d, and JVM provides an \u201cobject-oriented type system with a garbage collector\u201d abstraction. This \u201cone size \ufb01ts all\u201d approach is incredibly valuable\u2014and in practice, the mapping to these domains from ubiquitous source languages (C/C++ and Java respectively) is straightforward. ( Praise the unified LLVM IR ) At the same time, many problems are better modeled at a higher- or lower-level abstraction, e.g. source-level analysis of C++ code is very dif\ufb01cult on LLVM IR. We observe that many languages (including e.g. Swift, Rust, Julia, Fortran) develop their own IR in order to solve domain-speci\ufb01c problems, like language/library-speci\ufb01c optimizations, \ufb02ow-sensitive type checking. Similarly, machine learning systems typically use \u201cML graphs\u201d as a domain-speci\ufb01c abstraction in the same way. ( Point out the issues about LLVM IR ) While the development of domain speci\ufb01c IRs is a well studied art, their engineering and implementation cost remains high. \u2026 this can lead to lower quality compiler systems. ( Point out that developing customized IR framework is challenging ) The MLIR project aims to directly tackle these programming language design and implementation challenges\u2014by making it very cheap to de\ufb01ne and introduce new abstraction levels, and provide \u201cin the box\u201d infrastructure to solve common compiler engineering problems. MLIR does this by standardizing the Static Single Assignment (SSA)-based IR data structures providing a declarative system for de\ufb01ning IR dialects (demonstrated below using the Toy example) providing a wide range of common infrastructure (including documentation, parsing and printing logic, location tracking, multithreaded compilation support, pass management, etc). This image shows that most high-level languages have their own AST and associated infrastructure for transforming etc. Though language-specific, these are modules doing similar things. MLIR is a general framework to facilitate the development of such language-specific modules. It allows developers to use a unified codebase/framework to do their optimizations and develop some common, shared optimizations for multiple inputs. I recommend reading Toy Example Tutorial for a deep understanding. This image is MLIR\u2019s original motivation. They found that ML graphs have a lot of different compilers. The compilation process is fragmented and some compilers are not following the best practices.","title":"Motivation from the Google MLIR Paper"},{"location":"notes/MLIR/#case-studies","text":"","title":"Case Studies"},{"location":"notes/MLIR/#example-1-mlir-toy-example","text":"While reading through its documentation, I\u2019m starting to get a sense of what problem MLIR is trying to solve. The MLIR paper for sure describes the problem at a high level, but being able to read through the code example and its documentation helps a lot. The following quote is the same motivation described in the MLIR paper. Other compilers, like LLVM (see the Kaleidoscope tutorial ), offer a fixed set of predefined types and (usually low-level / RISC-like) instructions. It is up to the frontend for a given language to perform any language-specific type-checking, analysis, or transformation before emitting LLVM IR. <- also mentioned in the MLIR paper. For example, Clang will use its AST to perform not only static analysis but also transformations, such as C++ template instantiation through AST cloning and rewrite. Finally, languages with construction at a higher level than C/C++ may require non-trivial lowering from their AST to generate LLVM IR . Consequently, multiple frontends end up reimplementing significant pieces of infrastructure to support the need for these analyses and transformations . MLIR addresses this issue by being designed for extensibility. There are few pre-defined instructions ( operations in MLIR terminology) or types. Like C, Swift, Rust, etc., each language has its own AST optimizers that do some language-specific transformations and analysis. This is quite tedious to do. So: MLIR is designed to allow all IR elements, such as attributes, operations, and types, to be customized. At the same time, IR elements can always be reduced to the above fundamental concepts. This allows MLIR to parse, represent, and round-trip ** IR for any operation.** This is EXACTLY what I want to say for the APSys submission. Through dialects, MLIR allows for the representation of many different levels of abstraction; the Toy dialect that we have previously defined is one such example. Though these different dialects may represent different abstractions, there is often a set of common transformations and analyses that we would like to perform. The blog builds the Toy Example following these steps : It first defines the semantics of this toy language and some simple operations. It then defines an IR for the Toy language in an MLIR dialect. MLIR can transform the source code into its internal IR using the above dialect. It then performs \u201c High-level Language-Specific Analysis and Transformation \u201d and other optimizations on the generated IR within MLIR. The transformations are pretty straightforward, such as eliminating duplicated ops. These optimizations, however, would be difficult for LLVM to carry out. It then discussed an MLIR internal interface infrastructure that facilitates the above transformations. The rationale is that most transformations used by distinct languages are similar, hence a framework can reduce code duplication and also allow developers to design a set of shared common optimizations/passes. Then, the interesting part. It converts this Dialect into other MLIR built-in dialects (e.g., affine, arithmetic), thereby lowering the toy Dialect into more concrete memory accesses, and arithmetic ops, etc. Finally, it again lowers the above partially-lowered IR onto the LLVM IR. Once we are here, we can invoke LLVM to generate code (e.g., for x86 or ARM CPUs) or run with the LLVM JIT. Of course, instead of lowering it onto the LLVM IR, one can also lower it onto another IR, e.g., TPU IR (what TensorFlow does). My understanding MLIR is a generic framework that allows you to define your customized IR using MLIR\u2019s generic primitives (i.e., an indirection layer). From MLIR\u2019s perspective, your IR is just one of the many dialects it supports. More importantly, a dialect can fully or partially convert into other dialects. For instance, if you convert your IR into the LLVM IR, you can immediately take advantage of the LLVM\u2019s code-generation framework for CPUs. If you convert your IR into the TPU IR, you can then generate code running on TPUs. Say I want to build some P4 or FPGA stuff using MLIR, I would do : I would first define a language model together with a new IR using MLIR primitives. Then, within MLIR, I would do all sorts of language-specific optimizations, transformations, etc. I can also do some conversions among other dialects. After all that, say I\u2019ve got an optimized IR. What should I do next? I cannot fully lower it to the LLVM IR, because there is no P4/FPGA backend in the LLVM framework. If I target FPGA, I could generate FIRRTL, which is the input of CIRCIT or Chisel . If I target P4, I could generate the MLIR IR into something like a P4 IR/backend, which then will do vendor-specific compilation into deployable binaries. Is this P4 IR thing already part of the p4 compiler chain? If so, why should I go through all this trouble adding a new MLIR dialect, why not directly use the p4 compile chain? What benefits are we getting out of MLIR though? Answer: we will benefit from MLIR only if we are targeting multiple backends at the same time, thus we can share the same optimization infrastructure. In specific, one piece of code can run on top of a set of heterogeneous devices. All the optimizations are nicely done within the MLIR layer.","title":"Example 1: MLIR Toy Example"},{"location":"notes/MLIR/#example-2-google-iree","text":"IREE IREE (**I**ntermediate **R**epresentation **E**xecution **E**nvironment 1 ) is an MLIR -based end-to-end compiler and runtime that lowers Machine Learning (ML) models to a unified IR I\u2019m not exactly sure what IREE is doing. Overall, it takes an ML program and tries to transform it into scheduling and computation modules run on various hardware components. The bottom right part is interesting. You can see that it can lower onto the LLVM IR, further generating codes for various CPUs; it can also lower onto SPIR-V IR, a special IR defined for GPUs. I\u2019m not sure what VMVX is.","title":"Example 2: Google IREE"},{"location":"notes/MLIR/#example-3-llvm-circt","text":"CIRCT\u2019s inputs: Chisel\u2019s FIRRTL MLIR\u2019s output CIRCT\u2019s outputs: Verilog C++? TCL? CIRCT Charter - CIRCT https://llvm.org/devmtg/2021-11/slides/2021-CIRCT-LiftingHardwareDevOutOfThe20thCentury.pdf CIRCT implements its own FIRRTL parser, so it can take an FIR file to generate RTL Other than that, CIRCT could also take MLIR outputs to generate RTL. Apparently, CIRCT also uses the Dialects concepts.","title":"Example 3: LLVM CIRCT"},{"location":"notes/MLIR/#example-4-tensorflowpytorch-with-mlir","text":"Torch-MLIR: https://github.com/llvm/torch-mlir It compiles some Torch operations into a newly defined torch-dialect in MLIR. Within MLIR, the torch-dialect is further lowered onto built-in dialects such as affine https://github.com/llvm/torch-mlir/blob/main/Torch-MLIR.png","title":"Example 4: TensorFlow/PyTorch with MLIR"},{"location":"notes/MLIR/#example-5-scalehls-hpca22","text":"https://github.com/hanchenye/scalehls https://raw.githubusercontent.com/hanchenye/scalehls/master/docs/ScaleHLS.svg The whole system is implemented on top of MLIR. They introduced a new HLSCPP dialect. They take HLS C programs, or TORCH/ONNX graph-level programs, then produce highly-optimized HLS C/C++ programs. It is a very interesting read. The following image shows its workflow. My thought: I think we will continue seeing more MLIR-based solutions to help DSA development. It\u2019ll be interesting to see some higher-level, or higher-order primitives constructed in MLIR to help, say, FPGA-based SQL develpoment (or rather, any types of FPGA-based computations). In general, MLIR helps to raise the abstrantion, hence we are able to raise the programmability futher.","title":"Example 5: ScaleHLS, HPCA\u201922"},{"location":"notes/MLIR/#example-6-equeue-hpca22","text":"Compiler-Driven Simulation of Reconfigurable Hardware Accelerators, HPCA\u201822. The goal is to help simulation. Add a new dialect in MLIR to model different accelerators. There are two general approaches to do simulation: 1) use RTL-level, which is very precise and also very slow. 2) use high-level simulators, sth like gem5. Fast, but is far away from hardware. The goal of this paper is to use MLIR to build sth in the middle. It introduces a new dialect IR, which can describe various accelerator structure (e.g., how many processors, memory, DMA engines etc). Since MLIR can lower IR, their system can model the accelerator at different levels. On one extreme, they can do very high-level simulation (probably just use their new IR). On the other extreme, they can lower their IR to be close to actual hardware. Check their Fig3-Fig5 to understand how they can model different accelerators!","title":"Example 6: EQueue, HPCA'22"},{"location":"notes/MLIR/#example-7-pathways-google","text":"The paper is Pathways: Asynchronous Distributed Dataflow For ML, arXiv\u201822 From the paper: \u201cSec 4.2: The client then constructs a device location-agnostic PATHWAYS intermediate representation (IR) for the program, expressed as a custom MLIR (Lattner et al., 2021) dialect. The IR is progressively \u201clowered\u201d via a series of standard compiler passes, which eventually output a low-level representation that includes the physical device locations. This low-level program takes into account the network connectivity between physical devices and includes operations to transfer outputs from a source computation shard to the locations of its destination shards, including scatter and gather operations when a data exchange is required.\u201d","title":"Example 7: Pathways, Google"},{"location":"notes/MLIR/#misc","text":"Alpa, arXiv\u201821 proposes a set of methods to partition an ML training process to best utilize pipeline, data, model parallelism. This seems to be the first one doing all 3 at once. There are, of course, similar papers in the past doing 2 out of 3 (a paper from the Stanford folks). TVM IP stuff is also highly related.","title":"Misc"},{"location":"notes/MLIR/#general-pl-related-readings","text":"Saw this paper on twitter today (03/25/2022). It won the ICSE influential award. https://people.inf.ethz.ch/suz/publications/natural.pdf","title":"General PL Related Readings"},{"location":"notes/arch/","text":"Architecture \u00b6 Version History Date Description Dec 30, 2020 Initial This is my personal notes on architecture related topics. Cache Coherence \u00b6 See the Practical Cache Coherence blog. Reservation Station and ROB \u00b6 They serve different purposes. ROB can not replace reservation station. ROB records all instructions and their control information, their order. An instruction will alloc an ROB entry alive when it enters execution enegine and free the entry when it finally able to commit. An instruction will alloc an reservation station entry when it enters execution engine, just like ROB. But it will free the entry when the functional unit finished execution. Essentially, the ROB entry outlives the reservation station entry. This is why the number of ROB entries is larger than the number of reservation station entries. E.g., in Skylake, there are 224 ROB entries, and 97 reservation static entries. One thing I notice is that there is still a Comman Data Bus (CDB) connecting the output of execution engines to the reservation station and ROB. Image Physical Register Files and ROB \u00b6 When we add speculation to traditional Tomasulo, we will add a ROB table. Each entry in ROB has an attached buffer. Like reservation station (RS), ROB can also store and forward results. Physical register file is a separate unit. With it, the ROB no longer needs to store/forward data. We only need a renaming table to manage the mapping. The benefit of using a separate physical register file over ROB-with-buffer is that we can greatly reduce data movement. The ROB no longer needs write back data to register file, it will be stored when the computing unit produces it. Distributed v.s. Centralized Reservation Station \u00b6 Textbook Tomasulo uses distributed reservation station , each functional unit has its own attached RS entries. Some old CPUs like PowerPC 604, Pentium 4 and newer generation CPUs like AMD Zen series, RISCV-BOOM are using the distributed reservation station design. Regarding AMD Zen, the architecture figure shows there are 6 small schedulers within the Integer execution pipeline, each with 14 entries, so in total 84 entries. It appears each scheduler is used exclusively by one execution port, but the forwarding muxes below confuses me. This mux maybe able to distribute work across different ports thereby overtime resource fragmentation issue of distributed reservation station approach? Not sure how exactly it is designed. On the contray, recent Intel CPUs are all using centralized reservation station design. There is one giant unified reservation station, or scheduler in Intel\u2019s wording, working for all functional units. E.g., in Skylake , this scheduler has 96 entries, meaning there can be 96 instructions currently being executed by functional units (The number of ROB entries is larger than this number, because ROB still cache info for already excuted but uncommitted instructions). I don\u2019t really know the actual practical trade-off among these two choices. My guess for centralized v.s. distributed reservation station trade-offs are: For centralized design, the RS is not statically partitioned like the distributed design. So the RS usage can adapt to workloads to avoid some blocking. Centralized design for sure has more complex control logic and more challenging to implement! Centralized Reservation Station (Intel Skylake): Distributed Reservation Station (AMD Zen): Further Reading \u00b6 Intel optimization manual Wikichips Agner Fog\u2019s optimization manuals (the microarchitecture one)","title":"Architecture"},{"location":"notes/arch/#architecture","text":"Version History Date Description Dec 30, 2020 Initial This is my personal notes on architecture related topics.","title":"Architecture"},{"location":"notes/arch/#cache-coherence","text":"See the Practical Cache Coherence blog.","title":"Cache Coherence"},{"location":"notes/arch/#reservation-station-and-rob","text":"They serve different purposes. ROB can not replace reservation station. ROB records all instructions and their control information, their order. An instruction will alloc an ROB entry alive when it enters execution enegine and free the entry when it finally able to commit. An instruction will alloc an reservation station entry when it enters execution engine, just like ROB. But it will free the entry when the functional unit finished execution. Essentially, the ROB entry outlives the reservation station entry. This is why the number of ROB entries is larger than the number of reservation station entries. E.g., in Skylake, there are 224 ROB entries, and 97 reservation static entries. One thing I notice is that there is still a Comman Data Bus (CDB) connecting the output of execution engines to the reservation station and ROB. Image","title":"Reservation Station and ROB"},{"location":"notes/arch/#physical-register-files-and-rob","text":"When we add speculation to traditional Tomasulo, we will add a ROB table. Each entry in ROB has an attached buffer. Like reservation station (RS), ROB can also store and forward results. Physical register file is a separate unit. With it, the ROB no longer needs to store/forward data. We only need a renaming table to manage the mapping. The benefit of using a separate physical register file over ROB-with-buffer is that we can greatly reduce data movement. The ROB no longer needs write back data to register file, it will be stored when the computing unit produces it.","title":"Physical Register Files and ROB"},{"location":"notes/arch/#distributed-vs-centralized-reservation-station","text":"Textbook Tomasulo uses distributed reservation station , each functional unit has its own attached RS entries. Some old CPUs like PowerPC 604, Pentium 4 and newer generation CPUs like AMD Zen series, RISCV-BOOM are using the distributed reservation station design. Regarding AMD Zen, the architecture figure shows there are 6 small schedulers within the Integer execution pipeline, each with 14 entries, so in total 84 entries. It appears each scheduler is used exclusively by one execution port, but the forwarding muxes below confuses me. This mux maybe able to distribute work across different ports thereby overtime resource fragmentation issue of distributed reservation station approach? Not sure how exactly it is designed. On the contray, recent Intel CPUs are all using centralized reservation station design. There is one giant unified reservation station, or scheduler in Intel\u2019s wording, working for all functional units. E.g., in Skylake , this scheduler has 96 entries, meaning there can be 96 instructions currently being executed by functional units (The number of ROB entries is larger than this number, because ROB still cache info for already excuted but uncommitted instructions). I don\u2019t really know the actual practical trade-off among these two choices. My guess for centralized v.s. distributed reservation station trade-offs are: For centralized design, the RS is not statically partitioned like the distributed design. So the RS usage can adapt to workloads to avoid some blocking. Centralized design for sure has more complex control logic and more challenging to implement! Centralized Reservation Station (Intel Skylake): Distributed Reservation Station (AMD Zen):","title":"Distributed v.s. Centralized Reservation Station"},{"location":"notes/arch/#further-reading","text":"Intel optimization manual Wikichips Agner Fog\u2019s optimization manuals (the microarchitecture one)","title":"Further Reading"},{"location":"notes/aws-nitro/","text":"","title":"Aws nitro"},{"location":"notes/benchmark/","text":"Benchmarks \u00b6 Version History Date Description Apr 2, 2020 Update Aug 13, 2019 Update Aug 03, 2019 Initial draft Areas \u00b6 Synchronization/Concurrency Community \u00b6 Phoenix HPCA (heavy mmap/munmap, i.e., mm-sem usage) MOSBENCH/Metis (same as Phoenix) LevelDB (a popular workload) Linux locktorture Filesystems (fs) LiTL, ATC\u201816, https://github.com/multicore-locks/litl References ShuffleLock, SOSP\u201819 Compact NUMA-aware Locks, EuroSys\u201819 fill me in OS \u00b6 will-it-scale lmbench sysbench FPGA \u00b6 Rosetta: A Realistic High-Level Synthesis Benchmark Suite for Software Programmable FPGAs, FPGA\u201818 AmophOS has a lot more. Misc Information \u00b6 Systems Benchmarking Crimes","title":"Benchmarks"},{"location":"notes/benchmark/#benchmarks","text":"Version History Date Description Apr 2, 2020 Update Aug 13, 2019 Update Aug 03, 2019 Initial draft","title":"Benchmarks"},{"location":"notes/benchmark/#areas","text":"","title":"Areas"},{"location":"notes/benchmark/#synchronizationconcurrency-community","text":"Phoenix HPCA (heavy mmap/munmap, i.e., mm-sem usage) MOSBENCH/Metis (same as Phoenix) LevelDB (a popular workload) Linux locktorture Filesystems (fs) LiTL, ATC\u201816, https://github.com/multicore-locks/litl References ShuffleLock, SOSP\u201819 Compact NUMA-aware Locks, EuroSys\u201819 fill me in","title":"Synchronization/Concurrency Community"},{"location":"notes/benchmark/#os","text":"will-it-scale lmbench sysbench","title":"OS"},{"location":"notes/benchmark/#fpga","text":"Rosetta: A Realistic High-Level Synthesis Benchmark Suite for Software Programmable FPGAs, FPGA\u201818 AmophOS has a lot more.","title":"FPGA"},{"location":"notes/benchmark/#misc-information","text":"Systems Benchmarking Crimes","title":"Misc Information"},{"location":"notes/cache_coherence/","text":"Practical Cache Coherence \u00b6 Version History Date Description Jul 2, 2021 add implication discussion Feb 24, 2020 Kobe and Gigi. Add Intel CCIP. Oct 3, 2019 Add FPGA related discussion Jun 28, 2019 Initial draft Practical Cache Coherence Summary and Thoughs Implication for Synchronization Implication for On-Chip Bandwidth and NUMA Readings Case Study Intel AMD ARM OpenCAPI and CCIX CXL OpenPiton FPGA Formal Verification TL;DR. This is a note on how cache coherence protocols are implemented in real hardware. This note is NOT just about acadamic new ideas. I started this when I was having a hard time optimizing lock delegation , which relies on fine-tuning cache coherence to achieve extremely fast locks. Summary and Thoughs \u00b6 The textbooks tough us the basic concept of MESI. And specific algorithms like snoop and directory. What usually missing is the implementation details when it comes to: 1) how to solve conflicts, 2) what if there is no single shared bus. Modern processors have Network-on-Chip (NoC) . Within the die, cores, cache slices (large LLC is usually divided into slices), memory controllers and other components are connected via an on-chip network (e.g., a ring in old-generation Xeon, or a mesh in Xeon Scalable). This architecture is no different from connecting a set of distributed servers. The NoC has its own protocol (I guess ranging from L1 to L3, must be reliable data delivery). And all on-chip components communicate by sending/receiving packets. There is no central coordinator. What this means for cache coherence? Cache requests generated by MESI protocols should appear atomic to requesting cores. Given the distributed nature of all resources (via NoC), those cache requests are implemented like distributed transactions ! This brings great complexity to a performant and correct cache coherence implementation. Hardware is much much faster than a set of distributed nodes. Besides, it cannot implement arbitrary logic, whatever protocol they design has a tight time budget. For example, Intel uses the MESIF cache coherence protocol. In their implementation, when a core made a read to an invalid line, the corresponding cache will perform a cache read transaction to get the data from either other caches or memory. This transaction consists of multiple steps, such as: send requests, collect responses, and finally send ACKs. Those transactions will conflict if multiple reads and writes happen at the same time. Someone has to resolve it . It can be resolved by different cache controllers, or by a single serialization point like home agent. Just like you can have many ways to implement transactions for distributed systems, there are also many ways to do cache coherence transactions. And there are many. Atomic Read-Modify-Write (RMW) instructions will make cache coherence implementations even more complex. Those instructions include read-and-inc , test-and-set , and lock; -prefixed. I think, there will some \u201clock the bus\u201d, or \u201clocked state\u201d at the home agent per cache line. Having atomic RMW instructions will add more complexity to the overall transaction design. While reading Intel related cache coherence diagrams/transactions, you might find many different descriptions. Don\u2019t panic. They are just different implementations proposed by Intel. Different implementations will have different trade-offs and performance, you can check Frank\u2019s post for more details. Directory-based cache coherence protocol and implementation will be the future for multicore machines. Because it incurs much less coherence traffic than snoop-based ones, thus more scalable. The trend is confirmed by recent Intel UPI directory-based approach. Related readings: [1]: Why On-Chip Cache Coherence Is Here to Stay [2]: QPI 1.1 Invovled [3]: Paper: Multicast Snooping: A New Coherence Method Using a Multicast Address Network, ISCA \u201899 [4]: Paper: Using Destination-Set Prediction to Improve the Latency/Bandwidth Tradeoff in Shared-Memory Multiprocessors, ISCA\u201803 [5]: The trade-off: Left questions: - Do cache coherence implementations ensure fairness among cores? Implication for Synchronization \u00b6 Synchronization code (e.g., locking code) has deep relation with cache coherence and memory consistency. A lot optimizations are playing with certain cache coherence protocols. For example, a locking primitive may want to first read the lock then try to atomically change its value. By doing so, the first read will not trigger any cache invalidation to other cores, hence save latency and on-chip bandwidth. As for memory consistency, it affects how many barriers should be inserted and whether a release/acquire semantic should be used. Anyway, if you are implementing synchronization primitive, pay attention to cache coherence. Read the discussion posted by Dr. Bandwidth, especially this one on cache coherence flows on a procuder-consumer case . It is very useful if you are trying to implement high-performance spinlocks and concurrency data structures. Implication for On-Chip Bandwidth and NUMA \u00b6 Cache coherence consumes a LOT on-chip bandwidth. Think about all the messages it will send for a single transation. And this transaction can be easily triggered by normal read/write. So the cache coherent protocol end up using a lot on-chip bandwidth. This is problematic for two reasons: a) the NoC bus/ring is shared. It will affect other traffic hence performance. b) In a NUMA architecture, the interconnection between CPU dies is responsible for a lot things like data transfer, cache coherence traffic, and other misc traffic. If cache coherence uses a lot, there is little room for others. Many have complained this. So what\u2019s the mitigation? The first try is to move from Snoop to Directory so to avoid excessive traffic. Some sort of centralized coordinator could resolve conflicts therefore save tons of traffic. Intel\u2019s cache coherence protocol has involved for this direction as well. Other measures? I don\u2019t know. Readings \u00b6 The Architecture of the Nehalem Processor and Nehalem-EP SMP Platforms , chapter 5.2 Cache-Coherence Protocol for Multi-Processors. Intel: Performance Analysis Guide for Intel\u00ae Core\u2122 i7 Processor and Intel\u00ae Xeon\u2122 5500 processors Dr.Bandwidth on Core2Core cache coherence flows when running producer-consumer type of workload. . 100% recommended. Blog: NUMA Deep Dive Part 3: Cache Coherency The BEST blog I\u2019ve seen on the topic of Intel snoop models . Intel is using MESIF cache coherence protocol, but it has multiple cache coherence implementations. The first one is Source Snoop (or Early Snoop ), which is more like a traditional snoop-based cache coherence implementation. Upon miss, the caching agent will broadcast to other agents. The second one is Home Snoop , which is more like a directory-based cache coherence implementation. Upon miss, the caching agent will contact home agent, and then the home agent will send requests to other caching agents who have the requested cache line. There are other implementations like Cluster-on-Die. Intel UPI gets rid of all this complexity, it is only using directory-based, in the hope to reduce cache coherence traffic, which make sense. Related: Broadwell EP Snoop Models Related: Skylay UPI Paper: MESIF: A Two-Hop Cache Coherency Protocol for Point-to-Point Interconnects (2009)__ A MUST read. This paper has the most extensive description of the MESIF protocol implementation. It has many timing diagrams than describe how cache requests actually proceed. Those diagrams can help us understand what is needed to finish a cache request. Their slides has more timing diagrams. But do note: the implementation described by this paper is different from what Intel QPI has in products. The difference is discussed at chapter 4. MESIF and QPI, namely, other caching agents will send responses to Home agent rather than to requesting agent. QPI relies on Home agent to solve conflict. Also note: this is just one of the possible implementations to realize MESIF protocol. There could be many other ways, e.g., QPI source snooping, QPI home snooping. But all of them share the essential and general concepts and ideas. Appendix I: Large-Scale Multiprocessors and Scientific Applications , chapter 7 Implementing Cache Coherence. This is probably some most insightful discussion about real implementation of cache coherence. With the distributed nature and Network-on-Chip, implementing cache coherence in modern processors is no different than implementing a distributed transaction protocol. Cache activities like read miss or write miss have multi-step operations, but they need to appear as \u201catomic\u201d to users. Put in another way, misses are like transactions, they have multiple steps but they must be atomic. They can be retried. Having directory for cache coherence will make implementation easier. Because the place (e.g., L3) where directory resides can serve as the serialization point. They can solve write races. Home directory controller and cache controller will exchange messages like a set of distributed machines. In fact, with NoC, they are actually distributed system. Intel: An Introduction to the Intel\u00ae QuickPath Interconnect , page 15 MESIF. HotChips slide , has timing diagrams. It explains the Home Snoop and Source Snoop used by Intel. Based on their explanation, it seems both Home Snoop and Source Snoop are using a combination of snoop and directory. The Processor#4 (pg 17 and 18) maintains the directory. And this is a perfect demonstration of the details described in Appendix I: Large-Scale Multiprocessors and Scientific Applications . Related patent: Extending a cache coherency snoop broadcast protocol with directory information Paper: Multicast Snooping: A New Coherence Method Using a Multicast Address Network, ISCA \u201899 A hybrid snoop and directory cache coherence implementation. The insight is snoop cause too much bandwidth, directory incurs longer latency. So this paper proposed Multicast snoop , where it multicasts coherence transactions to selected processors, lowering the address bandwidth required for snooping. Paper: Why On-Chip Cache Coherence Is Here to Stay, Communications of ACM\u201802 This paper discusses why cache coherence can scale. A nice read. R1: Coherence\u2019s interconnection network traffic per miss scales when precisely tracking sharers. (Okay increased directory bits, what about those storage cost? See R2). R2: Hierarchy combined with inclusion enables efficient scaling of the storage cost for exact encoding of sharers. R3: private evictions should send explicit messages to shared cache to enable precise tracking. Thus the recall ( back invalidation ) traffic can be reduced when shared cache is evicting (assume inclusion cache). R4: Latencies of cache request can be amortized. Book: Parallel Computer Organization and Design , Chapter 7. Links coherence and consistency together. This chapter uses detailed graphs to show how different cache coherence implementations affect consistency. Book: A Primer on Memory Consistency and Cache Coherence Best book for this topic. Dr.Bandwidth on explaining core-to-core communication transactions! Seriously, it\u2019s so good! Although, I just feel there are so many unpublished details about the exact coherence transactions. Dr.Bandwidth himself used a lot \u201cmaybe\u201d, and listed possible actions. Transactional Memory Coherence and Consistency, ISCA\u201804 Programming with Transactional Coherence and Consistency (TCC) Slide1 Awarded the most influential paper at ISCA 2019. I took a read today (Jul 21, 2019). I feels like it\u2019s using the \u201cbatch\u201d optimization for all time. The TCC design, kind of combines both cache coherence and memory consistency: how transactions commit or orders, determins the coherence and consistency. It seems the load/store speculative execution used in their context is so similar to what Dr.Bandwidth said about Intel\u2019s implementation. Basically, the processor might read some data from L1/L2 and continue execution, but there is a chance, that the data is modifed by others, and the L3 caching agent or home agent could decide to revoke it. Once receiving such revoke message, the processor must cancel all executions that use the speculatively read data. It mentions couple Thread-Level Speculation papers, I think they should on this topic. Case Study \u00b6 Intel \u00b6 Misc Facts. Intel Caching Agent (Cbox) is per core (or per LLC slice). Intel Home Agent is per memory controller. \u201cThe LLC coherence engine (CBo) manages the interface between the core and the last level cache (LLC). All core transactions that access the LLC are directed from the core to a CBo via the ring interconnect. The CBo is responsible for managing data delivery from the LLC to the requesting core. It is also responsible for maintaining coherence between the cores within the socket that share the LLC; generating snoops and collecting snoop responses from the local cores when the MESIF protocol requires it.\u201d \u201cEvery physical memory address in the system is uniquely associated with a single Cbox instance via a proprietary hashing algorithm that is designed to keep the distribution of traffic across the CBox instances relatively uniform for a wide range of possible address patterns.\u201d Read more here, chapter 2.3 . Starting from Intel UPI, Caching Agent and Home Agent are combined as CHA. A good discussion about why QPI gradually drop Source Snoop and solely use Home Snoop . The motivation is scalability. It turns out the new UPI only supports directory-based protocol. This makes sense because 1) inter socket bandwidth is precious, 2) snoop will consume a lot bandwidth. Intel UPI is using directory-based home snoop coherency protocol Intel\u00ae Xeon\u00ae Processor Scalable Family Technical Overview To provide sufficient bandwidth, shared caches are typically interleaved by addresses with banks physically distributed across the chip. A Transaction Breakdown. Intel does not disclose too much details about their cache coherence implementations. The most valuable information is extracted from uncore PMU manuals, and discussions from Dr. Bandwidth. According to Dr. Bandwidth, the Intel CPU could dynamically adapt its coherence strategy during runtime according to workload. There won\u2019t be one fixed cache coherence implementation, there will be many. It depends on workload which one is used at runtime. What happens when a core tries to access a cache line? A detailed cache protocl breakdown derived from Dr.Bandwidth\u2019s comment. Physical addresses are uniquely hashed into L3 slices. That means each individual physical address belongs to a L3 slice, and also belongs to a home agent. Upon L2 miss, it will send requests to corresponding L3 slice. If the L3 slice is in the local socket, the request can be delievered within the same socket. If the L3 slice belongs to another remote socket, the L2 miss request will be sent over QPI/UPI. Also note that the L2 controller will not send snoop requests. (This is answering the question of \u201cwhy using local memory is faster than remote\u201d from the cache coherence perspective.) At L3, when received the request from a L2, If it\u2019s in source snoop model, it will send snoop messages to other sockets. If it\u2019s in home snoop model, it will send read message to other sockets. The another socket will generate snoop and collect responses. (R3QPI or home?) Quote Dr. Bandwidth: Maintaining consistency is easier if the data is sent to the L3 first, and then to the requesting core, but it is also possible to send to both at the same time (e.g., \u201cDirect2Core\u201d). In recent processors, these return paths are chosen dynamically based on undocumented states and settings of the processor. I\u2019m not sure who will ACK L2 at last. L3 or home agent? Both are possible. I think both L3 and home agent have directory information. They know where to send snoop/read messages. And both of them can serialize coherence transactions! It\u2019s just undocumented who is doing what. In generall, we need to bear the fact that we cannot just figure out how Intel cache coherence works underlying. We maybe just need to \u201cvaguely\u201d know the fact that: Both directory and snoop will be used in combination. L3/home agent will serialize conflicting transactions L3/home agent will send data to requesting core L3/home agent will send final ACK to requesting L2 A coherence transaction is a multi-step distributed transaction. It involes sending requests, serialize conflicts, receiving responses/ACKs. Read the discussion posted by Dr. Bandwidth, especially this one on detailed cache coherence flows on a procuder-consumer case , which is essential if you are trying to implement high-performance spinlocks and concurrency data structures. AMD \u00b6 AMD HyperTransport Assit for Cache Coherence Slide Slide ARM \u00b6 AMBA CHI Specifications This is probabaly the most comprehensive document I\u2019ve ever seen about cache coherence. Although terms used by ARM differs from the ones used by Intel, still, you can map them. Chapter 5 Interconnect Protocol Flows has a lot timing diagrams regarding read/write/atomic coherence transactions. It\u2019s a good reference to know, but it would be hard to actually understand the details. OpenCAPI and CCIX \u00b6 CCIX White Paper OpenCAPI CXL \u00b6 Like OpenCAPI and CCIX, it builds on top of PCIe. It is intra-server cache coherence protocol. Not very exciting to me. But it does receive some spotlight recently. OpenPiton \u00b6 OpenPiton Microarchitecture Specification Directory-based MESI This spec has detailed coherence message packet format and type. Unfortunately, it does not say anything about how they deal with coherence transaction conflicts. E.g., some timeline diagrams like Figrue \u2154 in this paper . BYOC: A \u201cBring Your Own Core\u201d Framework for Heterogeneous-ISA Research, ASPLOS\u201820 FPGA \u00b6 Analysis and Optimization of I/O Cache Coherency Strategies for SoC-FPGA Device, FPL\u201819 LEAP Shared Memories: Automating the Construction of FPGA Coherent Memories, FCCM\u201814. This work is built on their earlier work, which basically add the data caching concept to FPGA: using BRAM as L1, on-board DRAM as L2, host or remote DRAM as L3. In their earlier work, each FPGA application (or bitstream) has a private L1 cache. In this work, the add MESI coherence to these private L1 caches, as in they can make multiple L1 cache cache-coherent. The techniques and protocols from this paper are similar to the exisiting ones. For example, 1) they use a global serializing point to serialize transactions, 2) they designed a lot messaging types such as INV, RESP and so on. VMware Research Project PBerry A very interesting and promising project. They have this follow up work \u201cRethinking software runtimes for disaggregated memory, ASPLOS\u201821\u201d. But it is simulation using the HotOS paper idea. The real FPGA has not been built yet. They need to know Intel\u2019s protocol to build it, which is.. impossible? I think it is probably better to use RISC-V. Intel FPGA PAC Intel itself is building a FPGA-CPU cache coherent setting. They use the Intel UPI interconnect to natually the spectrum. The FPGA shell has some modules to handle this. Intel FPGA CCIP Maybe the ASPLOS\u201820 Optimus paper is uing CCIP-related research platform? Also some pointer chasing related stuff A Study of Pointer-Chasing Performance on Shared-Memory Processor-FPGA Systems, FPGA\u201816 Formal Verification \u00b6 I remember there are couple works from Princiton doing cache protocol verification.","title":"Practical Cache Coherence"},{"location":"notes/cache_coherence/#practical-cache-coherence","text":"Version History Date Description Jul 2, 2021 add implication discussion Feb 24, 2020 Kobe and Gigi. Add Intel CCIP. Oct 3, 2019 Add FPGA related discussion Jun 28, 2019 Initial draft Practical Cache Coherence Summary and Thoughs Implication for Synchronization Implication for On-Chip Bandwidth and NUMA Readings Case Study Intel AMD ARM OpenCAPI and CCIX CXL OpenPiton FPGA Formal Verification TL;DR. This is a note on how cache coherence protocols are implemented in real hardware. This note is NOT just about acadamic new ideas. I started this when I was having a hard time optimizing lock delegation , which relies on fine-tuning cache coherence to achieve extremely fast locks.","title":"Practical Cache Coherence"},{"location":"notes/cache_coherence/#summary-and-thoughs","text":"The textbooks tough us the basic concept of MESI. And specific algorithms like snoop and directory. What usually missing is the implementation details when it comes to: 1) how to solve conflicts, 2) what if there is no single shared bus. Modern processors have Network-on-Chip (NoC) . Within the die, cores, cache slices (large LLC is usually divided into slices), memory controllers and other components are connected via an on-chip network (e.g., a ring in old-generation Xeon, or a mesh in Xeon Scalable). This architecture is no different from connecting a set of distributed servers. The NoC has its own protocol (I guess ranging from L1 to L3, must be reliable data delivery). And all on-chip components communicate by sending/receiving packets. There is no central coordinator. What this means for cache coherence? Cache requests generated by MESI protocols should appear atomic to requesting cores. Given the distributed nature of all resources (via NoC), those cache requests are implemented like distributed transactions ! This brings great complexity to a performant and correct cache coherence implementation. Hardware is much much faster than a set of distributed nodes. Besides, it cannot implement arbitrary logic, whatever protocol they design has a tight time budget. For example, Intel uses the MESIF cache coherence protocol. In their implementation, when a core made a read to an invalid line, the corresponding cache will perform a cache read transaction to get the data from either other caches or memory. This transaction consists of multiple steps, such as: send requests, collect responses, and finally send ACKs. Those transactions will conflict if multiple reads and writes happen at the same time. Someone has to resolve it . It can be resolved by different cache controllers, or by a single serialization point like home agent. Just like you can have many ways to implement transactions for distributed systems, there are also many ways to do cache coherence transactions. And there are many. Atomic Read-Modify-Write (RMW) instructions will make cache coherence implementations even more complex. Those instructions include read-and-inc , test-and-set , and lock; -prefixed. I think, there will some \u201clock the bus\u201d, or \u201clocked state\u201d at the home agent per cache line. Having atomic RMW instructions will add more complexity to the overall transaction design. While reading Intel related cache coherence diagrams/transactions, you might find many different descriptions. Don\u2019t panic. They are just different implementations proposed by Intel. Different implementations will have different trade-offs and performance, you can check Frank\u2019s post for more details. Directory-based cache coherence protocol and implementation will be the future for multicore machines. Because it incurs much less coherence traffic than snoop-based ones, thus more scalable. The trend is confirmed by recent Intel UPI directory-based approach. Related readings: [1]: Why On-Chip Cache Coherence Is Here to Stay [2]: QPI 1.1 Invovled [3]: Paper: Multicast Snooping: A New Coherence Method Using a Multicast Address Network, ISCA \u201899 [4]: Paper: Using Destination-Set Prediction to Improve the Latency/Bandwidth Tradeoff in Shared-Memory Multiprocessors, ISCA\u201803 [5]: The trade-off: Left questions: - Do cache coherence implementations ensure fairness among cores?","title":"Summary and Thoughs"},{"location":"notes/cache_coherence/#implication-for-synchronization","text":"Synchronization code (e.g., locking code) has deep relation with cache coherence and memory consistency. A lot optimizations are playing with certain cache coherence protocols. For example, a locking primitive may want to first read the lock then try to atomically change its value. By doing so, the first read will not trigger any cache invalidation to other cores, hence save latency and on-chip bandwidth. As for memory consistency, it affects how many barriers should be inserted and whether a release/acquire semantic should be used. Anyway, if you are implementing synchronization primitive, pay attention to cache coherence. Read the discussion posted by Dr. Bandwidth, especially this one on cache coherence flows on a procuder-consumer case . It is very useful if you are trying to implement high-performance spinlocks and concurrency data structures.","title":"Implication for Synchronization"},{"location":"notes/cache_coherence/#implication-for-on-chip-bandwidth-and-numa","text":"Cache coherence consumes a LOT on-chip bandwidth. Think about all the messages it will send for a single transation. And this transaction can be easily triggered by normal read/write. So the cache coherent protocol end up using a lot on-chip bandwidth. This is problematic for two reasons: a) the NoC bus/ring is shared. It will affect other traffic hence performance. b) In a NUMA architecture, the interconnection between CPU dies is responsible for a lot things like data transfer, cache coherence traffic, and other misc traffic. If cache coherence uses a lot, there is little room for others. Many have complained this. So what\u2019s the mitigation? The first try is to move from Snoop to Directory so to avoid excessive traffic. Some sort of centralized coordinator could resolve conflicts therefore save tons of traffic. Intel\u2019s cache coherence protocol has involved for this direction as well. Other measures? I don\u2019t know.","title":"Implication for On-Chip Bandwidth and NUMA"},{"location":"notes/cache_coherence/#readings","text":"The Architecture of the Nehalem Processor and Nehalem-EP SMP Platforms , chapter 5.2 Cache-Coherence Protocol for Multi-Processors. Intel: Performance Analysis Guide for Intel\u00ae Core\u2122 i7 Processor and Intel\u00ae Xeon\u2122 5500 processors Dr.Bandwidth on Core2Core cache coherence flows when running producer-consumer type of workload. . 100% recommended. Blog: NUMA Deep Dive Part 3: Cache Coherency The BEST blog I\u2019ve seen on the topic of Intel snoop models . Intel is using MESIF cache coherence protocol, but it has multiple cache coherence implementations. The first one is Source Snoop (or Early Snoop ), which is more like a traditional snoop-based cache coherence implementation. Upon miss, the caching agent will broadcast to other agents. The second one is Home Snoop , which is more like a directory-based cache coherence implementation. Upon miss, the caching agent will contact home agent, and then the home agent will send requests to other caching agents who have the requested cache line. There are other implementations like Cluster-on-Die. Intel UPI gets rid of all this complexity, it is only using directory-based, in the hope to reduce cache coherence traffic, which make sense. Related: Broadwell EP Snoop Models Related: Skylay UPI Paper: MESIF: A Two-Hop Cache Coherency Protocol for Point-to-Point Interconnects (2009)__ A MUST read. This paper has the most extensive description of the MESIF protocol implementation. It has many timing diagrams than describe how cache requests actually proceed. Those diagrams can help us understand what is needed to finish a cache request. Their slides has more timing diagrams. But do note: the implementation described by this paper is different from what Intel QPI has in products. The difference is discussed at chapter 4. MESIF and QPI, namely, other caching agents will send responses to Home agent rather than to requesting agent. QPI relies on Home agent to solve conflict. Also note: this is just one of the possible implementations to realize MESIF protocol. There could be many other ways, e.g., QPI source snooping, QPI home snooping. But all of them share the essential and general concepts and ideas. Appendix I: Large-Scale Multiprocessors and Scientific Applications , chapter 7 Implementing Cache Coherence. This is probably some most insightful discussion about real implementation of cache coherence. With the distributed nature and Network-on-Chip, implementing cache coherence in modern processors is no different than implementing a distributed transaction protocol. Cache activities like read miss or write miss have multi-step operations, but they need to appear as \u201catomic\u201d to users. Put in another way, misses are like transactions, they have multiple steps but they must be atomic. They can be retried. Having directory for cache coherence will make implementation easier. Because the place (e.g., L3) where directory resides can serve as the serialization point. They can solve write races. Home directory controller and cache controller will exchange messages like a set of distributed machines. In fact, with NoC, they are actually distributed system. Intel: An Introduction to the Intel\u00ae QuickPath Interconnect , page 15 MESIF. HotChips slide , has timing diagrams. It explains the Home Snoop and Source Snoop used by Intel. Based on their explanation, it seems both Home Snoop and Source Snoop are using a combination of snoop and directory. The Processor#4 (pg 17 and 18) maintains the directory. And this is a perfect demonstration of the details described in Appendix I: Large-Scale Multiprocessors and Scientific Applications . Related patent: Extending a cache coherency snoop broadcast protocol with directory information Paper: Multicast Snooping: A New Coherence Method Using a Multicast Address Network, ISCA \u201899 A hybrid snoop and directory cache coherence implementation. The insight is snoop cause too much bandwidth, directory incurs longer latency. So this paper proposed Multicast snoop , where it multicasts coherence transactions to selected processors, lowering the address bandwidth required for snooping. Paper: Why On-Chip Cache Coherence Is Here to Stay, Communications of ACM\u201802 This paper discusses why cache coherence can scale. A nice read. R1: Coherence\u2019s interconnection network traffic per miss scales when precisely tracking sharers. (Okay increased directory bits, what about those storage cost? See R2). R2: Hierarchy combined with inclusion enables efficient scaling of the storage cost for exact encoding of sharers. R3: private evictions should send explicit messages to shared cache to enable precise tracking. Thus the recall ( back invalidation ) traffic can be reduced when shared cache is evicting (assume inclusion cache). R4: Latencies of cache request can be amortized. Book: Parallel Computer Organization and Design , Chapter 7. Links coherence and consistency together. This chapter uses detailed graphs to show how different cache coherence implementations affect consistency. Book: A Primer on Memory Consistency and Cache Coherence Best book for this topic. Dr.Bandwidth on explaining core-to-core communication transactions! Seriously, it\u2019s so good! Although, I just feel there are so many unpublished details about the exact coherence transactions. Dr.Bandwidth himself used a lot \u201cmaybe\u201d, and listed possible actions. Transactional Memory Coherence and Consistency, ISCA\u201804 Programming with Transactional Coherence and Consistency (TCC) Slide1 Awarded the most influential paper at ISCA 2019. I took a read today (Jul 21, 2019). I feels like it\u2019s using the \u201cbatch\u201d optimization for all time. The TCC design, kind of combines both cache coherence and memory consistency: how transactions commit or orders, determins the coherence and consistency. It seems the load/store speculative execution used in their context is so similar to what Dr.Bandwidth said about Intel\u2019s implementation. Basically, the processor might read some data from L1/L2 and continue execution, but there is a chance, that the data is modifed by others, and the L3 caching agent or home agent could decide to revoke it. Once receiving such revoke message, the processor must cancel all executions that use the speculatively read data. It mentions couple Thread-Level Speculation papers, I think they should on this topic.","title":"Readings"},{"location":"notes/cache_coherence/#case-study","text":"","title":"Case Study"},{"location":"notes/cache_coherence/#intel","text":"Misc Facts. Intel Caching Agent (Cbox) is per core (or per LLC slice). Intel Home Agent is per memory controller. \u201cThe LLC coherence engine (CBo) manages the interface between the core and the last level cache (LLC). All core transactions that access the LLC are directed from the core to a CBo via the ring interconnect. The CBo is responsible for managing data delivery from the LLC to the requesting core. It is also responsible for maintaining coherence between the cores within the socket that share the LLC; generating snoops and collecting snoop responses from the local cores when the MESIF protocol requires it.\u201d \u201cEvery physical memory address in the system is uniquely associated with a single Cbox instance via a proprietary hashing algorithm that is designed to keep the distribution of traffic across the CBox instances relatively uniform for a wide range of possible address patterns.\u201d Read more here, chapter 2.3 . Starting from Intel UPI, Caching Agent and Home Agent are combined as CHA. A good discussion about why QPI gradually drop Source Snoop and solely use Home Snoop . The motivation is scalability. It turns out the new UPI only supports directory-based protocol. This makes sense because 1) inter socket bandwidth is precious, 2) snoop will consume a lot bandwidth. Intel UPI is using directory-based home snoop coherency protocol Intel\u00ae Xeon\u00ae Processor Scalable Family Technical Overview To provide sufficient bandwidth, shared caches are typically interleaved by addresses with banks physically distributed across the chip. A Transaction Breakdown. Intel does not disclose too much details about their cache coherence implementations. The most valuable information is extracted from uncore PMU manuals, and discussions from Dr. Bandwidth. According to Dr. Bandwidth, the Intel CPU could dynamically adapt its coherence strategy during runtime according to workload. There won\u2019t be one fixed cache coherence implementation, there will be many. It depends on workload which one is used at runtime. What happens when a core tries to access a cache line? A detailed cache protocl breakdown derived from Dr.Bandwidth\u2019s comment. Physical addresses are uniquely hashed into L3 slices. That means each individual physical address belongs to a L3 slice, and also belongs to a home agent. Upon L2 miss, it will send requests to corresponding L3 slice. If the L3 slice is in the local socket, the request can be delievered within the same socket. If the L3 slice belongs to another remote socket, the L2 miss request will be sent over QPI/UPI. Also note that the L2 controller will not send snoop requests. (This is answering the question of \u201cwhy using local memory is faster than remote\u201d from the cache coherence perspective.) At L3, when received the request from a L2, If it\u2019s in source snoop model, it will send snoop messages to other sockets. If it\u2019s in home snoop model, it will send read message to other sockets. The another socket will generate snoop and collect responses. (R3QPI or home?) Quote Dr. Bandwidth: Maintaining consistency is easier if the data is sent to the L3 first, and then to the requesting core, but it is also possible to send to both at the same time (e.g., \u201cDirect2Core\u201d). In recent processors, these return paths are chosen dynamically based on undocumented states and settings of the processor. I\u2019m not sure who will ACK L2 at last. L3 or home agent? Both are possible. I think both L3 and home agent have directory information. They know where to send snoop/read messages. And both of them can serialize coherence transactions! It\u2019s just undocumented who is doing what. In generall, we need to bear the fact that we cannot just figure out how Intel cache coherence works underlying. We maybe just need to \u201cvaguely\u201d know the fact that: Both directory and snoop will be used in combination. L3/home agent will serialize conflicting transactions L3/home agent will send data to requesting core L3/home agent will send final ACK to requesting L2 A coherence transaction is a multi-step distributed transaction. It involes sending requests, serialize conflicts, receiving responses/ACKs. Read the discussion posted by Dr. Bandwidth, especially this one on detailed cache coherence flows on a procuder-consumer case , which is essential if you are trying to implement high-performance spinlocks and concurrency data structures.","title":"Intel"},{"location":"notes/cache_coherence/#amd","text":"AMD HyperTransport Assit for Cache Coherence Slide Slide","title":"AMD"},{"location":"notes/cache_coherence/#arm","text":"AMBA CHI Specifications This is probabaly the most comprehensive document I\u2019ve ever seen about cache coherence. Although terms used by ARM differs from the ones used by Intel, still, you can map them. Chapter 5 Interconnect Protocol Flows has a lot timing diagrams regarding read/write/atomic coherence transactions. It\u2019s a good reference to know, but it would be hard to actually understand the details.","title":"ARM"},{"location":"notes/cache_coherence/#opencapi-and-ccix","text":"CCIX White Paper OpenCAPI","title":"OpenCAPI and CCIX"},{"location":"notes/cache_coherence/#cxl","text":"Like OpenCAPI and CCIX, it builds on top of PCIe. It is intra-server cache coherence protocol. Not very exciting to me. But it does receive some spotlight recently.","title":"CXL"},{"location":"notes/cache_coherence/#openpiton","text":"OpenPiton Microarchitecture Specification Directory-based MESI This spec has detailed coherence message packet format and type. Unfortunately, it does not say anything about how they deal with coherence transaction conflicts. E.g., some timeline diagrams like Figrue \u2154 in this paper . BYOC: A \u201cBring Your Own Core\u201d Framework for Heterogeneous-ISA Research, ASPLOS\u201820","title":"OpenPiton"},{"location":"notes/cache_coherence/#fpga","text":"Analysis and Optimization of I/O Cache Coherency Strategies for SoC-FPGA Device, FPL\u201819 LEAP Shared Memories: Automating the Construction of FPGA Coherent Memories, FCCM\u201814. This work is built on their earlier work, which basically add the data caching concept to FPGA: using BRAM as L1, on-board DRAM as L2, host or remote DRAM as L3. In their earlier work, each FPGA application (or bitstream) has a private L1 cache. In this work, the add MESI coherence to these private L1 caches, as in they can make multiple L1 cache cache-coherent. The techniques and protocols from this paper are similar to the exisiting ones. For example, 1) they use a global serializing point to serialize transactions, 2) they designed a lot messaging types such as INV, RESP and so on. VMware Research Project PBerry A very interesting and promising project. They have this follow up work \u201cRethinking software runtimes for disaggregated memory, ASPLOS\u201821\u201d. But it is simulation using the HotOS paper idea. The real FPGA has not been built yet. They need to know Intel\u2019s protocol to build it, which is.. impossible? I think it is probably better to use RISC-V. Intel FPGA PAC Intel itself is building a FPGA-CPU cache coherent setting. They use the Intel UPI interconnect to natually the spectrum. The FPGA shell has some modules to handle this. Intel FPGA CCIP Maybe the ASPLOS\u201820 Optimus paper is uing CCIP-related research platform? Also some pointer chasing related stuff A Study of Pointer-Chasing Performance on Shared-Memory Processor-FPGA Systems, FPGA\u201816","title":"FPGA"},{"location":"notes/cache_coherence/#formal-verification","text":"I remember there are couple works from Princiton doing cache protocol verification.","title":"Formal Verification"},{"location":"notes/cgroup-swap/","text":"How linux cgroup trigger kernel swap \u00b6 Version History Date Description Dec 3, 2018 Initial version This is a note on how linux cgroup-mm triggers swap on the user-defined limit_in_bytes . This note assumes you have adequate knowledge on linux mm code. For more information about cgroup, please check the document from RedHat . This is NOT a complete walk through. There are several cgroup callbacks at mm/memory.c . Those functions are called to check if cgroup can honor this page allocation. All of these functions are located in mm/memcontrol.c mem_cgroup_try_charge() mem_cgroup_commit_charge() mem_cgroup_cancel_charge() Some facts about the implementation (up to linux 5.2) Each memory cgroup has its own LRU list vector All memory cgroup\u2019s LRU lists and even the global LRU lists, they share a global LRU lock on a per-node basis. (Weird! Why?). Take a closer look of mem_cgroup_try_charge() , whose behavior is actually quite similar to the case of a real OOM: check if we still available memory (here means memory usage is smaller than limit_in_bytes ), if unfortunately we run out of memory, it will then try to reclaim form the memory cgroup\u2019s LRU lists. If that did not work either, final step would be do OOM actions. mem_cgroup_try_charge() try_charge() page_counter_try_charge(): Check if we hit limit_in_bytes counter. Hierarchically charge pages, costly. try_to_free_mem_cgroup_pages() Callback to mm/vmscan.c to shrink the list ( Bingo! ) Also, reclaimer will establish swap pte entries mem_cgroup_oom() mem_cgroup_lruvec() Other than the global zone-wide LRU lists vector, each cgroup has its own LRU lists vector. Choose the vector that will be passed down to do shrink_page_list() etc. LRU Lists Maintainence \u00b6 Insertion to LRU lists is performed as follows: first, it will be inserted into a per-cpu array ( lru_add_pvec ). Once the array is full (default 15 entries), it will do a batch insertion into proper LRU lists (depends on mem_cgroup_lruvec we mentioned above). Why Linux is doing this way? To scale.","title":"Linux Cgroup and Swap"},{"location":"notes/cgroup-swap/#how-linux-cgroup-trigger-kernel-swap","text":"Version History Date Description Dec 3, 2018 Initial version This is a note on how linux cgroup-mm triggers swap on the user-defined limit_in_bytes . This note assumes you have adequate knowledge on linux mm code. For more information about cgroup, please check the document from RedHat . This is NOT a complete walk through. There are several cgroup callbacks at mm/memory.c . Those functions are called to check if cgroup can honor this page allocation. All of these functions are located in mm/memcontrol.c mem_cgroup_try_charge() mem_cgroup_commit_charge() mem_cgroup_cancel_charge() Some facts about the implementation (up to linux 5.2) Each memory cgroup has its own LRU list vector All memory cgroup\u2019s LRU lists and even the global LRU lists, they share a global LRU lock on a per-node basis. (Weird! Why?). Take a closer look of mem_cgroup_try_charge() , whose behavior is actually quite similar to the case of a real OOM: check if we still available memory (here means memory usage is smaller than limit_in_bytes ), if unfortunately we run out of memory, it will then try to reclaim form the memory cgroup\u2019s LRU lists. If that did not work either, final step would be do OOM actions. mem_cgroup_try_charge() try_charge() page_counter_try_charge(): Check if we hit limit_in_bytes counter. Hierarchically charge pages, costly. try_to_free_mem_cgroup_pages() Callback to mm/vmscan.c to shrink the list ( Bingo! ) Also, reclaimer will establish swap pte entries mem_cgroup_oom() mem_cgroup_lruvec() Other than the global zone-wide LRU lists vector, each cgroup has its own LRU lists vector. Choose the vector that will be passed down to do shrink_page_list() etc.","title":"How linux cgroup trigger kernel swap"},{"location":"notes/cgroup-swap/#lru-lists-maintainence","text":"Insertion to LRU lists is performed as follows: first, it will be inserted into a per-cpu array ( lru_add_pvec ). Once the array is full (default 15 entries), it will do a batch insertion into proper LRU lists (depends on mem_cgroup_lruvec we mentioned above). Why Linux is doing this way? To scale.","title":"LRU Lists Maintainence"},{"location":"notes/consistency/","text":"Consistency \u00b6 Version History Date Description Jun 30, 2021 Initial zotero collection . Introduction \u00b6 Processors \u00b6 Distributed Systems \u00b6","title":"Consistency"},{"location":"notes/consistency/#consistency","text":"Version History Date Description Jun 30, 2021 Initial zotero collection .","title":"Consistency"},{"location":"notes/consistency/#introduction","text":"","title":"Introduction"},{"location":"notes/consistency/#processors","text":"","title":"Processors"},{"location":"notes/consistency/#distributed-systems","text":"","title":"Distributed Systems"},{"location":"notes/cryptocurrency/","text":"Cryptocurrency \u00b6 Version History Date Description Jan 16, 2021 Planned Definition: https://en.wikipedia.org/wiki/Cryptocurrency#Formal_definition Bitcoin \u00b6 Paper: https://bitcoin.org/bitcoin.pdf","title":"Cryptocurrency"},{"location":"notes/cryptocurrency/#cryptocurrency","text":"Version History Date Description Jan 16, 2021 Planned Definition: https://en.wikipedia.org/wiki/Cryptocurrency#Formal_definition","title":"Cryptocurrency"},{"location":"notes/cryptocurrency/#bitcoin","text":"Paper: https://bitcoin.org/bitcoin.pdf","title":"Bitcoin"},{"location":"notes/cryptography/","text":"Cryptography \u00b6 Version History Date Description Oct 11, 2021 Add the github awesome link Jan 16, 2021 Updated Dec 27, 2020 Updated Dec 26, 2020 Created So today (Dec 26, 2020) I\u2019m trying to write some crypto functions to encrypt/decrypt network packets. Then I realize my knowledge about network security is just too shallow. Although I know AES, SHA etc to some extent, I\u2019m not really sure how to build them. Learning \u00b6 Try this one: awesome-cryptograghy . Some basic concepts: cryptographic-standards-and-guidelines Cryptographic Hash Function MD5 SHA-1 SHA-2 SHA-3 https://en.wikipedia.org/wiki/Avalanche_effect Public Key Cryptography https://en.wikipedia.org/wiki/PKCS_1 AES Twofish, 128-bit block plaintext -> ciphertext Courses: UCSE CSE207 by Prof Mihir Bellare TLS and SSH \u00b6 SSH has a similar process as SSL/TLS. See Understanding the SSH Encryption and Connection Process . SSL/TLS Cipher Suite OpenSSL , LibreSSL So TLS (or DTLS for UDP) has an extra handshake protocol after a TCP or UDP port is open. This handshake process uses asymmetric-keys (public/private) keys to exchange info (e.g., choose TLS info, send pub key etc). They will reach a consensus on which TLS version to use, which cipher suite to use, which session key, or encryption key to use. Finally they will start sending traffic using symmetric encryption (e.g., AES). In addition, they will use secure hashing (e.g., SHA3) to ensure the integrity of the packets. AES Related \u00b6 As I know it, it two variables controlling its variations: 1) key size, 128-bit, 192-bit, 256-bit => AES128, AES192, AES256 2) mode of chaining, for data that is larger than standard AES 128-bit block size. The modes can be CTR, CBC and so on. This is more advanced. AES is a block cipher . AES operates on 128-bit data block, and produces 128-bit encrypted data. Larger data (packets) needs to specify the mode of chaining. Block cipher Block cipher mode of operation Block size (cryptography) Details S-Box https://en.wikipedia.org/wiki/S-box https://en.wikipedia.org/wiki/Rijndael_S-box Key Schedule, round constant https://en.wikipedia.org/wiki/AES_key_schedule Quote mode of operation describes how to repeatedly apply a cipher\u2019s single-block operation to securely transform amounts of data larger than a block Quote Block ciphers operate on a fixed length string of bits. The length of this bit string is the block size. Both the input (plaintext) and output (ciphertext) are the same length; the output cannot be shorter than the input \u2013 this follows logically from the pigeonhole principle and the fact that the cipher must be reversible \u2013 and it is undesirable for the output to be longer than the input. SHA Related \u00b6 SHA-3 has several variations, depending the hash size, it can be SHA3-224, SHA3-256, SHA3-384, and SHA3-512 . https://keccak.team/index.html https://csrc.nist.gov/projects/hash-functions Case Studies \u00b6 As usual, let us look at some real world use cases and codes. Software \u00b6 Both of them have implemented a set of cryptographic functions, collectively called libcrypto . But.. these libraries have deep roots in their projects, thus using a lot project-specific macros etc, so I think they are not that easy to read. There are a lot simpler POC code out there. OpenSSL - libcrypto their arch page is really good: https://www.openssl.org/docs/OpenSSLStrategicArchitecture.html OpenSSL 3.0.0 Design OpenSSH - ssh/sshd/scp/etc Linux kernel crypto API FPGA \u00b6 Opencore SHA-3 Opencore AES SpninalCrypto So I personally use this in my research project. It is clean. ASIC \u00b6 CPU has extended instructions to accelerate AES and its friends: AES inst set","title":"Cryptography"},{"location":"notes/cryptography/#cryptography","text":"Version History Date Description Oct 11, 2021 Add the github awesome link Jan 16, 2021 Updated Dec 27, 2020 Updated Dec 26, 2020 Created So today (Dec 26, 2020) I\u2019m trying to write some crypto functions to encrypt/decrypt network packets. Then I realize my knowledge about network security is just too shallow. Although I know AES, SHA etc to some extent, I\u2019m not really sure how to build them.","title":"Cryptography"},{"location":"notes/cryptography/#learning","text":"Try this one: awesome-cryptograghy . Some basic concepts: cryptographic-standards-and-guidelines Cryptographic Hash Function MD5 SHA-1 SHA-2 SHA-3 https://en.wikipedia.org/wiki/Avalanche_effect Public Key Cryptography https://en.wikipedia.org/wiki/PKCS_1 AES Twofish, 128-bit block plaintext -> ciphertext Courses: UCSE CSE207 by Prof Mihir Bellare","title":"Learning"},{"location":"notes/cryptography/#tls-and-ssh","text":"SSH has a similar process as SSL/TLS. See Understanding the SSH Encryption and Connection Process . SSL/TLS Cipher Suite OpenSSL , LibreSSL So TLS (or DTLS for UDP) has an extra handshake protocol after a TCP or UDP port is open. This handshake process uses asymmetric-keys (public/private) keys to exchange info (e.g., choose TLS info, send pub key etc). They will reach a consensus on which TLS version to use, which cipher suite to use, which session key, or encryption key to use. Finally they will start sending traffic using symmetric encryption (e.g., AES). In addition, they will use secure hashing (e.g., SHA3) to ensure the integrity of the packets.","title":"TLS and SSH"},{"location":"notes/cryptography/#aes-related","text":"As I know it, it two variables controlling its variations: 1) key size, 128-bit, 192-bit, 256-bit => AES128, AES192, AES256 2) mode of chaining, for data that is larger than standard AES 128-bit block size. The modes can be CTR, CBC and so on. This is more advanced. AES is a block cipher . AES operates on 128-bit data block, and produces 128-bit encrypted data. Larger data (packets) needs to specify the mode of chaining. Block cipher Block cipher mode of operation Block size (cryptography) Details S-Box https://en.wikipedia.org/wiki/S-box https://en.wikipedia.org/wiki/Rijndael_S-box Key Schedule, round constant https://en.wikipedia.org/wiki/AES_key_schedule Quote mode of operation describes how to repeatedly apply a cipher\u2019s single-block operation to securely transform amounts of data larger than a block Quote Block ciphers operate on a fixed length string of bits. The length of this bit string is the block size. Both the input (plaintext) and output (ciphertext) are the same length; the output cannot be shorter than the input \u2013 this follows logically from the pigeonhole principle and the fact that the cipher must be reversible \u2013 and it is undesirable for the output to be longer than the input.","title":"AES Related"},{"location":"notes/cryptography/#sha-related","text":"SHA-3 has several variations, depending the hash size, it can be SHA3-224, SHA3-256, SHA3-384, and SHA3-512 . https://keccak.team/index.html https://csrc.nist.gov/projects/hash-functions","title":"SHA Related"},{"location":"notes/cryptography/#case-studies","text":"As usual, let us look at some real world use cases and codes.","title":"Case Studies"},{"location":"notes/cryptography/#software","text":"Both of them have implemented a set of cryptographic functions, collectively called libcrypto . But.. these libraries have deep roots in their projects, thus using a lot project-specific macros etc, so I think they are not that easy to read. There are a lot simpler POC code out there. OpenSSL - libcrypto their arch page is really good: https://www.openssl.org/docs/OpenSSLStrategicArchitecture.html OpenSSL 3.0.0 Design OpenSSH - ssh/sshd/scp/etc Linux kernel crypto API","title":"Software"},{"location":"notes/cryptography/#fpga","text":"Opencore SHA-3 Opencore AES SpninalCrypto So I personally use this in my research project. It is clean.","title":"FPGA"},{"location":"notes/cryptography/#asic","text":"CPU has extended instructions to accelerate AES and its friends: AES inst set","title":"ASIC"},{"location":"notes/dcn/","text":"Notes on Modern Data Center Networking \u00b6 Version History Date Description Oct 2, 2021 Planning This is my note on datacenter networking. This is work-in-progress. I will try to cover the following topics: Peering Cloud gateways Cloud internal routing Networking Topology Software Defined Networking (SDN) and OpenFlow Networking Load Balancers Networking Upgrade Switch Hardware and Software (e.g., p4 switch) Host-side NIC Design Host-side Network Virtualization (e.g., OpenVSwitch and VPC) Transport Design (Retransmission and Congestion Control) RDMA and RoCE Host-side Networking Stack Design Overview \u00b6 I should draw a figure, including host side network stack/nic, switch, topologies, sdn controllers and so on. And list which parts demand attention. Peering, Gateway, and Routing \u00b6 Topology \u00b6 Clos, fat-tree, jupiter, vl2, fb\u2019s 40/100g topology. SDN and OpenFlow \u00b6 Orion, and its predecessor. Upgrade \u00b6 NSDI papers, live update, cost. Network Virtualization \u00b6 openvswitch, Andromeda. Host Networking Stack \u00b6 Snap. Special Topics \u00b6 This section covers special topics. Special Topcis on Transport Design \u00b6 and programmable transport Congestion Control \u00b6 Shallow switch buffer. DCTCP. Special Topics on RDMA and RoCE \u00b6 Speical Topics on Programmable Switch and SmartNIC \u00b6 Special Topics on Kernel-Bypassing Netork Stacks \u00b6 RPC papers. ZygOS, Shenengo, Arrakis etc. whole stack design. Special Topics on Packet Scheduling \u00b6 PIFO etc. Special Topics on Datacenter Traffic Study \u00b6 IMC\u201810 etc. Special Topics on Middlebox and Network Function Virtualization (NFV) \u00b6 Special Topics on Circuit Switches \u00b6 TBD Special Topics on Failure, Reliability \u00b6 Link error rate. Applied erasure coding on packets. Trace studies. Cloud Case Studies \u00b6 In this section, we look at popular cloud vendors and briefly their networking stack status. GCP \u00b6 Their networking services https://github.com/priyankavergadia/google-cloud-4-words#networking . Azure \u00b6 SmartNIC Google Cloud \u00b6 1RMA, Swifit, Snap, Orion Alibaba \u00b6 p4 switch.","title":"Data Center Networking"},{"location":"notes/dcn/#notes-on-modern-data-center-networking","text":"Version History Date Description Oct 2, 2021 Planning This is my note on datacenter networking. This is work-in-progress. I will try to cover the following topics: Peering Cloud gateways Cloud internal routing Networking Topology Software Defined Networking (SDN) and OpenFlow Networking Load Balancers Networking Upgrade Switch Hardware and Software (e.g., p4 switch) Host-side NIC Design Host-side Network Virtualization (e.g., OpenVSwitch and VPC) Transport Design (Retransmission and Congestion Control) RDMA and RoCE Host-side Networking Stack Design","title":"Notes on Modern Data Center Networking"},{"location":"notes/dcn/#overview","text":"I should draw a figure, including host side network stack/nic, switch, topologies, sdn controllers and so on. And list which parts demand attention.","title":"Overview"},{"location":"notes/dcn/#peering-gateway-and-routing","text":"","title":"Peering, Gateway, and Routing"},{"location":"notes/dcn/#topology","text":"Clos, fat-tree, jupiter, vl2, fb\u2019s 40/100g topology.","title":"Topology"},{"location":"notes/dcn/#sdn-and-openflow","text":"Orion, and its predecessor.","title":"SDN and OpenFlow"},{"location":"notes/dcn/#upgrade","text":"NSDI papers, live update, cost.","title":"Upgrade"},{"location":"notes/dcn/#network-virtualization","text":"openvswitch, Andromeda.","title":"Network Virtualization"},{"location":"notes/dcn/#host-networking-stack","text":"Snap.","title":"Host Networking Stack"},{"location":"notes/dcn/#special-topics","text":"This section covers special topics.","title":"Special Topics"},{"location":"notes/dcn/#special-topcis-on-transport-design","text":"and programmable transport","title":"Special Topcis on Transport Design"},{"location":"notes/dcn/#congestion-control","text":"Shallow switch buffer. DCTCP.","title":"Congestion Control"},{"location":"notes/dcn/#special-topics-on-rdma-and-roce","text":"","title":"Special Topics on RDMA and RoCE"},{"location":"notes/dcn/#speical-topics-on-programmable-switch-and-smartnic","text":"","title":"Speical Topics on Programmable Switch and SmartNIC"},{"location":"notes/dcn/#special-topics-on-kernel-bypassing-netork-stacks","text":"RPC papers. ZygOS, Shenengo, Arrakis etc. whole stack design.","title":"Special Topics on Kernel-Bypassing Netork Stacks"},{"location":"notes/dcn/#special-topics-on-packet-scheduling","text":"PIFO etc.","title":"Special Topics on Packet Scheduling"},{"location":"notes/dcn/#special-topics-on-datacenter-traffic-study","text":"IMC\u201810 etc.","title":"Special Topics on Datacenter Traffic Study"},{"location":"notes/dcn/#special-topics-on-middlebox-and-network-function-virtualization-nfv","text":"","title":"Special Topics on Middlebox and Network Function Virtualization (NFV)"},{"location":"notes/dcn/#special-topics-on-circuit-switches","text":"TBD","title":"Special Topics on Circuit Switches"},{"location":"notes/dcn/#special-topics-on-failure-reliability","text":"Link error rate. Applied erasure coding on packets. Trace studies.","title":"Special Topics on Failure, Reliability"},{"location":"notes/dcn/#cloud-case-studies","text":"In this section, we look at popular cloud vendors and briefly their networking stack status.","title":"Cloud Case Studies"},{"location":"notes/dcn/#gcp","text":"Their networking services https://github.com/priyankavergadia/google-cloud-4-words#networking .","title":"GCP"},{"location":"notes/dcn/#azure","text":"SmartNIC","title":"Azure"},{"location":"notes/dcn/#google-cloud","text":"1RMA, Swifit, Snap, Orion","title":"Google Cloud"},{"location":"notes/dcn/#alibaba","text":"p4 switch.","title":"Alibaba"},{"location":"notes/dist-xact/","text":"Distributed Transactions and Databases \u00b6 Version History Date Description Apr 5, 2022 Reorg Feb 25, 2022 Initial Why I started this note \u00b6 This note was originally written in this google doc . This note was my attempt to revive the distributed transaction topic and to get a better understanding about database systems in general. The result was quite fruitful, I covered various concurrency control schemes, isolation levels, etc. The consensus protocols, query optimizations etc topics are not extensively discussed here. Today 02/16/2022, I\u2019m reading the FORD, FAST\u201922 paper, they are designing distributed transactions for disaggregated persistent memory, they talked about OCC, 2PL, primary-backup etc schemes, and I decided to take another serious look at this topic. I still have the vivid memory of me reading some old Transaction-related surveys (after the ZooKeeper paper) in a small, smelly, broken Purdue ECE room when I first started my PhD. I also had a vivid memory of a meeting among myself, Yiying, Stanko, Marcus in a VMR office room. We were talking about OCC, MVCC, and the then upcoming OSDI\u201918 hybrid transaction paper. I was confused. Anyways, let\u2019s get started. Quick Takeaways \u00b6 (1) Concurrency control (CC) is categorized as two types: pessimistic CC using 2-phase locking (2PL) and optimistic CC using Timestamp-Ordering (T/O). . This categorization is derived from a classical paper ( Concurrency Control in Distributed Database Systems , 1981). This image comes from An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914 . Note, I think the MVCC actually should be MVTO. (2) Multi-versioning (MV) is the prevalent default implementation choice in the wild, for its better performance on various scenarios. Most people think MV is a CC mechanism, but it is not. MV must work with a CC mechanism (e.g., 2PL , T/O ) to become a full solution, resulting in combos such as MVTO , MVOCC , MV2PL . In my opinion, the commonly mentioned MVCC in various literatures actually refers to MVTO , i.e., multi-versioning with timestamp-ordering (see the MVCC section below for more details). This image shows the commercial/research use of MVCC DBMS. Credit: An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201817 (3) For better performance, DBMS usually adopt Snapshot Isolation or Read Committed as their default isolation level . The Serializable isolation level is usually not the default one in commercial DBMS. It is baffling to know the fact that many real world systems are actually operating under a weak consistency model and we (and the world) are okay with it! The RedBook offers an interesting take on this topic. The market follows Gresham\u2019s law: bad money drives out good money (See the Isolation section for more details). This image shows the default Isolation level used by various systems. Credit: Highly Available Transactions: Virtues and Limitations, VLDB\u201813 Concepts \u00b6 Concurrency Control \u00b6 Pessimistic Concurrency Control & Optimistic Concurrency Control. Must Read Concurrency Control in Distributed Database Systems , 1981. This paper categorizes 2PL, MVCC, OCC etc into 2 big types. On Optimistic Methods for Concurrency Control, 1981 . This is the first OCC paper. An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914 . This CMU paper has follows the 1981 paper\u2019s categorization on CC methods. An Evaluation of Distributed Concurrency Control, VLDB\u201917 An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201917 . This paper is a must read, it explains what is MVTO, MV2PL, MVOCC, etc. Optional Aurogon: Taming Aborts in All Phases for Distributed In-Memory Transactions, FAST\u201822 Optional FORD, FAST\u201822 Courses CMU Database Systems (15-445/645) , thanks to Andy Pavlo Concurrency Control Theory Two-Phase Locking Concurrency Control Timestamp Ordering Concurrency Control Multi-Version Concurrency Control CMU Advanced Database Systems (15-721) , thanks to Andy Pavlo Multi-Version Concurrency Control (Design Decisions) Multi-Version Concurrency Control (Protocols) Multi-Version Concurrency Control (Garbage Collection) As we mentioned earlier, database concurrency control is categorized as two types: pessimistic CC using 2-phase locking (2PL) and optimistic CC using Timestamp-Ordering (T/O) . This categorization is derived from this classical paper Concurrency Control in Distributed Database Systems . The following table is from An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914 . Also from this CMU 15-445 slide : Recap: Pessimistic CC: Two-phase Locking (2PL) Optimistic CC: Timestamp Ordering (T/O) TO OCC MVCC-TO The well-known OCC , MVCC-TO concepts fall into the T/O category. However, don\u2019t confuse the MVCC with concurrency control. MVCC is not a concurrency control method. It must work with a CC method. The above table has MVCC under T/O because it is MVCC-T/O. (Old note: After reading the VLDB\u201917 paper, I think that MVCC can NOT be categorized as a standalone concurrency control method. Hence, we should not say MVCC, OCC, 2PL as if they are in the same league. MVCC states multiple versions of the same object/tuple, it needs to work with other concurrency control methods, so as to end up with MVTO, MVOCC, MV2PL. I think the most common one, or the one that people unconsciously talk about is MVTO. See the following MVCC section for more details!) Call back to Hotpot: I think its MRSW is 2PL+2PC, MRMW is OCC+2PC. Pessimistic CC: 2PL \u00b6 Not too much to explain here. Maybe read the MV2PL paper for the MV + 2PL combo. Optimistic CC: T/O \u00b6 The essense of T/O, as its name suggested, is using timestamp to order operations and transactions. Image there exist a perfect logical clock available to all distributed nodes. Whenever a node wants to run a transaction, it will take a timestamp based on the global clock. The node further attaches this timestamp to all operations within the transaction it wishes to execute. This practice establishes a global order on all transactions. Conflicts therefore can be resolved using timestamps. The above reasoning is a super high-level gist on how a T/O based CC could work. There are many nuances and implementation choices to be made. First of all, there is no such perfect clock among distributed nodes. Even if there is a centralize time management system, the cost will be super high. Because it has high-concurrency issues. Second, a system can order things in the beginning of a transaction, or in the middle, or in the end (OCC). Third, there might a single version, or multiple versions of the same data. Combined, they lead to several popular subcategories listed below. Basic Timestamp-Ordering (Basic T/O) Optimistic Concurrency Control (OCC) Multi-version Concurrency Control (MVCC) with T/O Quote the VLDB\u201814 paper: Timestamp ordering (T/O) concurrency control schemes generate a serialization order of transactions a priori and then the DBMS enforces this order. A transaction is assigned a unique, monotonically increasing timestamp before it is executed; this timestamp is used by the DBMS to process con\ufb02icting operations in the proper order (e.g., read and write operations on the same element, or two separate write operations on the same element). As for their detailed implementation rationale, I recommend reading An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914 , CMU 15-445 slide . Multi-Versioning \u00b6 Papers https://15721.courses.cs.cmu.edu/spring2020/schedule.html . This course has links to various MVCC papers An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201917 Serializable Snapshot Isolation in PostgreSQL, VLDB\u201912 Scalable Garbage Collection for In-Memory MVCC Systems, VLDB\u201917 After a couple days of intensive reading, my understanding about MVCC has expanded quite a lot. It kind of went like this: In the first stage, I would list MVCC as the opposite approach to OCC. And appears this is most people\u2019s impression? Meaning, when we talk about a system, we will describe it either as OCC or MVCC, as if they are two different things that cannot co-exist. After reading Peloton, VLDB\u201917 paper and the Alibaba blog post, I realized that my understanding wasn\u2019t correct. They reminded me that OCC, at its core, is a concurrency control method, with a clear goal of reducing the amount of time that a transaction holds locks . Since the original and most OCC implementations are using a single-versioned database plus local copies, we naturally think OCC \u21d2 single version. However, if we recall the core of OCC, it does not preclude multi-versioning! . OCC can work with MVCC. My misconception also applies to MVCC, not just OCC. Like the alibaba blog post said, MVCC alone is not a concurrency control method, it merely says there will be multiple versions of the same object/tuple . As a result, MVCC has to work with a real concurrency control method to become a full solution. That\u2019s why we have MVCC+TO, MVCC+2PL, MVCC+OCC. MVCC is an optimization technique for read and write requests. It does not completely solve the concurrency problem of databases, so it must be used with concurrency control techniques for a complete concurrency control. E.g., multiversion two-phase locking (MV2PL), multiversion timestamp ordering (MVTO), multiversion optimistic concurrency control (MVOCC), and MV-SSI. I highly recommend the An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201917 paper for a better understanding about MVTO, MVOCC, MV2PL, and how to implement them. This image is from this Alibaba Blog . It is inline with what the above VLDB\u201917 paper said. It is important to note that MVCC is the de-facto choice for modern DBMS for its better performance regarding read/write transactions . Isolation: Serializability, Snapshot Isolation, Linearliability \u00b6 Some official Isolation levels in DBMS systems: Serializable Repeatable reads Read committed Read uncommitted Readings: The RedBook Chapter 6 has great discussion on why weak consistency (e.g., non-serializable snapshot isolation) is more popular than the serializability, and their guess on why the world is \u201cokay\u201d with that usage. A Critique of ANSI SQL Isolation Levels, 1995 Database Isolation Levels explained | by sudan Real Transactions are Serializable CockroachDB provides strong (\u201cSERIALIZABLE\u201d) isolation by default to ensure that your application always sees the data it expects. When you use a non-SERIALIZABLE isolation level, you\u2019re giving the database permission to return an incorrect answer in the hope that it will be faster than producing the correct one. Oracle\u2019s implementation of the SERIALIZABLE isolation level is actually a weaker mode called \u201csnapshot isolation\u201d: It is stronger than READ COMMITTED but weaker than SERIALIZABLE. It is similar to REPEATABLE READ but not exactly equivalent PostgreSQL: Documentation: 14: 13.2. Transaction Isolation Highly Available Transactions: Virtues and Limitations, VLDB\u201917 Discussed the default isolation models used by various systems. Quite telling Most systems DO NOT have Serializable as the default. Takeaways Many real-world DBMS and NoSQL systems adopt a weak consistency model (e.g., non-serializable snapshot isolation) as the default isolation level. They prefer this over serializability because a weak consistency model offers better performance. Weak consistency could lead to anomalies that are super hard to reason about. So why is the real world okay using this model? The redbook\u2019s guess is that there is not enough concurrency in the real world workload so that corner cases rarely happen. I don\u2019t really buy this argument but I can\u2019t think of another good reason. None of these weak isolation models guarantees serializability, but, as we see below, their bene\ufb01ts are often considered to outweigh costs of possible consistency anomalies that might arise from their use . The reason I came across this is because I was trying to understand Snapshot Isolation while reading NAM-DB (it provides SI). And turns out it is a much deeper discussion. This wiki Snapshot Isolation has a great explanation on what SI exactly is, and how it compares to the strict serializability. * The following note was written before I read the SI wiki : I have a very vague understanding about read-snapshots. My first thought is that it is probably only possible with MVCC, but not with OCC. Because intuitively, MVCC maintains multiple versions of the same object, hence able to provide a snapshot with respect to time. Spanner uses MVCC (2PL+2PC+Paxos) and has snapshots-related APIs. FaRMv1, DrTM uses OCC and has no snapshots . * After reading the SI wiki : I think my first impression is correct. MVCC is convenient to implement Snapshot Isolation, as MVCC already maintains a series of recent history. However, I\u2019m not 100% sure whether we can implement SI with OCC as well . We definitely need extra states on top of a normal OCC, and will that just result in sth like MVCC? * **Snapshot Isolation essentially allows****disjoint writes****from concurrent transactions, hence could result in a final state that is not possible in a Serialiable transaction.**Check the example case in the wiki, it is great and simple. * System wise, I came across these that provide SI * Spanner - provide both serializable and (read-only) snapshot transactions * NAM-DB, VLDB\u201917 - provides SI-only transactions Serializable Snapshot Isolation (SI) Serializable Snapshot Isolation (SSI) Replication Protocols \u00b6 Paxos Vertical Paxos Raft Primary-Backup Virtual Synchrony TODO: come back and add more. Integrate Distributed Transaction and Replication \u00b6 (image from TAPIR, SOSP\u201915) I think most traditional DBMS systems implement distributed transactions and replication *protocols as two different things. For example, the dist-xact could be sth like 2PL+2PC, OCC+2PC, MVOCC+2PC. Beneath, the replication protocol could be Primary-Backup replication, Paxos, or Raft. For Google Spanner , (1) I think their distributed transaction is multi-versioned 2-phase locking with distributed 2-phase commit (i.e., MV2PL+2PC ). (2) Beneath, Spanner uses Paxos for data replication. The metadata is stored in GFS. In their design, a set of machines form a Paxos group. Each paxos group has a leader. During a transaction, this leader is the transaction manager for its Paxos group. If a distributed transaction spans multiple Paxos groups, all group leaders would run MV2PL+2PC among them; leaders themselves run Paxos protocol within their own Paxos group. This layering is good for modularization but at the cost of more data/messages exchanged. But Spanner is a geo-distributed database, such design might be okay. It is not like it is building on top of RDMA or something. The takeway message is that: The naive way of layering a distributed transaction protocol on top of a replication protocol results in over-coordination . It is only natural to co-design dist-xact and replication . For instance, FaRM, SOSP\u201915 & FORD, FAST\u201822 both describe a co-designed four-phase protocol (lock, validation, commit-backup, commit-primary). Related work in this space **Hotpot, SoCC\u201917**co-designs distributed transaction and replication in its MRSW and MRMW protocols (which are 2PL+2PC, and OCC+2PC, respectively) FaRMv1, SOSP\u201915 & NSDI\u201914 co-designs distributed transaction and replication in one 4-phase protocol, using RDMA FaRMv2, SIGMOD\u201919 TAPIR, SOSP\u201915 FORD: Fast One-sided RDMA-based Distributed Transactions for Disaggregated Persistent Memory, FAST\u201822 Papers from Mu Shuai 2-Phase Commit v.s. 2PL \u00b6 2-phase locking 2-phase commit 3-phase commit The two-phase commit (2PC) protocol should not be confused with the two-phase locking (2PL) protocol, a concurrency control protocol. [ NOTE: the description about OCC, MVCC, 2PL might be wrong. I had the wrong impression about them. But now I understand after reading the VLDB\u201917 paper. I believe the MVCC below can be thought of as MVCC-TO, or MVTO. ] CC methods such as 2PL, T/O(OCC, MVCC-TO, T/O) are used to ensure that concurrent operations to shared data are serialized, hence ensuring serializability and data consistency. CC ensures operations such as read and write are ordered properly. CC can be used both within a single node or across nodes (e.g., the An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201904 paper evaluates several CC methods within a single node). However, a simple CC is not sufficient when it comes to a distributed setting with multiple nodes: it cannot ensure a transaction commit could commit at all participating nodes. For instance, some nodes may have committed, others may have not - and this creates an inconsistent state. Let me use 2PL as an example: in 2PL, we first grab all locks across all involving nodes, we then run the execution/logic locally on a node, we then send all the new data (if any) to other nodes and release the locks. In the last step, there is no way for us to make sure that all participating nodes have received the message. If only some of them finalized/committed the transaction, then the whole database/system is in an inconsistent state. This is where Atomic Commit Protocol such as 2-phase commit comes to rescue. It ensures that all participants either all commit or none of them commits the transaction. It does so by using another 2-phase protocol: prepare + commit. It is not hard to understand. There are more complicated methods such as 3PC or Paxos Commit. I think my original confusion about 2PC and 2PL stems from my illusion that we can use 2PL to also implement what 2PC is designed to achieve. But after the above reasoning, I realized that is not possible. 2PC and 2PL have very clear distinctions. I also had a misconception that 2PC is needed because it can ensure durability . This is also false because 2PC is required simply to ensure atomic commit, for both scenarios w/ or w/o guarantees. If we want durability, then 2PC\u2019s participants would need to either do local logging or build on top of a replication mechanism such as Paxos. A short summary: Concurrency control protocols: 2PL, T/O (OCC, MVCC, etc) Atomic commit protocols 2PC, 2PC, paxos-commit Concurrency control methods can work in a single node or across node Once a CC goes distributed, it requires a atomic commit to ensure distributed consistency 2PL + 2PC, OCC + 2PC, MVCC + 2PC etc are concurrency control + atomic commit Atomic commit can include or exclude durability guarantee Classical Systems \u00b6 These systems of course touch most of the above concepts. ZooKeeper. The key thing is its Atomic Broadcast network library. Google BigTable, need a revisit Google Spanner. I have vivid memory reading it. TruTime. Need a revisit as well. It touches a lot of things, appears it is MVCC? And uses Paxos. Misc \u00b6 Scenarios and Hardware \u00b6 One key thing worth considering is the operating environment. Some systems like Spanner target geo-distributed data centers, which could go though low-latency WAN. Bottlenecks \u00b6 Many papers and systems have mentioned that the global timestamp allocation is a major bottleneck in Timestamp Ordering concurrency control systems (including OCC and MVCC). This is easy to understand: having some sort of global data structure that increases monotonically is hard in a distributed setting. I think that\u2019s why several systems (Spanner, FaRMv2) resort to proactively dealing with clock uncertainties. In-memory v.s. Disk-base DBMS \u00b6 XXX Self-Driving DBMS \u00b6 Essentially uses ML to make some decisions? Readings: Self-Driving Database Management Systems , CIDR\u201917 Automatic Database Management System Tuning Through Large-scale Machine Learning Papers and Readings \u00b6 Courses Schedule | CMU 15-445/645 :: Intro to Database Systems (Fall 2019) . This is DBMS basics, good start. Schedule - CMU 15-721 :: Advanced Database Systems (Spring 2020) . This is advanced paper reading. General Readings 01 Papers - ALL - a TAB is dedicated to this topic Zotero Paper Collection http://www.redbook.io/ The famous Red Book theanalyst/awesome-distributed-systems - Github Awesome List Distributed Systems Reading List - Reading List Good Readings Time, Clocks, and the Ordering of Events in a Distributed System, 1978 - classical On Optimistic Methods for Concurrency Control, 1981 First paper proposing OCC, definitely a seminal paper. Concurrency Control in Distributed Database Systems , 1981 This paper categorizes 2PL, MVCC, OCC etc into 2 big types. The CMU slides/papers use this categorization to this date. Linearizability: a correctness condition for concurrent objects , 1990 An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914 A good read on comparing various concurrency control schemes. Note that the MVCC mentioned in this paper is MVTO. An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201917 This is a really good read and should be read in great detail. Understand that OCC\u2019s core is to reduce the critical section time. And MVCC is not a concurrency control method on its own, it merely enables multiple versions of the same object/tuple. Hence MVCC could work with any concurrency control methods, resulting in combos like MVTO, MVOCC, MV2PL. An Evaluation of Distributed Concurrency Control, VLDB\u201917 This read reminds us the default Isolation level out in the wild is usually not serializability, but something weaker like Snapshot Isolation, or Read Committed. Misc \u00b6 The Marzullo\u2019s Algorithm, used by Google Spanner. https://en.wikipedia.org/wiki/Marzullo%27s_algorithm Opacity, from FaRMv2 What\u2019s Really New with NewSQL? What\u2019s Really New with NewSQL? Thoughts on Future Work \u00b6 Database is a long-standing area with tons of papers published every year. There is never lack of innovation in this area. The challenges usually stem from the use of new hardware, networking, and use cases. Based on the recent trends, I think the following directions interest me. Some of them have been explored already or being explored. Database with high speed network such as RDMA. The use of RDMA challenges the transaction design, the replication protocol design, and so on. It bascially calls for a system re-design. Systems such as FaRM, HERD, FORD, pDPM and so on have explored this area quite extensively. But I always feel there is more to explore here. For instance, explore the data structure designs. Database on disaggregation and progrmmable networking hardware. Qizhen has done some amazing work in this space. But hs work is limited to a certain design choices. Besides, we should bring in programmable networking hardware such as p4 switch, NIC, etc. Can we break down a database into small code pieces and then run them on top of a set of small devices.","title":"Distributed Transactions and Databases"},{"location":"notes/dist-xact/#distributed-transactions-and-databases","text":"Version History Date Description Apr 5, 2022 Reorg Feb 25, 2022 Initial","title":"Distributed Transactions and Databases"},{"location":"notes/dist-xact/#why-i-started-this-note","text":"This note was originally written in this google doc . This note was my attempt to revive the distributed transaction topic and to get a better understanding about database systems in general. The result was quite fruitful, I covered various concurrency control schemes, isolation levels, etc. The consensus protocols, query optimizations etc topics are not extensively discussed here. Today 02/16/2022, I\u2019m reading the FORD, FAST\u201922 paper, they are designing distributed transactions for disaggregated persistent memory, they talked about OCC, 2PL, primary-backup etc schemes, and I decided to take another serious look at this topic. I still have the vivid memory of me reading some old Transaction-related surveys (after the ZooKeeper paper) in a small, smelly, broken Purdue ECE room when I first started my PhD. I also had a vivid memory of a meeting among myself, Yiying, Stanko, Marcus in a VMR office room. We were talking about OCC, MVCC, and the then upcoming OSDI\u201918 hybrid transaction paper. I was confused. Anyways, let\u2019s get started.","title":"Why I started this note"},{"location":"notes/dist-xact/#quick-takeaways","text":"(1) Concurrency control (CC) is categorized as two types: pessimistic CC using 2-phase locking (2PL) and optimistic CC using Timestamp-Ordering (T/O). . This categorization is derived from a classical paper ( Concurrency Control in Distributed Database Systems , 1981). This image comes from An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914 . Note, I think the MVCC actually should be MVTO. (2) Multi-versioning (MV) is the prevalent default implementation choice in the wild, for its better performance on various scenarios. Most people think MV is a CC mechanism, but it is not. MV must work with a CC mechanism (e.g., 2PL , T/O ) to become a full solution, resulting in combos such as MVTO , MVOCC , MV2PL . In my opinion, the commonly mentioned MVCC in various literatures actually refers to MVTO , i.e., multi-versioning with timestamp-ordering (see the MVCC section below for more details). This image shows the commercial/research use of MVCC DBMS. Credit: An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201817 (3) For better performance, DBMS usually adopt Snapshot Isolation or Read Committed as their default isolation level . The Serializable isolation level is usually not the default one in commercial DBMS. It is baffling to know the fact that many real world systems are actually operating under a weak consistency model and we (and the world) are okay with it! The RedBook offers an interesting take on this topic. The market follows Gresham\u2019s law: bad money drives out good money (See the Isolation section for more details). This image shows the default Isolation level used by various systems. Credit: Highly Available Transactions: Virtues and Limitations, VLDB\u201813","title":"Quick Takeaways"},{"location":"notes/dist-xact/#concepts","text":"","title":"Concepts"},{"location":"notes/dist-xact/#concurrency-control","text":"Pessimistic Concurrency Control & Optimistic Concurrency Control. Must Read Concurrency Control in Distributed Database Systems , 1981. This paper categorizes 2PL, MVCC, OCC etc into 2 big types. On Optimistic Methods for Concurrency Control, 1981 . This is the first OCC paper. An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914 . This CMU paper has follows the 1981 paper\u2019s categorization on CC methods. An Evaluation of Distributed Concurrency Control, VLDB\u201917 An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201917 . This paper is a must read, it explains what is MVTO, MV2PL, MVOCC, etc. Optional Aurogon: Taming Aborts in All Phases for Distributed In-Memory Transactions, FAST\u201822 Optional FORD, FAST\u201822 Courses CMU Database Systems (15-445/645) , thanks to Andy Pavlo Concurrency Control Theory Two-Phase Locking Concurrency Control Timestamp Ordering Concurrency Control Multi-Version Concurrency Control CMU Advanced Database Systems (15-721) , thanks to Andy Pavlo Multi-Version Concurrency Control (Design Decisions) Multi-Version Concurrency Control (Protocols) Multi-Version Concurrency Control (Garbage Collection) As we mentioned earlier, database concurrency control is categorized as two types: pessimistic CC using 2-phase locking (2PL) and optimistic CC using Timestamp-Ordering (T/O) . This categorization is derived from this classical paper Concurrency Control in Distributed Database Systems . The following table is from An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914 . Also from this CMU 15-445 slide : Recap: Pessimistic CC: Two-phase Locking (2PL) Optimistic CC: Timestamp Ordering (T/O) TO OCC MVCC-TO The well-known OCC , MVCC-TO concepts fall into the T/O category. However, don\u2019t confuse the MVCC with concurrency control. MVCC is not a concurrency control method. It must work with a CC method. The above table has MVCC under T/O because it is MVCC-T/O. (Old note: After reading the VLDB\u201917 paper, I think that MVCC can NOT be categorized as a standalone concurrency control method. Hence, we should not say MVCC, OCC, 2PL as if they are in the same league. MVCC states multiple versions of the same object/tuple, it needs to work with other concurrency control methods, so as to end up with MVTO, MVOCC, MV2PL. I think the most common one, or the one that people unconsciously talk about is MVTO. See the following MVCC section for more details!) Call back to Hotpot: I think its MRSW is 2PL+2PC, MRMW is OCC+2PC.","title":"Concurrency Control"},{"location":"notes/dist-xact/#pessimistic-cc-2pl","text":"Not too much to explain here. Maybe read the MV2PL paper for the MV + 2PL combo.","title":"Pessimistic CC: 2PL"},{"location":"notes/dist-xact/#optimistic-cc-to","text":"The essense of T/O, as its name suggested, is using timestamp to order operations and transactions. Image there exist a perfect logical clock available to all distributed nodes. Whenever a node wants to run a transaction, it will take a timestamp based on the global clock. The node further attaches this timestamp to all operations within the transaction it wishes to execute. This practice establishes a global order on all transactions. Conflicts therefore can be resolved using timestamps. The above reasoning is a super high-level gist on how a T/O based CC could work. There are many nuances and implementation choices to be made. First of all, there is no such perfect clock among distributed nodes. Even if there is a centralize time management system, the cost will be super high. Because it has high-concurrency issues. Second, a system can order things in the beginning of a transaction, or in the middle, or in the end (OCC). Third, there might a single version, or multiple versions of the same data. Combined, they lead to several popular subcategories listed below. Basic Timestamp-Ordering (Basic T/O) Optimistic Concurrency Control (OCC) Multi-version Concurrency Control (MVCC) with T/O Quote the VLDB\u201814 paper: Timestamp ordering (T/O) concurrency control schemes generate a serialization order of transactions a priori and then the DBMS enforces this order. A transaction is assigned a unique, monotonically increasing timestamp before it is executed; this timestamp is used by the DBMS to process con\ufb02icting operations in the proper order (e.g., read and write operations on the same element, or two separate write operations on the same element). As for their detailed implementation rationale, I recommend reading An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914 , CMU 15-445 slide .","title":"Optimistic CC: T/O"},{"location":"notes/dist-xact/#multi-versioning","text":"Papers https://15721.courses.cs.cmu.edu/spring2020/schedule.html . This course has links to various MVCC papers An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201917 Serializable Snapshot Isolation in PostgreSQL, VLDB\u201912 Scalable Garbage Collection for In-Memory MVCC Systems, VLDB\u201917 After a couple days of intensive reading, my understanding about MVCC has expanded quite a lot. It kind of went like this: In the first stage, I would list MVCC as the opposite approach to OCC. And appears this is most people\u2019s impression? Meaning, when we talk about a system, we will describe it either as OCC or MVCC, as if they are two different things that cannot co-exist. After reading Peloton, VLDB\u201917 paper and the Alibaba blog post, I realized that my understanding wasn\u2019t correct. They reminded me that OCC, at its core, is a concurrency control method, with a clear goal of reducing the amount of time that a transaction holds locks . Since the original and most OCC implementations are using a single-versioned database plus local copies, we naturally think OCC \u21d2 single version. However, if we recall the core of OCC, it does not preclude multi-versioning! . OCC can work with MVCC. My misconception also applies to MVCC, not just OCC. Like the alibaba blog post said, MVCC alone is not a concurrency control method, it merely says there will be multiple versions of the same object/tuple . As a result, MVCC has to work with a real concurrency control method to become a full solution. That\u2019s why we have MVCC+TO, MVCC+2PL, MVCC+OCC. MVCC is an optimization technique for read and write requests. It does not completely solve the concurrency problem of databases, so it must be used with concurrency control techniques for a complete concurrency control. E.g., multiversion two-phase locking (MV2PL), multiversion timestamp ordering (MVTO), multiversion optimistic concurrency control (MVOCC), and MV-SSI. I highly recommend the An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201917 paper for a better understanding about MVTO, MVOCC, MV2PL, and how to implement them. This image is from this Alibaba Blog . It is inline with what the above VLDB\u201917 paper said. It is important to note that MVCC is the de-facto choice for modern DBMS for its better performance regarding read/write transactions .","title":"Multi-Versioning"},{"location":"notes/dist-xact/#isolation-serializability-snapshot-isolation-linearliability","text":"Some official Isolation levels in DBMS systems: Serializable Repeatable reads Read committed Read uncommitted Readings: The RedBook Chapter 6 has great discussion on why weak consistency (e.g., non-serializable snapshot isolation) is more popular than the serializability, and their guess on why the world is \u201cokay\u201d with that usage. A Critique of ANSI SQL Isolation Levels, 1995 Database Isolation Levels explained | by sudan Real Transactions are Serializable CockroachDB provides strong (\u201cSERIALIZABLE\u201d) isolation by default to ensure that your application always sees the data it expects. When you use a non-SERIALIZABLE isolation level, you\u2019re giving the database permission to return an incorrect answer in the hope that it will be faster than producing the correct one. Oracle\u2019s implementation of the SERIALIZABLE isolation level is actually a weaker mode called \u201csnapshot isolation\u201d: It is stronger than READ COMMITTED but weaker than SERIALIZABLE. It is similar to REPEATABLE READ but not exactly equivalent PostgreSQL: Documentation: 14: 13.2. Transaction Isolation Highly Available Transactions: Virtues and Limitations, VLDB\u201917 Discussed the default isolation models used by various systems. Quite telling Most systems DO NOT have Serializable as the default. Takeaways Many real-world DBMS and NoSQL systems adopt a weak consistency model (e.g., non-serializable snapshot isolation) as the default isolation level. They prefer this over serializability because a weak consistency model offers better performance. Weak consistency could lead to anomalies that are super hard to reason about. So why is the real world okay using this model? The redbook\u2019s guess is that there is not enough concurrency in the real world workload so that corner cases rarely happen. I don\u2019t really buy this argument but I can\u2019t think of another good reason. None of these weak isolation models guarantees serializability, but, as we see below, their bene\ufb01ts are often considered to outweigh costs of possible consistency anomalies that might arise from their use . The reason I came across this is because I was trying to understand Snapshot Isolation while reading NAM-DB (it provides SI). And turns out it is a much deeper discussion. This wiki Snapshot Isolation has a great explanation on what SI exactly is, and how it compares to the strict serializability. * The following note was written before I read the SI wiki : I have a very vague understanding about read-snapshots. My first thought is that it is probably only possible with MVCC, but not with OCC. Because intuitively, MVCC maintains multiple versions of the same object, hence able to provide a snapshot with respect to time. Spanner uses MVCC (2PL+2PC+Paxos) and has snapshots-related APIs. FaRMv1, DrTM uses OCC and has no snapshots . * After reading the SI wiki : I think my first impression is correct. MVCC is convenient to implement Snapshot Isolation, as MVCC already maintains a series of recent history. However, I\u2019m not 100% sure whether we can implement SI with OCC as well . We definitely need extra states on top of a normal OCC, and will that just result in sth like MVCC? * **Snapshot Isolation essentially allows****disjoint writes****from concurrent transactions, hence could result in a final state that is not possible in a Serialiable transaction.**Check the example case in the wiki, it is great and simple. * System wise, I came across these that provide SI * Spanner - provide both serializable and (read-only) snapshot transactions * NAM-DB, VLDB\u201917 - provides SI-only transactions Serializable Snapshot Isolation (SI) Serializable Snapshot Isolation (SSI)","title":"Isolation: Serializability, Snapshot Isolation, Linearliability"},{"location":"notes/dist-xact/#replication-protocols","text":"Paxos Vertical Paxos Raft Primary-Backup Virtual Synchrony TODO: come back and add more.","title":"Replication Protocols"},{"location":"notes/dist-xact/#integrate-distributed-transaction-and-replication","text":"(image from TAPIR, SOSP\u201915) I think most traditional DBMS systems implement distributed transactions and replication *protocols as two different things. For example, the dist-xact could be sth like 2PL+2PC, OCC+2PC, MVOCC+2PC. Beneath, the replication protocol could be Primary-Backup replication, Paxos, or Raft. For Google Spanner , (1) I think their distributed transaction is multi-versioned 2-phase locking with distributed 2-phase commit (i.e., MV2PL+2PC ). (2) Beneath, Spanner uses Paxos for data replication. The metadata is stored in GFS. In their design, a set of machines form a Paxos group. Each paxos group has a leader. During a transaction, this leader is the transaction manager for its Paxos group. If a distributed transaction spans multiple Paxos groups, all group leaders would run MV2PL+2PC among them; leaders themselves run Paxos protocol within their own Paxos group. This layering is good for modularization but at the cost of more data/messages exchanged. But Spanner is a geo-distributed database, such design might be okay. It is not like it is building on top of RDMA or something. The takeway message is that: The naive way of layering a distributed transaction protocol on top of a replication protocol results in over-coordination . It is only natural to co-design dist-xact and replication . For instance, FaRM, SOSP\u201915 & FORD, FAST\u201822 both describe a co-designed four-phase protocol (lock, validation, commit-backup, commit-primary). Related work in this space **Hotpot, SoCC\u201917**co-designs distributed transaction and replication in its MRSW and MRMW protocols (which are 2PL+2PC, and OCC+2PC, respectively) FaRMv1, SOSP\u201915 & NSDI\u201914 co-designs distributed transaction and replication in one 4-phase protocol, using RDMA FaRMv2, SIGMOD\u201919 TAPIR, SOSP\u201915 FORD: Fast One-sided RDMA-based Distributed Transactions for Disaggregated Persistent Memory, FAST\u201822 Papers from Mu Shuai","title":"Integrate Distributed Transaction and Replication"},{"location":"notes/dist-xact/#2-phase-commit-vs-2pl","text":"2-phase locking 2-phase commit 3-phase commit The two-phase commit (2PC) protocol should not be confused with the two-phase locking (2PL) protocol, a concurrency control protocol. [ NOTE: the description about OCC, MVCC, 2PL might be wrong. I had the wrong impression about them. But now I understand after reading the VLDB\u201917 paper. I believe the MVCC below can be thought of as MVCC-TO, or MVTO. ] CC methods such as 2PL, T/O(OCC, MVCC-TO, T/O) are used to ensure that concurrent operations to shared data are serialized, hence ensuring serializability and data consistency. CC ensures operations such as read and write are ordered properly. CC can be used both within a single node or across nodes (e.g., the An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201904 paper evaluates several CC methods within a single node). However, a simple CC is not sufficient when it comes to a distributed setting with multiple nodes: it cannot ensure a transaction commit could commit at all participating nodes. For instance, some nodes may have committed, others may have not - and this creates an inconsistent state. Let me use 2PL as an example: in 2PL, we first grab all locks across all involving nodes, we then run the execution/logic locally on a node, we then send all the new data (if any) to other nodes and release the locks. In the last step, there is no way for us to make sure that all participating nodes have received the message. If only some of them finalized/committed the transaction, then the whole database/system is in an inconsistent state. This is where Atomic Commit Protocol such as 2-phase commit comes to rescue. It ensures that all participants either all commit or none of them commits the transaction. It does so by using another 2-phase protocol: prepare + commit. It is not hard to understand. There are more complicated methods such as 3PC or Paxos Commit. I think my original confusion about 2PC and 2PL stems from my illusion that we can use 2PL to also implement what 2PC is designed to achieve. But after the above reasoning, I realized that is not possible. 2PC and 2PL have very clear distinctions. I also had a misconception that 2PC is needed because it can ensure durability . This is also false because 2PC is required simply to ensure atomic commit, for both scenarios w/ or w/o guarantees. If we want durability, then 2PC\u2019s participants would need to either do local logging or build on top of a replication mechanism such as Paxos. A short summary: Concurrency control protocols: 2PL, T/O (OCC, MVCC, etc) Atomic commit protocols 2PC, 2PC, paxos-commit Concurrency control methods can work in a single node or across node Once a CC goes distributed, it requires a atomic commit to ensure distributed consistency 2PL + 2PC, OCC + 2PC, MVCC + 2PC etc are concurrency control + atomic commit Atomic commit can include or exclude durability guarantee","title":"2-Phase Commit v.s. 2PL"},{"location":"notes/dist-xact/#classical-systems","text":"These systems of course touch most of the above concepts. ZooKeeper. The key thing is its Atomic Broadcast network library. Google BigTable, need a revisit Google Spanner. I have vivid memory reading it. TruTime. Need a revisit as well. It touches a lot of things, appears it is MVCC? And uses Paxos.","title":"Classical Systems"},{"location":"notes/dist-xact/#misc","text":"","title":"Misc"},{"location":"notes/dist-xact/#scenarios-and-hardware","text":"One key thing worth considering is the operating environment. Some systems like Spanner target geo-distributed data centers, which could go though low-latency WAN.","title":"Scenarios and Hardware"},{"location":"notes/dist-xact/#bottlenecks","text":"Many papers and systems have mentioned that the global timestamp allocation is a major bottleneck in Timestamp Ordering concurrency control systems (including OCC and MVCC). This is easy to understand: having some sort of global data structure that increases monotonically is hard in a distributed setting. I think that\u2019s why several systems (Spanner, FaRMv2) resort to proactively dealing with clock uncertainties.","title":"Bottlenecks"},{"location":"notes/dist-xact/#in-memory-vs-disk-base-dbms","text":"XXX","title":"In-memory v.s. Disk-base DBMS"},{"location":"notes/dist-xact/#self-driving-dbms","text":"Essentially uses ML to make some decisions? Readings: Self-Driving Database Management Systems , CIDR\u201917 Automatic Database Management System Tuning Through Large-scale Machine Learning","title":"Self-Driving DBMS"},{"location":"notes/dist-xact/#papers-and-readings","text":"Courses Schedule | CMU 15-445/645 :: Intro to Database Systems (Fall 2019) . This is DBMS basics, good start. Schedule - CMU 15-721 :: Advanced Database Systems (Spring 2020) . This is advanced paper reading. General Readings 01 Papers - ALL - a TAB is dedicated to this topic Zotero Paper Collection http://www.redbook.io/ The famous Red Book theanalyst/awesome-distributed-systems - Github Awesome List Distributed Systems Reading List - Reading List Good Readings Time, Clocks, and the Ordering of Events in a Distributed System, 1978 - classical On Optimistic Methods for Concurrency Control, 1981 First paper proposing OCC, definitely a seminal paper. Concurrency Control in Distributed Database Systems , 1981 This paper categorizes 2PL, MVCC, OCC etc into 2 big types. The CMU slides/papers use this categorization to this date. Linearizability: a correctness condition for concurrent objects , 1990 An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914 A good read on comparing various concurrency control schemes. Note that the MVCC mentioned in this paper is MVTO. An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201917 This is a really good read and should be read in great detail. Understand that OCC\u2019s core is to reduce the critical section time. And MVCC is not a concurrency control method on its own, it merely enables multiple versions of the same object/tuple. Hence MVCC could work with any concurrency control methods, resulting in combos like MVTO, MVOCC, MV2PL. An Evaluation of Distributed Concurrency Control, VLDB\u201917 This read reminds us the default Isolation level out in the wild is usually not serializability, but something weaker like Snapshot Isolation, or Read Committed.","title":"Papers and Readings"},{"location":"notes/dist-xact/#misc_1","text":"The Marzullo\u2019s Algorithm, used by Google Spanner. https://en.wikipedia.org/wiki/Marzullo%27s_algorithm Opacity, from FaRMv2 What\u2019s Really New with NewSQL? What\u2019s Really New with NewSQL?","title":"Misc"},{"location":"notes/dist-xact/#thoughts-on-future-work","text":"Database is a long-standing area with tons of papers published every year. There is never lack of innovation in this area. The challenges usually stem from the use of new hardware, networking, and use cases. Based on the recent trends, I think the following directions interest me. Some of them have been explored already or being explored. Database with high speed network such as RDMA. The use of RDMA challenges the transaction design, the replication protocol design, and so on. It bascially calls for a system re-design. Systems such as FaRM, HERD, FORD, pDPM and so on have explored this area quite extensively. But I always feel there is more to explore here. For instance, explore the data structure designs. Database on disaggregation and progrmmable networking hardware. Qizhen has done some amazing work in this space. But hs work is limited to a certain design choices. Besides, we should bring in programmable networking hardware such as p4 switch, NIC, etc. Can we break down a database into small code pieces and then run them on top of a set of small devices.","title":"Thoughts on Future Work"},{"location":"notes/dynamic_linking/","text":"Dynamic Linking \u00b6 Version History Date Description Mar 19, 2021 add sth about LD_PRELOAD Jan 01, 2021 Add kernel module loading part Dec 24, 2020 Adopted from my previous note This blog looks at some part of the user-space dynamic linker, how kernel loads user program, and how kernel loads kernel modules. The related code: glibc, kernel execve loader, kernel module loader. C Start Up (csu) \u00b6 For code pointers, see the glibc code here . In glibc: csu/libc-start.c __libc_start_main() is the entry point. Inside, it will call __libc_csu_init() . Then it will call user\u2019s main() . Great reference: Linux x86 Program Start Up . I saved a printed PDF copy in this repo. Dynamic Linking in User Space \u00b6 The dynamic linker/loader ld.so is part of glibc. I was particularly interested in how it resolves the dynamic symbols during runtime. I took a brief read of the source code and found some relevant ones. ld.so \u00b6 ld.so is the dynamic linker/loader: The programs ld.so find and load the shared objects (shared libraries) needed by a program, prepare the program to run, and then run it. You can run man ld.so to see more details. ld.so is a program, after all. It is part of glibc library. ELF\u2019s .interp section points to the dynamic linker. During execve(), kernel will jump to ld.so instead of user code entry point. Related code: elf/rtld.c , sysdep/generic , sysdep/x86_64/ , and more Inside dl_main() , you can see how LD_PRELOAD is handled. GOT[1] contains address of the link_map data structure. GOT[2] points to _dl_runtime_resolve() ! This is the runtime dynamic linker entry point. File sysdep/generic/dl-machine.c populates GOT[1] and GOT[2] . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 /* Set up the loaded object described by L so its unrelocated PLT entries will jump to the on-demand fixup code in dl-runtime.c. */ static inline int elf_machine_runtime_setup ( struct link_map * l , int lazy ) { extern void _dl_runtime_resolve ( Elf32_Word ); if ( lazy ) { /* The GOT entries for functions in the PLT have not yet been filled in. Their initial contents will arrange when called to push an offset into the .rel.plt section, push _GLOBAL_OFFSET_TABLE_[1], and then jump to _GLOBAL_OFFSET_TABLE[2]. */ Elf32_Addr * got = ( Elf32_Addr * ) D_PTR ( l , l_info [ DT_PLTGOT ]); got [ 1 ] = ( Elf32_Addr ) l ; /* Identify this shared object. */ /* This function will get called to fix up the GOT entry indicated by the offset on the stack, and then jump to the resolved address. */ got [ 2 ] = ( Elf32_Addr ) & _dl_runtime_resolve ; } return lazy ; } _dl_runtime_resolve() is architecture specific and has a mix of assembly and C code. The flow is similar to the syscall handling: it first saves the registers, then calling the actual resolver, then restore all saved registers. For 64bit x86, the source code is in sysdeps/x86_64/dl-trampoline.h : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 .globl _dl_runtime_resolve .type _dl_runtime_resolve , @function _dl_runtime_resolve: ... ... # Copy args pushed by PLT in register. # %rdi: link_map, %rsi: reloc_index mov ( LOCAL_STORAGE_AREA + 8 )( %BASE ), %RSI_LP mov LOCAL_STORAGE_AREA ( %BASE ), %RDI_LP call _dl_fixup # Call resolver. mov %RAX_LP , %R11_LP # Save return value ... Bingo, _dl_fixup() is the final piece of the runtime dynamic linker resolver. We could find it in elf/dl-runtime.c , which is a file for on-demand PLT fixup.: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /* This function is called through a special trampoline from the PLT the first time each PLT entry is called. We must perform the relocation specified in the PLT of the given shared object, and return the resolved function address to the trampoline, which will restart the original call to that address. Future calls will bounce directly from the PLT to the function. */ DL_FIXUP_VALUE_TYPE attribute_hidden __attribute (( noinline )) ARCH_FIXUP_ATTRIBUTE _dl_fixup ( # ifdef ELF_MACHINE_RUNTIME_FIXUP_ARGS ELF_MACHINE_RUNTIME_FIXUP_ARGS , # endif struct link_map * l , ElfW ( Word ) reloc_arg ) { ... } Understanding this piece of code requires some effort. Happy hacking! Fun fact about LD_PRELOAD \u00b6 If you use LD_PRELOAD to run a program, it will affect popen() since it will inherit environment variables. Hence, if you are doing some one time initilization within in your LD_PRELOAD library via, say constructor marked function, you should call unsetenv(\"LD_PRELOAD\") before popen() call. Understanding \u00b6 Most recent ELF produced by GCC is slightly different than the ones described by previous textbook or papers. The difference is small, though. You should use man elf to check latest. When a program imports a certain function or variable, the linker will include a string with the function or variable\u2019s name in the .dynstr section. A symbol (Elf Sym) that refers to the function or variable\u2019s name in the .dynsym section, and a relocation (Elf Rel) pointing to that symbol in the .rela.plt section. .rela.dyn and .rela.plt are for imported variables and functions, respectively. .plt is the normal one, it has instructions. .got and .got.plt maybe the first is for variable, and the latter is for function. But essentially the same global offset table functionality. Relationship among .dynstr , .dynsym , .rela.dyn or .rela.plt . Credit: link : PIC Lazy Binding. Credit: link : Note GOT and PLT were invented for share libraries, so those libraries can be used by arbitrary processes without changing any of the library text. However, nowadays, even an non-PIC binary will always have GOT and PLT sections. In theory, it probably should use basic load-time relocation to resolve dynamic symbols (See CSAPP chapter 7 if you are not familiar with this). I think GOT/PLT are used over load-time relocation technique for the following 2 reasons: a) load-time relocation needs to modify code and this not good during time. Especially considering code section probably is not writable. b) GOT/PLT\u2019s lazy-binding has performance win at start-up time. However, keep in mind that GOT/PLT\u2019s lazy-bindling pay extra runtime cost! Reading: System V Application Binary Interface How the ELF Ruined Christmas How Kernel Loads User Program \u00b6 Kernel loads user program via exec() or some variations. This post explained the flow in great details. Note that kernel can recognize dynamic linking via the .interp section and then invoke the dynamic linker ld.so instead of invoking user ELF binary directly. How Kernel Loads Kernel Module \u00b6 Kernel can load modules during runtime. Those modules are ELF binaries. Let\u2019s first examine those binaries and see how kernel parses them. Suppose we have this simple C module code: 1 2 3 4 5 6 7 8 9 10 11 12 int foo ( void ) { printk ( \"Hello World! \\n \" ); } static int hello_init ( void ) { printk ( \"Hello World! \\n \" ); printk ( \"Hello World! \\n \" ); foo (); return 0 ; } Once you compile it into a kernel module, we can examine the binary by using objdump -dx hello.ko . Those highlighted lines mark some of the dynamic linking slots. They will be patched by basic load-time relocation. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Disassembly of section .text.unlikely: 0000000000000000 <foo>: 0: e8 00 00 00 00 callq 5 <foo+0x5> 1: R_X86_64_PLT32 __fentry__-0x4 5: 55 push %rbp 6: 48 c7 c7 00 00 00 00 mov $0x0,%rdi 9: R_X86_64_32S .rodata.str1.1 d: 48 89 e5 mov %rsp,%rbp 10: e8 00 00 00 00 callq 15 <foo+0x15> 11: R_X86_64_PLT32 printk-0x4 15: 5d pop %rbp 16: c3 retq 0000000000000017 <init_module>: 17: e8 00 00 00 00 callq 1c <init_module+0x5> 18: R_X86_64_PLT32 __fentry__-0x4 1c: 55 push %rbp 1d: 48 c7 c7 00 00 00 00 mov $0x0,%rdi 20: R_X86_64_32S .rodata.str1.1 24: 48 89 e5 mov %rsp,%rbp 27: e8 00 00 00 00 callq 2c <init_module+0x15> 28: R_X86_64_PLT32 printk-0x4 2c: 48 c7 c7 00 00 00 00 mov $0x0,%rdi 2f: R_X86_64_32S .rodata.str1.1 33: e8 00 00 00 00 callq 38 <init_module+0x21> 34: R_X86_64_PLT32 printk-0x4 38: e8 00 00 00 00 callq 3d <init_module+0x26> 39: R_X86_64_PLT32 foo-0x4 3d: 31 c0 xor %eax,%eax 3f: 5d pop %rbp 40: c3 retq It is also worth checking out the .symtab section. If your module is using kernel functions or variables, the compiler does not know their precise addresses during compile time. The compiler will add several entries into the .symtab with properties marked as GLOBAL, UND . For example, you can run readelf -s hello.ko to check that. I will post part of the output: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Symbol table '.symtab' contains 29 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 SECTION LOCAL DEFAULT 1 .... 13: 0000000000000000 0 FILE LOCAL DEFAULT ABS haha.mod.c .... 21: 0000000000000017 42 FUNC LOCAL DEFAULT 5 hello_init 22: 0000000000000000 11 FUNC LOCAL DEFAULT 3 hello_exit 23: 0000000000000000 896 OBJECT GLOBAL DEFAULT 12 __this_module 24: 0000000000000000 11 FUNC GLOBAL DEFAULT 3 cleanup_module 25: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND __fentry__ 26: 0000000000000017 42 FUNC GLOBAL DEFAULT 5 init_module 27: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND printk 28: 0000000000000000 23 FUNC GLOBAL DEFAULT 5 foo The simplify_symbols() below will find the kernel virtual addresses for UNDEF symbols in the .symtab section. Those will further be used to patch dynamic relocation entries. Now let us dive into kernel implementation. The kernel has several system calls for module. The loading part is using SYSCALL_DEFINE3(init_module) . Within that, it calls the big function load_module() . In the begining of load_module() , there are some usual tasks examining ELF headers, allocating memory etc. After that, kernel will try to find the addresses for UNDEF symbols: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 kernel / module . c load_module () /* Fix up syms, so that st_value is a pointer to location. */ err = simplify_symbols ( mod , info ); if ( err < 0 ) goto free_modinfo ; err = apply_relocations ( mod , info ); if ( err < 0 ) goto free_modinfo ; ==> This function will find the kernel virtual addresses for UNDEF symbols in the ` . symtab ` section . simplify_symbols () case SHN_UNDEF : ksym = resolve_symbol_wait ( mod , info , name ); /* Ok if resolved. */ if ( ksym && ! IS_ERR ( ksym )) { sym [ i ]. st_value = kernel_symbol_value ( ksym ); break ; } After resolving symbols to the real kernel virtual addresses, the next step is to patch the code to update all the relocation entries. If will do so for sections with these two types: SHT_REL and SHT_RELA . It looks like x86_64 is only using apply_relocate_add() , the one with explict addends. 1 2 3 4 5 6 7 8 kernel / module . c apply_relocations () ... else if ( info -> sechdrs [ i ]. sh_type == SHT_REL ) err = apply_relocate ( info -> sechdrs , info -> strtab , info -> index . sym , i , mod ); else if ( info -> sechdrs [ i ]. sh_type == SHT_RELA ) err = apply_relocate_add ( info -> sechdrs , info -> strtab , info -> index . sym , i , mod ); Zoom into apply_relocate_add() , very interesting function. It is similar to the userspace linker ld.so. It could be summarized as follows: Find the start of the relocation entry section in ELF. Walk through each relocation entry, for each entry, do: Get the location where we need to patch the code (e.g., the assembly instructions dumped above) Find the symbol the entry is using. The symbol was alread resolved to kernel virtual address Update the location by applying certain computation on top of the resolved symbol address. The computation is dictated by entry type (e.g., R_X86_64_PLT32 ) See the full kernel code here . Summary \u00b6 There you have it. We walk through how kernel loads user program, how kernel loads kernel module, and how dynamic linker resolves dynamic linking. The kernel and ld.so share a lot similarities in dealing with the linking process. We have not covered the static linking part in this post, but its process is similar to how the basic load-time relocation patches instructions. The essense of linking and loading is to do lazy information binding and pass information along the toolchain. The whole concetps involves many parties, ranging from compiler, linker, and kernel. Each takes its own part in the process. As always, hope you enjoyed this blog. Happy Hacking!","title":"Dynamic Linking"},{"location":"notes/dynamic_linking/#dynamic-linking","text":"Version History Date Description Mar 19, 2021 add sth about LD_PRELOAD Jan 01, 2021 Add kernel module loading part Dec 24, 2020 Adopted from my previous note This blog looks at some part of the user-space dynamic linker, how kernel loads user program, and how kernel loads kernel modules. The related code: glibc, kernel execve loader, kernel module loader.","title":"Dynamic Linking"},{"location":"notes/dynamic_linking/#c-start-up-csu","text":"For code pointers, see the glibc code here . In glibc: csu/libc-start.c __libc_start_main() is the entry point. Inside, it will call __libc_csu_init() . Then it will call user\u2019s main() . Great reference: Linux x86 Program Start Up . I saved a printed PDF copy in this repo.","title":"C Start Up (csu)"},{"location":"notes/dynamic_linking/#dynamic-linking-in-user-space","text":"The dynamic linker/loader ld.so is part of glibc. I was particularly interested in how it resolves the dynamic symbols during runtime. I took a brief read of the source code and found some relevant ones.","title":"Dynamic Linking in User Space"},{"location":"notes/dynamic_linking/#ldso","text":"ld.so is the dynamic linker/loader: The programs ld.so find and load the shared objects (shared libraries) needed by a program, prepare the program to run, and then run it. You can run man ld.so to see more details. ld.so is a program, after all. It is part of glibc library. ELF\u2019s .interp section points to the dynamic linker. During execve(), kernel will jump to ld.so instead of user code entry point. Related code: elf/rtld.c , sysdep/generic , sysdep/x86_64/ , and more Inside dl_main() , you can see how LD_PRELOAD is handled. GOT[1] contains address of the link_map data structure. GOT[2] points to _dl_runtime_resolve() ! This is the runtime dynamic linker entry point. File sysdep/generic/dl-machine.c populates GOT[1] and GOT[2] . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 /* Set up the loaded object described by L so its unrelocated PLT entries will jump to the on-demand fixup code in dl-runtime.c. */ static inline int elf_machine_runtime_setup ( struct link_map * l , int lazy ) { extern void _dl_runtime_resolve ( Elf32_Word ); if ( lazy ) { /* The GOT entries for functions in the PLT have not yet been filled in. Their initial contents will arrange when called to push an offset into the .rel.plt section, push _GLOBAL_OFFSET_TABLE_[1], and then jump to _GLOBAL_OFFSET_TABLE[2]. */ Elf32_Addr * got = ( Elf32_Addr * ) D_PTR ( l , l_info [ DT_PLTGOT ]); got [ 1 ] = ( Elf32_Addr ) l ; /* Identify this shared object. */ /* This function will get called to fix up the GOT entry indicated by the offset on the stack, and then jump to the resolved address. */ got [ 2 ] = ( Elf32_Addr ) & _dl_runtime_resolve ; } return lazy ; } _dl_runtime_resolve() is architecture specific and has a mix of assembly and C code. The flow is similar to the syscall handling: it first saves the registers, then calling the actual resolver, then restore all saved registers. For 64bit x86, the source code is in sysdeps/x86_64/dl-trampoline.h : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 .globl _dl_runtime_resolve .type _dl_runtime_resolve , @function _dl_runtime_resolve: ... ... # Copy args pushed by PLT in register. # %rdi: link_map, %rsi: reloc_index mov ( LOCAL_STORAGE_AREA + 8 )( %BASE ), %RSI_LP mov LOCAL_STORAGE_AREA ( %BASE ), %RDI_LP call _dl_fixup # Call resolver. mov %RAX_LP , %R11_LP # Save return value ... Bingo, _dl_fixup() is the final piece of the runtime dynamic linker resolver. We could find it in elf/dl-runtime.c , which is a file for on-demand PLT fixup.: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /* This function is called through a special trampoline from the PLT the first time each PLT entry is called. We must perform the relocation specified in the PLT of the given shared object, and return the resolved function address to the trampoline, which will restart the original call to that address. Future calls will bounce directly from the PLT to the function. */ DL_FIXUP_VALUE_TYPE attribute_hidden __attribute (( noinline )) ARCH_FIXUP_ATTRIBUTE _dl_fixup ( # ifdef ELF_MACHINE_RUNTIME_FIXUP_ARGS ELF_MACHINE_RUNTIME_FIXUP_ARGS , # endif struct link_map * l , ElfW ( Word ) reloc_arg ) { ... } Understanding this piece of code requires some effort. Happy hacking!","title":"ld.so"},{"location":"notes/dynamic_linking/#fun-fact-about-ld_preload","text":"If you use LD_PRELOAD to run a program, it will affect popen() since it will inherit environment variables. Hence, if you are doing some one time initilization within in your LD_PRELOAD library via, say constructor marked function, you should call unsetenv(\"LD_PRELOAD\") before popen() call.","title":"Fun fact about LD_PRELOAD"},{"location":"notes/dynamic_linking/#understanding","text":"Most recent ELF produced by GCC is slightly different than the ones described by previous textbook or papers. The difference is small, though. You should use man elf to check latest. When a program imports a certain function or variable, the linker will include a string with the function or variable\u2019s name in the .dynstr section. A symbol (Elf Sym) that refers to the function or variable\u2019s name in the .dynsym section, and a relocation (Elf Rel) pointing to that symbol in the .rela.plt section. .rela.dyn and .rela.plt are for imported variables and functions, respectively. .plt is the normal one, it has instructions. .got and .got.plt maybe the first is for variable, and the latter is for function. But essentially the same global offset table functionality. Relationship among .dynstr , .dynsym , .rela.dyn or .rela.plt . Credit: link : PIC Lazy Binding. Credit: link : Note GOT and PLT were invented for share libraries, so those libraries can be used by arbitrary processes without changing any of the library text. However, nowadays, even an non-PIC binary will always have GOT and PLT sections. In theory, it probably should use basic load-time relocation to resolve dynamic symbols (See CSAPP chapter 7 if you are not familiar with this). I think GOT/PLT are used over load-time relocation technique for the following 2 reasons: a) load-time relocation needs to modify code and this not good during time. Especially considering code section probably is not writable. b) GOT/PLT\u2019s lazy-binding has performance win at start-up time. However, keep in mind that GOT/PLT\u2019s lazy-bindling pay extra runtime cost! Reading: System V Application Binary Interface How the ELF Ruined Christmas","title":"Understanding"},{"location":"notes/dynamic_linking/#how-kernel-loads-user-program","text":"Kernel loads user program via exec() or some variations. This post explained the flow in great details. Note that kernel can recognize dynamic linking via the .interp section and then invoke the dynamic linker ld.so instead of invoking user ELF binary directly.","title":"How Kernel Loads User Program"},{"location":"notes/dynamic_linking/#how-kernel-loads-kernel-module","text":"Kernel can load modules during runtime. Those modules are ELF binaries. Let\u2019s first examine those binaries and see how kernel parses them. Suppose we have this simple C module code: 1 2 3 4 5 6 7 8 9 10 11 12 int foo ( void ) { printk ( \"Hello World! \\n \" ); } static int hello_init ( void ) { printk ( \"Hello World! \\n \" ); printk ( \"Hello World! \\n \" ); foo (); return 0 ; } Once you compile it into a kernel module, we can examine the binary by using objdump -dx hello.ko . Those highlighted lines mark some of the dynamic linking slots. They will be patched by basic load-time relocation. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Disassembly of section .text.unlikely: 0000000000000000 <foo>: 0: e8 00 00 00 00 callq 5 <foo+0x5> 1: R_X86_64_PLT32 __fentry__-0x4 5: 55 push %rbp 6: 48 c7 c7 00 00 00 00 mov $0x0,%rdi 9: R_X86_64_32S .rodata.str1.1 d: 48 89 e5 mov %rsp,%rbp 10: e8 00 00 00 00 callq 15 <foo+0x15> 11: R_X86_64_PLT32 printk-0x4 15: 5d pop %rbp 16: c3 retq 0000000000000017 <init_module>: 17: e8 00 00 00 00 callq 1c <init_module+0x5> 18: R_X86_64_PLT32 __fentry__-0x4 1c: 55 push %rbp 1d: 48 c7 c7 00 00 00 00 mov $0x0,%rdi 20: R_X86_64_32S .rodata.str1.1 24: 48 89 e5 mov %rsp,%rbp 27: e8 00 00 00 00 callq 2c <init_module+0x15> 28: R_X86_64_PLT32 printk-0x4 2c: 48 c7 c7 00 00 00 00 mov $0x0,%rdi 2f: R_X86_64_32S .rodata.str1.1 33: e8 00 00 00 00 callq 38 <init_module+0x21> 34: R_X86_64_PLT32 printk-0x4 38: e8 00 00 00 00 callq 3d <init_module+0x26> 39: R_X86_64_PLT32 foo-0x4 3d: 31 c0 xor %eax,%eax 3f: 5d pop %rbp 40: c3 retq It is also worth checking out the .symtab section. If your module is using kernel functions or variables, the compiler does not know their precise addresses during compile time. The compiler will add several entries into the .symtab with properties marked as GLOBAL, UND . For example, you can run readelf -s hello.ko to check that. I will post part of the output: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Symbol table '.symtab' contains 29 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 SECTION LOCAL DEFAULT 1 .... 13: 0000000000000000 0 FILE LOCAL DEFAULT ABS haha.mod.c .... 21: 0000000000000017 42 FUNC LOCAL DEFAULT 5 hello_init 22: 0000000000000000 11 FUNC LOCAL DEFAULT 3 hello_exit 23: 0000000000000000 896 OBJECT GLOBAL DEFAULT 12 __this_module 24: 0000000000000000 11 FUNC GLOBAL DEFAULT 3 cleanup_module 25: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND __fentry__ 26: 0000000000000017 42 FUNC GLOBAL DEFAULT 5 init_module 27: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND printk 28: 0000000000000000 23 FUNC GLOBAL DEFAULT 5 foo The simplify_symbols() below will find the kernel virtual addresses for UNDEF symbols in the .symtab section. Those will further be used to patch dynamic relocation entries. Now let us dive into kernel implementation. The kernel has several system calls for module. The loading part is using SYSCALL_DEFINE3(init_module) . Within that, it calls the big function load_module() . In the begining of load_module() , there are some usual tasks examining ELF headers, allocating memory etc. After that, kernel will try to find the addresses for UNDEF symbols: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 kernel / module . c load_module () /* Fix up syms, so that st_value is a pointer to location. */ err = simplify_symbols ( mod , info ); if ( err < 0 ) goto free_modinfo ; err = apply_relocations ( mod , info ); if ( err < 0 ) goto free_modinfo ; ==> This function will find the kernel virtual addresses for UNDEF symbols in the ` . symtab ` section . simplify_symbols () case SHN_UNDEF : ksym = resolve_symbol_wait ( mod , info , name ); /* Ok if resolved. */ if ( ksym && ! IS_ERR ( ksym )) { sym [ i ]. st_value = kernel_symbol_value ( ksym ); break ; } After resolving symbols to the real kernel virtual addresses, the next step is to patch the code to update all the relocation entries. If will do so for sections with these two types: SHT_REL and SHT_RELA . It looks like x86_64 is only using apply_relocate_add() , the one with explict addends. 1 2 3 4 5 6 7 8 kernel / module . c apply_relocations () ... else if ( info -> sechdrs [ i ]. sh_type == SHT_REL ) err = apply_relocate ( info -> sechdrs , info -> strtab , info -> index . sym , i , mod ); else if ( info -> sechdrs [ i ]. sh_type == SHT_RELA ) err = apply_relocate_add ( info -> sechdrs , info -> strtab , info -> index . sym , i , mod ); Zoom into apply_relocate_add() , very interesting function. It is similar to the userspace linker ld.so. It could be summarized as follows: Find the start of the relocation entry section in ELF. Walk through each relocation entry, for each entry, do: Get the location where we need to patch the code (e.g., the assembly instructions dumped above) Find the symbol the entry is using. The symbol was alread resolved to kernel virtual address Update the location by applying certain computation on top of the resolved symbol address. The computation is dictated by entry type (e.g., R_X86_64_PLT32 ) See the full kernel code here .","title":"How Kernel Loads Kernel Module"},{"location":"notes/dynamic_linking/#summary","text":"There you have it. We walk through how kernel loads user program, how kernel loads kernel module, and how dynamic linker resolves dynamic linking. The kernel and ld.so share a lot similarities in dealing with the linking process. We have not covered the static linking part in this post, but its process is similar to how the basic load-time relocation patches instructions. The essense of linking and loading is to do lazy information binding and pass information along the toolchain. The whole concetps involves many parties, ranging from compiler, linker, and kernel. Each takes its own part in the process. As always, hope you enjoyed this blog. Happy Hacking!","title":"Summary"},{"location":"notes/hardware_pl/","text":"Hardware Design Languages \u00b6 Version History Date Description Nov 13, 2020 Initial Version Sep 28, 2020 Initial Version Introduction \u00b6 There is an increasing interest from both industry and acadamic on designing high-level domain-specific languages for hardware development (both FPGA and ASIC). These advancements would benefit both software and hardware developers. This document reflects my effort on configuring/running these systems and my thoughts on their pros and cons (if any). System Language Sponsor/Status Xilinx High-Level Synthesis C++ Industry. Mature Chisel Scala Industy and Acadamic. Mature SpinalHDL Scala Industry (solo effort). Mature Dahlia Scala Acadamic Google XLS Rust-like Industry. Pre-mature SpinalHDL \u00b6 SpinalHDL is a scala-based meta HLD programming language. SpinalHDL will convert Scala into Verilog. The generated Verilog is very simple and matches what we write in Scala. Besides, you can use Scala Functional Programming to express hardware, really powerful! I found the following stuff very convenient: 1. Connection . I need to connect a lot of AxiStream interfaces very frequently. To connect an input port onto an output port, we can do something like the following snippets. io . in >> io . out . 2. Functional Programming . I can do something like this to get the sum of an array: array . foldLeft ( 0 )( _+_ ) Google XLS \u00b6 The XLS (Accelerated HW Synthesis) project is a Rust-like DSL for hardware development. Build \u00b6 I used their docker build . , which is extremely lengthy. This is my first using Bazel. Once the build is done, use docker images to check the new docker image ID. To run, docker run -i -t <ID> /bin/bash . After that, follow their quick-guide . The whole project is pre-mature. There are not too many examples, the building process is too long, and even the basic .x -> .v generation needs quite some manual typing. Following its simple_adder quick-start instructions, the following Verilog code is generated: module __simple_add__add ( input wire clk , input wire [ 31 : 0 ] x , input wire [ 31 : 0 ] y , output wire [ 31 : 0 ] out ); // ===== Pipe stage 0: // Registers for pipe stage 0: reg [ 31 : 0 ] p0_x ; reg [ 31 : 0 ] p0_y ; always_ff @ ( posedge clk ) begin p0_x <= x ; p0_y <= y ; end // ===== Pipe stage 1: wire [ 31 : 0 ] p1_add_3_comb ; assign p1_add_3_comb = p0_x + p0_y ; // Registers for pipe stage 1: reg [ 31 : 0 ] p1_add_3 ; always_ff @ ( posedge clk ) begin p1_add_3 <= p1_add_3_comb ; end assign out = p1_add_3 ; endmodule LLVM CIRCT \u00b6 \u201cCIRCT\u201d stands for \u201cCircuit IR Compilers and Tools\u201d . This is also an early-stage LLVM project.","title":"Hardware Design Languages"},{"location":"notes/hardware_pl/#hardware-design-languages","text":"Version History Date Description Nov 13, 2020 Initial Version Sep 28, 2020 Initial Version","title":"Hardware Design Languages"},{"location":"notes/hardware_pl/#introduction","text":"There is an increasing interest from both industry and acadamic on designing high-level domain-specific languages for hardware development (both FPGA and ASIC). These advancements would benefit both software and hardware developers. This document reflects my effort on configuring/running these systems and my thoughts on their pros and cons (if any). System Language Sponsor/Status Xilinx High-Level Synthesis C++ Industry. Mature Chisel Scala Industy and Acadamic. Mature SpinalHDL Scala Industry (solo effort). Mature Dahlia Scala Acadamic Google XLS Rust-like Industry. Pre-mature","title":"Introduction"},{"location":"notes/hardware_pl/#spinalhdl","text":"SpinalHDL is a scala-based meta HLD programming language. SpinalHDL will convert Scala into Verilog. The generated Verilog is very simple and matches what we write in Scala. Besides, you can use Scala Functional Programming to express hardware, really powerful! I found the following stuff very convenient: 1. Connection . I need to connect a lot of AxiStream interfaces very frequently. To connect an input port onto an output port, we can do something like the following snippets. io . in >> io . out . 2. Functional Programming . I can do something like this to get the sum of an array: array . foldLeft ( 0 )( _+_ )","title":"SpinalHDL"},{"location":"notes/hardware_pl/#google-xls","text":"The XLS (Accelerated HW Synthesis) project is a Rust-like DSL for hardware development.","title":"Google XLS"},{"location":"notes/hardware_pl/#build","text":"I used their docker build . , which is extremely lengthy. This is my first using Bazel. Once the build is done, use docker images to check the new docker image ID. To run, docker run -i -t <ID> /bin/bash . After that, follow their quick-guide . The whole project is pre-mature. There are not too many examples, the building process is too long, and even the basic .x -> .v generation needs quite some manual typing. Following its simple_adder quick-start instructions, the following Verilog code is generated: module __simple_add__add ( input wire clk , input wire [ 31 : 0 ] x , input wire [ 31 : 0 ] y , output wire [ 31 : 0 ] out ); // ===== Pipe stage 0: // Registers for pipe stage 0: reg [ 31 : 0 ] p0_x ; reg [ 31 : 0 ] p0_y ; always_ff @ ( posedge clk ) begin p0_x <= x ; p0_y <= y ; end // ===== Pipe stage 1: wire [ 31 : 0 ] p1_add_3_comb ; assign p1_add_3_comb = p0_x + p0_y ; // Registers for pipe stage 1: reg [ 31 : 0 ] p1_add_3 ; always_ff @ ( posedge clk ) begin p1_add_3 <= p1_add_3_comb ; end assign out = p1_add_3 ; endmodule","title":"Build"},{"location":"notes/hardware_pl/#llvm-circt","text":"\u201cCIRCT\u201d stands for \u201cCircuit IR Compilers and Tools\u201d . This is also an early-stage LLVM project.","title":"LLVM CIRCT"},{"location":"notes/kvm-basic/","text":"Just some basics about KVM \u00b6 Update: you can fine more info here https://gdoc.pub/doc/e/2PACX-1vSsskD0A2XgHoZhaYLAkS7lmCOrfxkGXk1WTovWEAyeoELVdBjrE-NzD8h-NvJfKhxMpUg2aXzaD-XG . Resources \u00b6 Intel Virtualisation: How VT-x, KVM and QEMU Work Together Hacking Notes \u00b6 If you are hacking some low-level stuff that is running as a VM, pay close attention if KVM is involved. I started this note because I spent sometime twisting page_fault IDT entry, but it turns out KVM uses async_page_fault . Oh, well. KVM page fault entry ( arch/x86/entry/entry_64.S ) It is idtentry async_page_fault do_async_page_fault has_error_code=1 ..not idtentry page_fault do_page_fault has_error_code=1 More on Virturlization \u00b6 Well. I swear I want to learn more about Virturlization.. Intel SDM, volume 3, Chapter 23 - Chapter 33. \u2013 Yizhou Shan Created: May 20, 2019 Last Updated: Sep 11, 2019","title":"Linux KVM"},{"location":"notes/kvm-basic/#just-some-basics-about-kvm","text":"Update: you can fine more info here https://gdoc.pub/doc/e/2PACX-1vSsskD0A2XgHoZhaYLAkS7lmCOrfxkGXk1WTovWEAyeoELVdBjrE-NzD8h-NvJfKhxMpUg2aXzaD-XG .","title":"Just some basics about KVM"},{"location":"notes/kvm-basic/#resources","text":"Intel Virtualisation: How VT-x, KVM and QEMU Work Together","title":"Resources"},{"location":"notes/kvm-basic/#hacking-notes","text":"If you are hacking some low-level stuff that is running as a VM, pay close attention if KVM is involved. I started this note because I spent sometime twisting page_fault IDT entry, but it turns out KVM uses async_page_fault . Oh, well. KVM page fault entry ( arch/x86/entry/entry_64.S ) It is idtentry async_page_fault do_async_page_fault has_error_code=1 ..not idtentry page_fault do_page_fault has_error_code=1","title":"Hacking Notes"},{"location":"notes/kvm-basic/#more-on-virturlization","text":"Well. I swear I want to learn more about Virturlization.. Intel SDM, volume 3, Chapter 23 - Chapter 33. \u2013 Yizhou Shan Created: May 20, 2019 Last Updated: Sep 11, 2019","title":"More on Virturlization"},{"location":"notes/os/","text":"Operating Systems \u00b6 Multics Plan 9 Taos SPIN: V++: - Cache kernel. Nemesis - A more hybrid approach - QoS Crosstalk Singularity, Helios","title":"Operating Systems"},{"location":"notes/os/#operating-systems","text":"Multics Plan 9 Taos SPIN: V++: - Cache kernel. Nemesis - A more hybrid approach - QoS Crosstalk Singularity, Helios","title":"Operating Systems"},{"location":"notes/packet-sched/","text":"Switch Buffering Architecture and Packet Scheduling Algorithms \u00b6 Version History Date Description Jun 28, 2021 minor update Jan 15, 2021 add some FM10000 figs Jan 13, 2021 more Jan 12, 2021 Initial Version I came across this topic for a research project I\u2019m doing. switch buffering architecture and packet scheduling are two closely related topics. The buffering architecture could limit which scheduling algorithms can be used. Nonetheless, I think they are two different things and we should look at them separately. For example, consider a Combined Input Output Queued Switch (CIOQ), it is possible to use a Shared Memory Buffer to implement the output queues and use a separate PIFO blocks for packet scheduling. Facts about state-of-the-art switches: They use a large central packet buffer, can be as large as 64MB (i.e., Tofino2). They could have some input and output buffers independent from the central packet buffer, but these buffers would be small. They have something called Traffic Manager for packet scheduling. They usually have fixed packet scheduler, as in the algorithms cannot be changed after production. The typical ones are priority-based scheduling and so on. I\u2019m not quite sure whether they have the programmable packet scheduler concept pioneered by the PIFO paper. Switch Buffering Architecture \u00b6 List of different switch buffering architectures: Input Queued (place buffer after each rx port) Virtual Output Queued (each rx port has per-tx queues) Output Queued (place buffer before each tx port) Combined Input and Output Queued (both rx and tx ports have buffers) Shared Memory (depends, it could be a central packet buffer for all tx ports while each tx port still has a small queue) The Output Queue (OQ) mode has the best performance (see ref-2). But if there is incast (multiple rx go to one tx), the buffer before each tx must be able to run N times faster. Since it is impossible to scale the memory bandwidth with respect to network bandwidth, the OQ is rarely used now. On the other hand, the memory in Input Queued (IQ) switch needs only run as fast as the line rate. This makes input queueing very appealing for switches with fast line rates, or with a large number of ports. For this reason, the highest performance switches and routers use input-queued crossbar switches (ref-2). And a lot recent FPGA-based switch papers are using the input-queued mode. BUTT, IQ mode suffers from HOL blocking. So naturally, people came up with the Virtual Output Queued (VOQ) mode, in which each tx port has a buffer at each rx port. However, all those IQ, OQ, VOQ, and CIOQ mode can not easily share the buffers among different ports, i.e., not able to dynamically partition the buffer usage. (I think) this issue calls for the shared memory based switch, in which the central packet buffer can be easily partitioned among tx ports, just a few counters will do. In fact, the switches I know (though only a few), all use shared memory mode. For example, the Inte Barefoot programmable p4 switch Tofino2 has a 64MB central packet buffer. Packet Scheduling \u00b6 There is nothing special about packet scheduling, it is just scheduling a bunch of packets :). This topic is concerned about in which order to transmit packets and when to tranmit them. Just like other scheduling work, there is Work-Conserving v.s. Non-Work-Conserving algorithms. The simplest algorithm is FIFO. But it could have a lot issues, e.g., HOL blocking. Since there might be multiple queues waiting to be transmitted, there could be RR, and weighted RR (WRR). And there are some advanced ones like Strict Priority, Shorted-Time-XXX. Normally, in our current machine, CPU will do the scheduling rather than the NIC itself. For example, kernel has Queuing Discipline layer that supports quite a lot algorithms. With the increasing bandwidth, packet scheduling is more important than before. It is buring CPU cycles, it may have bad perf, etc. So people have tried to offload that onto NIC or propose new CPU-friendly algorithms (i.e., Eiffel, NSDI\u201819 from Google). Packet scheduling is also a important piece for switches. Even for programmable switches, this part is not programmable. So there are work trying to solve that. The PIFO SIGCOMM\u201816 paper is for sure one of the seminal work in this space. To summarize, there are few aspects to consider: 1. where is it running? CPU, NIC, switch, or somewhere else. 2. is it programmable or fixed-function? Case Study \u00b6 Let us look at some real usages out there. Linux Kernel \u00b6 Kernel has a subsystem called queuing discipline, or qdisc . It is a framework to schedule network packets. It is built in the classical way: a generic layer and a set of ops for callback, just like how VFS is built. You can find a lot resources about it online. Anyhow, you can find the code in net/sched/sch_*.c . You can probably look into sch_api.c , sch_generic.c , these seem to be general (e.g., register_qdisc() ). The default qdisc is called pfifo_xxx , you can do a git grep to find it. It has quite a lot other algorithms like RED in sch_red.c . So all those are software-based packet scheduling implementations. If you are interested, you can also check out an NSDI\u201819 paper called Eiffel from Google, which also advocates for software-based packet scheduling. FPGA-based Switching \u00b6 For packet scheduling: we need special data structure design. I\u2019m only aware of these two papers dealing with this: PIFO, SIGCOMM\u201816 PIEO, SIGCOMM\u201819 Both of them have a hardware primitive and a framework to express various packet scheduling algorithms on top of their primitive. PIFO\u2019s source code seems robust and has been used by later projects (e.g., PANIC OSDI\u201820). But PIFO\u2019s verilog implementation suffers from scalability issue. It solely uses LUTs to implement its storage and logic, no BRAM is used. I\u2019m not sure about PIEO. Q: Will a Softcore-based packet scheduler able to keep up the throughput? If not, can be customize the softcore to be packet scheduler friendly? The benefit is probably we can write scheduling algorithm in C (and change freely during runtime) while have hardware (line rate) performance. Intel Barefoot Tofino2 \u00b6 See here , especially the Traffic Manager slide: Intel FM10000 Multi-Host Switch \u00b6 This is a shared-memory switch. This is from their spec. Only payload goes into the shared memory. Headers go into frame processing pipeline. This one shows how headers and payload are separated. Essentially, the packet scheduler only deals with HEADERS. This switch has 8 queues per TX port. If there is multicast, the headers will will duplicated multiple times. Broadcom Trident \u00b6 Resources: https://docs.broadcom.com/doc/12395356 Final Thoughts \u00b6 Although the shared memory based switch works for now, I\u2019m not sure whether it will continue working in the furture. For one, the network bandwidth is increasing, 200Gbps, 400Gbps. Will the memory still be able to sustain such high bandwidth? I doubt that. Also, share memory switch consumes a lot power. Not just the SRAM/DRAM, but also the SERDES transivers. Those guys consume A LOT energy. And this is exactly the reason people started looking into circuit switch. As for packet scheduling, I think there is definitely space for future work. For example, a better FPGA-friendly programmable framework, a dynamic framework shifting the packet scheduling task among CPU/NIC/Switch, a better p4-based algorithm etc. With the growing network bandwidth, all things should be revisted. References \u00b6 The iSLIP scheduling algorithm for input-queued switches, 1999 Matching Output Queueing with a Combined Input Output Queued Switch, 1999 This paper proposed PIFO. It is trying to prove a CIOQ switch can be as good as a output queued switch. Saturating the Transceiver Bandwidth: Switch Fabric Design on FPGAs, 2012 Use shared memory as switch. Investigating the Feasibility of FPGA-based Network Switches, 2019 High-Performance FPGA Network Switch Architecture, 2020 Scheduling Algorithms for High Performance Network Switching on FPGAs: A Survey, 2018 Intel\u00ae Ethernet Switch FM10000 Series Intel Barefoot Tofino2 has a 64MB Unified Packet Buffer PIFO, SIGCOMM\u201816 PIEO, SIGCOMM\u201819 Eiffel, NSDI\u201819 Loom, NSDI\u201819 Programmable Calendar Queue, NSDI\u201820 Carousel, SIGCOMM\u201817","title":"Switch Buffering and Packet Scheduling"},{"location":"notes/packet-sched/#switch-buffering-architecture-and-packet-scheduling-algorithms","text":"Version History Date Description Jun 28, 2021 minor update Jan 15, 2021 add some FM10000 figs Jan 13, 2021 more Jan 12, 2021 Initial Version I came across this topic for a research project I\u2019m doing. switch buffering architecture and packet scheduling are two closely related topics. The buffering architecture could limit which scheduling algorithms can be used. Nonetheless, I think they are two different things and we should look at them separately. For example, consider a Combined Input Output Queued Switch (CIOQ), it is possible to use a Shared Memory Buffer to implement the output queues and use a separate PIFO blocks for packet scheduling. Facts about state-of-the-art switches: They use a large central packet buffer, can be as large as 64MB (i.e., Tofino2). They could have some input and output buffers independent from the central packet buffer, but these buffers would be small. They have something called Traffic Manager for packet scheduling. They usually have fixed packet scheduler, as in the algorithms cannot be changed after production. The typical ones are priority-based scheduling and so on. I\u2019m not quite sure whether they have the programmable packet scheduler concept pioneered by the PIFO paper.","title":"Switch Buffering Architecture and Packet Scheduling Algorithms"},{"location":"notes/packet-sched/#switch-buffering-architecture","text":"List of different switch buffering architectures: Input Queued (place buffer after each rx port) Virtual Output Queued (each rx port has per-tx queues) Output Queued (place buffer before each tx port) Combined Input and Output Queued (both rx and tx ports have buffers) Shared Memory (depends, it could be a central packet buffer for all tx ports while each tx port still has a small queue) The Output Queue (OQ) mode has the best performance (see ref-2). But if there is incast (multiple rx go to one tx), the buffer before each tx must be able to run N times faster. Since it is impossible to scale the memory bandwidth with respect to network bandwidth, the OQ is rarely used now. On the other hand, the memory in Input Queued (IQ) switch needs only run as fast as the line rate. This makes input queueing very appealing for switches with fast line rates, or with a large number of ports. For this reason, the highest performance switches and routers use input-queued crossbar switches (ref-2). And a lot recent FPGA-based switch papers are using the input-queued mode. BUTT, IQ mode suffers from HOL blocking. So naturally, people came up with the Virtual Output Queued (VOQ) mode, in which each tx port has a buffer at each rx port. However, all those IQ, OQ, VOQ, and CIOQ mode can not easily share the buffers among different ports, i.e., not able to dynamically partition the buffer usage. (I think) this issue calls for the shared memory based switch, in which the central packet buffer can be easily partitioned among tx ports, just a few counters will do. In fact, the switches I know (though only a few), all use shared memory mode. For example, the Inte Barefoot programmable p4 switch Tofino2 has a 64MB central packet buffer.","title":"Switch Buffering Architecture"},{"location":"notes/packet-sched/#packet-scheduling","text":"There is nothing special about packet scheduling, it is just scheduling a bunch of packets :). This topic is concerned about in which order to transmit packets and when to tranmit them. Just like other scheduling work, there is Work-Conserving v.s. Non-Work-Conserving algorithms. The simplest algorithm is FIFO. But it could have a lot issues, e.g., HOL blocking. Since there might be multiple queues waiting to be transmitted, there could be RR, and weighted RR (WRR). And there are some advanced ones like Strict Priority, Shorted-Time-XXX. Normally, in our current machine, CPU will do the scheduling rather than the NIC itself. For example, kernel has Queuing Discipline layer that supports quite a lot algorithms. With the increasing bandwidth, packet scheduling is more important than before. It is buring CPU cycles, it may have bad perf, etc. So people have tried to offload that onto NIC or propose new CPU-friendly algorithms (i.e., Eiffel, NSDI\u201819 from Google). Packet scheduling is also a important piece for switches. Even for programmable switches, this part is not programmable. So there are work trying to solve that. The PIFO SIGCOMM\u201816 paper is for sure one of the seminal work in this space. To summarize, there are few aspects to consider: 1. where is it running? CPU, NIC, switch, or somewhere else. 2. is it programmable or fixed-function?","title":"Packet Scheduling"},{"location":"notes/packet-sched/#case-study","text":"Let us look at some real usages out there.","title":"Case Study"},{"location":"notes/packet-sched/#linux-kernel","text":"Kernel has a subsystem called queuing discipline, or qdisc . It is a framework to schedule network packets. It is built in the classical way: a generic layer and a set of ops for callback, just like how VFS is built. You can find a lot resources about it online. Anyhow, you can find the code in net/sched/sch_*.c . You can probably look into sch_api.c , sch_generic.c , these seem to be general (e.g., register_qdisc() ). The default qdisc is called pfifo_xxx , you can do a git grep to find it. It has quite a lot other algorithms like RED in sch_red.c . So all those are software-based packet scheduling implementations. If you are interested, you can also check out an NSDI\u201819 paper called Eiffel from Google, which also advocates for software-based packet scheduling.","title":"Linux Kernel"},{"location":"notes/packet-sched/#fpga-based-switching","text":"For packet scheduling: we need special data structure design. I\u2019m only aware of these two papers dealing with this: PIFO, SIGCOMM\u201816 PIEO, SIGCOMM\u201819 Both of them have a hardware primitive and a framework to express various packet scheduling algorithms on top of their primitive. PIFO\u2019s source code seems robust and has been used by later projects (e.g., PANIC OSDI\u201820). But PIFO\u2019s verilog implementation suffers from scalability issue. It solely uses LUTs to implement its storage and logic, no BRAM is used. I\u2019m not sure about PIEO. Q: Will a Softcore-based packet scheduler able to keep up the throughput? If not, can be customize the softcore to be packet scheduler friendly? The benefit is probably we can write scheduling algorithm in C (and change freely during runtime) while have hardware (line rate) performance.","title":"FPGA-based Switching"},{"location":"notes/packet-sched/#intel-barefoot-tofino2","text":"See here , especially the Traffic Manager slide:","title":"Intel Barefoot Tofino2"},{"location":"notes/packet-sched/#intel-fm10000-multi-host-switch","text":"This is a shared-memory switch. This is from their spec. Only payload goes into the shared memory. Headers go into frame processing pipeline. This one shows how headers and payload are separated. Essentially, the packet scheduler only deals with HEADERS. This switch has 8 queues per TX port. If there is multicast, the headers will will duplicated multiple times.","title":"Intel FM10000 Multi-Host Switch"},{"location":"notes/packet-sched/#broadcom-trident","text":"Resources: https://docs.broadcom.com/doc/12395356","title":"Broadcom Trident"},{"location":"notes/packet-sched/#final-thoughts","text":"Although the shared memory based switch works for now, I\u2019m not sure whether it will continue working in the furture. For one, the network bandwidth is increasing, 200Gbps, 400Gbps. Will the memory still be able to sustain such high bandwidth? I doubt that. Also, share memory switch consumes a lot power. Not just the SRAM/DRAM, but also the SERDES transivers. Those guys consume A LOT energy. And this is exactly the reason people started looking into circuit switch. As for packet scheduling, I think there is definitely space for future work. For example, a better FPGA-friendly programmable framework, a dynamic framework shifting the packet scheduling task among CPU/NIC/Switch, a better p4-based algorithm etc. With the growing network bandwidth, all things should be revisted.","title":"Final Thoughts"},{"location":"notes/packet-sched/#references","text":"The iSLIP scheduling algorithm for input-queued switches, 1999 Matching Output Queueing with a Combined Input Output Queued Switch, 1999 This paper proposed PIFO. It is trying to prove a CIOQ switch can be as good as a output queued switch. Saturating the Transceiver Bandwidth: Switch Fabric Design on FPGAs, 2012 Use shared memory as switch. Investigating the Feasibility of FPGA-based Network Switches, 2019 High-Performance FPGA Network Switch Architecture, 2020 Scheduling Algorithms for High Performance Network Switching on FPGAs: A Survey, 2018 Intel\u00ae Ethernet Switch FM10000 Series Intel Barefoot Tofino2 has a 64MB Unified Packet Buffer PIFO, SIGCOMM\u201816 PIEO, SIGCOMM\u201819 Eiffel, NSDI\u201819 Loom, NSDI\u201819 Programmable Calendar Queue, NSDI\u201820 Carousel, SIGCOMM\u201817","title":"References"},{"location":"notes/paper_fpga/","text":"An FPGA Reading List \u00b6 Version History Date Description Aug 26, 2020 Add those 2 ISCA\u201820 papers to Host Virtual Memory Section Nov 30, 2019 Add a lot security papers Oct 22, 2019 Shuffle scheduling section. More focused. Add two more recent fpga-virt papers Oct 5, 2019 More on scheduling. Add NoC. Add Security. Oct 4, 2019 Add more papers extracted from AmophOS Oct 3, 2019 Initial version from Github A list of related papers I came across while doing FPGA-related research. If you\u2019d like to contribute, please comment below or create PR here . Virtualization Scheduling NoC Memory Hierarchy Dynamic Memory Allocation Integrate with Host Virtual Memory Integrate with Host OSs Security Summary Languages, Runtime, and Framework Xilinx HLS Xilinx CAD High-Level Languages and Platforms Integrate with Frameworks Cloud Infrastructure Misc Applications Programmable Network Database Storage Machine Learning Graph Key-Value Store Bio Consensus Video Processing Blockchain Micro-services FPGA Internal General Partial Reconfiguration Logical Optimization and Technology Mapping Place and Route RTL2FPGA Virtualization \u00b6 Scheduling \u00b6 Scheduling is big topic for FPGA. Unlike the traditional CPU scheduling, there are more aspects to consider, e.g., 1) Partial reconfiguration (PR), 2) Dynamic self PR, 3) Preemptive scheduling, 4) Relocation, 5) Floorplanning, and so on. Preemptive Scheduling \u00b6 Preemptive multitasking on FPGAs, 2000 Multitasking on FPGA Coprocessors, 2000 Context saving and restoring for multitasking in reconfigurable systems, 2005 ReconOS Cooperative multithreading in dynamically reconfigurable systems, FPL\u201809 Block, drop or roll(back): Alternative preemption methods for RH multi-tasking, FCCM\u201809 Hardware Context-Switch Methodology for Dynamically Partially Reconfigurable Systems, 2010 On-chip Context Save and Restore of Hardware Tasks on Partially Reconfigurable FPGAs, 2013 HTR: on-chip Hardware Task Relocation For Partially Reconfigurable FPGAs, 2013 Preemptive Hardware Multitasking in ReconOS, 2015 Preemptive Reconfiguration \u00b6 Preemption of the Partial Reconfiguration Process to Enable Real-Time Computing, 2018 Bitstreams \u00b6 Github 7-series bitmap reverse engineering PARBIT: A Tool to Transform Bitfiles to Implement Partial Reconfiguration of Field Programmable Gate Arrays (FPGAs), 2001 BIL: A TOOL-CHAIN FOR BITSTREAM REVERSE-ENGINEERING, 2012 BITMAN: A Tool and API for FPGA Bitstream Manipulations, 2017 Relocation: \u00b6 Context saving and restoring for multitasking in reconfigurable systems, 2005 REPLICA2Pro: Task Relocation by Bitstream Manipulation in Virtex-II/Pro FPGAs, 2006 Relocation and Automatic Floor-planning of FPGA Partial Configuration Bit-Streams, MSR 2008 Internal and External Bitstream Relocation for Partial Dynamic Reconfiguration, 2009 PRR-PRR Dynamic Relocation, 2009 HTR: on-chip Hardware Task Relocation For Partially Reconfigurable FPGAs, 2003 AutoReloc, 2016 HTR: on-chip Hardware Task Relocation For Partially Reconfigurable FPGAs, 2013 Others \u00b6 hthreads: A hardware/software co-designed multithreaded RTOS kernel, 2005 hthreads: Enabling a Uniform Programming Model Across the Software/Hardware Boundary, FCCM\u201816 Tartan: Evaluating Spatial Computation for Whole Program Execution, ASPLOS\u201806 A virtual hardware operating system for the Xilinx XC6200, 1996 The Swappable Logic Unit: a Paradigm for Virtual Hardware, FCCM\u201897 Run-time management of dynamically reconfigurable designs, 1998 All above ones are early work on FPGA scheduling. Worth a read, but don\u2019t take some of their assumptions. Some have been changed after SO many years. S1. Reconfigurable Hardware Operating Systems: From Design Concepts to Realizations, 2003 S2. Operating Systems for Reconfigurable Embedded Platforms: Online Scheduling of Real-Time Tasks, 2004 Very fruitful discussion. The paper schedules bitstreams inside FPGA, following a Real-Time sched policy (deadline) . Different from CPU sched, FPGA scheduling needs to consider \u201careas\u201d. The chip is a rectangle box, allocating areas needs great care to avoid fragmentation! Context saving and restoring for multitasking in reconfigurable systems, FPL\u201805 Optimizing deschedule perf. This paper discusses ways to save and restore the state information of a hardware task. There are generally three approachs: a) adding indirection. Let app use system API to read/write states. b) yield-type API. c) use PR controller to read back bitstream. This paper used ICAP to read the bitstream back and extract necenssay state information that must be present at next bitstream resume. Scheduling intervals for reconfigurable computing, FCCM\u201808 Hardware context-switch methodology for dynamically partially reconfigurable systems, 2010 Online Scheduling for Multi-core Shared Reconfigurable Fabric, DATE\u201812 Multi-shape Tasks Scheduling for Online Multitasking on FPGAs, 2014 AmophOS, OSDI\u201818 Hardware context switching on FPGAs, 2014 Efficient Hardware Context-Switch for Task Migration between Heterogeneous FPGAs, 2016 NoC \u00b6 Network-on-Chip on FPGA. Interconnection Networks Enable Fine-Grain Dynamic Multi-Tasking on FPGAs, 2002 Like the idea of separating computation from communication. Also a lot discussions about possible NoC designs within FPGA. LEAP Soft connections: Addressing the hardware-design modularity problem, DAC\u201809 Virtual channel concept. Time-insensitive. Leveraging Latency-Insensitivity to Ease Multiple FPGA Design, FPGA\u201812 CONNECT: re-examining conventional wisdom for designing nocs in the context of FPGAs, FPGA\u201812 Your Programmable NIC Should be a Programmable Switch, HotNets\u201818 Memory Hierarchy \u00b6 Papers deal with BRAM, registers, on-board DRAM, and host DRAM. LEAP Scratchpads: Automatic Memory and Cache Management for Reconfigurable Logic, FPGA\u201811 Main design hierarchy: Use BRAM as L1 cache, use on-board DRAM as L2 cache, and host memory as the backing store. Everthing is abstracted away through their interface (similar to load/store). Programming is pretty much the same as if you are writing for CPU. According to sec 2.2.2, its scratchpad controller, is using simple segment-based mapping scheme. Like AmorphOS\u2019s one. LEAP Shared Memories: Automating the Construction of FPGA Coherent Memories, FCCM\u201814 Follow up work on LEAP Scratchpads, extends the work to have cache coherence between multiple FPGAs. Coherent Scatchpads with MOSI protocol. MATCHUP: Memory Abstractions for Heap Manipulating Programs, FPGA\u201815 CoRAM: An In-Fabric Memory Architecture for FPGA-Based Computing CoRAM provides an interface for managing the on- and off-chip memory resource of an FPGA. It use \u201ccontrol threads\u201d enforce low-level control on data movement. Seriously, the CoRAM is just like Processor L1-L3 caches. CoRAM Prototype and evaluation of the CoRAM memory architecture for FPGA-based computing, FPGA\u201812 Prototype on FPGA. Sharing, Protection, and Compatibility for Reconfigurable Fabric with AMORPHOS, OSDI\u201818 Hull: provides memory protection for on-board DRAM using segment-based address translation. Virtualized Execution Runtime for FPGA Accelerators in the Cloud, IEEE Access\u201817 Dynamic Memory Allocation \u00b6 malloc() and free() for FPGA on-board DRAM. A High-Performance Memory Allocator for Object-Oriented Systems, IEEE\u201896 SysAlloc: A Hardware Manager for Dynamic Memory Allocation in Heterogeneous Systems, FPL\u201815 Hi-DMM: High-Performance Dynamic Memory Management in High-Level Synthesis, IEEE\u201818 Integrate with Host Virtual Memory \u00b6 Papers deal with OS Virtual Memory System (VMS). Note that, all these papers introduce some form of MMU into the FPGA to let FPGA be able to work with host VMS. This added MMU is similar to CPU\u2019s MMU and RDMA NIC\u2019s internal cache . Note that the VMS still runs inside Linux (include pgfault, swapping, TLB shootdown and so on.), except one recent ISCA\u201820 paper. Virtual Memory Window for Application-Specific Reconfigurable Coprocessors, DAC\u201804 Early work that adds a new MMU to FPGA to let FPGA logic access on-chip DRAM . Note, it\u2019s not the system main memory. Thus the translation pgtable is different. Has some insights on prefetching and MMU CAM design. Seamless Hardware Software Integration in Reconfigurable Computing Systems, 2005 Follow up summary on previous DAC\u201804 Virtual Memory Window. A Reconfigurable Hardware Interface for a Modern Computing System, FCCM\u201807 This work adds a new MMU which includes a 16-entry TLB to FPGA. FPGA and CPU shares the same user virtual address space, use the same physical memory. FPGA and CPU share memory at cacheline granularity , FPGA is just another core in this sense. Upon a TLB miss at FPGA MMU, the FPGA sends interrupt to CPU, to let software to handle the TLB miss . Using software-managed TLB miss is not efficient. But they made cache coherence between FPGA and CPU easy. Low-Latency High-Bandwidth HW/SW Communication in a Virtual Memory Environment, FPL\u201808 This work actually add a new MMU to FPGA, which works just like CPU MMU. It\u2019s similar to IOMMU, in some sense. But I think they missed one important aspect: cache coherence between CPU and FPGA. There is not too much information about this in the paper, it seems they do not have cache at FPGA. Anyhow, this is why recently CCIX and OpenCAPI are proposed. Memory Virtualization for Multithreaded Reconfigurable Hardware, FPL\u201811 Part of the ReconOS project They implemented a simple MMU inside FPGA that includes a TLB. On protection violation or page invalid access cases, their MMU just hand over to CPU pgfault routines. How is this different from the FPL\u201808 one? Actually, IMO, they are the same. S4 Virtualized Execution Runtime for FPGA Accelerators in the Cloud, IEEE Access\u201817 This paper also implemented a hardware MMU, but the virtual memory system still run on Linux. Also listed in Cloud Infrastructure part. Lightweight Virtual Memory Support for Many-Core Accelerators in Heterogeneous Embedded SoCs, 2015 Lightweight Virtual Memory Support for Zero-Copy Sharing of Pointer-Rich Data Structures in Heterogeneous Embedded SoCs, IEEE\u201817 Part of the PULP project. Essentially a software-managed IOMMU. The control path is running as a Linux kernel module. The datapath is a lightweight AXI transation translation. Flick: Fast and Lightweight ISA-Crossing Call for Heterogeneous-ISA Environments, ISCA\u201820 This paper adds an MMU/TLB into FPGA-side RISC-V to fetch/translate host pgtable entries. This paper\u2019s goal is to migrate threads between different ISAs, the key is VM. But what\u2019s new? A Case for Hardware-Based Demand Paging, ISCA\u201820 This paper is not FPGA-based, but does augments host MMU with pgfault handling capability. This paper targets file-backed pgfault, more specific, ultra-low-latency SSD backed files. It adds several HW units to let CPU MMU able to handle and resolve such pgfaults (essentially offload VFS->FS->BLK->NVMe Driver functionalties into HW. Some part is done via mmap() beforehand). It\u2019s async free page list, async LRU handling are used by our work as well. Integrate with Host OSs \u00b6 A Virtual Hardware Operating System for the Xilinx XC6200, FPL\u201896 Operating systems for reconfigurable embedded platforms: online scheduling of real-time tasks, IEEE\u201804 hthreads: a hardware/software co-designed multithreaded RTOS kernel, 2005 Reconfigurable computing: architectures and design methods, IEE\u201805 BORPH: An Operating System for FPGA-Based Reconfigurable Computers. PhD Thesis. FUSE: Front-end user framework for O/S abstraction of hardware accelerators, FCCM\u201811 ReconOS \u2013 an Operating System Approach for Reconfigurable Computing, IEEE Micro\u201814 Invoke kernel from FPGA. They built a shell in FPGA and delegation threads in CPU to achieve this. They implemented their own MMU (using pre-established pgtables) to let FPGA logic to access system memory. Ref . Read the \u201cOperating Systems for Reconfigurable Computing\u201d sidebar, nice summary. LEAP Soft connections: Addressing the hardware-design modularity problem, DAC\u201809 Channel concept. Good. LEAP Scratchpads: Automatic Memory and Cache Management for Reconfigurable Logic, FPGA\u201811 BRAM/on-board DRAM/host DRAM layering. Caching. LEAP Shared Memories: Automating the Construction of FPGA Coherent Memories Add cache-coherence on top of previous work. Also check out my note on Cache Coherence . LEAP FPGA Operating System, FPL\u201814. A Survey on FPGA Virtualization, FPL\u201818 ZUCL 2.0: Virtualised Memory and Communication for ZYNQ UltraScale+ FPGAs, FSP\u201819 Security \u00b6 If I were to recommend, I\u2019d suggest start from: Recent Attacks and Defenses on FPGA-based Systems, 2019 Physical Side-Channel Attacks and Covert Communication on FPGAs: A Survey, 2019 FPGA security: Motivations, features, and applications, 2014 The whole list: FPGAhammer : Remote Voltage Fault Attacks on Shared FPGAs , suitable for DFA on AES FPGA-Based Remote Power Side-Channel Attacks Characterization of long wire data leakage in deep submicron FPGAS Protecting against cryptographic Trojans in FPGAS FPGA Side Channel Attacks without Physical Access FPGA security: Motivations, features, and applications FPGA side-channel receivers Security of FPGAs in data centers Secure Function Evaluation Using an FPGA Overlay Architecture Mitigating Electrical-level Attacks towards Secure Multi-Tenant FPGAs in the Cloud The Costs of Confidentiality in Virtualized FPGAs Temporal Thermal Covert Channels in Cloud FPGAs Characterizing Power Distribution Attacks in Multi-User FPGA Environments FASE: FPGA Acceleration of Secure Function Evaluation Securing Cryptographic Circuits by Exploiting Implementation Diversity and Partial Reconfiguration on FPGAs Measuring Long Wire Leakage with Ring Oscillators in Cloud FPGAs Physical Side-Channel Attacks and Covert Communication on FPGAs: A Survey Leaky Wires: Information Leakage and Covert Communication Between FPGA Long Wires Using the Power Side Channel of FPGAs for Communication An Inside Job: Remote Power Analysis Attacks on FPGAs Leakier Wires: Exploiting FPGA Long Wires for Covert- and Side-channel Attacks Voltage drop-based fault attacks on FPGAs using valid bitstreams Moats and Drawbridges: An Isolation Primitive for Reconfigurable Hardware Based Systems Sensing nanosecond-scale voltage attacks and natural transients in FPGAs Holistic Power Side-Channel Leakage Assessment: Hiding Intermittent Information Leakage with Architectural Support for Blinking Examining the consequences of high-level synthesis optimizations on power side-channel Register transfer level information flow tracking for provably secure hardware design A Protection and Pay-per-use Licensing Scheme for On-cloud FPGA Circuit IPs Recent Attacks and Defenses on FPGA-based Systems PFC: Privacy Preserving FPGA Cloud - A Case Study of MapReduce A Pay-per-Use Licensing Scheme for Hardware IP Cores in Recent SRAM-Based FPGAs FPGAs for trusted cloud computing Summary \u00b6 Summary on current FPGA Virtualization Status. Prior art mainly focus on: 1) How to virtualize on-chip BRAM (e.g., CoRAM, LEAP Scratchpad), 2) How to work with host, specifically, how to use the host DRAM, how to use host virtual memory. 3) How to schedule bitstreams inside a FPGA chip. 4) How to provide certain services to make FPGA programming easier (mostly work with host OS). Languages, Runtime, and Framework \u00b6 Innovations in the toolchain space. Xilinx HLS \u00b6 Design Patterns for Code Reuse in HLS Packet Processing Pipelines, FCCM\u201819 A very good HLS library from Mellanox folks. Templatised Soft Floating-Point for High-Level Synthesis, FCCM\u201819 ST-Accel: A High-Level Programming Platform for Streaming Applications on FPGA, FCCM\u201818 HLScope+: Fast and Accurate Performance Estimation for FPGA HLS, ICCAD\u201817 Separation Logic-Assisted Code Transformations for Efficient High-Level Synthesis, FCCM\u201814 An HLS design aids that analyze the original program at compile time and perform automated code transformations. The tool analysis pointer-manipulating programs and automatically splits heap-allocated data structures into disjoint, independent regions. The tool is for C++ heap operations. To put in another way: the tool looks at your BRAM usage, found any false-dependencies, and make multiple independent regions, then your II is improved. MATCHUP: Memory Abstractions for Heap Manipulating Programs, FPGA\u201815 This is an HLS toolchain aid. Follow-up work of the above FCCM\u201814 one. This time they use LEAP scracchpads as the underlying caching block. Xilinx CAD \u00b6 Maverick: A Stand-alone CAD Flow for Partially Reconfigurable FPGA Modules, FCCM\u201819 High-Level Languages and Platforms \u00b6 Just-in-Time Compilation for Verilog, ASPLOS\u201819 Chisel: Constructing Hardware in a Scala Embedded Language, DAC\u201812 Chisel is being actively improved and used by UCB folks. Rosetta: A Realistic High-Level Synthesis Benchmark Suite for Software Programmable FPGAs, FPGA\u201818 From JVM to FPGA: Bridging Abstraction Hierarchy via Optimized Deep Pipelining, HotCloud\u201818 HeteroCL: A Multi-Paradigm Programming Infrastructure for Software-Defined Reconfigurable Computing, FPGA\u201819 LINQits: Big Data on Little Clients, ISCA\u201813 From Microsoft, used to express SQL-like functions (thus big data) and runs on ZYNQ (thus little client), You wrote C#, LINQits translate it to verilog, and run the whole thing at a ZYNQ (ARM+FPGA) board. Lime: a Java-Compatible and Synthesizable Language for Heterogeneous Architectures, OOPSLA\u201810 Lime is a Java-based programming model and runtime from IBM which aims to provide a single unified language to program heterogeneous architectures, from FPGAs to conventional CPUs A line of work from Standord Generating configurable hardware from parallel patterns, ASPLOS\u201816 Plasticine: A Reconfigurable Architecture For Parallel Patterns, ISCA\u201817 Spatial: A Language and Compiler for Application Accelerators, PLDI\u201818 Spatial generates Chisel code along with C++ code which can be used on a host CPU to control the execution of the accelerator on the target FPGA. This kind of academic papers must have a lot good ideas. But the truth is it will not be reliable because it\u2019s from academic labs. Integrate with Frameworks \u00b6 Map-reduce as a Programming Model for Custom Computing Machines, FCCM\u201808 This paper proposes a model to translate MapReduce code written in C to code that could run on FPGA and GPU. Many details are omitted, and they don\u2019t really have the compiler. Single-host framework, everything is in FPGA and GPU. Axel: A Heterogeneous Cluster with FPGAs and GPUs, FPGA\u201810 A distributed MapReduce Framework, targets clusters with CPU, GPU, and FPGA. Mainly the idea of scheduling FPGA/GPU jobs. Distributed Framework. FPMR: MapReduce Framework on FPGA, FPGA\u201810 A MapReduce framework on a single host\u2019s FPGA. You need to write Verilog/HLS for processing logic to hook with their framework. The framework mainly includes a data transfer controller, a simple schedule that enable certain blocks at certain time. Single-host framework, everything is in FPGA. Melia: A MapReduce Framework on OpenCL-Based FPGAs, IEEE\u201816 Another framework, written in OpenCL, and users can use OpenCL to program as well. Similar to previous work, it\u2019s more about the framework design, not specific algorithms on FPGA. Single-host framework, everything is in FPGA. But they have a discussion on running on multiple FPGAs. Four MapReduce FPGA papers here, I believe there are more. The marriage between MapReduce and FPGA is not something hard to understand. FPGA can be viewed as another core with different capabilities. The thing is, given FPGA\u2019s reprogram-time and limited on-board memory, how to design a good scheduling algorithm and data moving/caching mechanisms. Those papers give some hints on this. UCLA: When Apache Spark Meets FPGAs: A Case Study for Next-Generation DNA Sequencing Acceleration, HotCloud\u201816 UCLA: Programming and Runtime Support to Blaze FPGA Accelerator Deployment at Datacenter Scale, SoCC\u201816 A system that hooks FPGA with Spark. There is a line of work that hook FPGA with big data processing framework (Spark), so the implementation of FPGA and the scale-out software can be separated. The Spark can schedule FPGA jobs to different machines, and take care of scale-out, failure handling etc. But, I personally think this line of work is really just an extension to ReconOS/FUSE/BORPH line of work. The main reason is: both these two lines of work try to integrate jobs run on CPU and jobs run on FPGA, so CPU and FPGA have an easier way to talk, or put in another way, CPU and FPGA have a better division of labor. Whether it\u2019s single-machine (like ReconOS, Melia), or distributed (like Blaze, Axel), they are essentially the same. UCLA: Heterogeneous Datacenters: Options and Opportunities, DAC\u201816 Follow up work of Blaze. Nice comparison of big and wimpy cores. Cloud Infrastructure \u00b6 Huawei: FPGA as a Service in the Cloud UCLA: Customizable Computing: From Single Chip to Datacenters, IEEE\u201818 UCLA: Accelerator-Rich Architectures: Opportunities and Progresses, DAC\u201814 Reminds me of OmniX . Disaggregation at a different scale. This paper actually targets single-machine case. But it can reflect a distributed setting. Enabling FPGAs in the Cloud, CF\u201814 Paper raised four important aspects to enable FPGA in cloud: Abstraction, Sharing, Compatibility, and Security. FPGA itself requires a shell (paper calls it service logic) and being partitioned into multiple slots. Things discussed in the paper are straightforward, but worth reading. They did not solve the FPGA sharing issue, which, is solved by AmorphOS. FPGAs in the Cloud: Booting Virtualized Hardware Accelerators with OpenStack, FCCM\u201814 Use OpenStack to manage FPGA resource. The FPGA is partitioned into multiple regions, each region can use PR. The FPGA shell includes: 1) basic MAC, and packet dispatcher, 2) memory controller, and segment-based partition scheme, 3) a soft processor used for runtime PR control. One very important aspect of this project is: they envision input to FPGA comes from Ethernet, which is very true nowadays. And this also makes their project quite similar to Catapult. It\u2019s a very solid paper, though the evaluation is a little bit weak. What could be added: migration, different-sized region. The above CF and FCCM papers are similar in the sense that they are both building SW framework and HW shell to provide a unified cloud management system. They differ in their shell design: CF one take inputs from DMA engine, which is local system DRAM, FCCM one take inputs from Ethernet. The things after DMA or MAC, are essentially similar. It seems all of them are using simple segment-based memory partition for user FPGA logic. What\u2019s the pros and cons of using paging here? S1 DyRACT: A partial reconfiguration enabled accelerator and test platform, FPL\u201814 S2 Virtualized FPGA Accelerators for Efficient Cloud Computing, CloudCom\u201815 S3 Designing a Virtual Runtime for FPGA Accelerators in the Cloud, FPL\u201816 S4 Virtualized Execution Runtime for FPGA Accelerators in the Cloud, IEEE Access\u201817 The above four papers came from the same group of folks. S1 developed a framework to use PCIe to do PR, okay. S2 is a follow-up on S1, read S2\u2019s chapter IV hardware architecture, many implementation details like internal FPGA switch, AXI stream interface. But no memory virtualization discussion. S3 is a two page short paper. S4 is the realization of S3. I was particularly interested if S4 has implemented their own virtual memory management. The answer is NO. S4 leveraged on-chip Linux, they just build a customized MMU (in the form of using BRAM to store page tables. This approach is similar to the papers listed in Integrate with Virtual Memory ). Many things discussed in S4 have been proposed multiple times in previous cloud FPGA papers since 2014. MS: A Reconfigurable Fabric for Accelerating Large-Scale Datacenter Services, ISCA\u201814 MS: A Cloud-Scale Acceleration Architecture, Micro\u201816 Catapult is unique in its shell, which includes the Lightweight Transport Layer (LTL), and Elastic Router(ER). The cloud management part, which the paper just briefly mentioned, actually should include everything the above CF\u201814 and FCCM\u201814 have. The LTL has congestion control, packet loss detection/resend, ACK/NACK. The ER is a crossbar switch used by FPGA internal modules, which is essential to connect shell and roles. These two Catapult papers are simply a must read. MS: A Configurable Cloud-Scale DNN Processor for Real-Time AI, Micro\u201818 MS: Azure Accelerated Networking: SmartNICs in the Public Cloud, NSDI\u201818 MS: Direct Universal Access : Making Data Center Resources Available to FPGA, NSDI\u201819 Catapult is just sweet, isn\u2019t it? ASIC Clouds: Specializing the Datacenter, ISCA\u201816 Virtualizating FPGAs in the Cloud, ASPLOS\u201820 , to appear. Misc \u00b6 A Study of Pointer-Chasing Performance on Shared-Memory Processor-FPGA Systems, FPGA\u201816 Applications \u00b6 Programmable Network \u00b6 MS: ClickNP: Highly Flexible and High Performance Network Processing with Reconfigurable Hardware, SIGCOMM\u201816 MS: Multi-Path Transport for RDMA in Datacenters, NSDI\u201818 MS: Azure Accelerated Networking: SmartNICs in the Public Cloud, NSDI\u201818 Mellanox. NICA: An Infrastructure for Inline Acceleration of Network Applications, ATC\u201819 The Case For In-Network Computing On Demand, EuroSys\u201819 Fast, Scalable, and Programmable Packet Scheduler in Hardware, SIGCOMM\u201819 HPCC: high precision congestion control, SIGCOMM\u201819 Offloading Distributed Applications onto SmartNICs using iPipe, SIGCOMM\u201819 Not necessary FPGA, but SmartNICs. The actor programming model seems a good fit. There is another paper from ATC\u201819 that optimizes distributed actor runtime . Database and SQL \u00b6 On-the-fly Composition of FPGA-Based SQL Query Accelerators Using A Partially Reconfigurable Module Library, 2012 Accelerating database systems using FPGAs: A survey, FPL\u201818 Storage \u00b6 Cognitive SSD: A Deep Learning Engine for In-Storage Data Retrieval, ATC\u201819 INSIDER: Designing In-Storage Computing System for Emerging High-Performance Drive, ATC\u201819 LightStore: Software-defined Network-attached Key-value Drives, ASPLOS\u201819 FIDR: A Scalable Storage System for Fine-Grain Inline Data Reduction with Efficient Memory Handling, MICRO\u201819 CIDR: A Cost-Effective In-line Data Reduction System for Terabit-per-Second Scale SSD Array, HPCA\u201819 Machine Learning \u00b6 TABLA: A Unified Template-based Framework for Accelerating Statistical Machine Learning, HPCA\u201816 Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks, FPGA\u201815 From High-Level Deep Neural Models to FPGAs, ISCA\u201816 Deep Learning on FPGAs: Past, Present, and Future, arXiv\u201816 Accelerating binarized neural networks: Comparison of FPGA, CPU, GPU, and ASIC, FPT\u201816 FINN: A Framework for Fast, Scalable Binarized Neural Network Inference, FPGA\u201817 In-Datacenter Performance Analysis of a Tensor Processing Unit, ISCA\u201817 Accelerating Binarized Convolutional Neural Networks with Software-Programmable FPGAs, FPGA\u201817 A Configurable Cloud-Scale DNN Processor for Real-Time AI, ISCA\u201818 Microsoft Project Brainware. Built on Catapult. A Network-Centric Hardware/Algorithm Co-Design to Accelerate Distributed Training of Deep Neural Networks, MICRO\u201818 DNNBuilder: an Automated Tool for Building High-Performance DNN Hardware Accelerators for FPGAs, ICCAD\u201818 FA3C : FPGA-Accelerated Deep Reinforcement Learning\uff0c ASPLOS\u201919 Cognitive SSD: A Deep Learning Engine for In-Storage Data Retrieval, ATC\u201819 Graph \u00b6 A Scalable Processing-in-Memory Accelerator for Parallel Graph Processing, ISCA\u201815 Energy Efficient Architecture for Graph Analytics Accelerators, ISCA\u201816 Boosting the Performance of FPGA-based Graph Processor using Hybrid Memory Cube: A Case for Breadth First Search, FPGA\u201817 FPGA-Accelerated Transactional Execution of Graph Workloads, FPGA\u201817 An FPGA Framework for Edge-Centric Graph Processing, CF\u201818 Key-Value Store \u00b6 Achieving 10Gbps line-rate key-value stores with FPGAs, HotCloud\u201813 Thin Servers with Smart Pipes: Designing SoC Accelerators for Memcached, ISCA\u201813 An FPGA Memcached Appliance, FPGA\u201813 Scaling out to a Single-Node 80Gbps Memcached Server with 40Terabytes of Memory, HotStorage\u201815 KV-Direct: High-Performance In-Memory Key-Value Store with Programmable NIC, SOSP\u201817 This link is also useful for better understading Morning Paper Ultra-Low-Latency and Flexible In-Memory Key-Value Store System Design on CPU-FPGA, FPT\u201818 Bio \u00b6 When Apache Spark Meets FPGAs: A Case Study for Next-Generation DNA Sequencing Acceleration, HotCloud\u201816 FPGA Accelerated INDEL Realignment in the Cloud, HPCA\u201819 Consensus \u00b6 Consensus in a Box: Inexpensive Coordination in Hardware, NSDI\u201816 Video Processing \u00b6 Quantifying the Benefits of Dynamic Partial Reconfiguration for Embedded Vision Applications (FPL 2019) Time-Shared Execution of Realtime Computer Vision Pipelines by Dynamic Partial Reconfiguration (FPL 2018) FPGA Internal \u00b6 FPGA20: Highlighting Significant Contributions from 20 Years of the International Symposium on Field-Programmable Gate Arrays (1992\u20132011) General \u00b6 FPGA and CPLD architectures: a tutorial, 1996 Reconfigurable computing: a survey of systems and software, 2002 Reconfigurable computing: architectures and design methods FPGA Architecture: Survey and Challenges, 2007 Read the first two paragraphs of each section and then come back to read all of that if needed. RAMP: Research Accelerator For Multiple Processors, 2007 Three Ages of FPGAs: A Retrospective on the First Thirty Years of FPGA Technology, IEEE\u201815 Partial Reconfiguration \u00b6 FPGA Dynamic and Partial Reconfiguration: A Survey of Architectures, Methods, and Applications, CSUR\u201818 Must read. DyRACT: A partial reconfiguration enabled accelerator and test platform, FPL\u201814 A high speed open source controller for FPGA partial reconfiguration Hardware context-switch methodology for dynamically partially reconfigurable systems, 2010 Logical Optimization and Technology Mapping \u00b6 FlowMap: An Optimal Technology Mapping Algorithm for Delay Optimization in Lookup-Table Based FPGA Designs, 1994 Combinational Logic Synthesis for LUT Based Field Programmable Gate Arrays, 1996 DAOmap: A Depth-optimal Area Optimization Mapping Algorithm for FPGA Designs, 2004 Place and Route \u00b6 VPR: A New Packing, Placement and Routing Tool for FPGA Research, 1997 VTR 7.0: Next Generation Architecture and CAD System for FPGAs, 2014 RTL2FPGA \u00b6 A Case for FAME: FPGA Architecture Model Execution, 2010 Strober: Fast and Accurate Sample-Based Energy Simulation for Arbitrary RTL, 2016 Evaluation of RISC-V RTL with FPGA-Accelerated Simulation, 2017 FireSim: FPGA-Accelerated Cycle-Exact Scale-Out System Simulation in the Public Cloud, 2018","title":"Papers"},{"location":"notes/paper_fpga/#an-fpga-reading-list","text":"Version History Date Description Aug 26, 2020 Add those 2 ISCA\u201820 papers to Host Virtual Memory Section Nov 30, 2019 Add a lot security papers Oct 22, 2019 Shuffle scheduling section. More focused. Add two more recent fpga-virt papers Oct 5, 2019 More on scheduling. Add NoC. Add Security. Oct 4, 2019 Add more papers extracted from AmophOS Oct 3, 2019 Initial version from Github A list of related papers I came across while doing FPGA-related research. If you\u2019d like to contribute, please comment below or create PR here . Virtualization Scheduling NoC Memory Hierarchy Dynamic Memory Allocation Integrate with Host Virtual Memory Integrate with Host OSs Security Summary Languages, Runtime, and Framework Xilinx HLS Xilinx CAD High-Level Languages and Platforms Integrate with Frameworks Cloud Infrastructure Misc Applications Programmable Network Database Storage Machine Learning Graph Key-Value Store Bio Consensus Video Processing Blockchain Micro-services FPGA Internal General Partial Reconfiguration Logical Optimization and Technology Mapping Place and Route RTL2FPGA","title":"An FPGA Reading List"},{"location":"notes/paper_fpga/#virtualization","text":"","title":"Virtualization"},{"location":"notes/paper_fpga/#scheduling","text":"Scheduling is big topic for FPGA. Unlike the traditional CPU scheduling, there are more aspects to consider, e.g., 1) Partial reconfiguration (PR), 2) Dynamic self PR, 3) Preemptive scheduling, 4) Relocation, 5) Floorplanning, and so on.","title":"Scheduling"},{"location":"notes/paper_fpga/#preemptive-scheduling","text":"Preemptive multitasking on FPGAs, 2000 Multitasking on FPGA Coprocessors, 2000 Context saving and restoring for multitasking in reconfigurable systems, 2005 ReconOS Cooperative multithreading in dynamically reconfigurable systems, FPL\u201809 Block, drop or roll(back): Alternative preemption methods for RH multi-tasking, FCCM\u201809 Hardware Context-Switch Methodology for Dynamically Partially Reconfigurable Systems, 2010 On-chip Context Save and Restore of Hardware Tasks on Partially Reconfigurable FPGAs, 2013 HTR: on-chip Hardware Task Relocation For Partially Reconfigurable FPGAs, 2013 Preemptive Hardware Multitasking in ReconOS, 2015","title":"Preemptive Scheduling"},{"location":"notes/paper_fpga/#preemptive-reconfiguration","text":"Preemption of the Partial Reconfiguration Process to Enable Real-Time Computing, 2018","title":"Preemptive Reconfiguration"},{"location":"notes/paper_fpga/#bitstreams","text":"Github 7-series bitmap reverse engineering PARBIT: A Tool to Transform Bitfiles to Implement Partial Reconfiguration of Field Programmable Gate Arrays (FPGAs), 2001 BIL: A TOOL-CHAIN FOR BITSTREAM REVERSE-ENGINEERING, 2012 BITMAN: A Tool and API for FPGA Bitstream Manipulations, 2017","title":"Bitstreams"},{"location":"notes/paper_fpga/#relocation","text":"Context saving and restoring for multitasking in reconfigurable systems, 2005 REPLICA2Pro: Task Relocation by Bitstream Manipulation in Virtex-II/Pro FPGAs, 2006 Relocation and Automatic Floor-planning of FPGA Partial Configuration Bit-Streams, MSR 2008 Internal and External Bitstream Relocation for Partial Dynamic Reconfiguration, 2009 PRR-PRR Dynamic Relocation, 2009 HTR: on-chip Hardware Task Relocation For Partially Reconfigurable FPGAs, 2003 AutoReloc, 2016 HTR: on-chip Hardware Task Relocation For Partially Reconfigurable FPGAs, 2013","title":"Relocation:"},{"location":"notes/paper_fpga/#others","text":"hthreads: A hardware/software co-designed multithreaded RTOS kernel, 2005 hthreads: Enabling a Uniform Programming Model Across the Software/Hardware Boundary, FCCM\u201816 Tartan: Evaluating Spatial Computation for Whole Program Execution, ASPLOS\u201806 A virtual hardware operating system for the Xilinx XC6200, 1996 The Swappable Logic Unit: a Paradigm for Virtual Hardware, FCCM\u201897 Run-time management of dynamically reconfigurable designs, 1998 All above ones are early work on FPGA scheduling. Worth a read, but don\u2019t take some of their assumptions. Some have been changed after SO many years. S1. Reconfigurable Hardware Operating Systems: From Design Concepts to Realizations, 2003 S2. Operating Systems for Reconfigurable Embedded Platforms: Online Scheduling of Real-Time Tasks, 2004 Very fruitful discussion. The paper schedules bitstreams inside FPGA, following a Real-Time sched policy (deadline) . Different from CPU sched, FPGA scheduling needs to consider \u201careas\u201d. The chip is a rectangle box, allocating areas needs great care to avoid fragmentation! Context saving and restoring for multitasking in reconfigurable systems, FPL\u201805 Optimizing deschedule perf. This paper discusses ways to save and restore the state information of a hardware task. There are generally three approachs: a) adding indirection. Let app use system API to read/write states. b) yield-type API. c) use PR controller to read back bitstream. This paper used ICAP to read the bitstream back and extract necenssay state information that must be present at next bitstream resume. Scheduling intervals for reconfigurable computing, FCCM\u201808 Hardware context-switch methodology for dynamically partially reconfigurable systems, 2010 Online Scheduling for Multi-core Shared Reconfigurable Fabric, DATE\u201812 Multi-shape Tasks Scheduling for Online Multitasking on FPGAs, 2014 AmophOS, OSDI\u201818 Hardware context switching on FPGAs, 2014 Efficient Hardware Context-Switch for Task Migration between Heterogeneous FPGAs, 2016","title":"Others"},{"location":"notes/paper_fpga/#noc","text":"Network-on-Chip on FPGA. Interconnection Networks Enable Fine-Grain Dynamic Multi-Tasking on FPGAs, 2002 Like the idea of separating computation from communication. Also a lot discussions about possible NoC designs within FPGA. LEAP Soft connections: Addressing the hardware-design modularity problem, DAC\u201809 Virtual channel concept. Time-insensitive. Leveraging Latency-Insensitivity to Ease Multiple FPGA Design, FPGA\u201812 CONNECT: re-examining conventional wisdom for designing nocs in the context of FPGAs, FPGA\u201812 Your Programmable NIC Should be a Programmable Switch, HotNets\u201818","title":"NoC"},{"location":"notes/paper_fpga/#memory-hierarchy","text":"Papers deal with BRAM, registers, on-board DRAM, and host DRAM. LEAP Scratchpads: Automatic Memory and Cache Management for Reconfigurable Logic, FPGA\u201811 Main design hierarchy: Use BRAM as L1 cache, use on-board DRAM as L2 cache, and host memory as the backing store. Everthing is abstracted away through their interface (similar to load/store). Programming is pretty much the same as if you are writing for CPU. According to sec 2.2.2, its scratchpad controller, is using simple segment-based mapping scheme. Like AmorphOS\u2019s one. LEAP Shared Memories: Automating the Construction of FPGA Coherent Memories, FCCM\u201814 Follow up work on LEAP Scratchpads, extends the work to have cache coherence between multiple FPGAs. Coherent Scatchpads with MOSI protocol. MATCHUP: Memory Abstractions for Heap Manipulating Programs, FPGA\u201815 CoRAM: An In-Fabric Memory Architecture for FPGA-Based Computing CoRAM provides an interface for managing the on- and off-chip memory resource of an FPGA. It use \u201ccontrol threads\u201d enforce low-level control on data movement. Seriously, the CoRAM is just like Processor L1-L3 caches. CoRAM Prototype and evaluation of the CoRAM memory architecture for FPGA-based computing, FPGA\u201812 Prototype on FPGA. Sharing, Protection, and Compatibility for Reconfigurable Fabric with AMORPHOS, OSDI\u201818 Hull: provides memory protection for on-board DRAM using segment-based address translation. Virtualized Execution Runtime for FPGA Accelerators in the Cloud, IEEE Access\u201817","title":"Memory Hierarchy"},{"location":"notes/paper_fpga/#dynamic-memory-allocation","text":"malloc() and free() for FPGA on-board DRAM. A High-Performance Memory Allocator for Object-Oriented Systems, IEEE\u201896 SysAlloc: A Hardware Manager for Dynamic Memory Allocation in Heterogeneous Systems, FPL\u201815 Hi-DMM: High-Performance Dynamic Memory Management in High-Level Synthesis, IEEE\u201818","title":"Dynamic Memory Allocation"},{"location":"notes/paper_fpga/#integrate-with-host-virtual-memory","text":"Papers deal with OS Virtual Memory System (VMS). Note that, all these papers introduce some form of MMU into the FPGA to let FPGA be able to work with host VMS. This added MMU is similar to CPU\u2019s MMU and RDMA NIC\u2019s internal cache . Note that the VMS still runs inside Linux (include pgfault, swapping, TLB shootdown and so on.), except one recent ISCA\u201820 paper. Virtual Memory Window for Application-Specific Reconfigurable Coprocessors, DAC\u201804 Early work that adds a new MMU to FPGA to let FPGA logic access on-chip DRAM . Note, it\u2019s not the system main memory. Thus the translation pgtable is different. Has some insights on prefetching and MMU CAM design. Seamless Hardware Software Integration in Reconfigurable Computing Systems, 2005 Follow up summary on previous DAC\u201804 Virtual Memory Window. A Reconfigurable Hardware Interface for a Modern Computing System, FCCM\u201807 This work adds a new MMU which includes a 16-entry TLB to FPGA. FPGA and CPU shares the same user virtual address space, use the same physical memory. FPGA and CPU share memory at cacheline granularity , FPGA is just another core in this sense. Upon a TLB miss at FPGA MMU, the FPGA sends interrupt to CPU, to let software to handle the TLB miss . Using software-managed TLB miss is not efficient. But they made cache coherence between FPGA and CPU easy. Low-Latency High-Bandwidth HW/SW Communication in a Virtual Memory Environment, FPL\u201808 This work actually add a new MMU to FPGA, which works just like CPU MMU. It\u2019s similar to IOMMU, in some sense. But I think they missed one important aspect: cache coherence between CPU and FPGA. There is not too much information about this in the paper, it seems they do not have cache at FPGA. Anyhow, this is why recently CCIX and OpenCAPI are proposed. Memory Virtualization for Multithreaded Reconfigurable Hardware, FPL\u201811 Part of the ReconOS project They implemented a simple MMU inside FPGA that includes a TLB. On protection violation or page invalid access cases, their MMU just hand over to CPU pgfault routines. How is this different from the FPL\u201808 one? Actually, IMO, they are the same. S4 Virtualized Execution Runtime for FPGA Accelerators in the Cloud, IEEE Access\u201817 This paper also implemented a hardware MMU, but the virtual memory system still run on Linux. Also listed in Cloud Infrastructure part. Lightweight Virtual Memory Support for Many-Core Accelerators in Heterogeneous Embedded SoCs, 2015 Lightweight Virtual Memory Support for Zero-Copy Sharing of Pointer-Rich Data Structures in Heterogeneous Embedded SoCs, IEEE\u201817 Part of the PULP project. Essentially a software-managed IOMMU. The control path is running as a Linux kernel module. The datapath is a lightweight AXI transation translation. Flick: Fast and Lightweight ISA-Crossing Call for Heterogeneous-ISA Environments, ISCA\u201820 This paper adds an MMU/TLB into FPGA-side RISC-V to fetch/translate host pgtable entries. This paper\u2019s goal is to migrate threads between different ISAs, the key is VM. But what\u2019s new? A Case for Hardware-Based Demand Paging, ISCA\u201820 This paper is not FPGA-based, but does augments host MMU with pgfault handling capability. This paper targets file-backed pgfault, more specific, ultra-low-latency SSD backed files. It adds several HW units to let CPU MMU able to handle and resolve such pgfaults (essentially offload VFS->FS->BLK->NVMe Driver functionalties into HW. Some part is done via mmap() beforehand). It\u2019s async free page list, async LRU handling are used by our work as well.","title":"Integrate with Host Virtual Memory"},{"location":"notes/paper_fpga/#integrate-with-host-oss","text":"A Virtual Hardware Operating System for the Xilinx XC6200, FPL\u201896 Operating systems for reconfigurable embedded platforms: online scheduling of real-time tasks, IEEE\u201804 hthreads: a hardware/software co-designed multithreaded RTOS kernel, 2005 Reconfigurable computing: architectures and design methods, IEE\u201805 BORPH: An Operating System for FPGA-Based Reconfigurable Computers. PhD Thesis. FUSE: Front-end user framework for O/S abstraction of hardware accelerators, FCCM\u201811 ReconOS \u2013 an Operating System Approach for Reconfigurable Computing, IEEE Micro\u201814 Invoke kernel from FPGA. They built a shell in FPGA and delegation threads in CPU to achieve this. They implemented their own MMU (using pre-established pgtables) to let FPGA logic to access system memory. Ref . Read the \u201cOperating Systems for Reconfigurable Computing\u201d sidebar, nice summary. LEAP Soft connections: Addressing the hardware-design modularity problem, DAC\u201809 Channel concept. Good. LEAP Scratchpads: Automatic Memory and Cache Management for Reconfigurable Logic, FPGA\u201811 BRAM/on-board DRAM/host DRAM layering. Caching. LEAP Shared Memories: Automating the Construction of FPGA Coherent Memories Add cache-coherence on top of previous work. Also check out my note on Cache Coherence . LEAP FPGA Operating System, FPL\u201814. A Survey on FPGA Virtualization, FPL\u201818 ZUCL 2.0: Virtualised Memory and Communication for ZYNQ UltraScale+ FPGAs, FSP\u201819","title":"Integrate with Host OSs"},{"location":"notes/paper_fpga/#security","text":"If I were to recommend, I\u2019d suggest start from: Recent Attacks and Defenses on FPGA-based Systems, 2019 Physical Side-Channel Attacks and Covert Communication on FPGAs: A Survey, 2019 FPGA security: Motivations, features, and applications, 2014 The whole list: FPGAhammer : Remote Voltage Fault Attacks on Shared FPGAs , suitable for DFA on AES FPGA-Based Remote Power Side-Channel Attacks Characterization of long wire data leakage in deep submicron FPGAS Protecting against cryptographic Trojans in FPGAS FPGA Side Channel Attacks without Physical Access FPGA security: Motivations, features, and applications FPGA side-channel receivers Security of FPGAs in data centers Secure Function Evaluation Using an FPGA Overlay Architecture Mitigating Electrical-level Attacks towards Secure Multi-Tenant FPGAs in the Cloud The Costs of Confidentiality in Virtualized FPGAs Temporal Thermal Covert Channels in Cloud FPGAs Characterizing Power Distribution Attacks in Multi-User FPGA Environments FASE: FPGA Acceleration of Secure Function Evaluation Securing Cryptographic Circuits by Exploiting Implementation Diversity and Partial Reconfiguration on FPGAs Measuring Long Wire Leakage with Ring Oscillators in Cloud FPGAs Physical Side-Channel Attacks and Covert Communication on FPGAs: A Survey Leaky Wires: Information Leakage and Covert Communication Between FPGA Long Wires Using the Power Side Channel of FPGAs for Communication An Inside Job: Remote Power Analysis Attacks on FPGAs Leakier Wires: Exploiting FPGA Long Wires for Covert- and Side-channel Attacks Voltage drop-based fault attacks on FPGAs using valid bitstreams Moats and Drawbridges: An Isolation Primitive for Reconfigurable Hardware Based Systems Sensing nanosecond-scale voltage attacks and natural transients in FPGAs Holistic Power Side-Channel Leakage Assessment: Hiding Intermittent Information Leakage with Architectural Support for Blinking Examining the consequences of high-level synthesis optimizations on power side-channel Register transfer level information flow tracking for provably secure hardware design A Protection and Pay-per-use Licensing Scheme for On-cloud FPGA Circuit IPs Recent Attacks and Defenses on FPGA-based Systems PFC: Privacy Preserving FPGA Cloud - A Case Study of MapReduce A Pay-per-Use Licensing Scheme for Hardware IP Cores in Recent SRAM-Based FPGAs FPGAs for trusted cloud computing","title":"Security"},{"location":"notes/paper_fpga/#summary","text":"Summary on current FPGA Virtualization Status. Prior art mainly focus on: 1) How to virtualize on-chip BRAM (e.g., CoRAM, LEAP Scratchpad), 2) How to work with host, specifically, how to use the host DRAM, how to use host virtual memory. 3) How to schedule bitstreams inside a FPGA chip. 4) How to provide certain services to make FPGA programming easier (mostly work with host OS).","title":"Summary"},{"location":"notes/paper_fpga/#languages-runtime-and-framework","text":"Innovations in the toolchain space.","title":"Languages, Runtime, and Framework"},{"location":"notes/paper_fpga/#xilinx-hls","text":"Design Patterns for Code Reuse in HLS Packet Processing Pipelines, FCCM\u201819 A very good HLS library from Mellanox folks. Templatised Soft Floating-Point for High-Level Synthesis, FCCM\u201819 ST-Accel: A High-Level Programming Platform for Streaming Applications on FPGA, FCCM\u201818 HLScope+: Fast and Accurate Performance Estimation for FPGA HLS, ICCAD\u201817 Separation Logic-Assisted Code Transformations for Efficient High-Level Synthesis, FCCM\u201814 An HLS design aids that analyze the original program at compile time and perform automated code transformations. The tool analysis pointer-manipulating programs and automatically splits heap-allocated data structures into disjoint, independent regions. The tool is for C++ heap operations. To put in another way: the tool looks at your BRAM usage, found any false-dependencies, and make multiple independent regions, then your II is improved. MATCHUP: Memory Abstractions for Heap Manipulating Programs, FPGA\u201815 This is an HLS toolchain aid. Follow-up work of the above FCCM\u201814 one. This time they use LEAP scracchpads as the underlying caching block.","title":"Xilinx HLS"},{"location":"notes/paper_fpga/#xilinx-cad","text":"Maverick: A Stand-alone CAD Flow for Partially Reconfigurable FPGA Modules, FCCM\u201819","title":"Xilinx CAD"},{"location":"notes/paper_fpga/#high-level-languages-and-platforms","text":"Just-in-Time Compilation for Verilog, ASPLOS\u201819 Chisel: Constructing Hardware in a Scala Embedded Language, DAC\u201812 Chisel is being actively improved and used by UCB folks. Rosetta: A Realistic High-Level Synthesis Benchmark Suite for Software Programmable FPGAs, FPGA\u201818 From JVM to FPGA: Bridging Abstraction Hierarchy via Optimized Deep Pipelining, HotCloud\u201818 HeteroCL: A Multi-Paradigm Programming Infrastructure for Software-Defined Reconfigurable Computing, FPGA\u201819 LINQits: Big Data on Little Clients, ISCA\u201813 From Microsoft, used to express SQL-like functions (thus big data) and runs on ZYNQ (thus little client), You wrote C#, LINQits translate it to verilog, and run the whole thing at a ZYNQ (ARM+FPGA) board. Lime: a Java-Compatible and Synthesizable Language for Heterogeneous Architectures, OOPSLA\u201810 Lime is a Java-based programming model and runtime from IBM which aims to provide a single unified language to program heterogeneous architectures, from FPGAs to conventional CPUs A line of work from Standord Generating configurable hardware from parallel patterns, ASPLOS\u201816 Plasticine: A Reconfigurable Architecture For Parallel Patterns, ISCA\u201817 Spatial: A Language and Compiler for Application Accelerators, PLDI\u201818 Spatial generates Chisel code along with C++ code which can be used on a host CPU to control the execution of the accelerator on the target FPGA. This kind of academic papers must have a lot good ideas. But the truth is it will not be reliable because it\u2019s from academic labs.","title":"High-Level Languages and Platforms"},{"location":"notes/paper_fpga/#integrate-with-frameworks","text":"Map-reduce as a Programming Model for Custom Computing Machines, FCCM\u201808 This paper proposes a model to translate MapReduce code written in C to code that could run on FPGA and GPU. Many details are omitted, and they don\u2019t really have the compiler. Single-host framework, everything is in FPGA and GPU. Axel: A Heterogeneous Cluster with FPGAs and GPUs, FPGA\u201810 A distributed MapReduce Framework, targets clusters with CPU, GPU, and FPGA. Mainly the idea of scheduling FPGA/GPU jobs. Distributed Framework. FPMR: MapReduce Framework on FPGA, FPGA\u201810 A MapReduce framework on a single host\u2019s FPGA. You need to write Verilog/HLS for processing logic to hook with their framework. The framework mainly includes a data transfer controller, a simple schedule that enable certain blocks at certain time. Single-host framework, everything is in FPGA. Melia: A MapReduce Framework on OpenCL-Based FPGAs, IEEE\u201816 Another framework, written in OpenCL, and users can use OpenCL to program as well. Similar to previous work, it\u2019s more about the framework design, not specific algorithms on FPGA. Single-host framework, everything is in FPGA. But they have a discussion on running on multiple FPGAs. Four MapReduce FPGA papers here, I believe there are more. The marriage between MapReduce and FPGA is not something hard to understand. FPGA can be viewed as another core with different capabilities. The thing is, given FPGA\u2019s reprogram-time and limited on-board memory, how to design a good scheduling algorithm and data moving/caching mechanisms. Those papers give some hints on this. UCLA: When Apache Spark Meets FPGAs: A Case Study for Next-Generation DNA Sequencing Acceleration, HotCloud\u201816 UCLA: Programming and Runtime Support to Blaze FPGA Accelerator Deployment at Datacenter Scale, SoCC\u201816 A system that hooks FPGA with Spark. There is a line of work that hook FPGA with big data processing framework (Spark), so the implementation of FPGA and the scale-out software can be separated. The Spark can schedule FPGA jobs to different machines, and take care of scale-out, failure handling etc. But, I personally think this line of work is really just an extension to ReconOS/FUSE/BORPH line of work. The main reason is: both these two lines of work try to integrate jobs run on CPU and jobs run on FPGA, so CPU and FPGA have an easier way to talk, or put in another way, CPU and FPGA have a better division of labor. Whether it\u2019s single-machine (like ReconOS, Melia), or distributed (like Blaze, Axel), they are essentially the same. UCLA: Heterogeneous Datacenters: Options and Opportunities, DAC\u201816 Follow up work of Blaze. Nice comparison of big and wimpy cores.","title":"Integrate with Frameworks"},{"location":"notes/paper_fpga/#cloud-infrastructure","text":"Huawei: FPGA as a Service in the Cloud UCLA: Customizable Computing: From Single Chip to Datacenters, IEEE\u201818 UCLA: Accelerator-Rich Architectures: Opportunities and Progresses, DAC\u201814 Reminds me of OmniX . Disaggregation at a different scale. This paper actually targets single-machine case. But it can reflect a distributed setting. Enabling FPGAs in the Cloud, CF\u201814 Paper raised four important aspects to enable FPGA in cloud: Abstraction, Sharing, Compatibility, and Security. FPGA itself requires a shell (paper calls it service logic) and being partitioned into multiple slots. Things discussed in the paper are straightforward, but worth reading. They did not solve the FPGA sharing issue, which, is solved by AmorphOS. FPGAs in the Cloud: Booting Virtualized Hardware Accelerators with OpenStack, FCCM\u201814 Use OpenStack to manage FPGA resource. The FPGA is partitioned into multiple regions, each region can use PR. The FPGA shell includes: 1) basic MAC, and packet dispatcher, 2) memory controller, and segment-based partition scheme, 3) a soft processor used for runtime PR control. One very important aspect of this project is: they envision input to FPGA comes from Ethernet, which is very true nowadays. And this also makes their project quite similar to Catapult. It\u2019s a very solid paper, though the evaluation is a little bit weak. What could be added: migration, different-sized region. The above CF and FCCM papers are similar in the sense that they are both building SW framework and HW shell to provide a unified cloud management system. They differ in their shell design: CF one take inputs from DMA engine, which is local system DRAM, FCCM one take inputs from Ethernet. The things after DMA or MAC, are essentially similar. It seems all of them are using simple segment-based memory partition for user FPGA logic. What\u2019s the pros and cons of using paging here? S1 DyRACT: A partial reconfiguration enabled accelerator and test platform, FPL\u201814 S2 Virtualized FPGA Accelerators for Efficient Cloud Computing, CloudCom\u201815 S3 Designing a Virtual Runtime for FPGA Accelerators in the Cloud, FPL\u201816 S4 Virtualized Execution Runtime for FPGA Accelerators in the Cloud, IEEE Access\u201817 The above four papers came from the same group of folks. S1 developed a framework to use PCIe to do PR, okay. S2 is a follow-up on S1, read S2\u2019s chapter IV hardware architecture, many implementation details like internal FPGA switch, AXI stream interface. But no memory virtualization discussion. S3 is a two page short paper. S4 is the realization of S3. I was particularly interested if S4 has implemented their own virtual memory management. The answer is NO. S4 leveraged on-chip Linux, they just build a customized MMU (in the form of using BRAM to store page tables. This approach is similar to the papers listed in Integrate with Virtual Memory ). Many things discussed in S4 have been proposed multiple times in previous cloud FPGA papers since 2014. MS: A Reconfigurable Fabric for Accelerating Large-Scale Datacenter Services, ISCA\u201814 MS: A Cloud-Scale Acceleration Architecture, Micro\u201816 Catapult is unique in its shell, which includes the Lightweight Transport Layer (LTL), and Elastic Router(ER). The cloud management part, which the paper just briefly mentioned, actually should include everything the above CF\u201814 and FCCM\u201814 have. The LTL has congestion control, packet loss detection/resend, ACK/NACK. The ER is a crossbar switch used by FPGA internal modules, which is essential to connect shell and roles. These two Catapult papers are simply a must read. MS: A Configurable Cloud-Scale DNN Processor for Real-Time AI, Micro\u201818 MS: Azure Accelerated Networking: SmartNICs in the Public Cloud, NSDI\u201818 MS: Direct Universal Access : Making Data Center Resources Available to FPGA, NSDI\u201819 Catapult is just sweet, isn\u2019t it? ASIC Clouds: Specializing the Datacenter, ISCA\u201816 Virtualizating FPGAs in the Cloud, ASPLOS\u201820 , to appear.","title":"Cloud Infrastructure"},{"location":"notes/paper_fpga/#misc","text":"A Study of Pointer-Chasing Performance on Shared-Memory Processor-FPGA Systems, FPGA\u201816","title":"Misc"},{"location":"notes/paper_fpga/#applications","text":"","title":"Applications"},{"location":"notes/paper_fpga/#programmable-network","text":"MS: ClickNP: Highly Flexible and High Performance Network Processing with Reconfigurable Hardware, SIGCOMM\u201816 MS: Multi-Path Transport for RDMA in Datacenters, NSDI\u201818 MS: Azure Accelerated Networking: SmartNICs in the Public Cloud, NSDI\u201818 Mellanox. NICA: An Infrastructure for Inline Acceleration of Network Applications, ATC\u201819 The Case For In-Network Computing On Demand, EuroSys\u201819 Fast, Scalable, and Programmable Packet Scheduler in Hardware, SIGCOMM\u201819 HPCC: high precision congestion control, SIGCOMM\u201819 Offloading Distributed Applications onto SmartNICs using iPipe, SIGCOMM\u201819 Not necessary FPGA, but SmartNICs. The actor programming model seems a good fit. There is another paper from ATC\u201819 that optimizes distributed actor runtime .","title":"Programmable Network"},{"location":"notes/paper_fpga/#database-and-sql","text":"On-the-fly Composition of FPGA-Based SQL Query Accelerators Using A Partially Reconfigurable Module Library, 2012 Accelerating database systems using FPGAs: A survey, FPL\u201818","title":"Database and SQL"},{"location":"notes/paper_fpga/#storage","text":"Cognitive SSD: A Deep Learning Engine for In-Storage Data Retrieval, ATC\u201819 INSIDER: Designing In-Storage Computing System for Emerging High-Performance Drive, ATC\u201819 LightStore: Software-defined Network-attached Key-value Drives, ASPLOS\u201819 FIDR: A Scalable Storage System for Fine-Grain Inline Data Reduction with Efficient Memory Handling, MICRO\u201819 CIDR: A Cost-Effective In-line Data Reduction System for Terabit-per-Second Scale SSD Array, HPCA\u201819","title":"Storage"},{"location":"notes/paper_fpga/#machine-learning","text":"TABLA: A Unified Template-based Framework for Accelerating Statistical Machine Learning, HPCA\u201816 Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks, FPGA\u201815 From High-Level Deep Neural Models to FPGAs, ISCA\u201816 Deep Learning on FPGAs: Past, Present, and Future, arXiv\u201816 Accelerating binarized neural networks: Comparison of FPGA, CPU, GPU, and ASIC, FPT\u201816 FINN: A Framework for Fast, Scalable Binarized Neural Network Inference, FPGA\u201817 In-Datacenter Performance Analysis of a Tensor Processing Unit, ISCA\u201817 Accelerating Binarized Convolutional Neural Networks with Software-Programmable FPGAs, FPGA\u201817 A Configurable Cloud-Scale DNN Processor for Real-Time AI, ISCA\u201818 Microsoft Project Brainware. Built on Catapult. A Network-Centric Hardware/Algorithm Co-Design to Accelerate Distributed Training of Deep Neural Networks, MICRO\u201818 DNNBuilder: an Automated Tool for Building High-Performance DNN Hardware Accelerators for FPGAs, ICCAD\u201818 FA3C : FPGA-Accelerated Deep Reinforcement Learning\uff0c ASPLOS\u201919 Cognitive SSD: A Deep Learning Engine for In-Storage Data Retrieval, ATC\u201819","title":"Machine Learning"},{"location":"notes/paper_fpga/#graph","text":"A Scalable Processing-in-Memory Accelerator for Parallel Graph Processing, ISCA\u201815 Energy Efficient Architecture for Graph Analytics Accelerators, ISCA\u201816 Boosting the Performance of FPGA-based Graph Processor using Hybrid Memory Cube: A Case for Breadth First Search, FPGA\u201817 FPGA-Accelerated Transactional Execution of Graph Workloads, FPGA\u201817 An FPGA Framework for Edge-Centric Graph Processing, CF\u201818","title":"Graph"},{"location":"notes/paper_fpga/#key-value-store","text":"Achieving 10Gbps line-rate key-value stores with FPGAs, HotCloud\u201813 Thin Servers with Smart Pipes: Designing SoC Accelerators for Memcached, ISCA\u201813 An FPGA Memcached Appliance, FPGA\u201813 Scaling out to a Single-Node 80Gbps Memcached Server with 40Terabytes of Memory, HotStorage\u201815 KV-Direct: High-Performance In-Memory Key-Value Store with Programmable NIC, SOSP\u201817 This link is also useful for better understading Morning Paper Ultra-Low-Latency and Flexible In-Memory Key-Value Store System Design on CPU-FPGA, FPT\u201818","title":"Key-Value Store"},{"location":"notes/paper_fpga/#bio","text":"When Apache Spark Meets FPGAs: A Case Study for Next-Generation DNA Sequencing Acceleration, HotCloud\u201816 FPGA Accelerated INDEL Realignment in the Cloud, HPCA\u201819","title":"Bio"},{"location":"notes/paper_fpga/#consensus","text":"Consensus in a Box: Inexpensive Coordination in Hardware, NSDI\u201816","title":"Consensus"},{"location":"notes/paper_fpga/#video-processing","text":"Quantifying the Benefits of Dynamic Partial Reconfiguration for Embedded Vision Applications (FPL 2019) Time-Shared Execution of Realtime Computer Vision Pipelines by Dynamic Partial Reconfiguration (FPL 2018)","title":"Video Processing"},{"location":"notes/paper_fpga/#fpga-internal","text":"FPGA20: Highlighting Significant Contributions from 20 Years of the International Symposium on Field-Programmable Gate Arrays (1992\u20132011)","title":"FPGA Internal"},{"location":"notes/paper_fpga/#general","text":"FPGA and CPLD architectures: a tutorial, 1996 Reconfigurable computing: a survey of systems and software, 2002 Reconfigurable computing: architectures and design methods FPGA Architecture: Survey and Challenges, 2007 Read the first two paragraphs of each section and then come back to read all of that if needed. RAMP: Research Accelerator For Multiple Processors, 2007 Three Ages of FPGAs: A Retrospective on the First Thirty Years of FPGA Technology, IEEE\u201815","title":"General"},{"location":"notes/paper_fpga/#partial-reconfiguration","text":"FPGA Dynamic and Partial Reconfiguration: A Survey of Architectures, Methods, and Applications, CSUR\u201818 Must read. DyRACT: A partial reconfiguration enabled accelerator and test platform, FPL\u201814 A high speed open source controller for FPGA partial reconfiguration Hardware context-switch methodology for dynamically partially reconfigurable systems, 2010","title":"Partial Reconfiguration"},{"location":"notes/paper_fpga/#logical-optimization-and-technology-mapping","text":"FlowMap: An Optimal Technology Mapping Algorithm for Delay Optimization in Lookup-Table Based FPGA Designs, 1994 Combinational Logic Synthesis for LUT Based Field Programmable Gate Arrays, 1996 DAOmap: A Depth-optimal Area Optimization Mapping Algorithm for FPGA Designs, 2004","title":"Logical Optimization and Technology Mapping"},{"location":"notes/paper_fpga/#place-and-route","text":"VPR: A New Packing, Placement and Routing Tool for FPGA Research, 1997 VTR 7.0: Next Generation Architecture and CAD System for FPGAs, 2014","title":"Place and Route"},{"location":"notes/paper_fpga/#rtl2fpga","text":"A Case for FAME: FPGA Architecture Model Execution, 2010 Strober: Fast and Accurate Sample-Based Energy Simulation for Arbitrary RTL, 2016 Evaluation of RISC-V RTL with FPGA-Accelerated Simulation, 2017 FireSim: FPGA-Accelerated Cycle-Exact Scale-Out System Simulation in the Public Cloud, 2018","title":"RTL2FPGA"},{"location":"notes/paper_perf_shadows/","text":"Hiding In The Shadows \u00b6 Version History Date Description Jul 11, 2019 Initial draft There are shadows under the sun. There are shadows in your life. There are shadows in your computer. This note is about latency tolerance techniques . This note is about how to get the most out of the otherwise-wasted resource. Nanoseconds \u00b6 Architecture solutions to attack nanosecond-level performance shadows that are mostly created by lower level data and instruction cache misses. OoO and SMT are the base to hide these latencies, but they fall short when ROB is full (or some other reasons). When that happens, these academic ideas come in rescue. Runahead \u00b6 Quote In runahead, once the processor stalls, it uses the instruction window to continue to fetch and execute operations. The goal of runahead is to generate new cache misses, thereby turning subsequent demand requests into cache hits instead of cache misses.[5] Papers Improving Data Cache Performance by Pre-executing Instructions Under a Cache Miss, ICS\u201997 Runahead Execution: An Alternative to Very Large Instruction Windows for Out-of-order Processors, HPCA\u201903 Efficient Runahead Execution: Power-Efficient Memory Latency Tolerance, IEEE Micro\u201906 Good timeline graphs show the benefit of Runahead. Runahead Threads to Improve SMT Performance, HPCA\u201908 QoS control policy. Continuous Runahead: Transparent Hardware Acceleration for Memory Intensive Workloads, MICRO\u201916 Nice idea to tackle the issue that runahead does not get enough time to run. Also has the notion of ideal runahead coverage. Comments We should separate mechanism and policy. Runahead is the mechanism. It includes: Enter runahead Execution in runahead context (most important thing is to maintain those INV bits and pseudo-retires) Exit runahead Prefetch is one of the policy, a major one. It\u2019s the side effect of running instructions in the execution phase of runahead mode. QoS control is another policy. This means adding specific rules to the execution phase. More specifically: limit the core resource usage of the runahead thread, thus reduce the impact on the co-running HW thread. Helper Threads (or Precomputation) \u00b6 Quote A helper thread is a stripped down version of the main thread that only includes the necessary instructions to generate memory accesses, including control flow instructions [10]. Quote Precomputation uses idle thread contexts in a multithreaded architecture to improve performance of single-threaded applications. It attacks program stalls from data cache misses by pre-computing future memory accesses in available thread contexts, and prefetching these data.[1] Quote Such pre-execution threads are purely speculative, and their instructions are never committed into the main computation. Instead, the pre-execution threads run code designed to trigger cache misses. As long as the pre-execution threads execute far enough in front of the main thread, they effectively hide the latency of the cache misses so that the main thread experiences signicantly fewer memory stalls.[5] Papers Speculative Precomputation: Long-range Prefetching of Delinquent Loads, ISCA\u201801 Dynamic Speculative Precomputation, Micro\u201801 Take a step further by using HW to construct the offloaded code slice automatically. Execution-based Prediction Using Speculative Slices, ISCA\u201801 Tolerating Memory Latency through Software-Controlled Pre-Execution in Simultaneous Multithreading Processors, ISCA\u201801 What\u2019s up with ISCA\u201801? This paper proposed to use software to control when to start running precomputation and when to exit. It uses compiler\u2019s help to generate those code slices, and insert special start/end instructions. On the contrast, hardware-controller precomputation relies on hints such as cache misses. Design and Evaluation of Compiler Algorithms for PreExecution, ASPLOS\u201802 5.1 A Study of Source-Level Compiler Algorithms for Automatic Construction of Pre-Execution Code, TOCS\u201804 Dynamic Helper Threaded Prefetching on the Sun UltraSPARC\u00ae CMP Processor, Micro\u201805 The function table at helper thread seems nice and useful. Accelerating and Adapting Precomputation Threads for Effcient Prefetching, HPCA\u201807 Dynamically construct precomputation code, called p-slices. They can adapt the same program differently depending on the program\u2019s data input and the underlying hardware architecture. Inter-core Prefetching for Multicore Processors Using Migrating Helper Threads , ASPLOS\u201811 Pure software solution. I like the idea. But I don\u2019t think it will work for realistic applications. Learned setcontext(), getcontext(), and swapcontext() . Bootstrapping: Using SMT Hardware to Improve Single-Thread Performance, ASPLOS\u201819 Freeway: Maximizing MLP for slice-out-of-order execution, HPCA\u201819 Strictly speaking this is not in this catogory. But it is this paper that lead me to Runahead and Helper thread topic. I was doing something similar so those techniques caught my eye. Comments The catch about precomputation is that it must create lightweight threads that can actually proceed faster than the main thread, so that they stay out in front. Other catch is: you also need to create the code slice that will run on another core context. First of all, how is this code slice different from the original code? The extracted code will be simplified in the sense that it will only access memory without doing other computations. The second question is how this code slice is extracted and then constructed? There are many ways. You can handwrite, or use a static compiler to pre-generate them (by using techniques in above papers), or use hardware to dynamically generate them during runtime, or use software to dynamically generate them during runtime. There are ways to it, but I don\u2019t think this is the core of precomputation. Also, same thing here, we should separate mechanism and policies. Helper thread (or precomputation) is mainly used as a vehicle for speculatively generating data addresses and prefetching. Thread-Level Speculation \u00b6 Fill me in. Locks \u00b6 Applying the insight of \u201cget the most out of the otherwise-wasted resource\u201d to the lock area. I will wait for Sanidhya\u2019s SOSP\u201819 paper. :-) Misc \u00b6 Stretch: Balancing QoS and throughput for colocated server workloads on SMT cores (Best Paper), HPCA\u201819 Keyword: ROB , Co-location QoS . This paper tackles the perf interference when running co-running two SMT threads on a single physical core, which is the common case in datacenters. However co-running latency-sensitive jobs and batch jobs will have huge impact on the perf of both. This paper found: \u201cLatency-sensitive workloads show little benefit from large ROB capacities in modern server processors .. because frequent cache misses and data-dependent computation limit both instruction and memory-level parallelisms (ILP and MLP). In contrast, many batch workloads benefit from a large ROB that helps unlock higher ILP and MLP.\u201d So they propose to have a ROB partition scheme rather than static equal partition. Of course they also did some very extensive studies before deciding to scale ROB. They first found shared ROB has the biggest impact on perf interference than any other resources such as branch predictor, cache, and so on. They further found that latency-sensitive workload can tolerate some perf slack, which means they will not violate their QoS even with a smaller ROB. Anyway, I think this is a very nice paper. Good reasoning, simple solution, but works effectively. Put it all together \u00b6 Both runahead and helper thread were proposed to do prefetch. But they have a key difference. Runahead is invoked in the same core , and is invoked when ROB is full (not always though). Helper thread is invoked at another core . Besides, runahead can just fetch the instructions and run, no need to cook another code slice. But for helper thread, it needs to extract a code slice that will run on another core. I think the most important thing is to realize their insight. In the most straightforward and plain way: they are trying to get the most out of the otherwise-wasted resource. For example, in runahead, they realize that with some help, the CPU is still able to generate cache misses even if the instruction table is full. For precomputation, obviously it is using the other idle cores. The simple insight itself is not interesting enough, usually where it\u2019s applied make things quite interesting. Microseconds \u00b6 Fill me in Milliseconds \u00b6 Sleep. And wake me up when september ends. And this seems to be enough. ;-) This is true for OS to handle slow HDD and slow network.","title":"Performance-Shadows"},{"location":"notes/paper_perf_shadows/#hiding-in-the-shadows","text":"Version History Date Description Jul 11, 2019 Initial draft There are shadows under the sun. There are shadows in your life. There are shadows in your computer. This note is about latency tolerance techniques . This note is about how to get the most out of the otherwise-wasted resource.","title":"Hiding In The Shadows"},{"location":"notes/paper_perf_shadows/#nanoseconds","text":"Architecture solutions to attack nanosecond-level performance shadows that are mostly created by lower level data and instruction cache misses. OoO and SMT are the base to hide these latencies, but they fall short when ROB is full (or some other reasons). When that happens, these academic ideas come in rescue.","title":"Nanoseconds"},{"location":"notes/paper_perf_shadows/#runahead","text":"Quote In runahead, once the processor stalls, it uses the instruction window to continue to fetch and execute operations. The goal of runahead is to generate new cache misses, thereby turning subsequent demand requests into cache hits instead of cache misses.[5] Papers Improving Data Cache Performance by Pre-executing Instructions Under a Cache Miss, ICS\u201997 Runahead Execution: An Alternative to Very Large Instruction Windows for Out-of-order Processors, HPCA\u201903 Efficient Runahead Execution: Power-Efficient Memory Latency Tolerance, IEEE Micro\u201906 Good timeline graphs show the benefit of Runahead. Runahead Threads to Improve SMT Performance, HPCA\u201908 QoS control policy. Continuous Runahead: Transparent Hardware Acceleration for Memory Intensive Workloads, MICRO\u201916 Nice idea to tackle the issue that runahead does not get enough time to run. Also has the notion of ideal runahead coverage. Comments We should separate mechanism and policy. Runahead is the mechanism. It includes: Enter runahead Execution in runahead context (most important thing is to maintain those INV bits and pseudo-retires) Exit runahead Prefetch is one of the policy, a major one. It\u2019s the side effect of running instructions in the execution phase of runahead mode. QoS control is another policy. This means adding specific rules to the execution phase. More specifically: limit the core resource usage of the runahead thread, thus reduce the impact on the co-running HW thread.","title":"Runahead"},{"location":"notes/paper_perf_shadows/#helper-threads-or-precomputation","text":"Quote A helper thread is a stripped down version of the main thread that only includes the necessary instructions to generate memory accesses, including control flow instructions [10]. Quote Precomputation uses idle thread contexts in a multithreaded architecture to improve performance of single-threaded applications. It attacks program stalls from data cache misses by pre-computing future memory accesses in available thread contexts, and prefetching these data.[1] Quote Such pre-execution threads are purely speculative, and their instructions are never committed into the main computation. Instead, the pre-execution threads run code designed to trigger cache misses. As long as the pre-execution threads execute far enough in front of the main thread, they effectively hide the latency of the cache misses so that the main thread experiences signicantly fewer memory stalls.[5] Papers Speculative Precomputation: Long-range Prefetching of Delinquent Loads, ISCA\u201801 Dynamic Speculative Precomputation, Micro\u201801 Take a step further by using HW to construct the offloaded code slice automatically. Execution-based Prediction Using Speculative Slices, ISCA\u201801 Tolerating Memory Latency through Software-Controlled Pre-Execution in Simultaneous Multithreading Processors, ISCA\u201801 What\u2019s up with ISCA\u201801? This paper proposed to use software to control when to start running precomputation and when to exit. It uses compiler\u2019s help to generate those code slices, and insert special start/end instructions. On the contrast, hardware-controller precomputation relies on hints such as cache misses. Design and Evaluation of Compiler Algorithms for PreExecution, ASPLOS\u201802 5.1 A Study of Source-Level Compiler Algorithms for Automatic Construction of Pre-Execution Code, TOCS\u201804 Dynamic Helper Threaded Prefetching on the Sun UltraSPARC\u00ae CMP Processor, Micro\u201805 The function table at helper thread seems nice and useful. Accelerating and Adapting Precomputation Threads for Effcient Prefetching, HPCA\u201807 Dynamically construct precomputation code, called p-slices. They can adapt the same program differently depending on the program\u2019s data input and the underlying hardware architecture. Inter-core Prefetching for Multicore Processors Using Migrating Helper Threads , ASPLOS\u201811 Pure software solution. I like the idea. But I don\u2019t think it will work for realistic applications. Learned setcontext(), getcontext(), and swapcontext() . Bootstrapping: Using SMT Hardware to Improve Single-Thread Performance, ASPLOS\u201819 Freeway: Maximizing MLP for slice-out-of-order execution, HPCA\u201819 Strictly speaking this is not in this catogory. But it is this paper that lead me to Runahead and Helper thread topic. I was doing something similar so those techniques caught my eye. Comments The catch about precomputation is that it must create lightweight threads that can actually proceed faster than the main thread, so that they stay out in front. Other catch is: you also need to create the code slice that will run on another core context. First of all, how is this code slice different from the original code? The extracted code will be simplified in the sense that it will only access memory without doing other computations. The second question is how this code slice is extracted and then constructed? There are many ways. You can handwrite, or use a static compiler to pre-generate them (by using techniques in above papers), or use hardware to dynamically generate them during runtime, or use software to dynamically generate them during runtime. There are ways to it, but I don\u2019t think this is the core of precomputation. Also, same thing here, we should separate mechanism and policies. Helper thread (or precomputation) is mainly used as a vehicle for speculatively generating data addresses and prefetching.","title":"Helper Threads (or Precomputation)"},{"location":"notes/paper_perf_shadows/#thread-level-speculation","text":"Fill me in.","title":"Thread-Level Speculation"},{"location":"notes/paper_perf_shadows/#locks","text":"Applying the insight of \u201cget the most out of the otherwise-wasted resource\u201d to the lock area. I will wait for Sanidhya\u2019s SOSP\u201819 paper. :-)","title":"Locks"},{"location":"notes/paper_perf_shadows/#misc","text":"Stretch: Balancing QoS and throughput for colocated server workloads on SMT cores (Best Paper), HPCA\u201819 Keyword: ROB , Co-location QoS . This paper tackles the perf interference when running co-running two SMT threads on a single physical core, which is the common case in datacenters. However co-running latency-sensitive jobs and batch jobs will have huge impact on the perf of both. This paper found: \u201cLatency-sensitive workloads show little benefit from large ROB capacities in modern server processors .. because frequent cache misses and data-dependent computation limit both instruction and memory-level parallelisms (ILP and MLP). In contrast, many batch workloads benefit from a large ROB that helps unlock higher ILP and MLP.\u201d So they propose to have a ROB partition scheme rather than static equal partition. Of course they also did some very extensive studies before deciding to scale ROB. They first found shared ROB has the biggest impact on perf interference than any other resources such as branch predictor, cache, and so on. They further found that latency-sensitive workload can tolerate some perf slack, which means they will not violate their QoS even with a smaller ROB. Anyway, I think this is a very nice paper. Good reasoning, simple solution, but works effectively.","title":"Misc"},{"location":"notes/paper_perf_shadows/#put-it-all-together","text":"Both runahead and helper thread were proposed to do prefetch. But they have a key difference. Runahead is invoked in the same core , and is invoked when ROB is full (not always though). Helper thread is invoked at another core . Besides, runahead can just fetch the instructions and run, no need to cook another code slice. But for helper thread, it needs to extract a code slice that will run on another core. I think the most important thing is to realize their insight. In the most straightforward and plain way: they are trying to get the most out of the otherwise-wasted resource. For example, in runahead, they realize that with some help, the CPU is still able to generate cache misses even if the instruction table is full. For precomputation, obviously it is using the other idle cores. The simple insight itself is not interesting enough, usually where it\u2019s applied make things quite interesting.","title":"Put it all together"},{"location":"notes/paper_perf_shadows/#microseconds","text":"Fill me in","title":"Microseconds"},{"location":"notes/paper_perf_shadows/#milliseconds","text":"Sleep. And wake me up when september ends. And this seems to be enough. ;-) This is true for OS to handle slow HDD and slow network.","title":"Milliseconds"},{"location":"notes/proc/","text":"Special Files \u00b6 /sys/devices/system/<name> Creation: subsys_system_register() , @ drivers/base/bus.c Note that this subdirectory is a legacy. Newer stuffer are added into other folders inside /sys . /sys/devices/system/cpu/* , @ drivers/base/cpu.c Root Object is cpu_root_attrs . The online file belongs to another sub-object And this register_cpu() function is used to setup the directories for each cpu. Many applications use /sys/devices/system/cpu/online to get the number of available CPUs. And it\u2019s hard to change this behavior because it\u2019s usually encoded inside glibc. Thus, if you want to \u201chide\u201d certain CPUs from applications for some reason, you can write a kernel module that use set_cpu_active(cpu, false) , and then use the following small patch. (Note that using set_cpu_online(cpu, false) will confuse CPU idle routine and panic.) diff --git a/drivers/base/cpu.c b/drivers/base/cpu.c --- a/drivers/base/cpu.c +++ b/drivers/base/cpu.c @@ -220,7 +220,8 @@ static ssize_t show_cpus_attr(struct device *dev, /* Keep in sync with cpu_subsys_attrs */ static struct cpu_attr cpu_attrs[] = { - _CPU_ATTR(online, &__cpu_online_mask), + _CPU_ATTR(online, &__cpu_active_mask), _CPU_ATTR(possible, &__cpu_possible_mask), _CPU_ATTR(present, &__cpu_present_mask), }; /proc/pressure https://lwn.net/Articles/759658/ \u2013 Yizhou Shan Created: Jul 26, 2019 Last Updated: Aug 03, 2019","title":"Linux Special Files"},{"location":"notes/proc/#special-files","text":"/sys/devices/system/<name> Creation: subsys_system_register() , @ drivers/base/bus.c Note that this subdirectory is a legacy. Newer stuffer are added into other folders inside /sys . /sys/devices/system/cpu/* , @ drivers/base/cpu.c Root Object is cpu_root_attrs . The online file belongs to another sub-object And this register_cpu() function is used to setup the directories for each cpu. Many applications use /sys/devices/system/cpu/online to get the number of available CPUs. And it\u2019s hard to change this behavior because it\u2019s usually encoded inside glibc. Thus, if you want to \u201chide\u201d certain CPUs from applications for some reason, you can write a kernel module that use set_cpu_active(cpu, false) , and then use the following small patch. (Note that using set_cpu_online(cpu, false) will confuse CPU idle routine and panic.) diff --git a/drivers/base/cpu.c b/drivers/base/cpu.c --- a/drivers/base/cpu.c +++ b/drivers/base/cpu.c @@ -220,7 +220,8 @@ static ssize_t show_cpus_attr(struct device *dev, /* Keep in sync with cpu_subsys_attrs */ static struct cpu_attr cpu_attrs[] = { - _CPU_ATTR(online, &__cpu_online_mask), + _CPU_ATTR(online, &__cpu_active_mask), _CPU_ATTR(possible, &__cpu_possible_mask), _CPU_ATTR(present, &__cpu_present_mask), }; /proc/pressure https://lwn.net/Articles/759658/ \u2013 Yizhou Shan Created: Jul 26, 2019 Last Updated: Aug 03, 2019","title":"Special Files"},{"location":"notes/program_advice/","text":"Programming and Writing Advice \u00b6 Version History Date Description Mar 28, 2020 Started. FreeBSD \u00b6 Quote Source . Our ideology can be described by the following guidelines: Do not add new functionality unless an implementor cannot complete a real application without it. It is as important to decide what a system is not as to decide what it is. Do not serve all the world\u2019s needs; rather, make the system extensible so that additional needs can be met in an upwardly compatible fashion. The only thing worse than generalizing from one example is generalizing from no examples at all. If a problem is not completely understood, it is probably best to provide no solution at all. If you can get 90 percent of the desired effect for 10 percent of the work, use the simpler solution. Isolate complexity as much as possible. Provide mechanism, rather than policy. In particular, place user interface policy in the client\u2019s hands. From Scheifler & Gettys: \u201cX Window System\u201d Prof. John Ousterhout\u2019s Favorite Sayings \u00b6 Quote Source : The greatest performance improvement of all is when a system goes from not-working to working Use your intuition to ask questions, not to answer them The most important component of evolution is death Facts precede concepts If you don\u2019t know what the problem was, you haven\u2019t fixed it If it hasn\u2019t been used, it doesn\u2019t work The only thing worse than a problem that happens all the time is a problem that doesn\u2019t happen all the time The three most powerful words for building credibility are \u201cI don\u2019t know\u201d Coherent systems are inherently unstable Butler W. Lampson\u2019s Hints for Computer System Design \u00b6 https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/acrobat-17.pdf Performance Evaluation \u00b6 Systems Benchmarking Crimes Tim Harris: designing experiments for understanding performance Very practical and useful suggestions. Writing Tips \u00b6 Plain Writing Act of 2010, Federal Plain Language Guidelines. . Dash Writing Tips","title":"Guideline & Advice"},{"location":"notes/program_advice/#programming-and-writing-advice","text":"Version History Date Description Mar 28, 2020 Started.","title":"Programming and Writing Advice"},{"location":"notes/program_advice/#freebsd","text":"Quote Source . Our ideology can be described by the following guidelines: Do not add new functionality unless an implementor cannot complete a real application without it. It is as important to decide what a system is not as to decide what it is. Do not serve all the world\u2019s needs; rather, make the system extensible so that additional needs can be met in an upwardly compatible fashion. The only thing worse than generalizing from one example is generalizing from no examples at all. If a problem is not completely understood, it is probably best to provide no solution at all. If you can get 90 percent of the desired effect for 10 percent of the work, use the simpler solution. Isolate complexity as much as possible. Provide mechanism, rather than policy. In particular, place user interface policy in the client\u2019s hands. From Scheifler & Gettys: \u201cX Window System\u201d","title":"FreeBSD"},{"location":"notes/program_advice/#prof-john-ousterhouts-favorite-sayings","text":"Quote Source : The greatest performance improvement of all is when a system goes from not-working to working Use your intuition to ask questions, not to answer them The most important component of evolution is death Facts precede concepts If you don\u2019t know what the problem was, you haven\u2019t fixed it If it hasn\u2019t been used, it doesn\u2019t work The only thing worse than a problem that happens all the time is a problem that doesn\u2019t happen all the time The three most powerful words for building credibility are \u201cI don\u2019t know\u201d Coherent systems are inherently unstable","title":"Prof. John Ousterhout's Favorite Sayings"},{"location":"notes/program_advice/#butler-w-lampsons-hints-for-computer-system-design","text":"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/acrobat-17.pdf","title":"Butler W. Lampson's Hints for Computer System Design"},{"location":"notes/program_advice/#performance-evaluation","text":"Systems Benchmarking Crimes Tim Harris: designing experiments for understanding performance Very practical and useful suggestions.","title":"Performance Evaluation"},{"location":"notes/program_advice/#writing-tips","text":"Plain Writing Act of 2010, Federal Plain Language Guidelines. . Dash Writing Tips","title":"Writing Tips"},{"location":"notes/resource-disaggregation-spectrum/","text":"Data Center Resource Disaggregation \u00b6 Version History Date Description Mar 7, 2022 Initial This note discusses Resource Disaggregation\u2019s Design Spectrum. In our categorization, the traditional distributed systems approach is logical resource disaggregation . The newly emerged hardware resource disaggregation is physical resource disaggregation . The main difference lies in whether an indirection layer is required to achieve the conceptual resource pool view. Combined, they are two extreme design points of the resource disaggregation idea. All images below are from my recent defense slides. This note is part of my defense\u2019s intro. The full defense slide is here . Intro \u00b6 Resource Disaggregation is a really general idea with a wide design spectrum that covers many designs and systems in data centers. The essense of resource disaggregation is to decouple resources so as to achieve independent resource scaling and failing . It has been applied in different granularities and to many different domains. The traditional resource disaggregation is usually built on top of monolithic servers using conventional distributed systems. It has been applied everywhere in data centers, just in different granularities. For example, in the classical storage disaggregation deployment, storage pools are disaggregated from compute pools; in machine learning deployment, paramemter servers are disaggregated from workers; in typical SDN deployment, control plane servers are disaggregated from data plane servers/switches. All these examples are instantiations of the resource disaggregation idea. Hardware Resource Disaggregation is a super HOT research proposal that breaks the physical monolithic servers into segregated, network-attached hardware resource pools, each of which can be built, managed, and scaled independently. The disaggregated approach largely increases the management flexibility of a data center. Hardware resource disaggregation is a drastic depature from the traditional computing paradigm and it calls for a top-down redesign on hardware, system software, networking, and applications. Design Formula \u00b6 Is hardware resource disaggregation just a buzzword? Is it just another old wine in the new bottle kind of idea? I argue that the traditional resource disaggregation design approach using distributed systems and the newly emerged hardware resource disaggregation are not exclusive to each other and in fact can be unified within one design spectrum, with each being one end of the spectrum. Before we dig into the design spectrum. I want to spent a few words on the Resource Disaggregation Formula : one would take a set of system software and a set of disaggregated hardware devices or servers, then use whatever approach, to produce the same ultimate goal, which is the conceptual resource pool view . The pool can be a CPU pool, a memory pool, a Parameter Server pool. Basically every standalone \u201cconceptual\u201d resource. Think about the examples we mentioned earlier, all systems follow this formula, just produce different \u201cresource pools\u201d. Design Spectrum \u00b6 Now, the categorization. On the far left, we have the logical resource disaggregation , which represents the traditional resource disaggregation model. This model builds on top of monolithic servers. A server would contribute part or all its resource to a certain resource pool. A server can be a part of multiple pools. Usually, an indirection layer at each server is required to achieve this goal. Essentially, the ultimate resource pool just logically maps back to the actual servers. This is the common-wisdon on building distributed systems. On the far right, we have the physical resource disaggregation , which represents the emerging hardware resource disaggregation model. This model builds on top of disaggregated hardware devices. Usually, no indirection layer is required. So essentially, the ultimate resource pool could physically maps back to the actual physical devices. In the middle, we have the Hybrid Disaggregation which has the best of both worlds. It has both normal servers and disaggregated devices. The following image shows the design spectrum. My Work \u00b6 So far, my work in this space has covered all grounds. (DUH! I defined the specturm to fit my work! :-) )","title":"Resource Disaggregation Design Spectrums"},{"location":"notes/resource-disaggregation-spectrum/#data-center-resource-disaggregation","text":"Version History Date Description Mar 7, 2022 Initial This note discusses Resource Disaggregation\u2019s Design Spectrum. In our categorization, the traditional distributed systems approach is logical resource disaggregation . The newly emerged hardware resource disaggregation is physical resource disaggregation . The main difference lies in whether an indirection layer is required to achieve the conceptual resource pool view. Combined, they are two extreme design points of the resource disaggregation idea. All images below are from my recent defense slides. This note is part of my defense\u2019s intro. The full defense slide is here .","title":"Data Center Resource Disaggregation"},{"location":"notes/resource-disaggregation-spectrum/#intro","text":"Resource Disaggregation is a really general idea with a wide design spectrum that covers many designs and systems in data centers. The essense of resource disaggregation is to decouple resources so as to achieve independent resource scaling and failing . It has been applied in different granularities and to many different domains. The traditional resource disaggregation is usually built on top of monolithic servers using conventional distributed systems. It has been applied everywhere in data centers, just in different granularities. For example, in the classical storage disaggregation deployment, storage pools are disaggregated from compute pools; in machine learning deployment, paramemter servers are disaggregated from workers; in typical SDN deployment, control plane servers are disaggregated from data plane servers/switches. All these examples are instantiations of the resource disaggregation idea. Hardware Resource Disaggregation is a super HOT research proposal that breaks the physical monolithic servers into segregated, network-attached hardware resource pools, each of which can be built, managed, and scaled independently. The disaggregated approach largely increases the management flexibility of a data center. Hardware resource disaggregation is a drastic depature from the traditional computing paradigm and it calls for a top-down redesign on hardware, system software, networking, and applications.","title":"Intro"},{"location":"notes/resource-disaggregation-spectrum/#design-formula","text":"Is hardware resource disaggregation just a buzzword? Is it just another old wine in the new bottle kind of idea? I argue that the traditional resource disaggregation design approach using distributed systems and the newly emerged hardware resource disaggregation are not exclusive to each other and in fact can be unified within one design spectrum, with each being one end of the spectrum. Before we dig into the design spectrum. I want to spent a few words on the Resource Disaggregation Formula : one would take a set of system software and a set of disaggregated hardware devices or servers, then use whatever approach, to produce the same ultimate goal, which is the conceptual resource pool view . The pool can be a CPU pool, a memory pool, a Parameter Server pool. Basically every standalone \u201cconceptual\u201d resource. Think about the examples we mentioned earlier, all systems follow this formula, just produce different \u201cresource pools\u201d.","title":"Design Formula"},{"location":"notes/resource-disaggregation-spectrum/#design-spectrum","text":"Now, the categorization. On the far left, we have the logical resource disaggregation , which represents the traditional resource disaggregation model. This model builds on top of monolithic servers. A server would contribute part or all its resource to a certain resource pool. A server can be a part of multiple pools. Usually, an indirection layer at each server is required to achieve this goal. Essentially, the ultimate resource pool just logically maps back to the actual servers. This is the common-wisdon on building distributed systems. On the far right, we have the physical resource disaggregation , which represents the emerging hardware resource disaggregation model. This model builds on top of disaggregated hardware devices. Usually, no indirection layer is required. So essentially, the ultimate resource pool could physically maps back to the actual physical devices. In the middle, we have the Hybrid Disaggregation which has the best of both worlds. It has both normal servers and disaggregated devices. The following image shows the design spectrum.","title":"Design Spectrum"},{"location":"notes/resource-disaggregation-spectrum/#my-work","text":"So far, my work in this space has covered all grounds. (DUH! I defined the specturm to fit my work! :-) )","title":"My Work"},{"location":"notes/rmap/","text":"Linux Reverse Mapping ( rmap ) \u00b6 Version History Date Description Jan 6, 2021 minor update Jun 16, 2019 add sanitizers section Reserve map, or rmap, is a linux data structure used by the memory-management system. It is a reverse mapping from the physical page back to the PTEs. More specically, from the struct page back to the list of PTEs that point to the page. The rmap data structure is used heavily by memory related system calls, such as mmap , munmap , madvise , brk , and so on. And it is used by both anonmouys and file-backed pages. With the help of rmap , kernel is able to identify all the PTEs that point a certain page. Therefore, when kernel is trying to, say evict the page, it will be able to clear all the PTEs point to the page. The rmap data structured is used by both user and kernel pages. It makes the tracking of page sharing easier. The rmap concept seems simple and straightforward to implement, but it is very challenging to design a space- and performance-efficient one. The linux kernel uses quite a lot of tricks to optimize the rmap . You will understand how linux rmap works if you read the following articles carefully: PDF: Object-based Reverse Mapping LWN: Virtual Memory II: the return of objrmap LWN: The object-based reverse-mapping VM Old Notes \u00b6 I implemente the basic PTE-chain based rmap for LegoOS . I can see the downsides of it. I tried to understand the linux rmap before, somehow gave up because I couldn\u2019t fully understand one thing: for a page that is shared among multiple processes\u2019 VMAs, the source code suggests it will always have same offset from the beginning of all VMA (i.e., vm_start ). But does it actually works like this for ALL cases? I just think it\u2019s possible that a page is mapped by an VMA which has a slightly different starting address. I still have doubt about it. But after accepting this assumption, it\u2019s just easy to understand. I will check later on. The code suggests: The offset of a page is saved in page->index . For anonmouys pages, the page->index is saved by page_set_anon_rmap() . When doing rmap walk over multiple VMAs: For anon : unsigned long address = vma_address(page, vma); For file : unsigned long address = vma_address(page, vma); And vma_address() is basically page->index static inline unsigned long __vma_address ( struct page * page , struct vm_area_struct * vma ) { pgoff_t pgoff = page_to_pgoff ( page ); return vma -> vm_start + (( pgoff - vma -> vm_pgoff ) << PAGE_SHIFT ); } Compared to basic PTE-chain based solution, object-based rmap: The real benefit During page fault, we only need to set page->mapping to point to struct anon_vma , rather than allocating a new structure and insert. The downside During rmap walk, we need extra computation to walk each VMA\u2019s page table to make sure that the page is actually mapped within this specific VMA. Adding struct anon_vma is really similar to the idea of reusing address_space , i.e., having a data structure trampoline. Some more boring details: All pages within a single VMA share just one anon_vma . vma->anon_vma indicates if a VMA has attached or note. Related function is anon_vma_prepare() within do_anonymous_fault() link .","title":"Linux Reverse Mapping"},{"location":"notes/rmap/#linux-reverse-mapping-rmap","text":"Version History Date Description Jan 6, 2021 minor update Jun 16, 2019 add sanitizers section Reserve map, or rmap, is a linux data structure used by the memory-management system. It is a reverse mapping from the physical page back to the PTEs. More specically, from the struct page back to the list of PTEs that point to the page. The rmap data structure is used heavily by memory related system calls, such as mmap , munmap , madvise , brk , and so on. And it is used by both anonmouys and file-backed pages. With the help of rmap , kernel is able to identify all the PTEs that point a certain page. Therefore, when kernel is trying to, say evict the page, it will be able to clear all the PTEs point to the page. The rmap data structured is used by both user and kernel pages. It makes the tracking of page sharing easier. The rmap concept seems simple and straightforward to implement, but it is very challenging to design a space- and performance-efficient one. The linux kernel uses quite a lot of tricks to optimize the rmap . You will understand how linux rmap works if you read the following articles carefully: PDF: Object-based Reverse Mapping LWN: Virtual Memory II: the return of objrmap LWN: The object-based reverse-mapping VM","title":"Linux Reverse Mapping (rmap)"},{"location":"notes/rmap/#old-notes","text":"I implemente the basic PTE-chain based rmap for LegoOS . I can see the downsides of it. I tried to understand the linux rmap before, somehow gave up because I couldn\u2019t fully understand one thing: for a page that is shared among multiple processes\u2019 VMAs, the source code suggests it will always have same offset from the beginning of all VMA (i.e., vm_start ). But does it actually works like this for ALL cases? I just think it\u2019s possible that a page is mapped by an VMA which has a slightly different starting address. I still have doubt about it. But after accepting this assumption, it\u2019s just easy to understand. I will check later on. The code suggests: The offset of a page is saved in page->index . For anonmouys pages, the page->index is saved by page_set_anon_rmap() . When doing rmap walk over multiple VMAs: For anon : unsigned long address = vma_address(page, vma); For file : unsigned long address = vma_address(page, vma); And vma_address() is basically page->index static inline unsigned long __vma_address ( struct page * page , struct vm_area_struct * vma ) { pgoff_t pgoff = page_to_pgoff ( page ); return vma -> vm_start + (( pgoff - vma -> vm_pgoff ) << PAGE_SHIFT ); } Compared to basic PTE-chain based solution, object-based rmap: The real benefit During page fault, we only need to set page->mapping to point to struct anon_vma , rather than allocating a new structure and insert. The downside During rmap walk, we need extra computation to walk each VMA\u2019s page table to make sure that the page is actually mapped within this specific VMA. Adding struct anon_vma is really similar to the idea of reusing address_space , i.e., having a data structure trampoline. Some more boring details: All pages within a single VMA share just one anon_vma . vma->anon_vma indicates if a VMA has attached or note. Related function is anon_vma_prepare() within do_anonymous_fault() link .","title":"Old Notes"},{"location":"notes/ssd/","text":"SSD 101 \u00b6 Version History Date Description Nov 15, 2022 Initial Grab-and-go SSD 101 for newbies.","title":"SSD 101"},{"location":"notes/ssd/#ssd-101","text":"Version History Date Description Nov 15, 2022 Initial Grab-and-go SSD 101 for newbies.","title":"SSD 101"},{"location":"notes/sysml/","text":"System for ML \u00b6 Version History Date Description Jul 7, 2021 new I\u2019m learning SysML and DNN, from the very beginning. As always, I will document and share my learning process. Let me know if you have reading recommendations, always welcomed! I mostly focus on the system aspects, in particular, how to design efficient large-scale machine learning frameworks. I care about operating system, network, storage, new hardware, and any other system related stuff. ML workload has its unique traits.","title":"SysML"},{"location":"notes/sysml/#system-for-ml","text":"Version History Date Description Jul 7, 2021 new I\u2019m learning SysML and DNN, from the very beginning. As always, I will document and share my learning process. Let me know if you have reading recommendations, always welcomed! I mostly focus on the system aspects, in particular, how to design efficient large-scale machine learning frameworks. I care about operating system, network, storage, new hardware, and any other system related stuff. ML workload has its unique traits.","title":"System for ML"},{"location":"notes/trace/","text":"Linux Tracing \u00b6 Version History Date Description Jan 18, 2021 Minor update Sep 6, 2020 Add more eBPF Jun 10, 2019 Initial version This blog tries to explain how various linux tracers work, especially their core low-level mechanisms and relationships with each other. Intro \u00b6 In Linux, we have: ftrace kprobe uprobe perf_event tracepoints eBPF For all these tools, we can think this way: Tracing needs two parts, 1) Mechanims to get data and do callback. This means we need a way to let our tracing/profiling code got invoked on a running system. This can be static or dynamic. Static means we added our tracing code to source code, like tracepoints. Dynamic means we added our tracing code when system is running, like ftrace and kprobe. 2) Do our stuff within callback. All of them provide some sort of handling. But eBPF is the most extensive one. For example, ftrace , kprobe , and perf_event include the callback facilities, although they are not just limited to this. ftrace has the call mount way to do callback on every single function invocation. kprobe dynamically patch instructions and to do callback within exception handlers. perf_event can let CPU fire NMI interrupt. Those are all mechanisms to catch perf data. In all, ftrace, kprobe, uprobe, perf_event, tracepoints all have mechanisms to get data and do callback. ftrace is not programmable by normal users, it only prints the info. kprobe allows us to attach customized pre-/post-handlers. perf_event is not programmable, it only reports numbers. Unlike all above subsystems, eBPF itself cannot intercept any programs, but it can be attached to any of the above probes and run customized programs. That\u2019s why eBPF looks so versatile! The BPF Performance Tools book section 2 also takes a deep dive into this topic, and it links all subsystems together with a bit of history as well. Also see the blog from Julia: Linux tracing systems & how they fit together . ftrace \u00b6 Mechanism For each un-inlined function, gcc inserts a call mcount , or a call fentry instruction at the very beginning. This means whenever a function is called, the mcount() or the fentry() callback will be invoked. Having these call instructions introduce a lot overheads. So by default kernel replace call with nop . Only after we echo something > setup_filter_functions will the ftrace code replace nop with call . Do note, Linux uses the linker magic again here, check Steven\u2019s slides. You can do a objdump vmlinux -d , and able to see the following instructions for almost all functions: callq ffffffff81a01560 <__fentry__> . x86 related code: arch/x86/kernel/ftrace_64.S , arch/x86/kernel/ftrace.c Questions: it seems we can know when a function got called by using fentry, but how can we know the function has returned? The trick is: the returning address is pushed to stack when a function got called. So ftrace, again, can replace that return address, so it can catch the exit time, and calculate the latency of a function. Neat!! Resources ftrace internal from Steven Usage Files under /sys/kernel/debug/tracing/* perf help ftrace kprobe \u00b6 Mechanism Kprobe replaces the original assembly instruction with an int3 trap instruction. So when we ran into the PC of the original instruction, an int3 CPU exception will happen. Within do_in3() , kernel will callback to core kprobe layer to do pre-handler . After singlestep, CPU have debug exception. Kernel walks into do_debug() , where kprobe run post-handler . Kprobe is powerful, because it\u2019s able to trace almost everything at instruction level. Kprobe can NOT touch things inside entry.S . It needs a valid pt_regs to operate. Resources An introduction to kprobes (LWN) eBPF \u00b6 Mechanism I think one of the most important things is to understand what\u2019s the relationship between eBPF and the others. Part I: Hook . eBPF attach its program to kprobe/uprobe/ftrace/perf_event. You can think eBPF of a generic callback layer for kprobe/uprobe/ftrace/perf_event. It\u2019s essentially the second part of tracing we mentioned above. (see include/uapi/linux/bpf.h , you can find BPF_PROG_TYPE_KPROBE , BPF_PROG_TYPE_PERF_EVENT ) Part II: Run . eBPF runs user supplied programs when the above hooks are invoked. eBPF is event-driven. Usually as a user, we do not need to write and load eBPF programs directly. That process is quite intense, you need to compile programs into eBPF bytecode, and then use eBPF SYSCALL to load into kernel. Quite a lot higher-level frameworks have been introduced. For example, bcc a layer on top of raw eBPF and smooth the process. bpftrace is even a layer higher than bcc, where users can write scripts to control eBPF. There are more frameworks on this space. Once you understand how it works below, it is not hard to understand and use high-level frameworks. Resources Brendan D. Gregg Blog Github: Awesome-eBPF Cilium: BPF and XDP Reference Guide Blog: An eBPF overview bcc bpftrace perf \u00b6 perf tool is simply amazing. It not only use CPU PMU, but also integrated with ftrace/kprobe/eBPF. perf is a tool to present data, but also a tool to collect data. Good references http://www.brendangregg.com/perf.html https://developers.redhat.com/blog/2019/04/23/how-to-use-the-linux-perf-tool-to-count-software-events/ https://opensource.com/article/18/7/fun-perf-and-python Trace in real time: Print the number of page faults happen in every one second: perf stat -e \"page-faults\" -I 1000 -a -- sleep 10 Print the numberf of mmap syscall happen in every one second: perf stat -e \"syscalls:sys_enter_mmap\" -I 1000 -a -- sleep 10 Dynamically trace kernel functions: perf probe --add do_anonymous_page perf stat -I 5000 -e \"page-faults,probe:do_anonymous_page\" -- sleep 10 perf probe --del = probe:do_anonymous_page References \u00b6 I have built the LegoOS profilers , and profile points before. Kernel maintains a top-level trace index file here .","title":"Linux Trace and Profile"},{"location":"notes/trace/#linux-tracing","text":"Version History Date Description Jan 18, 2021 Minor update Sep 6, 2020 Add more eBPF Jun 10, 2019 Initial version This blog tries to explain how various linux tracers work, especially their core low-level mechanisms and relationships with each other.","title":"Linux Tracing"},{"location":"notes/trace/#intro","text":"In Linux, we have: ftrace kprobe uprobe perf_event tracepoints eBPF For all these tools, we can think this way: Tracing needs two parts, 1) Mechanims to get data and do callback. This means we need a way to let our tracing/profiling code got invoked on a running system. This can be static or dynamic. Static means we added our tracing code to source code, like tracepoints. Dynamic means we added our tracing code when system is running, like ftrace and kprobe. 2) Do our stuff within callback. All of them provide some sort of handling. But eBPF is the most extensive one. For example, ftrace , kprobe , and perf_event include the callback facilities, although they are not just limited to this. ftrace has the call mount way to do callback on every single function invocation. kprobe dynamically patch instructions and to do callback within exception handlers. perf_event can let CPU fire NMI interrupt. Those are all mechanisms to catch perf data. In all, ftrace, kprobe, uprobe, perf_event, tracepoints all have mechanisms to get data and do callback. ftrace is not programmable by normal users, it only prints the info. kprobe allows us to attach customized pre-/post-handlers. perf_event is not programmable, it only reports numbers. Unlike all above subsystems, eBPF itself cannot intercept any programs, but it can be attached to any of the above probes and run customized programs. That\u2019s why eBPF looks so versatile! The BPF Performance Tools book section 2 also takes a deep dive into this topic, and it links all subsystems together with a bit of history as well. Also see the blog from Julia: Linux tracing systems & how they fit together .","title":"Intro"},{"location":"notes/trace/#ftrace","text":"Mechanism For each un-inlined function, gcc inserts a call mcount , or a call fentry instruction at the very beginning. This means whenever a function is called, the mcount() or the fentry() callback will be invoked. Having these call instructions introduce a lot overheads. So by default kernel replace call with nop . Only after we echo something > setup_filter_functions will the ftrace code replace nop with call . Do note, Linux uses the linker magic again here, check Steven\u2019s slides. You can do a objdump vmlinux -d , and able to see the following instructions for almost all functions: callq ffffffff81a01560 <__fentry__> . x86 related code: arch/x86/kernel/ftrace_64.S , arch/x86/kernel/ftrace.c Questions: it seems we can know when a function got called by using fentry, but how can we know the function has returned? The trick is: the returning address is pushed to stack when a function got called. So ftrace, again, can replace that return address, so it can catch the exit time, and calculate the latency of a function. Neat!! Resources ftrace internal from Steven Usage Files under /sys/kernel/debug/tracing/* perf help ftrace","title":"ftrace"},{"location":"notes/trace/#kprobe","text":"Mechanism Kprobe replaces the original assembly instruction with an int3 trap instruction. So when we ran into the PC of the original instruction, an int3 CPU exception will happen. Within do_in3() , kernel will callback to core kprobe layer to do pre-handler . After singlestep, CPU have debug exception. Kernel walks into do_debug() , where kprobe run post-handler . Kprobe is powerful, because it\u2019s able to trace almost everything at instruction level. Kprobe can NOT touch things inside entry.S . It needs a valid pt_regs to operate. Resources An introduction to kprobes (LWN)","title":"kprobe"},{"location":"notes/trace/#ebpf","text":"Mechanism I think one of the most important things is to understand what\u2019s the relationship between eBPF and the others. Part I: Hook . eBPF attach its program to kprobe/uprobe/ftrace/perf_event. You can think eBPF of a generic callback layer for kprobe/uprobe/ftrace/perf_event. It\u2019s essentially the second part of tracing we mentioned above. (see include/uapi/linux/bpf.h , you can find BPF_PROG_TYPE_KPROBE , BPF_PROG_TYPE_PERF_EVENT ) Part II: Run . eBPF runs user supplied programs when the above hooks are invoked. eBPF is event-driven. Usually as a user, we do not need to write and load eBPF programs directly. That process is quite intense, you need to compile programs into eBPF bytecode, and then use eBPF SYSCALL to load into kernel. Quite a lot higher-level frameworks have been introduced. For example, bcc a layer on top of raw eBPF and smooth the process. bpftrace is even a layer higher than bcc, where users can write scripts to control eBPF. There are more frameworks on this space. Once you understand how it works below, it is not hard to understand and use high-level frameworks. Resources Brendan D. Gregg Blog Github: Awesome-eBPF Cilium: BPF and XDP Reference Guide Blog: An eBPF overview bcc bpftrace","title":"eBPF"},{"location":"notes/trace/#perf","text":"perf tool is simply amazing. It not only use CPU PMU, but also integrated with ftrace/kprobe/eBPF. perf is a tool to present data, but also a tool to collect data. Good references http://www.brendangregg.com/perf.html https://developers.redhat.com/blog/2019/04/23/how-to-use-the-linux-perf-tool-to-count-software-events/ https://opensource.com/article/18/7/fun-perf-and-python Trace in real time: Print the number of page faults happen in every one second: perf stat -e \"page-faults\" -I 1000 -a -- sleep 10 Print the numberf of mmap syscall happen in every one second: perf stat -e \"syscalls:sys_enter_mmap\" -I 1000 -a -- sleep 10 Dynamically trace kernel functions: perf probe --add do_anonymous_page perf stat -I 5000 -e \"page-faults,probe:do_anonymous_page\" -- sleep 10 perf probe --del = probe:do_anonymous_page","title":"perf"},{"location":"notes/trace/#references","text":"I have built the LegoOS profilers , and profile points before. Kernel maintains a top-level trace index file here .","title":"References"},{"location":"notes/userfaultfd/","text":"Linux Userfaultfd \u00b6 Version History Date Description Jan 6, 2021 Minor update Jun 4, 2019 Initial version Code Study \u00b6 (Notes based on linux 5.2-rc3) Code Layout Major file: fs/userfaultfd.c , which has all the functions and callbacks. Callers spread across: mm/memory.c , mm/mremap.c , mm/mmap.c , and some others. The userfaultfd code is not that hard to understand if you already know how waitqueue etc work. It\u2019s built center around the file_ops , and couple callbacks for mm. handle_userfault() , called by mm/memory.c : Userfaultfd callback only happens for anonymous pgfault Userfaultfd skip all the LRU, rmap, cgroup Userfaultfd does not use the shared global zero page userfaultfd_unmap_prep(), userfaultfd_unmap_complete() , called by mm/mmap.c , and mm/mremap.c : Userfaultfd got notified if there are remap and unmap Userfaultfd deliver events via userfaultfd_event_wait_completion() I found code in mmap.c and mremap.c is NOT skipping rmap/lru code. Since userfaultfd related pages don\u2019t have these setup during pgfault, I think those rmap/lru cleanup code will notice this and handle it well. In conclusion, userfault skip the expansive rmap/lru setup/teardown. Why userfaultfd? \u00b6 It was at first developed to enhance VM migration: after migration, the destination QEMU can handle pgfault and bring pages from remote via network. Some databases also use it to have customized feature: http://tech.adroll.com/blog/data/2016/11/29/traildb-mmap-s3.html . Some academic papers are also using it to do customized processing in user space (e.g., remote regions). But I don\u2019t think this is going to be practical for performance-critical systems. My thought? The use case is very similar to what we did in Hotpot: get the faulting user address, and fetch it from remote. Due to kernel limitations and security constraints, the userfaultfd has to go through many layers and multiple kernel/user crossing. It would be interesting to inject eBPF code from user to kernel to handle pgfault (any research value?)","title":"Linux Userfaultfd"},{"location":"notes/userfaultfd/#linux-userfaultfd","text":"Version History Date Description Jan 6, 2021 Minor update Jun 4, 2019 Initial version","title":"Linux Userfaultfd"},{"location":"notes/userfaultfd/#code-study","text":"(Notes based on linux 5.2-rc3) Code Layout Major file: fs/userfaultfd.c , which has all the functions and callbacks. Callers spread across: mm/memory.c , mm/mremap.c , mm/mmap.c , and some others. The userfaultfd code is not that hard to understand if you already know how waitqueue etc work. It\u2019s built center around the file_ops , and couple callbacks for mm. handle_userfault() , called by mm/memory.c : Userfaultfd callback only happens for anonymous pgfault Userfaultfd skip all the LRU, rmap, cgroup Userfaultfd does not use the shared global zero page userfaultfd_unmap_prep(), userfaultfd_unmap_complete() , called by mm/mmap.c , and mm/mremap.c : Userfaultfd got notified if there are remap and unmap Userfaultfd deliver events via userfaultfd_event_wait_completion() I found code in mmap.c and mremap.c is NOT skipping rmap/lru code. Since userfaultfd related pages don\u2019t have these setup during pgfault, I think those rmap/lru cleanup code will notice this and handle it well. In conclusion, userfault skip the expansive rmap/lru setup/teardown.","title":"Code Study"},{"location":"notes/userfaultfd/#why-userfaultfd","text":"It was at first developed to enhance VM migration: after migration, the destination QEMU can handle pgfault and bring pages from remote via network. Some databases also use it to have customized feature: http://tech.adroll.com/blog/data/2016/11/29/traildb-mmap-s3.html . Some academic papers are also using it to do customized processing in user space (e.g., remote regions). But I don\u2019t think this is going to be practical for performance-critical systems. My thought? The use case is very similar to what we did in Hotpot: get the faulting user address, and fetch it from remote. Due to kernel limitations and security constraints, the userfaultfd has to go through many layers and multiple kernel/user crossing. It would be interesting to inject eBPF code from user to kernel to handle pgfault (any research value?)","title":"Why userfaultfd?"},{"location":"notes/virt/","text":"Modern Virtualization Technology \u00b6 Version History Date Description Jul 17, 2022 Update deliverables Nov 19, 2021 Add slides Nov 19, 2021 Add slides Jun 22, 2021 add steps and bare-metal virt Dec 31, 2020 minor update Feb 4, 2020 Add VFIO stuff Jan 26, 2020 Minor adjustment Jan 25, 2020 Initial Document Deliverables \u00b6 I have created two documents about virtualization. Hope they will be useful to you. Knowledge - Virtualization List of resources about virtualization Light QEMU /KVM code study IO virtualization such as QEMU device emulation, virtio, IOMMU, etc. Introduction of Cloud Virtualization Cards A gentle introduction to cloud virtualization cards E.g., AWS Nitro, NVIDIA BlueField DPU, Microsoft FPGA Introduction \u00b6 This blog tries to cover a short history on virtualization, the practices used by cloud vendors, the specialized virtualization cards (e.g., AWS Nitro), and some detailed notes on QEMU/KVM. I started this doc when I was trying to understand how virtualization actually works. I was just reading QEMU/KVM and taking notes, but I end up exploring more. Favorite quote about QEMU (in fact, about virtualization in general): Quote And at the end of the day, all virtualization really means is running a particular set of assembly instructions (the guest OS) to manipulate locations within a giant memory map for causing a particular set of side effects, where QEMU is just a user-space application providing a memory map and mimicking the same side effects you would get when executing those guest instructions on the appropriate bare metal hardware Also check out Awesome-Virtualization . A Short History of Virtualization \u00b6 Software-based Virtualization . This is where VMware started. No hardware support but just smart software tricks. You should read their papers. Para-virtualization . This is what Xen invented. They changed the guest OS for a better emulation. No hardware support still. But the guest OS is changed. Hardware-assited Virtualization . This is what AMD and Intel Vt-d + IOMMU for. The CPU would support virtualization mode and non-virtualization mode (in x86, each mode has Ring 0-3). However, the hardware change alone cannot work. They must work a virtual machine monitor for at least device emulation and other things. This is where KVM and QEMU came in. KVM enables Linux to use those CPU features and turns Linux into a type-2 hypervisor. Userspace QEMU, acting as a VMM, helps setup KVM and emulates devices (QEMU can also do passthrough via VFIO). Offload virtualization to dedicated hardware . This is what big cloud vendors are doing. For example, AWS Nitro cards, Mirosoft FPGA based SmartNIC cards. Emulation is costly. Especially for I/O data path. This problem got worse since hardware is faster and faster (e.g., 100G networking). So rather than relying on QEMU (or vendor kernel) to emulate storage/network/misc devices, these vendors build customized cards that would handle the \u201cdevice emulation\u201d part in hardware! Other than that, vendors offload quite a lot hypervisor functionalaties as well. E.g., Microsoft offload OpenVSwitch alike modules to their FPGA (called GFT in the NSDI\u201818 paper). Guest VMs, of course, are not aware any of these. They see the same MMIO spaces. This approach greatly saves host CPU usage, hence reduces Datacenter Virtualization Tax. Bare-metal Virtualization . Going back to where we started! Even with those great virtulization cards, the CPU still has virtualization modes enabled, and this has a cost! In particular, the 2-level page table (EPT) is still in play and guest VMs will exit on certain instructions (e.g., CPUID). All these take a toll on performance even if the VM does no I/O. Since vendors usually have 1-to-1 pCPU and vCPU mapping, this virtualization overhead is simply annoying and should be avoided. Hence bare-metal virtualization, as in no hypervisors and no virtualization modes, yet we are still able to pack untrusted tenant VMs on one physical machine. Isn\u2019t this amazing? Details \u00b6 Images below come from this slide I made: Slides on Cloud Virtualization Cards . KVM and QEMU/Firecraker Workflow \u00b6 The following image shows the typical workflow when a VM tries to access I/O devices. It will VM exit to the KVM module, which then dispatch (essentially return the ioctl call) the events to the userspace hypervisor (e.g., QEMU, Firecracker). Inside those hypervisors, there would be many implementation choices. Say the VM is tring to send out a packet via the emualted NIC, QEMU at this point will send out that packet using normal sockets (via host Linux). This is the basic flow: VM -> KVM -> QEMU/Firecracker -> host Linux. Internally, it could have many variantions. The green line represents SR-IOV enabled passthrough path. The VM can skip all hypervisor modules. SR-IOV is an all-or-nothing solution, so, once enabled, a cloud vendor / sysadmin has no way to control VM\u2019s usage on I/O devices. Cloud Vendors Reserve Cores to Run Hypervisor \u00b6 Vendors would reserve cores to run the hypervisor. For several important reasons. First, they want to have separate processing provisioning. Second, to reduce switches on user core. This is a common practice for some cloud vendors. But they try to move away from it by using speciazed hardware and save the cores for users. Modern Virtualization Hardware \u00b6 Cloud vendors have been using specialized virtualization cards to speed up virtualization and to reduce datacenter infrastructue tax. Those cards are particularly useful for high-speed I/O devices (recall the workflow we presented earlier, it has huge perf cost). Examples include AWS Nitro cards, Microsoft FPGA based SmartNIC cards (NSDI\u201818). You can use NVIDIA DPU or Intel IPU to build a similar one as well. Those cards, essentially move the hypervisor modules into the hardware. At a high-level, they are \u201cSR-IOV + Hardware-based QEMU\u201d . For storage + NIC, they can have two discrete cards or a unified one. The latter avoids the PCIe crossing. You can have NVMe-over-Fabric really easily. Knowledge - Virtualization \u00b6 Below is the note I took when I was reading QEMU/KVM source code. The questions I\u2019ve focused on are: 1) how QEMU emulates all the devices. 2) how KVM uses CPU features to switch between VMs, catch faults, return to QEMU etc. 3) how KVM and QEMU work together. 4) how virto works and how device-passthrough works (via VFIO). 5) Finally, if I want to write a new virtual machine monitor like QEMU, what should I build. Several recent projects (e.g., rust-vmm, firecracker) have hints on this. Google Doc Version PDF Version","title":"Modern Virtualization"},{"location":"notes/virt/#modern-virtualization-technology","text":"Version History Date Description Jul 17, 2022 Update deliverables Nov 19, 2021 Add slides Nov 19, 2021 Add slides Jun 22, 2021 add steps and bare-metal virt Dec 31, 2020 minor update Feb 4, 2020 Add VFIO stuff Jan 26, 2020 Minor adjustment Jan 25, 2020 Initial Document","title":"Modern Virtualization Technology"},{"location":"notes/virt/#deliverables","text":"I have created two documents about virtualization. Hope they will be useful to you. Knowledge - Virtualization List of resources about virtualization Light QEMU /KVM code study IO virtualization such as QEMU device emulation, virtio, IOMMU, etc. Introduction of Cloud Virtualization Cards A gentle introduction to cloud virtualization cards E.g., AWS Nitro, NVIDIA BlueField DPU, Microsoft FPGA","title":"Deliverables"},{"location":"notes/virt/#introduction","text":"This blog tries to cover a short history on virtualization, the practices used by cloud vendors, the specialized virtualization cards (e.g., AWS Nitro), and some detailed notes on QEMU/KVM. I started this doc when I was trying to understand how virtualization actually works. I was just reading QEMU/KVM and taking notes, but I end up exploring more. Favorite quote about QEMU (in fact, about virtualization in general): Quote And at the end of the day, all virtualization really means is running a particular set of assembly instructions (the guest OS) to manipulate locations within a giant memory map for causing a particular set of side effects, where QEMU is just a user-space application providing a memory map and mimicking the same side effects you would get when executing those guest instructions on the appropriate bare metal hardware Also check out Awesome-Virtualization .","title":"Introduction"},{"location":"notes/virt/#a-short-history-of-virtualization","text":"Software-based Virtualization . This is where VMware started. No hardware support but just smart software tricks. You should read their papers. Para-virtualization . This is what Xen invented. They changed the guest OS for a better emulation. No hardware support still. But the guest OS is changed. Hardware-assited Virtualization . This is what AMD and Intel Vt-d + IOMMU for. The CPU would support virtualization mode and non-virtualization mode (in x86, each mode has Ring 0-3). However, the hardware change alone cannot work. They must work a virtual machine monitor for at least device emulation and other things. This is where KVM and QEMU came in. KVM enables Linux to use those CPU features and turns Linux into a type-2 hypervisor. Userspace QEMU, acting as a VMM, helps setup KVM and emulates devices (QEMU can also do passthrough via VFIO). Offload virtualization to dedicated hardware . This is what big cloud vendors are doing. For example, AWS Nitro cards, Mirosoft FPGA based SmartNIC cards. Emulation is costly. Especially for I/O data path. This problem got worse since hardware is faster and faster (e.g., 100G networking). So rather than relying on QEMU (or vendor kernel) to emulate storage/network/misc devices, these vendors build customized cards that would handle the \u201cdevice emulation\u201d part in hardware! Other than that, vendors offload quite a lot hypervisor functionalaties as well. E.g., Microsoft offload OpenVSwitch alike modules to their FPGA (called GFT in the NSDI\u201818 paper). Guest VMs, of course, are not aware any of these. They see the same MMIO spaces. This approach greatly saves host CPU usage, hence reduces Datacenter Virtualization Tax. Bare-metal Virtualization . Going back to where we started! Even with those great virtulization cards, the CPU still has virtualization modes enabled, and this has a cost! In particular, the 2-level page table (EPT) is still in play and guest VMs will exit on certain instructions (e.g., CPUID). All these take a toll on performance even if the VM does no I/O. Since vendors usually have 1-to-1 pCPU and vCPU mapping, this virtualization overhead is simply annoying and should be avoided. Hence bare-metal virtualization, as in no hypervisors and no virtualization modes, yet we are still able to pack untrusted tenant VMs on one physical machine. Isn\u2019t this amazing?","title":"A Short History of Virtualization"},{"location":"notes/virt/#details","text":"Images below come from this slide I made: Slides on Cloud Virtualization Cards .","title":"Details"},{"location":"notes/virt/#kvm-and-qemufirecraker-workflow","text":"The following image shows the typical workflow when a VM tries to access I/O devices. It will VM exit to the KVM module, which then dispatch (essentially return the ioctl call) the events to the userspace hypervisor (e.g., QEMU, Firecracker). Inside those hypervisors, there would be many implementation choices. Say the VM is tring to send out a packet via the emualted NIC, QEMU at this point will send out that packet using normal sockets (via host Linux). This is the basic flow: VM -> KVM -> QEMU/Firecracker -> host Linux. Internally, it could have many variantions. The green line represents SR-IOV enabled passthrough path. The VM can skip all hypervisor modules. SR-IOV is an all-or-nothing solution, so, once enabled, a cloud vendor / sysadmin has no way to control VM\u2019s usage on I/O devices.","title":"KVM and QEMU/Firecraker Workflow"},{"location":"notes/virt/#cloud-vendors-reserve-cores-to-run-hypervisor","text":"Vendors would reserve cores to run the hypervisor. For several important reasons. First, they want to have separate processing provisioning. Second, to reduce switches on user core. This is a common practice for some cloud vendors. But they try to move away from it by using speciazed hardware and save the cores for users.","title":"Cloud Vendors Reserve Cores to Run Hypervisor"},{"location":"notes/virt/#modern-virtualization-hardware","text":"Cloud vendors have been using specialized virtualization cards to speed up virtualization and to reduce datacenter infrastructue tax. Those cards are particularly useful for high-speed I/O devices (recall the workflow we presented earlier, it has huge perf cost). Examples include AWS Nitro cards, Microsoft FPGA based SmartNIC cards (NSDI\u201818). You can use NVIDIA DPU or Intel IPU to build a similar one as well. Those cards, essentially move the hypervisor modules into the hardware. At a high-level, they are \u201cSR-IOV + Hardware-based QEMU\u201d . For storage + NIC, they can have two discrete cards or a unified one. The latter avoids the PCIe crossing. You can have NVMe-over-Fabric really easily.","title":"Modern Virtualization Hardware"},{"location":"notes/virt/#knowledge-virtualization","text":"Below is the note I took when I was reading QEMU/KVM source code. The questions I\u2019ve focused on are: 1) how QEMU emulates all the devices. 2) how KVM uses CPU features to switch between VMs, catch faults, return to QEMU etc. 3) how KVM and QEMU work together. 4) how virto works and how device-passthrough works (via VFIO). 5) Finally, if I want to write a new virtual machine monitor like QEMU, what should I build. Several recent projects (e.g., rust-vmm, firecracker) have hints on this. Google Doc Version PDF Version","title":"Knowledge - Virtualization"},{"location":"notes/xperf/","text":"x86 Ring Switch Overhead (Page Fault version) \u00b6 Version History Date Description Feb 2, 2020 Move github content to here Aug 7, 2019 Initial draft This page describes the mechanisms to measure the pure x86 ring switch overhead, i.e., from ring 3 to ring 0 and back. It is not straightforward to measure this in Linux kernel. Because when a user program traps from user space to kernel space, kernel will first run some assembly instructions to save the registers and load some new ones for kernel usage (i.e., syscall , common IDT , and some directly registered ). And only then, the kernel will run the C code. Thus if we place the measurement code in the first C function that will run (e.g., do_syscall_64 ), it will be much larger than the actual ring switch overhead. My proposed solutions hacks the entry_64.S and tries to save a timestamp as soon as possible. The first version centers around page fault handler, whose trapping mechanism is different from syscalls. However, I think it could be easily ported. The code is here . Takeaways: It ain\u2019t cheap! It usually take ~400 cycles to trap from user to kernel space. User-to-kernel crossing is more expansive than kernel-to-user crossing! Virtilization adds more overhead The following content is adopted from the Github repo. Numbers \u00b6 The numbers reported by this repo are slightly larger than the real crossing overhead because some instructions are needed in between to do bookkeeping. Check below for details. Some preliminary numbers measured on top of Intel Xeon E5-v3 2.4GHz Platform User to Kernel (Cycles) Kernel to User (Cycles) VM ~600 ~370 Bare-metal ~440 ~270 Mechanisms \u00b6 Files changed \u00b6 The whole patch is xperf.patch arch/x86/entry/entry_64.S arch/x86/mm/fault.c : save u2k_k to user stack xperf/xperf.c : userspace test code User to kernel (u2k) \u00b6 At a high-level, the flow is: User save TSC into stack User pgfault Cross to kernel, get TSC, and save to user stack But devil is in the details, especially this low-level assembly code. There are several difficulties: Once in kernel, we need to save TSC without corrupting any other registers and memory content. Any corruption leads to panic etc. The challenge is to find somewhere to save stuff. Options are: kernel stack, user stack, per-cpu. Using user stack is dangerous, because we can\u2019t use safe probe in this assembly (i.e., copy_from/to_user()). Using kernel stack is not flexible because we need to manually find a spot above pt_regs, and this subject to number of call invoked. We need to ensure the measuring only applied to measure program, but not all user program. We let user save a MAGIC on user stack. The approach: entry_64.S : Save rax/rdx into kernel stack, because they are known to be good if the exceptions came from user space. entry_64.S : Save TSC into a per-cpu area. With swapgs surrounded. entry_64.S : Restore rax/rdx fault.c : use copy_to_user to save u2k_k in user stack. Enable/Disable: entry_64.S : Change xperf_idtentry back to idtentry for both page_fault and async_page_fault . Note: u2k hack is safe because we don\u2019t probe user virtual address directly in assembly. Userspace accessing is done via copy_from_user() . Kernel to user (k2u) \u00b6 At a high-level, the flow is: Kernel save TSC into user stack Kernel IRET Cross to user, get TSC, and calculate latency This is relatively simpiler than measuring u2k because we can safely use kernel stack. The approach: Save scratch %rax, %rdx, %rcx into kernel stack Check if MAGIC match rdtsc save to user stack restore scratch registers Enable/Disable: entry_64.S: There is a xperf_return_kernel_tsc code block. Note: k2u hack is NOT SAFE because we probe user virtual address directly in assembly, i.e., movq %rax, (%rcx) in our hack. During my experiments, sometimes it will crash, but not always. xperf/xperf.c \u00b6 This user program will report both u2k and k2u crossing numbers. After compilation, use objdump xperf.o -d to check assembly, mfence rdtsc <- u2k_u shl $0x20 , % rdx or % rdx , % rax mov % rax ,( % rdi ) <- save to user stack movl $0x12345678 ,( % rsi ) <- pgfault rdtsc <- k2u_u mfence The user stack layout upon pgfault is: | .. | | 8 B magic | ( filled by user ) + 24 | 8 B u2k_u | ( filled by user ) + 16 | 8 B u2k_k | ( filled by kernel ) + 8 | 8 B k2u_k | ( filled by kernel ) <-- % rsp TSC Measurement \u00b6 TSC will be reodered if no actions are taken. We use mfence to mimize runtime errors. Ideally, we want a test sequence like this: /* * User to Kernel * * mfence * rdtsc <- u2k_u * (user) * ------- pgfault -------- * (kernel) * rdtsc <- u2k_k * mfence */ /* * Kernel to User * * mfence * rdtsc <- k2u_k * (kernel) * ------- IRET -------- * (user) * rdtsc <- k2u_k * mfence */ But we need some instructions in between to do essential setup. So the real instruction flow is: U2K (User) mfence rdtsc <- u2k_u shl $0x20,%rdx or %rdx,%rax mov %rax,(%rdi) movl $0x12345678,(%rsi) -------------------------------- Crossing (Kernel) testb $3, CS-ORIG_RAX(%rsp) jz 1f movq %rax, -8(%rsp) movq %rdx, -16(%rsp) rdtsc <- u2k_k mfence K2U (Kernel) mfence rdtsc <- k2u_k shl $32, %rdx or %rdx, %rax movq %rax, (%rcx) popq %rcx popq %rdx popq %rax INTERRUPT_RETURN -------------------------------- Crossing (User) rdtsc <- k2u_u mfence Misc \u00b6 For VM scenario, the page fault entry point is async_page_fault , not the page_fault . HOWTO Run \u00b6 FAT NOTE: Enabling k2u code might bring crash It\u2019s not safe to disable KPTI Switch back to normal kernel after testing Make sure if you have a way to reboot your machine! Steps: Copy your current kernel\u2019s .config into this repo make oldconfig Disable CONFIG_PAGE_TABLE_ISOLATION Compile kernel and install. Reboot into new kernel Disable hugepage echo never > /sys/kernel/mm/transparent_hugepage/enabled Run xperf/xperf.c , you will get a report.","title":"Linux x86 Ring Switch"},{"location":"notes/xperf/#x86-ring-switch-overhead-page-fault-version","text":"Version History Date Description Feb 2, 2020 Move github content to here Aug 7, 2019 Initial draft This page describes the mechanisms to measure the pure x86 ring switch overhead, i.e., from ring 3 to ring 0 and back. It is not straightforward to measure this in Linux kernel. Because when a user program traps from user space to kernel space, kernel will first run some assembly instructions to save the registers and load some new ones for kernel usage (i.e., syscall , common IDT , and some directly registered ). And only then, the kernel will run the C code. Thus if we place the measurement code in the first C function that will run (e.g., do_syscall_64 ), it will be much larger than the actual ring switch overhead. My proposed solutions hacks the entry_64.S and tries to save a timestamp as soon as possible. The first version centers around page fault handler, whose trapping mechanism is different from syscalls. However, I think it could be easily ported. The code is here . Takeaways: It ain\u2019t cheap! It usually take ~400 cycles to trap from user to kernel space. User-to-kernel crossing is more expansive than kernel-to-user crossing! Virtilization adds more overhead The following content is adopted from the Github repo.","title":"x86 Ring Switch Overhead (Page Fault version)"},{"location":"notes/xperf/#numbers","text":"The numbers reported by this repo are slightly larger than the real crossing overhead because some instructions are needed in between to do bookkeeping. Check below for details. Some preliminary numbers measured on top of Intel Xeon E5-v3 2.4GHz Platform User to Kernel (Cycles) Kernel to User (Cycles) VM ~600 ~370 Bare-metal ~440 ~270","title":"Numbers"},{"location":"notes/xperf/#mechanisms","text":"","title":"Mechanisms"},{"location":"notes/xperf/#files-changed","text":"The whole patch is xperf.patch arch/x86/entry/entry_64.S arch/x86/mm/fault.c : save u2k_k to user stack xperf/xperf.c : userspace test code","title":"Files changed"},{"location":"notes/xperf/#user-to-kernel-u2k","text":"At a high-level, the flow is: User save TSC into stack User pgfault Cross to kernel, get TSC, and save to user stack But devil is in the details, especially this low-level assembly code. There are several difficulties: Once in kernel, we need to save TSC without corrupting any other registers and memory content. Any corruption leads to panic etc. The challenge is to find somewhere to save stuff. Options are: kernel stack, user stack, per-cpu. Using user stack is dangerous, because we can\u2019t use safe probe in this assembly (i.e., copy_from/to_user()). Using kernel stack is not flexible because we need to manually find a spot above pt_regs, and this subject to number of call invoked. We need to ensure the measuring only applied to measure program, but not all user program. We let user save a MAGIC on user stack. The approach: entry_64.S : Save rax/rdx into kernel stack, because they are known to be good if the exceptions came from user space. entry_64.S : Save TSC into a per-cpu area. With swapgs surrounded. entry_64.S : Restore rax/rdx fault.c : use copy_to_user to save u2k_k in user stack. Enable/Disable: entry_64.S : Change xperf_idtentry back to idtentry for both page_fault and async_page_fault . Note: u2k hack is safe because we don\u2019t probe user virtual address directly in assembly. Userspace accessing is done via copy_from_user() .","title":"User to kernel (u2k)"},{"location":"notes/xperf/#kernel-to-user-k2u","text":"At a high-level, the flow is: Kernel save TSC into user stack Kernel IRET Cross to user, get TSC, and calculate latency This is relatively simpiler than measuring u2k because we can safely use kernel stack. The approach: Save scratch %rax, %rdx, %rcx into kernel stack Check if MAGIC match rdtsc save to user stack restore scratch registers Enable/Disable: entry_64.S: There is a xperf_return_kernel_tsc code block. Note: k2u hack is NOT SAFE because we probe user virtual address directly in assembly, i.e., movq %rax, (%rcx) in our hack. During my experiments, sometimes it will crash, but not always.","title":"Kernel to user (k2u)"},{"location":"notes/xperf/#xperfxperfc","text":"This user program will report both u2k and k2u crossing numbers. After compilation, use objdump xperf.o -d to check assembly, mfence rdtsc <- u2k_u shl $0x20 , % rdx or % rdx , % rax mov % rax ,( % rdi ) <- save to user stack movl $0x12345678 ,( % rsi ) <- pgfault rdtsc <- k2u_u mfence The user stack layout upon pgfault is: | .. | | 8 B magic | ( filled by user ) + 24 | 8 B u2k_u | ( filled by user ) + 16 | 8 B u2k_k | ( filled by kernel ) + 8 | 8 B k2u_k | ( filled by kernel ) <-- % rsp","title":"xperf/xperf.c"},{"location":"notes/xperf/#tsc-measurement","text":"TSC will be reodered if no actions are taken. We use mfence to mimize runtime errors. Ideally, we want a test sequence like this: /* * User to Kernel * * mfence * rdtsc <- u2k_u * (user) * ------- pgfault -------- * (kernel) * rdtsc <- u2k_k * mfence */ /* * Kernel to User * * mfence * rdtsc <- k2u_k * (kernel) * ------- IRET -------- * (user) * rdtsc <- k2u_k * mfence */ But we need some instructions in between to do essential setup. So the real instruction flow is: U2K (User) mfence rdtsc <- u2k_u shl $0x20,%rdx or %rdx,%rax mov %rax,(%rdi) movl $0x12345678,(%rsi) -------------------------------- Crossing (Kernel) testb $3, CS-ORIG_RAX(%rsp) jz 1f movq %rax, -8(%rsp) movq %rdx, -16(%rsp) rdtsc <- u2k_k mfence K2U (Kernel) mfence rdtsc <- k2u_k shl $32, %rdx or %rdx, %rax movq %rax, (%rcx) popq %rcx popq %rdx popq %rax INTERRUPT_RETURN -------------------------------- Crossing (User) rdtsc <- k2u_u mfence","title":"TSC Measurement"},{"location":"notes/xperf/#misc","text":"For VM scenario, the page fault entry point is async_page_fault , not the page_fault .","title":"Misc"},{"location":"notes/xperf/#howto-run","text":"FAT NOTE: Enabling k2u code might bring crash It\u2019s not safe to disable KPTI Switch back to normal kernel after testing Make sure if you have a way to reboot your machine! Steps: Copy your current kernel\u2019s .config into this repo make oldconfig Disable CONFIG_PAGE_TABLE_ISOLATION Compile kernel and install. Reboot into new kernel Disable hugepage echo never > /sys/kernel/mm/transparent_hugepage/enabled Run xperf/xperf.c , you will get a report.","title":"HOWTO Run"},{"location":"notes/go/golang/","text":"Go \u00b6 Version History Date Description Nov 5, 2021 Initial I decided to learn Go and use it build some sample projects. I may just start from a simple webserver. Since Go is used a lot in virtualization part (e.g., Docker, gVisor) and databases (mangoDB?), I\u2019m thinking of doing along that line as well. The learning code will be pushed into https://github.com/lastweek/learn-go . Resources \u00b6 awesome-go gVisor Notes \u00b6 Function call pass by value or reference For function call, the following are passed by value: a) struct b) basic data type (e.g., int). So the function receives a copy of each argument; modifications to the copy do not affect the caller. However, the following are pointer like: pointers (to struct, int), slice, map, function, or channel. The caller may be affected by any modifications the function makes to variable indirectly referred to by the argument. (Some testing code here https://github.com/lastweek/learn-go/blob/master/playground/datatypes.go ) Defer Defer is one of my favorite featues of Go. I have bad memories on maintaining the error handling code in C, especially in kernel: I have to carefully order the error handling code at the end of function, have proper labels and write proper goto. Here, defer elegantly solves this complex error handling issue. Goroutine Stack: a goroutine usually has a small stack typically 2KB. But unlike an OS thread, a goroutine\u2019s stack is not fixed; it grows and shrinks as needed. It could beas much as 1GB. Scheduling: what\u2019s the policy there? Does the runtime use some sort of timer if user code is not giving up control? It is an M:N scheduler. Some internal documentation: https://github.com/golang/go/blob/master/src/runtime/HACKING.md Go Runtime \u00b6 The source code is here under this directory src/runtime . A huge directory with a lot of files. Why not create more subdirectories to better organize all these files?","title":"Learn Go"},{"location":"notes/go/golang/#go","text":"Version History Date Description Nov 5, 2021 Initial I decided to learn Go and use it build some sample projects. I may just start from a simple webserver. Since Go is used a lot in virtualization part (e.g., Docker, gVisor) and databases (mangoDB?), I\u2019m thinking of doing along that line as well. The learning code will be pushed into https://github.com/lastweek/learn-go .","title":"Go"},{"location":"notes/go/golang/#resources","text":"awesome-go gVisor","title":"Resources"},{"location":"notes/go/golang/#notes","text":"Function call pass by value or reference For function call, the following are passed by value: a) struct b) basic data type (e.g., int). So the function receives a copy of each argument; modifications to the copy do not affect the caller. However, the following are pointer like: pointers (to struct, int), slice, map, function, or channel. The caller may be affected by any modifications the function makes to variable indirectly referred to by the argument. (Some testing code here https://github.com/lastweek/learn-go/blob/master/playground/datatypes.go ) Defer Defer is one of my favorite featues of Go. I have bad memories on maintaining the error handling code in C, especially in kernel: I have to carefully order the error handling code at the end of function, have proper labels and write proper goto. Here, defer elegantly solves this complex error handling issue. Goroutine Stack: a goroutine usually has a small stack typically 2KB. But unlike an OS thread, a goroutine\u2019s stack is not fixed; it grows and shrinks as needed. It could beas much as 1GB. Scheduling: what\u2019s the policy there? Does the runtime use some sort of timer if user code is not giving up control? It is an M:N scheduler. Some internal documentation: https://github.com/golang/go/blob/master/src/runtime/HACKING.md","title":"Notes"},{"location":"notes/go/golang/#go-runtime","text":"The source code is here under this directory src/runtime . A huge directory with a lot of files. Why not create more subdirectories to better organize all these files?","title":"Go Runtime"},{"location":"notes/go/gvisor/","text":"gVisor Case Study \u00b6 gVisor is an application kernel to run container jobs. It is like a library OS. It intercept syscalls made into Linux kernel and implement almost everything in userspace. Of course, since gVisor itself is still running as a user program in Linux, gVisor will interact with Linux kernel. In other words, gVisor interact with Linux kernel on application\u2019s behalf. Why gVisor? It is result of the perf & security trade-off between VM and container. To use VM, we have native perf and limited security exposure, most things are protected by hardware. But the downside is the slow start time and simply too heavy. Container is lightweight, you can deploy code directly. However, all containers share the underlying Linux kernel. So the security exposure space is much much large, it is the whole Linux kernel! And in fact, kernel does have a lot of security issues. That\u2019s why gVisor wants to take things into their own hand. By using gVisor and sandboxing apps using their library/app kernel, most of the OS functionalties are built into app\u2019s own domain, will not affect others. So the shared surface is smaller. It is interesting that gVisor comes out from May 2018. And the MIT Biscuit go-based OS comes out around Oct 2018. Both are using Go to write OS functionalties. Resources \u00b6 They have a good explanation on their architecture here . Papers: The True Cost of Containing: A gVisor Case Study, HotCloud\u201819 . Blending Containers and Virtual Machines: A Study of Firecracker and gVisor, VEE\u201920 Note \u00b6 Source code is https://github.com/google/gvisor . I actually not particular sure where should I start. We don\u2019t really need to understand gVisor in order to use it though. I did a quick go through. The major kernel can be found in pkg/ and pkg/sentry . The sentry is their core kernel. I decided to run it. I followed the docker+gVisor quick start guide. So apparently, docker can use gVisor instead of Linux to launch the container. We explicitly use the runsc runtime from gVisor. After the container is started, I run dmesg. It looks interesting. Same for files under /proc . Everything is emualted by gVisor. docker run --runtime = runsc --rm -it ubuntu /bin/bash root@59e9ca6d20a2:/proc# dmesg [ 0.000000] Starting gVisor... [ 0.461512] Waiting for children... [ 0.882428] Searching for socket adapter... [ 1.224004] Gathering forks... [ 1.310421] Consulting tar man page... [ 1.542386] Committing treasure map to memory... [ 1.648830] Feeding the init monster... [ 1.910484] Letting the watchdogs out... [ 2.316306] Mounting deweydecimalfs... [ 2.734728] Creating process schedule... [ 3.013152] Generating random numbers by fair dice roll... [ 3.351471] Setting up VFS2... [ 3.508762] Ready!","title":"gVisor"},{"location":"notes/go/gvisor/#gvisor-case-study","text":"gVisor is an application kernel to run container jobs. It is like a library OS. It intercept syscalls made into Linux kernel and implement almost everything in userspace. Of course, since gVisor itself is still running as a user program in Linux, gVisor will interact with Linux kernel. In other words, gVisor interact with Linux kernel on application\u2019s behalf. Why gVisor? It is result of the perf & security trade-off between VM and container. To use VM, we have native perf and limited security exposure, most things are protected by hardware. But the downside is the slow start time and simply too heavy. Container is lightweight, you can deploy code directly. However, all containers share the underlying Linux kernel. So the security exposure space is much much large, it is the whole Linux kernel! And in fact, kernel does have a lot of security issues. That\u2019s why gVisor wants to take things into their own hand. By using gVisor and sandboxing apps using their library/app kernel, most of the OS functionalties are built into app\u2019s own domain, will not affect others. So the shared surface is smaller. It is interesting that gVisor comes out from May 2018. And the MIT Biscuit go-based OS comes out around Oct 2018. Both are using Go to write OS functionalties.","title":"gVisor Case Study"},{"location":"notes/go/gvisor/#resources","text":"They have a good explanation on their architecture here . Papers: The True Cost of Containing: A gVisor Case Study, HotCloud\u201819 . Blending Containers and Virtual Machines: A Study of Firecracker and gVisor, VEE\u201920","title":"Resources"},{"location":"notes/go/gvisor/#note","text":"Source code is https://github.com/google/gvisor . I actually not particular sure where should I start. We don\u2019t really need to understand gVisor in order to use it though. I did a quick go through. The major kernel can be found in pkg/ and pkg/sentry . The sentry is their core kernel. I decided to run it. I followed the docker+gVisor quick start guide. So apparently, docker can use gVisor instead of Linux to launch the container. We explicitly use the runsc runtime from gVisor. After the container is started, I run dmesg. It looks interesting. Same for files under /proc . Everything is emualted by gVisor. docker run --runtime = runsc --rm -it ubuntu /bin/bash root@59e9ca6d20a2:/proc# dmesg [ 0.000000] Starting gVisor... [ 0.461512] Waiting for children... [ 0.882428] Searching for socket adapter... [ 1.224004] Gathering forks... [ 1.310421] Consulting tar man page... [ 1.542386] Committing treasure map to memory... [ 1.648830] Feeding the init monster... [ 1.910484] Letting the watchdogs out... [ 2.316306] Mounting deweydecimalfs... [ 2.734728] Creating process schedule... [ 3.013152] Generating random numbers by fair dice roll... [ 3.351471] Setting up VFS2... [ 3.508762] Ready!","title":"Note"},{"location":"notes/languages/rust/","text":"Note on Rust \u00b6 Version History Date Description Jan 9, 2021 Initial Version Learn \u00b6 Jan 9, 2020 As the first step, I\u2019m reading https://doc.rust-lang.org/book/ . The documentation part is really really nice. Run cargo doc --open .","title":"Note on Rust"},{"location":"notes/languages/rust/#note-on-rust","text":"Version History Date Description Jan 9, 2021 Initial Version","title":"Note on Rust"},{"location":"notes/languages/rust/#learn","text":"Jan 9, 2020 As the first step, I\u2019m reading https://doc.rust-lang.org/book/ . The documentation part is really really nice. Run cargo doc --open .","title":"Learn"},{"location":"notes/linux/","text":"on Linux \u00b6 Resources \u00b6 https://www.kernel.org/doc/html/latest/ https://makelinux.github.io/kernel/map/ https://0xax.gitbooks.io/linux-insides/content/index.html","title":"Linux Index"},{"location":"notes/linux/#on-linux","text":"","title":"on Linux"},{"location":"notes/linux/#resources","text":"https://www.kernel.org/doc/html/latest/ https://makelinux.github.io/kernel/map/ https://0xax.gitbooks.io/linux-insides/content/index.html","title":"Resources"},{"location":"notes/linux/fork/","text":"Misc on Linux fork, switch_to, and scheduling \u00b6 Version History Date Description Oct 23, 2021 Initial So I had some whiskey and chips last night. Sitting there watching TV, browsing random blogs. Then I came across a blog I saved long time ago about linux switch_to history. Then I recalled the moment I reliazed how switch_to/fork etc works, it was amazing. So I decide to read the source code again and do some documentation. I\u2019m mostly reading my LegoOS code. This note is quite uncomplete though. I won\u2019t have time going through the obvious. Prepare Kernel Stack and Function Pointers \u00b6 copy_process() -> copy_thread(). This is the stack layout after copy_thread() . Also the rough layout when the newly created thread is enqueued into runqueue. The copy_thread() is architecture specific, I\u2019m using x86 as an example. This is a magic function as it plays with the stack, which is implicitly used by simply returning. And this is confusing to a lot people, including myself when I got started. Some facts about the kernel stack. The kernel stack is allocated during fork() before we run into copy_thread() . We can reference it by calling task_stack_page(p) . The stack has a fixed size (maybe the latest version has changed this?), a configurable value called THREAD_SIZE , default is 2 pages I remember. So the end (top) of the stack is simply task_stack_page(p) + THREAD_SIZE . Stack grows from top to bottom. Hence, kernel uses a simple trick. It leverages the bottom of the kernel stack to save a struct called thread_info . Quite an important data structure. The assumption is that kernel will not actually grow to the bottom. They do have a method to detect kernel stack corruption, I will not cover it here. Alright, during copy_thread() , we basically have a \u201cfresh\u201d stack. We have copied everything from the old stack to the new stack (done before calling into copy_thread ). The core job here is to setup the top of the stack, so that when this newly created thread can run into certain predefined functions. Top of the kernel stack is the struct pt_regs , this is true across the whole kernel. So it is fairly easy to grab the pointer to it by using a simple macro called task_pt_regs(p) , which just has simple pointer calculation. Here, copy_thread() used a structure called struct fork_frame , which contains a struct inactive_task_frame and a struct pt_regs . Again, leveraging the memory layout, we can easily calculate the pointers to either structures. Note, the struct fork_frame layout is crucial to understanding how fork\u2019ed process gets running and how kernel thread runs into passed functions. The bottom of the struct fork_frame is a field called ret_addr . This is essentially the first function gets run when this newly created thread gets running (scheduled by runqueue). Here it is assigned to a function called ret_from_fork() , which should be straightforward to understand. We will look into that later. Alright, if this fork() is actually creating a kernel thread, we will save the kernel function pointer and argument pointer to the struct fork_frame as well! All these info saved here will be used later on in the assembly ( entry_64.S ). childregs = task_pt_regs ( p ); fork_frame = container_of ( childregs , struct fork_frame , regs ); frame -> ret_addr = ( unsigned long ) ret_from_fork ; ... ... /* * Save the kernel function pointer * and argument pointer to the `struct fork_frame` */ if ( unlikely ( p -> flags & PF_KTHREAD )) { p -> thread . pkru = pkru_get_init_value (); memset ( childregs , 0 , sizeof ( struct pt_regs )); kthread_frame_init ( frame , sp , arg ); return 0 ; } Then the newly created thread will be enqueued into the runqueue. Eventually it will gets running. Running For the first time after fork() \u00b6 When the scheduler decides to run a thread, it will at least call context_switch() , which internally calls switch_to() , which is just a macro around __switch_to_asm . #define switch_to(prev, next, last) \\ do { \\ (( last ) = __switch_to_asm (( prev ), ( next ))); \\ } while ( 0 ) __switch_to_asm is simply playing around the struct fork_frame we discussed above. It first the current thread\u2019s state, switch stack (to the newly created thread\u2019s stack), then starts popping out regs, eventually, only the ret_addr field remains in the stack!! This is very important: we jump to the __switch_to() function. Hence no return address will be pushed into the stack. Later on, when __switch_to() finishes and returns, the hardware will use the last field in the stack, which is the ret_addr field we placed there during copy_thread() ! Elegant, isn\u2019t it? So, for a newly created process, the control flow is as follows context_switch ( c ) __switch_to_asm ( asm ) __switch_to ( c ) ret_from_fork ( asm ) ==> return system call ==> run kernel function Note the two lines switching stack. The TASK_threadsp is actually referring to p->thread.sp . For a newly created thread, p->thread.sp was set during copy_thread() and it directly points to the starting address of struct fork_frame . Note that there is a key difference with regard to normal threads scheduling, i.e., threading got de-scheduled and scheduled again. For the normal case, threads either willingly give up control or got preempted. Either way, the kernel stack will have all the calling trace (different from a newly forked thread\u2019s stack, which is clean), and the p->thread.sp points there. Assume we have 2 threads A and B. A is originally running. A willingly goes to sleep by calling schedule(), inside which, it eventually calls context_switch()->__switch_to_asm() . This saves a return address to context_switch() into the bottom of the kernel stack (and this is the ret_field position for struct fork_frame )! When A got re-scheduled again, it runs into __switch_to_asm again. Unlike the fork case, here the ret_field points to where A gave up control, essentially the original context_switch() . So A will resume to context_switch() and run into finish_task_switch() . /* * %rdi: prev task * %rsi: next task */ ENTRY ( __switch_to_asm ) pushq % rbp pushq % rbx pushq % r12 pushq % r13 pushq % r14 pushq % r15 /* Switch stack */ movq % rsp , TASK_threadsp ( % rdi ) movq TASK_threadsp ( % rsi ), % rsp /* restore callee-saved registers */ popq % r15 popq % r14 popq % r13 popq % r12 popq % rbx popq % rbp /* * Note: * After popping out the above fields, now we only have * the `ret_field` left in the stack, which was pushed * into the stack by `copy_thread()`! * This is a *JUMP* to __switch_to() function! */ jmp __switch_to END ( __switch_to_asm ) I want to spend a few words on ret_from_fork as well. It is a quite interesting function. As we discussed above, a newly created thread will first run ret_from_fork() . And it got into this function by simply return from __switch_to() . As you can see, it will check whether we are creating a new kernel thread. If it is, we will invoke the kernel function directly (this is how kthread create new kernel thread). And this kernel thread is allowed to return to userspace by calling exec and its friends! /* * A newly forked process directly context switches into this address. * * rax: prev task we switched from * rbx: kernel thread func (NULL for user thread) * r12: kernel thread arg */ ENTRY ( ret_from_fork ) movq % rax , % rdi call schedule_tail /* rdi: 'prev' task parameter */ testq % rbx , % rbx /* from kernel_thread? */ jnz 1f /* kernel threads are uncommon */ 2 : movq % rsp , % rdi call syscall_return_slowpath /* return with IRQs disabled */ SWAPGS /* switch to user gs.base */ jmp restore_regs_and_iret 1 : /* kernel thread */ movq % r12 , % rdi call *% rbx /* * A kernel thread is allowed to return here after successfully * calling do_execve(). Exit to userspace to complete the execve() * syscall: */ movq $0 , RAX ( % rsp ) jmp 2 b END ( ret_from_fork ) Misc \u00b6 Linux current \u00b6 The current macro refers to the current running thread. It is very convient variable and it works like magic before. Long time ago, current is a macro that has a set of assmebly instructions calculating the pointer to task_struct based on the current kernel stack pointer . Since the kernel stack has a fixed size, so it is easy to derive the bottom of the kernel stack by masking the current sp pointer. Then, kernel saved some extra info there to make a connection to the task_struct. Simple and works well. Nowadays, in x86, the current becomes a per-cpu variable. IMO, it is actually much cleaner. The variable is called current_task . It got updated inside __switch_to . current becomes a function reading the current_task , should is much lightweigh than old solutions. Linux pt_regs \u00b6 PT stands for program trace. pt_regs includes the whole register status, very arch-specific. They live at the top of the kernel stack. When a program trap from user to kernel space, the first thing kernel would do is to construct such pt_regs (check entry_64.S ). However, things might got tricky though. Threads in kernel can be interrupted as well. So we could have multiple pt_regs instances inside kernel stack frame. So logically, there is a stack of pt_regs , and kernel code should use the right pt_regs rather than blindly use the top of the kernel stack! Leveraging ret and iret \u00b6 Kernel uses this trick a lot. At its core, ret and iret transfer control to the addresses saved in the stack. So if we change the saved addresses, C\u2019s return XX becomes very magical. It can return to unexpected places. This trick is used by __switch_to_asm and ret_from_fork . Kernel Exception Handling \u00b6 Kernel can handle exceptions from kernel itself, or fixup exceptions. Some of the exceptions are okay. Say copy_from_user() , there might be page fault during this call. And kernel should be able to recognize that in the page fault handler and resume execution.","title":"Linux fork/switch_to"},{"location":"notes/linux/fork/#misc-on-linux-fork-switch_to-and-scheduling","text":"Version History Date Description Oct 23, 2021 Initial So I had some whiskey and chips last night. Sitting there watching TV, browsing random blogs. Then I came across a blog I saved long time ago about linux switch_to history. Then I recalled the moment I reliazed how switch_to/fork etc works, it was amazing. So I decide to read the source code again and do some documentation. I\u2019m mostly reading my LegoOS code. This note is quite uncomplete though. I won\u2019t have time going through the obvious.","title":"Misc on Linux fork, switch_to, and scheduling"},{"location":"notes/linux/fork/#prepare-kernel-stack-and-function-pointers","text":"copy_process() -> copy_thread(). This is the stack layout after copy_thread() . Also the rough layout when the newly created thread is enqueued into runqueue. The copy_thread() is architecture specific, I\u2019m using x86 as an example. This is a magic function as it plays with the stack, which is implicitly used by simply returning. And this is confusing to a lot people, including myself when I got started. Some facts about the kernel stack. The kernel stack is allocated during fork() before we run into copy_thread() . We can reference it by calling task_stack_page(p) . The stack has a fixed size (maybe the latest version has changed this?), a configurable value called THREAD_SIZE , default is 2 pages I remember. So the end (top) of the stack is simply task_stack_page(p) + THREAD_SIZE . Stack grows from top to bottom. Hence, kernel uses a simple trick. It leverages the bottom of the kernel stack to save a struct called thread_info . Quite an important data structure. The assumption is that kernel will not actually grow to the bottom. They do have a method to detect kernel stack corruption, I will not cover it here. Alright, during copy_thread() , we basically have a \u201cfresh\u201d stack. We have copied everything from the old stack to the new stack (done before calling into copy_thread ). The core job here is to setup the top of the stack, so that when this newly created thread can run into certain predefined functions. Top of the kernel stack is the struct pt_regs , this is true across the whole kernel. So it is fairly easy to grab the pointer to it by using a simple macro called task_pt_regs(p) , which just has simple pointer calculation. Here, copy_thread() used a structure called struct fork_frame , which contains a struct inactive_task_frame and a struct pt_regs . Again, leveraging the memory layout, we can easily calculate the pointers to either structures. Note, the struct fork_frame layout is crucial to understanding how fork\u2019ed process gets running and how kernel thread runs into passed functions. The bottom of the struct fork_frame is a field called ret_addr . This is essentially the first function gets run when this newly created thread gets running (scheduled by runqueue). Here it is assigned to a function called ret_from_fork() , which should be straightforward to understand. We will look into that later. Alright, if this fork() is actually creating a kernel thread, we will save the kernel function pointer and argument pointer to the struct fork_frame as well! All these info saved here will be used later on in the assembly ( entry_64.S ). childregs = task_pt_regs ( p ); fork_frame = container_of ( childregs , struct fork_frame , regs ); frame -> ret_addr = ( unsigned long ) ret_from_fork ; ... ... /* * Save the kernel function pointer * and argument pointer to the `struct fork_frame` */ if ( unlikely ( p -> flags & PF_KTHREAD )) { p -> thread . pkru = pkru_get_init_value (); memset ( childregs , 0 , sizeof ( struct pt_regs )); kthread_frame_init ( frame , sp , arg ); return 0 ; } Then the newly created thread will be enqueued into the runqueue. Eventually it will gets running.","title":"Prepare Kernel Stack and Function Pointers"},{"location":"notes/linux/fork/#running-for-the-first-time-after-fork","text":"When the scheduler decides to run a thread, it will at least call context_switch() , which internally calls switch_to() , which is just a macro around __switch_to_asm . #define switch_to(prev, next, last) \\ do { \\ (( last ) = __switch_to_asm (( prev ), ( next ))); \\ } while ( 0 ) __switch_to_asm is simply playing around the struct fork_frame we discussed above. It first the current thread\u2019s state, switch stack (to the newly created thread\u2019s stack), then starts popping out regs, eventually, only the ret_addr field remains in the stack!! This is very important: we jump to the __switch_to() function. Hence no return address will be pushed into the stack. Later on, when __switch_to() finishes and returns, the hardware will use the last field in the stack, which is the ret_addr field we placed there during copy_thread() ! Elegant, isn\u2019t it? So, for a newly created process, the control flow is as follows context_switch ( c ) __switch_to_asm ( asm ) __switch_to ( c ) ret_from_fork ( asm ) ==> return system call ==> run kernel function Note the two lines switching stack. The TASK_threadsp is actually referring to p->thread.sp . For a newly created thread, p->thread.sp was set during copy_thread() and it directly points to the starting address of struct fork_frame . Note that there is a key difference with regard to normal threads scheduling, i.e., threading got de-scheduled and scheduled again. For the normal case, threads either willingly give up control or got preempted. Either way, the kernel stack will have all the calling trace (different from a newly forked thread\u2019s stack, which is clean), and the p->thread.sp points there. Assume we have 2 threads A and B. A is originally running. A willingly goes to sleep by calling schedule(), inside which, it eventually calls context_switch()->__switch_to_asm() . This saves a return address to context_switch() into the bottom of the kernel stack (and this is the ret_field position for struct fork_frame )! When A got re-scheduled again, it runs into __switch_to_asm again. Unlike the fork case, here the ret_field points to where A gave up control, essentially the original context_switch() . So A will resume to context_switch() and run into finish_task_switch() . /* * %rdi: prev task * %rsi: next task */ ENTRY ( __switch_to_asm ) pushq % rbp pushq % rbx pushq % r12 pushq % r13 pushq % r14 pushq % r15 /* Switch stack */ movq % rsp , TASK_threadsp ( % rdi ) movq TASK_threadsp ( % rsi ), % rsp /* restore callee-saved registers */ popq % r15 popq % r14 popq % r13 popq % r12 popq % rbx popq % rbp /* * Note: * After popping out the above fields, now we only have * the `ret_field` left in the stack, which was pushed * into the stack by `copy_thread()`! * This is a *JUMP* to __switch_to() function! */ jmp __switch_to END ( __switch_to_asm ) I want to spend a few words on ret_from_fork as well. It is a quite interesting function. As we discussed above, a newly created thread will first run ret_from_fork() . And it got into this function by simply return from __switch_to() . As you can see, it will check whether we are creating a new kernel thread. If it is, we will invoke the kernel function directly (this is how kthread create new kernel thread). And this kernel thread is allowed to return to userspace by calling exec and its friends! /* * A newly forked process directly context switches into this address. * * rax: prev task we switched from * rbx: kernel thread func (NULL for user thread) * r12: kernel thread arg */ ENTRY ( ret_from_fork ) movq % rax , % rdi call schedule_tail /* rdi: 'prev' task parameter */ testq % rbx , % rbx /* from kernel_thread? */ jnz 1f /* kernel threads are uncommon */ 2 : movq % rsp , % rdi call syscall_return_slowpath /* return with IRQs disabled */ SWAPGS /* switch to user gs.base */ jmp restore_regs_and_iret 1 : /* kernel thread */ movq % r12 , % rdi call *% rbx /* * A kernel thread is allowed to return here after successfully * calling do_execve(). Exit to userspace to complete the execve() * syscall: */ movq $0 , RAX ( % rsp ) jmp 2 b END ( ret_from_fork )","title":"Running For the first time after fork()"},{"location":"notes/linux/fork/#misc","text":"","title":"Misc"},{"location":"notes/linux/fork/#linux-current","text":"The current macro refers to the current running thread. It is very convient variable and it works like magic before. Long time ago, current is a macro that has a set of assmebly instructions calculating the pointer to task_struct based on the current kernel stack pointer . Since the kernel stack has a fixed size, so it is easy to derive the bottom of the kernel stack by masking the current sp pointer. Then, kernel saved some extra info there to make a connection to the task_struct. Simple and works well. Nowadays, in x86, the current becomes a per-cpu variable. IMO, it is actually much cleaner. The variable is called current_task . It got updated inside __switch_to . current becomes a function reading the current_task , should is much lightweigh than old solutions.","title":"Linux current"},{"location":"notes/linux/fork/#linux-pt_regs","text":"PT stands for program trace. pt_regs includes the whole register status, very arch-specific. They live at the top of the kernel stack. When a program trap from user to kernel space, the first thing kernel would do is to construct such pt_regs (check entry_64.S ). However, things might got tricky though. Threads in kernel can be interrupted as well. So we could have multiple pt_regs instances inside kernel stack frame. So logically, there is a stack of pt_regs , and kernel code should use the right pt_regs rather than blindly use the top of the kernel stack!","title":"Linux pt_regs"},{"location":"notes/linux/fork/#leveraging-ret-and-iret","text":"Kernel uses this trick a lot. At its core, ret and iret transfer control to the addresses saved in the stack. So if we change the saved addresses, C\u2019s return XX becomes very magical. It can return to unexpected places. This trick is used by __switch_to_asm and ret_from_fork .","title":"Leveraging ret and iret"},{"location":"notes/linux/fork/#kernel-exception-handling","text":"Kernel can handle exceptions from kernel itself, or fixup exceptions. Some of the exceptions are okay. Say copy_from_user() , there might be page fault during this call. And kernel should be able to recognize that in the page fault handler and resume execution.","title":"Kernel Exception Handling"},{"location":"notes/linux/linux-boot/","text":"Linux boot sequence after GRUB \u00b6 Version History Date Description Jan 6, 2021 minor update Dec 23, 2020 initial version This note is aboue the linux/grub boot protocol and a walk through of the low-level booting code. This is adopted from my previous note . I was looking into this while I was building the LegoOS boot process. I was trying to find out how GRUB2 loads the kernel image and how it prepares all the boot environment. Linux Boot Protocol and Code Sequence \u00b6 Linux (x86) has a boot protocol between the bootloader and kernel image itself, described here . Essentially, there is a contiguous memory region passing information between these two entities. This big region just like a big C struct : some fields are filled by kernel duing compile time ( arch/x86/boot/tools/build.c and some in code), some fields are filled by GRUB2 during boot time to tell kernel some important addresses, e.g., kernel parameters, ramdisk locations etc. GRUB2 code follows the protocol, and you can partially tell from the grub_cmd_linux() function. Last time I working on this was late 2016, I truly spent a lot investigating how GRUB and linux boot works. I will try to document a bit, if my memory serves: In the Linux kernel, file arch/x86/boot/header.S is the first file got run after GRUB2. This file is a bit complicated but not hard to understand! It has 3 parts. For the first part, it detects if it was loaded by a bootloader, if not, just by printing an error message and reboot. It the kernel was loaded by a bootloader like GRUB2, the first part will never execute. The bootload will directly jump to the second part. This is part of the boot protocol. For the second part, it lists all the fields described by the boot protocol. And finally the third part is real-mode instructions that got run after the GRUB2 jumo. The starting function is called start_of_setup , which will do some stack checking, and then jump to C code in arch/x86/boot/main.c . arch/x86/boot/main.c runs on real-mode, it will do some setup and jump to protected-mode (32-bit). It is running after BIOS but before the actual Linux kernel. Thus this piece of code must rely on BIOS to do stuff, which makes it very unique. The major task of the setup code is to prepare the struct boot_params , which has all the boot information, some of them were extracted from the header.S . The struct boot_params will be passed down and used by many kernel subsystems later on. The final jump happens in arch/x86/boot/pmjump.S # # Jump to protected-mode kernel, 0x100000 # which is the compressed/head_$(BITS).o # jmp *% eax Then, we are in arch/x86/boot/compressed/head_64.S . Above pmjump jumps to startup_32 , it will enable paging, tweak GDT table etc, setup pagetable, and transition to 64-bit entry point startup_64 . And finally, we are in 64-bit. The final jump will go to arch/x86/kernel/head_64.S . We are close! Now we are in arch/x86/kernel/head_64.S . We are in 64-bit. But some further setup is needed. This part is really low-level and engaging. I would never know I how managed to understand and port all this shit. It setup a lot GDT, IDT stuff, and some pgfault handlers. It turns out those early pgfault handlers are NECESSARY and I remember they played an very interesting role! Finally, this assembly will jump to arch/x86/kernel/head64.c , the C code! I guess an interesting part is secondary_startup_64 . This code is actually run by non-booting CPUs, or secondary CPUs. After the major boot CPU is up and running (already within start_kernel() ), I believe its the smp_init() that will send IPI wakeup interrupts to all present secondary CPUs. The secondary CPUs will start from real-mode, obviously. Then they will transition from 16bit to 32bit, from 32bit to 64bit. That code is in arch/x86/realmode/rm/trampoline.S ! arch/x86/realmode is interesting. It uses piggyback technique. All the real-mode and 32bit code are in arch/x86/realmode/rm/* , a special linker script is used to construct the code in a specific way! Think about mix 16bit, 32bit, 64bit code together, nasty! Hooray, C world. We are in arch/x86/kernel/head64.c . The starting function is x86_64_start_kernel ! And the end is the start_kernel , the one in init/main.c . In all, there are a lot jumps after GRUB2 loads the kernel image, and it\u2019s really a long road before we can reach start_kernel() . It probably should not be this complex, but the x86 architecture is just making it worse. GRUB2: linux v.s. linux16 \u00b6 An interesting thing is that there are two ways to load an kernel image in /boot/grub2/grub.cfg , either using linux vmlinuz-3.10.0 or linux16 vmlinuz-3.10.0 . They have different effects. I remember only the linux16 one works for me, but not remembering why. At least on CentOS 7, it\u2019s all linux16 . Different distro may have different preferences? The linux16 and initrd16 in grub-core/loader/i386/pc/linux.c : GRUB_MOD_INIT ( linux16 ) { cmd_linux = grub_register_command ( \"linux16\" , grub_cmd_linux , 0 , N_ ( \"Load Linux.\" )); cmd_initrd = grub_register_command ( \"initrd16\" , grub_cmd_initrd , 0 , N_ ( \"Load initrd.\" )); my_mod = mod ; } The linux and initrd in grub-core/loader/i386/linux.c : static grub_command_t cmd_linux , cmd_initrd ; GRUB_MOD_INIT ( linux ) { cmd_linux = grub_register_command ( \"linux\" , grub_cmd_linux , 0 , N_ ( \"Load Linux.\" )); cmd_initrd = grub_register_command ( \"initrd\" , grub_cmd_initrd , 0 , N_ ( \"Load initrd.\" )); my_mod = mod ; }","title":"Linux Boot Sequence"},{"location":"notes/linux/linux-boot/#linux-boot-sequence-after-grub","text":"Version History Date Description Jan 6, 2021 minor update Dec 23, 2020 initial version This note is aboue the linux/grub boot protocol and a walk through of the low-level booting code. This is adopted from my previous note . I was looking into this while I was building the LegoOS boot process. I was trying to find out how GRUB2 loads the kernel image and how it prepares all the boot environment.","title":"Linux boot sequence after GRUB"},{"location":"notes/linux/linux-boot/#linux-boot-protocol-and-code-sequence","text":"Linux (x86) has a boot protocol between the bootloader and kernel image itself, described here . Essentially, there is a contiguous memory region passing information between these two entities. This big region just like a big C struct : some fields are filled by kernel duing compile time ( arch/x86/boot/tools/build.c and some in code), some fields are filled by GRUB2 during boot time to tell kernel some important addresses, e.g., kernel parameters, ramdisk locations etc. GRUB2 code follows the protocol, and you can partially tell from the grub_cmd_linux() function. Last time I working on this was late 2016, I truly spent a lot investigating how GRUB and linux boot works. I will try to document a bit, if my memory serves: In the Linux kernel, file arch/x86/boot/header.S is the first file got run after GRUB2. This file is a bit complicated but not hard to understand! It has 3 parts. For the first part, it detects if it was loaded by a bootloader, if not, just by printing an error message and reboot. It the kernel was loaded by a bootloader like GRUB2, the first part will never execute. The bootload will directly jump to the second part. This is part of the boot protocol. For the second part, it lists all the fields described by the boot protocol. And finally the third part is real-mode instructions that got run after the GRUB2 jumo. The starting function is called start_of_setup , which will do some stack checking, and then jump to C code in arch/x86/boot/main.c . arch/x86/boot/main.c runs on real-mode, it will do some setup and jump to protected-mode (32-bit). It is running after BIOS but before the actual Linux kernel. Thus this piece of code must rely on BIOS to do stuff, which makes it very unique. The major task of the setup code is to prepare the struct boot_params , which has all the boot information, some of them were extracted from the header.S . The struct boot_params will be passed down and used by many kernel subsystems later on. The final jump happens in arch/x86/boot/pmjump.S # # Jump to protected-mode kernel, 0x100000 # which is the compressed/head_$(BITS).o # jmp *% eax Then, we are in arch/x86/boot/compressed/head_64.S . Above pmjump jumps to startup_32 , it will enable paging, tweak GDT table etc, setup pagetable, and transition to 64-bit entry point startup_64 . And finally, we are in 64-bit. The final jump will go to arch/x86/kernel/head_64.S . We are close! Now we are in arch/x86/kernel/head_64.S . We are in 64-bit. But some further setup is needed. This part is really low-level and engaging. I would never know I how managed to understand and port all this shit. It setup a lot GDT, IDT stuff, and some pgfault handlers. It turns out those early pgfault handlers are NECESSARY and I remember they played an very interesting role! Finally, this assembly will jump to arch/x86/kernel/head64.c , the C code! I guess an interesting part is secondary_startup_64 . This code is actually run by non-booting CPUs, or secondary CPUs. After the major boot CPU is up and running (already within start_kernel() ), I believe its the smp_init() that will send IPI wakeup interrupts to all present secondary CPUs. The secondary CPUs will start from real-mode, obviously. Then they will transition from 16bit to 32bit, from 32bit to 64bit. That code is in arch/x86/realmode/rm/trampoline.S ! arch/x86/realmode is interesting. It uses piggyback technique. All the real-mode and 32bit code are in arch/x86/realmode/rm/* , a special linker script is used to construct the code in a specific way! Think about mix 16bit, 32bit, 64bit code together, nasty! Hooray, C world. We are in arch/x86/kernel/head64.c . The starting function is x86_64_start_kernel ! And the end is the start_kernel , the one in init/main.c . In all, there are a lot jumps after GRUB2 loads the kernel image, and it\u2019s really a long road before we can reach start_kernel() . It probably should not be this complex, but the x86 architecture is just making it worse.","title":"Linux Boot Protocol and Code Sequence"},{"location":"notes/linux/linux-boot/#grub2-linux-vs-linux16","text":"An interesting thing is that there are two ways to load an kernel image in /boot/grub2/grub.cfg , either using linux vmlinuz-3.10.0 or linux16 vmlinuz-3.10.0 . They have different effects. I remember only the linux16 one works for me, but not remembering why. At least on CentOS 7, it\u2019s all linux16 . Different distro may have different preferences? The linux16 and initrd16 in grub-core/loader/i386/pc/linux.c : GRUB_MOD_INIT ( linux16 ) { cmd_linux = grub_register_command ( \"linux16\" , grub_cmd_linux , 0 , N_ ( \"Load Linux.\" )); cmd_initrd = grub_register_command ( \"initrd16\" , grub_cmd_initrd , 0 , N_ ( \"Load initrd.\" )); my_mod = mod ; } The linux and initrd in grub-core/loader/i386/linux.c : static grub_command_t cmd_linux , cmd_initrd ; GRUB_MOD_INIT ( linux ) { cmd_linux = grub_register_command ( \"linux\" , grub_cmd_linux , 0 , N_ ( \"Load Linux.\" )); cmd_initrd = grub_register_command ( \"initrd\" , grub_cmd_initrd , 0 , N_ ( \"Load initrd.\" )); my_mod = mod ; }","title":"GRUB2: linux v.s. linux16"},{"location":"notes/linux/linux-completion/","text":"wait, swait, completion \u00b6 Version History Date Description Oct 28, 2021 created Completion, swait, and wait are kernel APIs. They provide barrier-like semantics. They are easy to use and simple to understand as well. The swait (simple waitqueue) was added to the kernel around 2016 by Peter Zijlstra. As the email ( git log -p kernel/sched/swait.c ) and comments in the file point out, they just want to have a simpler version for this frequently used data structure. The waitqueue has unnecessary overhead for simple use cases. waitqueue can be found in kernel/sched/wait.c swait can be found in kernel/sched/swait.c . completion can be found in kernel/sched/completion.c The swait and waiqueue_t are essentially the same: they are a queue of sleeping threads. They provide APIs for you to insert (sleep) and delete (wakeup) threads within the queue. I recommend start from swait, it is simple enough as long as you are familiar with kernel list ops. The completion API essentially builds itself on top of swait . The complete() call directly call swake_up_locked() . I guess the only interesting thing is wait_for_completion() . static long __sched wait_for_common ( struct completion * x , long timeout , int state ) { return __wait_for_common ( x , schedule_timeout , timeout , state ); } All different flavors of wait eventually fall into the following func. It adds the current thread into the swait queue, change the thread state, then simply calls action() function pointer, which, in normal cases, is schedule_timeout() . So this is the place a thread goes to sleep and wait for the other thread to call complete() . static inline long __sched do_wait_for_common ( struct completion * x , long ( * action )( long ), long timeout , int state ) { if ( ! x -> done ) { DECLARE_SWAITQUEUE ( wait ); do { if ( signal_pending_state ( state , current )) { timeout = - ERESTARTSYS ; break ; } __prepare_to_swait ( & x -> wait , & wait ); __set_current_state ( state ); raw_spin_unlock_irq ( & x -> wait . lock ); timeout = action ( timeout ); raw_spin_lock_irq ( & x -> wait . lock ); } while ( ! x -> done && timeout ); __finish_swait ( & x -> wait , & wait ); if ( ! x -> done ) return timeout ; } if ( x -> done != UINT_MAX ) x -> done -- ; return timeout ?: 1 ; } References \u00b6 Documentation/scheduler/completion.rst","title":"Linux Completion/swait"},{"location":"notes/linux/linux-completion/#wait-swait-completion","text":"Version History Date Description Oct 28, 2021 created Completion, swait, and wait are kernel APIs. They provide barrier-like semantics. They are easy to use and simple to understand as well. The swait (simple waitqueue) was added to the kernel around 2016 by Peter Zijlstra. As the email ( git log -p kernel/sched/swait.c ) and comments in the file point out, they just want to have a simpler version for this frequently used data structure. The waitqueue has unnecessary overhead for simple use cases. waitqueue can be found in kernel/sched/wait.c swait can be found in kernel/sched/swait.c . completion can be found in kernel/sched/completion.c The swait and waiqueue_t are essentially the same: they are a queue of sleeping threads. They provide APIs for you to insert (sleep) and delete (wakeup) threads within the queue. I recommend start from swait, it is simple enough as long as you are familiar with kernel list ops. The completion API essentially builds itself on top of swait . The complete() call directly call swake_up_locked() . I guess the only interesting thing is wait_for_completion() . static long __sched wait_for_common ( struct completion * x , long timeout , int state ) { return __wait_for_common ( x , schedule_timeout , timeout , state ); } All different flavors of wait eventually fall into the following func. It adds the current thread into the swait queue, change the thread state, then simply calls action() function pointer, which, in normal cases, is schedule_timeout() . So this is the place a thread goes to sleep and wait for the other thread to call complete() . static inline long __sched do_wait_for_common ( struct completion * x , long ( * action )( long ), long timeout , int state ) { if ( ! x -> done ) { DECLARE_SWAITQUEUE ( wait ); do { if ( signal_pending_state ( state , current )) { timeout = - ERESTARTSYS ; break ; } __prepare_to_swait ( & x -> wait , & wait ); __set_current_state ( state ); raw_spin_unlock_irq ( & x -> wait . lock ); timeout = action ( timeout ); raw_spin_lock_irq ( & x -> wait . lock ); } while ( ! x -> done && timeout ); __finish_swait ( & x -> wait , & wait ); if ( ! x -> done ) return timeout ; } if ( x -> done != UINT_MAX ) x -> done -- ; return timeout ?: 1 ; }","title":"wait, swait, completion"},{"location":"notes/linux/linux-completion/#references","text":"Documentation/scheduler/completion.rst","title":"References"},{"location":"notes/linux/linux-function-trace/","text":"How to Dump Function Call Graph in Linux \u00b6 Version History Date Description Nov 1, 2021 new I want to share the method I use to dump the function call graph in a live Linux machine. This is particularly useful when you are studying the source code and try to understand the call flow. This is not the only way to do so, but I found it convenient in my own reading flow. The approach I took is fairly simple, I use ftrace . It has a feature to monitor the call graph AND dump the latency. I wrote a very simple script for this purpose. The whole scripts are uploaded to this repo https://github.com/lastweek/linux-ftrace . These are the steps I\u2019d take Modify the set_graph_function.sh , add the functions I want to dump. Run set_graph_function.sh directly. Dump the trace by running cat_trace_file.sh . Disable tracing by running disable.sh . The nice thing about ftrace is that it also measures the latency. If you want to understand how ftrace is able to dynamically measure the latency and has such a great flexibility, please check out my other blog here: http://lastweek.io/notes/trace/#ftrace . Examples \u00b6 Say I want to check handle_mm_fault() \u2018s runtime call graph. I would first modify the scipts to include this func. set -e DIR = /sys/kernel/debug/tracing # Presetup if any # ./prepare.sh # Disable tracing and clear trace echo 0 > $DIR /tracing_on echo > $DIR /trace echo > $DIR /set_ftrace_filter echo > $DIR /set_graph_function # Setup tracer type echo function_graph > $DIR /current_tracer # # The functions we'd trace # echo handle_mm_fault >> $DIR /set_graph_function echo \"Enabled graph functions:\" cat $DIR /set_graph_function echo 1 > $DIR /tracing_on Run the scripts, and look into the trace file, it would give us something like the following. Though, keep in mind that functions like handle_mm_fault() is very dynamic, there are many call graph combos. # tracer: function_graph # # CPU DURATION FUNCTION CALLS # | | | | | | | 39) | handle_mm_fault() { 39) 0.677 us | mem_cgroup_from_task(); 39) 0.918 us | __count_memcg_events(); 39) | __handle_mm_fault() { 39) | do_huge_pmd_numa_page() { 39) 0.682 us | _raw_spin_lock(); 39) 0.570 us | pmd_trans_migrating(); 39) | mpol_misplaced() { 39) 0.471 us | __get_vma_policy(); 39) | get_vma_policy.part.0() { 39) 0.387 us | get_task_policy.part.0(); 39) 1.091 us | } 39) | should_numa_migrate_memory() { 39) 0.374 us | page_cpupid_xchg_last(); 39) 1.095 us | } 39) 4.410 us | } 39) 0.389 us | unlock_page(); 39) | task_numa_fault() { 39) | __kmalloc() { 39) 0.382 us | kmalloc_slab(); 39) | _cond_resched() { 39) 0.391 us | rcu_all_qs(); 39) 1.115 us | } 39) 0.391 us | should_failslab(); 39) 0.461 us | memcg_kmem_put_cache(); 39) 4.628 us | } 39) 0.529 us | task_numa_placement(); 39) 6.481 us | } 39) + 15.130 us | } 39) + 16.854 us | } 39) + 21.198 us | }","title":"Linux Dump Function Graph"},{"location":"notes/linux/linux-function-trace/#how-to-dump-function-call-graph-in-linux","text":"Version History Date Description Nov 1, 2021 new I want to share the method I use to dump the function call graph in a live Linux machine. This is particularly useful when you are studying the source code and try to understand the call flow. This is not the only way to do so, but I found it convenient in my own reading flow. The approach I took is fairly simple, I use ftrace . It has a feature to monitor the call graph AND dump the latency. I wrote a very simple script for this purpose. The whole scripts are uploaded to this repo https://github.com/lastweek/linux-ftrace . These are the steps I\u2019d take Modify the set_graph_function.sh , add the functions I want to dump. Run set_graph_function.sh directly. Dump the trace by running cat_trace_file.sh . Disable tracing by running disable.sh . The nice thing about ftrace is that it also measures the latency. If you want to understand how ftrace is able to dynamically measure the latency and has such a great flexibility, please check out my other blog here: http://lastweek.io/notes/trace/#ftrace .","title":"How to Dump Function Call Graph in Linux"},{"location":"notes/linux/linux-function-trace/#examples","text":"Say I want to check handle_mm_fault() \u2018s runtime call graph. I would first modify the scipts to include this func. set -e DIR = /sys/kernel/debug/tracing # Presetup if any # ./prepare.sh # Disable tracing and clear trace echo 0 > $DIR /tracing_on echo > $DIR /trace echo > $DIR /set_ftrace_filter echo > $DIR /set_graph_function # Setup tracer type echo function_graph > $DIR /current_tracer # # The functions we'd trace # echo handle_mm_fault >> $DIR /set_graph_function echo \"Enabled graph functions:\" cat $DIR /set_graph_function echo 1 > $DIR /tracing_on Run the scripts, and look into the trace file, it would give us something like the following. Though, keep in mind that functions like handle_mm_fault() is very dynamic, there are many call graph combos. # tracer: function_graph # # CPU DURATION FUNCTION CALLS # | | | | | | | 39) | handle_mm_fault() { 39) 0.677 us | mem_cgroup_from_task(); 39) 0.918 us | __count_memcg_events(); 39) | __handle_mm_fault() { 39) | do_huge_pmd_numa_page() { 39) 0.682 us | _raw_spin_lock(); 39) 0.570 us | pmd_trans_migrating(); 39) | mpol_misplaced() { 39) 0.471 us | __get_vma_policy(); 39) | get_vma_policy.part.0() { 39) 0.387 us | get_task_policy.part.0(); 39) 1.091 us | } 39) | should_numa_migrate_memory() { 39) 0.374 us | page_cpupid_xchg_last(); 39) 1.095 us | } 39) 4.410 us | } 39) 0.389 us | unlock_page(); 39) | task_numa_fault() { 39) | __kmalloc() { 39) 0.382 us | kmalloc_slab(); 39) | _cond_resched() { 39) 0.391 us | rcu_all_qs(); 39) 1.115 us | } 39) 0.391 us | should_failslab(); 39) 0.461 us | memcg_kmem_put_cache(); 39) 4.628 us | } 39) 0.529 us | task_numa_placement(); 39) 6.481 us | } 39) + 15.130 us | } 39) + 16.854 us | } 39) + 21.198 us | }","title":"Examples"},{"location":"notes/linux/linux-iouring/","text":"Linux io_uring \u00b6 Version History Date Description Jan 8, 2021 Initial It has been two years since io_uring was added into mainline kernel. Over this short course, io_uring has grown a lot. The idea of using kernel, or even building kernel in an async way, ryhthms with a research idea I had, that\u2019s why I have always kept an eye on the development of io_uring. Nonetheless, I\u2019m not sure how real world softwares are picking it up. The io_uring introduced a set of new APIs and we have to rewrite applications to take advantage of its benefits. Although it may have performance benefits, this may prevent a wider adoption. Some argue there is nothing new about io_uring. I partially agree. It is a common practice to use rings to bridge multiple communicating parties, or to realize async ops. But actually implement the feature for syscalls is challenging. There are not too many stuff out there, you will mostly come across the following writeups: 1) Ringing in a new asynchronous I/O API 2) The rapid growth of io_uring There is user library called liburing to ease the use of io_ring. The kernel code is fs/io_uring.c . Such a big file. Bad practice. I think the whole io_uring thing is worth checking out. And you should think about what you can further do about it. I think it has great potentials.","title":"Linux io_uring"},{"location":"notes/linux/linux-iouring/#linux-io_uring","text":"Version History Date Description Jan 8, 2021 Initial It has been two years since io_uring was added into mainline kernel. Over this short course, io_uring has grown a lot. The idea of using kernel, or even building kernel in an async way, ryhthms with a research idea I had, that\u2019s why I have always kept an eye on the development of io_uring. Nonetheless, I\u2019m not sure how real world softwares are picking it up. The io_uring introduced a set of new APIs and we have to rewrite applications to take advantage of its benefits. Although it may have performance benefits, this may prevent a wider adoption. Some argue there is nothing new about io_uring. I partially agree. It is a common practice to use rings to bridge multiple communicating parties, or to realize async ops. But actually implement the feature for syscalls is challenging. There are not too many stuff out there, you will mostly come across the following writeups: 1) Ringing in a new asynchronous I/O API 2) The rapid growth of io_uring There is user library called liburing to ease the use of io_ring. The kernel code is fs/io_uring.c . Such a big file. Bad practice. I think the whole io_uring thing is worth checking out. And you should think about what you can further do about it. I think it has great potentials.","title":"Linux io_uring"},{"location":"notes/linux/linux-linker-script/","text":"Linux Linker Script Framework \u00b6 Version History Date Description Oct 30, 2021 Initial Has nothing better to do, so to write some random note on linker script. Intro \u00b6 The kernel is complied in a very controlled way. It has a linker script to control exactly what sections are generated and where they are. The linker script is architecture specific. I will examine arch/x86/kernel/vmliniux.ld.S . Yes, it is an assembly file. The build framework will compile it into vmlinux.ld . The reason that it is in assembly format is simple. We need to use a lot of macros, that are shared with C code. Assembly files allow us to do that, linker script does not. When I wrote LegoOS, I used the exact framework. The whole thing was very confusing to me in the beginning. The kernel code interacts with the linker script quite a lot, actually. The most common use, is to annnotate C code (say put into a special section), and then the linker script will aggregate them. Let me summarize the common flow: Create a new section name. And use it to annotate your function and data. For example, I can create __section(\"test\") , and mark int foo __section(\"test\") . Then look into vmlinux.lds.S , add a new section. Also, add begin and end marcos before and after the section. You can use these macros in your C code. . = ALIGN ( 8 ); . test_section : AT ( ADDR (. test_section ) - LOAD_OFFSET ) { __test_section_start = .; * (. test ); __test_section_end = .; } And in your C code, you can declare __test_section_start and __test_section_end , and use them. Kernel uses this trick a lot. If everything in this section is the same type of data structures, you can simply walk through it as if it is an array. Let\u2019s look at an example, say the x86 apicdrivers. They defined a macro to annotate apic drivers. #define apic_driver(sym) \\ static const struct apic * __apicdrivers_ ## sym __used \\ __aligned ( sizeof ( struct apic * )) \\ __section ( \".apicdrivers\" ) = { & sym } static const struct apic testAPICdriver = { ... }; apic_driver ( testAPICdriver ) And inside linker script, they define: . = ALIGN ( 8 ); . apicdrivers : AT ( ADDR (. apicdrivers ) - LOAD_OFFSET ) { __apicdrivers = .; * (. apicdrivers ); __apicdrivers_end = .; } Finally, define them in C and use it. extern struct apic * __apicdrivers [], * __apicdrivers_end []; struct apic ** drv ; for ( drv = __apicdrivers ; drv < __apicdrivers_end ; drv ++ ) { ... } The kernel scheduler code the trick to define various scheduler drivers too. Kernel \u00b6 Various things that use linker script to organize their data and functions. per-cpu data ftrace init and exit functions ACPI, APIC IRQCHIP Exception handlers cacheline aligned Boring Details \u00b6 In the vmlinux.lds.S , those header files are included. The most important one is vmlinux.lds.h . #include <asm-generic/vmlinux.lds.h> #include <asm/asm-offsets.h> #include <asm/thread_info.h> #include <asm/page_types.h> #include <asm/orc_lookup.h> #include <asm/cache.h> #include <asm/boot.h> And be sure to checkout the vmlinux.lds.h . The top comments. It lays out the basic structrue of a linker script in linux. And it defines all the macros used in the assembly linker file. /* * Helper macros to support writing architecture specific * linker scripts. * * A minimal linker scripts has following content: * [This is a sample, architectures may have special requiriements] * * OUTPUT_FORMAT(...) * OUTPUT_ARCH(...) * ENTRY(...) * SECTIONS * { * . = START; * __init_begin = .; * HEAD_TEXT_SECTION * INIT_TEXT_SECTION(PAGE_SIZE) * INIT_DATA_SECTION(...) * PERCPU_SECTION(CACHELINE_SIZE) * __init_end = .; * * _stext = .; * TEXT_SECTION = 0 * _etext = .; * * _sdata = .; * RO_DATA(PAGE_SIZE) * RW_DATA(...) * _edata = .; * * EXCEPTION_TABLE(...) * * BSS_SECTION(0, 0, 0) * _end = .; * * STABS_DEBUG * DWARF_DEBUG * ELF_DETAILS * * DISCARDS // must be the last * } * * [__init_begin, __init_end] is the init section that may be freed after init * // __init_begin and __init_end should be page aligned, so that we can * // free the whole .init memory * [_stext, _etext] is the text section * [_sdata, _edata] is the data section * * Some of the included output section have their own set of constants. * Examples are: [__initramfs_start, __initramfs_end] for initramfs and * [__nosave_begin, __nosave_end] for the nosave data */","title":"Linux Linker Script"},{"location":"notes/linux/linux-linker-script/#linux-linker-script-framework","text":"Version History Date Description Oct 30, 2021 Initial Has nothing better to do, so to write some random note on linker script.","title":"Linux Linker Script Framework"},{"location":"notes/linux/linux-linker-script/#intro","text":"The kernel is complied in a very controlled way. It has a linker script to control exactly what sections are generated and where they are. The linker script is architecture specific. I will examine arch/x86/kernel/vmliniux.ld.S . Yes, it is an assembly file. The build framework will compile it into vmlinux.ld . The reason that it is in assembly format is simple. We need to use a lot of macros, that are shared with C code. Assembly files allow us to do that, linker script does not. When I wrote LegoOS, I used the exact framework. The whole thing was very confusing to me in the beginning. The kernel code interacts with the linker script quite a lot, actually. The most common use, is to annnotate C code (say put into a special section), and then the linker script will aggregate them. Let me summarize the common flow: Create a new section name. And use it to annotate your function and data. For example, I can create __section(\"test\") , and mark int foo __section(\"test\") . Then look into vmlinux.lds.S , add a new section. Also, add begin and end marcos before and after the section. You can use these macros in your C code. . = ALIGN ( 8 ); . test_section : AT ( ADDR (. test_section ) - LOAD_OFFSET ) { __test_section_start = .; * (. test ); __test_section_end = .; } And in your C code, you can declare __test_section_start and __test_section_end , and use them. Kernel uses this trick a lot. If everything in this section is the same type of data structures, you can simply walk through it as if it is an array. Let\u2019s look at an example, say the x86 apicdrivers. They defined a macro to annotate apic drivers. #define apic_driver(sym) \\ static const struct apic * __apicdrivers_ ## sym __used \\ __aligned ( sizeof ( struct apic * )) \\ __section ( \".apicdrivers\" ) = { & sym } static const struct apic testAPICdriver = { ... }; apic_driver ( testAPICdriver ) And inside linker script, they define: . = ALIGN ( 8 ); . apicdrivers : AT ( ADDR (. apicdrivers ) - LOAD_OFFSET ) { __apicdrivers = .; * (. apicdrivers ); __apicdrivers_end = .; } Finally, define them in C and use it. extern struct apic * __apicdrivers [], * __apicdrivers_end []; struct apic ** drv ; for ( drv = __apicdrivers ; drv < __apicdrivers_end ; drv ++ ) { ... } The kernel scheduler code the trick to define various scheduler drivers too.","title":"Intro"},{"location":"notes/linux/linux-linker-script/#kernel","text":"Various things that use linker script to organize their data and functions. per-cpu data ftrace init and exit functions ACPI, APIC IRQCHIP Exception handlers cacheline aligned","title":"Kernel"},{"location":"notes/linux/linux-linker-script/#boring-details","text":"In the vmlinux.lds.S , those header files are included. The most important one is vmlinux.lds.h . #include <asm-generic/vmlinux.lds.h> #include <asm/asm-offsets.h> #include <asm/thread_info.h> #include <asm/page_types.h> #include <asm/orc_lookup.h> #include <asm/cache.h> #include <asm/boot.h> And be sure to checkout the vmlinux.lds.h . The top comments. It lays out the basic structrue of a linker script in linux. And it defines all the macros used in the assembly linker file. /* * Helper macros to support writing architecture specific * linker scripts. * * A minimal linker scripts has following content: * [This is a sample, architectures may have special requiriements] * * OUTPUT_FORMAT(...) * OUTPUT_ARCH(...) * ENTRY(...) * SECTIONS * { * . = START; * __init_begin = .; * HEAD_TEXT_SECTION * INIT_TEXT_SECTION(PAGE_SIZE) * INIT_DATA_SECTION(...) * PERCPU_SECTION(CACHELINE_SIZE) * __init_end = .; * * _stext = .; * TEXT_SECTION = 0 * _etext = .; * * _sdata = .; * RO_DATA(PAGE_SIZE) * RW_DATA(...) * _edata = .; * * EXCEPTION_TABLE(...) * * BSS_SECTION(0, 0, 0) * _end = .; * * STABS_DEBUG * DWARF_DEBUG * ELF_DETAILS * * DISCARDS // must be the last * } * * [__init_begin, __init_end] is the init section that may be freed after init * // __init_begin and __init_end should be page aligned, so that we can * // free the whole .init memory * [_stext, _etext] is the text section * [_sdata, _edata] is the data section * * Some of the included output section have their own set of constants. * Examples are: [__initramfs_start, __initramfs_end] for initramfs and * [__nosave_begin, __nosave_end] for the nosave data */","title":"Boring Details"},{"location":"notes/linux/linux-percpu/","text":"","title":"Linux percpu"},{"location":"notes/linux/linux-rcu/","text":"Linux RCU \u00b6 Version History Date Description Oct 24, 2021 Add code reading section Oct 23, 2021 Initial References \u00b6 What is RCU, Fundamentally? This is a great article. You should really understand the example cases in this article. It could give a better understanding on why RCU works and how to modify your code to use it. RCU Usage In the Linux Kernel: One Decade Later http://blog.foool.net/wp-content/uploads/linuxdocs/RCU.pdf I write this note as I read the related blog and the code. So my understanding expressed in this note is sequential. After reading various blogs and the kernel source code, I did reach a good conclusion and have a good understanding in the end. Notes \u00b6 RCU is just brilliant but also painfully hard to understand in the first place. I want to walk through how RCU is actually implemented in the kernel and take some notes (Oct 23, 2021). The synchronize_rcu() is the most interesting function. By definition, it will only return after making sure no other CPUs are still in the reader side critical section. In a non-preemptive kernel, it can simply wait all other CPUs to have a context switch. But in a preemptive kernel, it becomes more complicated. Just a naive thought, one can use some sort of per-cpu variable to track whether a CPU has a context switch during the synchronize_rcu() call. In the latest code (v5.9), this is the impl. So it appears synchronize_rcu_expedited() will speedup the grace period by forcefully send IPI to other CPUs to enforce context switch. The normal wait is the wait_rcu_gp() function. Very complicated function. It has several callback etc. But I guess it has to has a way to check other CPUs\u2019 status, right? To know whether other CPUs have context switched or so on. Anymore, I didn\u2019t expect to understand RCU impl in just few hours. I should use this a bit more and read a bit more. void synchronize_rcu ( void ) { if ( rcu_blocking_is_gp ()) return ; // Context allows vacuous grace periods. if ( rcu_gp_is_expedited ()) synchronize_rcu_expedited (); else wait_rcu_gp ( call_rcu ); } Ah, I think the RCU usage paper gives a nice high-level summary on Linux\u2019s implementaiton: In practice Linux implements synchronize_rcu by waiting for all CPUs in the system to pass through a context switch, instead of scheduling a thread on each CPU. This design optimizes the Linux RCU implementation for low-cost RCU critical sections, but at the cost of delaying synchronize_rcu callers longer than necessary. In principle, a writer waiting for a particular reader need only wait for that reader to complete an RCU critical section. The reader, however, must communicate to the writer that the RCU critical section is complete. The Linux RCU implementation essentially batches reader-to-writer communication by waiting for context switches. When possible, writers can use an asynchronous version of synchronize_rcu , call_rcu , that will asynchronously invokes a specified callback after all CPUs have passed through at least one context switch. The Linux RCU implementation tries to amortize the cost of detecting context switches over many synchronize_rcu and call_rcu operations. Detecting context switches requires maintaining state shared between CPUs . A CPU must update state, which other CPUs read, that indicate it executed a context switch. Updating shared state can be costly, because it causes other CPUs to cache miss. RCU reduces this cost by reporting per-CPU state roughly once per scheduling clock tick . If the kernel calls synchronize_rcu and call_rcu many times in that period, RCU will have reduced the average cost of each call to synchronize_rcu and call_rcu at the cost of higher latency. Linux can satisfy more than 1,000 calls to synchronize_rcu and call_rcu in a single batch [22]. For latency sensitive kernel subsystems, RCU provides expedited synchronization functions that execute without waiting for all CPUs to execute multiple context switches. How to use RCU? \u00b6 After reading several RCU code snippets, it is not hard to notice that they have a common theme. Especicially for the List related operations, there is no final atomic modification in the updater thread. This atomic update serves as a barrier. The reaeders rely on this pointer to grab info pointed by this pointer. This is very important trick to leverage RCU. If you code is not like, you should add this level of indirection, package your data behind a pointer and modify the reader to follow the pointer. Also, the List RCU related operations may seem confusing in the start, because, naturally, we\u2019d think there are so many operations inside list walk, insert and removal, how come they are safe? The catch is that, usually for readers who are doing list-walk, they only use the next pointer. So for insert and removal , they only need to gurantee the of next , meaning, they need to make sure that the list/data is correct (no NULL pointer) for both before and after updaing next pointer. And this is sufficient for readers! In all, changing to RCU requires a good understanding on your own logic. If your data structrue is not packaged, package it behind some pointers. And make sure the readers integrity can be ensured by relying on this single pointer. One more thing is Reader Retry. It is obvious that the readers might see stale data. So it is up to the designers to retry. The designer can rely on the Sequence Lock for this purpose for example. You can read the RCU usage paper for more suggestions. Code Reading \u00b6 This section is my note on the actual codes. There are two possible implementations: tiny and tree. Tiny is for UP system. Tree is the most standard one. So I will be looking into kernel/rcu/tree.c first My general approach to new code: 1) look top and bottom of the file. Top usually defines some importnat global variables. Bottom usually has the init functions, which could tell us what\u2019s going on, what threads are created etc. Then I scroll up from bottom. gp stands for Grace Period Important Data Structrues and Threads One global struct rcu_state . Init by rcu_init_one() . See include/linux/rcu/tree.h for detailed comments. Per CPU struct rcu_data . struct rcu_node There is thread called rcu_gp_kthread() , comment says this is a kthread that handles grace period. Shouldn\u2019t there be one per CPU? Why there is just one though? Initialization rcu_init() I saw rcutree_online_cpu() and rcutree_offline_cpu() . The core seems to be the rnp->ffmask , the ffmask . It appears this mask represent the cpu status in RCU subsystem. Pay attention to it later. rcutree_prepare_cpu() : init per-CPU RCU data ( rcu_data ). I have no idea what those fields in rcu_data are doing. And it is re-loading quite some info from the global rcu_state . Core It seems rnp->gp_seq != rdp->gp_seq means a grace period is started? Based on various functions, it appears that if they need a grace period, they will invoke the rcu_gp_kthread() ! Inside rcu_gp_kthread() it is just a big loop. It constantly sleeps. Once waken up, it will use rcu_gp_init() to actuallt start a grace period! Quite heavy. The core seems to be rcu_seq_start(&rcu_state.gp_seq); : update the gp_seq , the VERY variable that others use to check grace period. Think this is it. Now I still need to figure out how grace period got integrated into synchronize_rcu . So inside synchronize_rcu() , the main thing is wait_rcu_gp() , seems waiting for the grace period to finish. Ah we are getting close. The wait_rcu_gp() takes the call_rcu() function as a parameter. The call_rcu() queues an RCU callback for invocation AFTER a grace period (YES! Makes sense. So now, we know who is creating grace period - that above kthread and where we are waiting). For __wait_rcu_gp() , I don\u2019t understand much other than this complicated function callback. ( crcu_array [ i ])( & rs_array [ i ]. head , wakeme_after_rcu ); Note, if we are calling from synchronize_rcu , this crcu_array[i] is essentially call_rcu() function. So the above callback essentially becomes: call_rcu ( & rs_array [ i ]. head , wakeme_after_rcu ); In __call_rcu , I think the core is the following couple lines. It packages the incoming function callback and enqueue into the rcu segcblist. Not only synchronize_rcu() calls call_rcu() , any kernel code can call this to register a function to, say, free an object! Nice. Since callbacks MUST be called after it is safe to do so, meaning all CPUs have context switched. So we should find the place where callbacks are run. __call_rcu () ... head -> func = func ; head -> next = NULL ; ... rcu_segcblist_enqueue ( & rdp -> cblist , head ); .. Now try to find the place run callbacks. First up, examine the enqueue function. ThenIn the following func, the rsclp->tails caught my eye. Follow this. void rcu_segcblist_enqueue ( struct rcu_segcblist * rsclp , struct rcu_head * rhp ) { rcu_segcblist_inc_len ( rsclp ); rcu_segcblist_inc_seglen ( rsclp , RCU_NEXT_TAIL ); rhp -> next = NULL ; WRITE_ONCE ( * rsclp -> tails [ RCU_NEXT_TAIL ], rhp ); WRITE_ONCE ( rsclp -> tails [ RCU_NEXT_TAIL ], & rhp -> next ); } Since someone MUST call these callbacks after grace period. If we found that place, we will know which code represent the end of grace period. So I search for func and tails . Bang, we are in rcu_do_batch() . As you can see, it will walk through the callback list and run one by one. Note this callbacks come from either other kernel code or rcu itself. This callback is short, usually free the object or complete sth. /* * Invoke any RCU callbacks that have made it to the end of their grace * period. Throttle as specified by rdp->blimit. */ static void rcu_do_batch ( struct rcu_data * rdp ) { ... /* Invoke callbacks. */ tick_dep_set_task ( current , TICK_DEP_BIT_RCU ); rhp = rcu_cblist_dequeue ( & rcl ); for (; rhp ; rhp = rcu_cblist_dequeue ( & rcl )) { ... f = rhp -> func ; WRITE_ONCE ( rhp -> func , ( rcu_callback_t ) 0L ); f ( rhp ); ... } ... } Now we should find who calls rcu_do_batch . It is called by rcu_core() only, which is called by rcu_cpu_kthread() . This rcu_cpu_kthread() is different from the rcu_gp_thread (the one who START grace period). This function is registered via the smpboot_regsiter_percpu_thread() framework. This framework creates an internal thread repeatly calling the registered callbacks. So rcu_cpu_kthread() is actually running in a loop! It is just that the Loop logic is within the smpbook framework. It runs if rcu_data.rcu_cpu_has_work is 1, which is only set by invoke_rcu_core_kthread() . /* * Wake up this CPU's rcuc kthread to do RCU core processing. */ static void invoke_rcu_core ( void ) { if ( ! cpu_online ( smp_processor_id ())) return ; if ( use_softirq ) raise_softirq ( RCU_SOFTIRQ ); else invoke_rcu_core_kthread (); } So, WHOEVER calls invoke_rcu_core() should be the one checking whether a grace period has expired!! The cloest caller I found is this. The description is inline with what the RCU usage paper said. They do batch processing every scheduling-tick. Pay attention to rcu_pending() . So rcu_pending() checks if there is any RCU-related work to be done. If so, call invoke_rcu_core() to do all the callbacks. I mean, rcu_pending() should mean a grace period has ended, right? /* * This function is invoked from each scheduling-clock interrupt, * and checks to see if this CPU is in a non-context-switch quiescent * state, for example, user mode or idle loop. It also schedules RCU * core processing. If the current grace period has gone on too long, * it will ask the scheduler to manufacture a context switch for the sole * purpose of providing the needed quiescent state. */ void rcu_sched_clock_irq ( int user ) { ... if ( rcu_pending ( user )) invoke_rcu_core (); ... } Go for rcu_pending() . Though it checks grace period but it appears it does not check whether it ended or not. Maybe my fundamental understanding about the grace period impl is not correct. /* * Check to see if there is any immediate RCU-related work to be done by * the current CPU, returning 1 if so and zero otherwise. The checks are * in order of increasing expense: checks that can be carried out against * CPU-local state are performed first. However, we must check for CPU * stalls first, else we might not get a chance. */ static int rcu_pending ( int user ) { ... gp_in_progress = rcu_gp_in_progress (); .. } /* * Return true if an RCU grace period is in progress. The READ_ONCE()s * permit this function to be invoked without holding the root rcu_node * structure's ->lock, but of course results can be subject to change. */ static int rcu_gp_in_progress ( void ) { return rcu_seq_state ( rcu_seq_current ( & rcu_state . gp_seq )); } I must have missed a lot important connections, most importantly, how they ensure all CPUs have experienced a context switch and how exactly grace period is used here, meaning how it enforce things? I do see a lot of callback registerd and those callbacks usually are very simple, mostly do the complete() call. And the whole RCU subsystem has several data structures, rcu_data , rcu_node etc. And several threads, rcu_gp_kthread() , who advances grace period. rcu_cpu_kthread() who actually run the registered callbacks from call_rcu/synchronize_rcu. Anyway this is conclusion for me, for now (Oct 24, 2021). I might look into the userspace impl later. Nonetheless the core of synchronize_rcu() is fairly simple: make sure a grace period has gone (e.g., all other CPUs have context switched). But a real efficient implementation is quite complicated, esp in Linux kernel. After Thought \u00b6 Finished code reading. So it appears that for normal kernel code, use call_rcu() to register a callback is better than synchronize_rcu() . The former simply register the callback (e.g., free an object) and returns. The callback will be invoked once a grace period has expired. On the other hand, synchronize_rcu() is synchronize, it waits a grace period has actually passed. For most code, this is not necessary, as most code just want to do some cleanup code, as long as it is done.","title":"Linux RCU"},{"location":"notes/linux/linux-rcu/#linux-rcu","text":"Version History Date Description Oct 24, 2021 Add code reading section Oct 23, 2021 Initial","title":"Linux RCU"},{"location":"notes/linux/linux-rcu/#references","text":"What is RCU, Fundamentally? This is a great article. You should really understand the example cases in this article. It could give a better understanding on why RCU works and how to modify your code to use it. RCU Usage In the Linux Kernel: One Decade Later http://blog.foool.net/wp-content/uploads/linuxdocs/RCU.pdf I write this note as I read the related blog and the code. So my understanding expressed in this note is sequential. After reading various blogs and the kernel source code, I did reach a good conclusion and have a good understanding in the end.","title":"References"},{"location":"notes/linux/linux-rcu/#notes","text":"RCU is just brilliant but also painfully hard to understand in the first place. I want to walk through how RCU is actually implemented in the kernel and take some notes (Oct 23, 2021). The synchronize_rcu() is the most interesting function. By definition, it will only return after making sure no other CPUs are still in the reader side critical section. In a non-preemptive kernel, it can simply wait all other CPUs to have a context switch. But in a preemptive kernel, it becomes more complicated. Just a naive thought, one can use some sort of per-cpu variable to track whether a CPU has a context switch during the synchronize_rcu() call. In the latest code (v5.9), this is the impl. So it appears synchronize_rcu_expedited() will speedup the grace period by forcefully send IPI to other CPUs to enforce context switch. The normal wait is the wait_rcu_gp() function. Very complicated function. It has several callback etc. But I guess it has to has a way to check other CPUs\u2019 status, right? To know whether other CPUs have context switched or so on. Anymore, I didn\u2019t expect to understand RCU impl in just few hours. I should use this a bit more and read a bit more. void synchronize_rcu ( void ) { if ( rcu_blocking_is_gp ()) return ; // Context allows vacuous grace periods. if ( rcu_gp_is_expedited ()) synchronize_rcu_expedited (); else wait_rcu_gp ( call_rcu ); } Ah, I think the RCU usage paper gives a nice high-level summary on Linux\u2019s implementaiton: In practice Linux implements synchronize_rcu by waiting for all CPUs in the system to pass through a context switch, instead of scheduling a thread on each CPU. This design optimizes the Linux RCU implementation for low-cost RCU critical sections, but at the cost of delaying synchronize_rcu callers longer than necessary. In principle, a writer waiting for a particular reader need only wait for that reader to complete an RCU critical section. The reader, however, must communicate to the writer that the RCU critical section is complete. The Linux RCU implementation essentially batches reader-to-writer communication by waiting for context switches. When possible, writers can use an asynchronous version of synchronize_rcu , call_rcu , that will asynchronously invokes a specified callback after all CPUs have passed through at least one context switch. The Linux RCU implementation tries to amortize the cost of detecting context switches over many synchronize_rcu and call_rcu operations. Detecting context switches requires maintaining state shared between CPUs . A CPU must update state, which other CPUs read, that indicate it executed a context switch. Updating shared state can be costly, because it causes other CPUs to cache miss. RCU reduces this cost by reporting per-CPU state roughly once per scheduling clock tick . If the kernel calls synchronize_rcu and call_rcu many times in that period, RCU will have reduced the average cost of each call to synchronize_rcu and call_rcu at the cost of higher latency. Linux can satisfy more than 1,000 calls to synchronize_rcu and call_rcu in a single batch [22]. For latency sensitive kernel subsystems, RCU provides expedited synchronization functions that execute without waiting for all CPUs to execute multiple context switches.","title":"Notes"},{"location":"notes/linux/linux-rcu/#how-to-use-rcu","text":"After reading several RCU code snippets, it is not hard to notice that they have a common theme. Especicially for the List related operations, there is no final atomic modification in the updater thread. This atomic update serves as a barrier. The reaeders rely on this pointer to grab info pointed by this pointer. This is very important trick to leverage RCU. If you code is not like, you should add this level of indirection, package your data behind a pointer and modify the reader to follow the pointer. Also, the List RCU related operations may seem confusing in the start, because, naturally, we\u2019d think there are so many operations inside list walk, insert and removal, how come they are safe? The catch is that, usually for readers who are doing list-walk, they only use the next pointer. So for insert and removal , they only need to gurantee the of next , meaning, they need to make sure that the list/data is correct (no NULL pointer) for both before and after updaing next pointer. And this is sufficient for readers! In all, changing to RCU requires a good understanding on your own logic. If your data structrue is not packaged, package it behind some pointers. And make sure the readers integrity can be ensured by relying on this single pointer. One more thing is Reader Retry. It is obvious that the readers might see stale data. So it is up to the designers to retry. The designer can rely on the Sequence Lock for this purpose for example. You can read the RCU usage paper for more suggestions.","title":"How to use RCU?"},{"location":"notes/linux/linux-rcu/#code-reading","text":"This section is my note on the actual codes. There are two possible implementations: tiny and tree. Tiny is for UP system. Tree is the most standard one. So I will be looking into kernel/rcu/tree.c first My general approach to new code: 1) look top and bottom of the file. Top usually defines some importnat global variables. Bottom usually has the init functions, which could tell us what\u2019s going on, what threads are created etc. Then I scroll up from bottom. gp stands for Grace Period Important Data Structrues and Threads One global struct rcu_state . Init by rcu_init_one() . See include/linux/rcu/tree.h for detailed comments. Per CPU struct rcu_data . struct rcu_node There is thread called rcu_gp_kthread() , comment says this is a kthread that handles grace period. Shouldn\u2019t there be one per CPU? Why there is just one though? Initialization rcu_init() I saw rcutree_online_cpu() and rcutree_offline_cpu() . The core seems to be the rnp->ffmask , the ffmask . It appears this mask represent the cpu status in RCU subsystem. Pay attention to it later. rcutree_prepare_cpu() : init per-CPU RCU data ( rcu_data ). I have no idea what those fields in rcu_data are doing. And it is re-loading quite some info from the global rcu_state . Core It seems rnp->gp_seq != rdp->gp_seq means a grace period is started? Based on various functions, it appears that if they need a grace period, they will invoke the rcu_gp_kthread() ! Inside rcu_gp_kthread() it is just a big loop. It constantly sleeps. Once waken up, it will use rcu_gp_init() to actuallt start a grace period! Quite heavy. The core seems to be rcu_seq_start(&rcu_state.gp_seq); : update the gp_seq , the VERY variable that others use to check grace period. Think this is it. Now I still need to figure out how grace period got integrated into synchronize_rcu . So inside synchronize_rcu() , the main thing is wait_rcu_gp() , seems waiting for the grace period to finish. Ah we are getting close. The wait_rcu_gp() takes the call_rcu() function as a parameter. The call_rcu() queues an RCU callback for invocation AFTER a grace period (YES! Makes sense. So now, we know who is creating grace period - that above kthread and where we are waiting). For __wait_rcu_gp() , I don\u2019t understand much other than this complicated function callback. ( crcu_array [ i ])( & rs_array [ i ]. head , wakeme_after_rcu ); Note, if we are calling from synchronize_rcu , this crcu_array[i] is essentially call_rcu() function. So the above callback essentially becomes: call_rcu ( & rs_array [ i ]. head , wakeme_after_rcu ); In __call_rcu , I think the core is the following couple lines. It packages the incoming function callback and enqueue into the rcu segcblist. Not only synchronize_rcu() calls call_rcu() , any kernel code can call this to register a function to, say, free an object! Nice. Since callbacks MUST be called after it is safe to do so, meaning all CPUs have context switched. So we should find the place where callbacks are run. __call_rcu () ... head -> func = func ; head -> next = NULL ; ... rcu_segcblist_enqueue ( & rdp -> cblist , head ); .. Now try to find the place run callbacks. First up, examine the enqueue function. ThenIn the following func, the rsclp->tails caught my eye. Follow this. void rcu_segcblist_enqueue ( struct rcu_segcblist * rsclp , struct rcu_head * rhp ) { rcu_segcblist_inc_len ( rsclp ); rcu_segcblist_inc_seglen ( rsclp , RCU_NEXT_TAIL ); rhp -> next = NULL ; WRITE_ONCE ( * rsclp -> tails [ RCU_NEXT_TAIL ], rhp ); WRITE_ONCE ( rsclp -> tails [ RCU_NEXT_TAIL ], & rhp -> next ); } Since someone MUST call these callbacks after grace period. If we found that place, we will know which code represent the end of grace period. So I search for func and tails . Bang, we are in rcu_do_batch() . As you can see, it will walk through the callback list and run one by one. Note this callbacks come from either other kernel code or rcu itself. This callback is short, usually free the object or complete sth. /* * Invoke any RCU callbacks that have made it to the end of their grace * period. Throttle as specified by rdp->blimit. */ static void rcu_do_batch ( struct rcu_data * rdp ) { ... /* Invoke callbacks. */ tick_dep_set_task ( current , TICK_DEP_BIT_RCU ); rhp = rcu_cblist_dequeue ( & rcl ); for (; rhp ; rhp = rcu_cblist_dequeue ( & rcl )) { ... f = rhp -> func ; WRITE_ONCE ( rhp -> func , ( rcu_callback_t ) 0L ); f ( rhp ); ... } ... } Now we should find who calls rcu_do_batch . It is called by rcu_core() only, which is called by rcu_cpu_kthread() . This rcu_cpu_kthread() is different from the rcu_gp_thread (the one who START grace period). This function is registered via the smpboot_regsiter_percpu_thread() framework. This framework creates an internal thread repeatly calling the registered callbacks. So rcu_cpu_kthread() is actually running in a loop! It is just that the Loop logic is within the smpbook framework. It runs if rcu_data.rcu_cpu_has_work is 1, which is only set by invoke_rcu_core_kthread() . /* * Wake up this CPU's rcuc kthread to do RCU core processing. */ static void invoke_rcu_core ( void ) { if ( ! cpu_online ( smp_processor_id ())) return ; if ( use_softirq ) raise_softirq ( RCU_SOFTIRQ ); else invoke_rcu_core_kthread (); } So, WHOEVER calls invoke_rcu_core() should be the one checking whether a grace period has expired!! The cloest caller I found is this. The description is inline with what the RCU usage paper said. They do batch processing every scheduling-tick. Pay attention to rcu_pending() . So rcu_pending() checks if there is any RCU-related work to be done. If so, call invoke_rcu_core() to do all the callbacks. I mean, rcu_pending() should mean a grace period has ended, right? /* * This function is invoked from each scheduling-clock interrupt, * and checks to see if this CPU is in a non-context-switch quiescent * state, for example, user mode or idle loop. It also schedules RCU * core processing. If the current grace period has gone on too long, * it will ask the scheduler to manufacture a context switch for the sole * purpose of providing the needed quiescent state. */ void rcu_sched_clock_irq ( int user ) { ... if ( rcu_pending ( user )) invoke_rcu_core (); ... } Go for rcu_pending() . Though it checks grace period but it appears it does not check whether it ended or not. Maybe my fundamental understanding about the grace period impl is not correct. /* * Check to see if there is any immediate RCU-related work to be done by * the current CPU, returning 1 if so and zero otherwise. The checks are * in order of increasing expense: checks that can be carried out against * CPU-local state are performed first. However, we must check for CPU * stalls first, else we might not get a chance. */ static int rcu_pending ( int user ) { ... gp_in_progress = rcu_gp_in_progress (); .. } /* * Return true if an RCU grace period is in progress. The READ_ONCE()s * permit this function to be invoked without holding the root rcu_node * structure's ->lock, but of course results can be subject to change. */ static int rcu_gp_in_progress ( void ) { return rcu_seq_state ( rcu_seq_current ( & rcu_state . gp_seq )); } I must have missed a lot important connections, most importantly, how they ensure all CPUs have experienced a context switch and how exactly grace period is used here, meaning how it enforce things? I do see a lot of callback registerd and those callbacks usually are very simple, mostly do the complete() call. And the whole RCU subsystem has several data structures, rcu_data , rcu_node etc. And several threads, rcu_gp_kthread() , who advances grace period. rcu_cpu_kthread() who actually run the registered callbacks from call_rcu/synchronize_rcu. Anyway this is conclusion for me, for now (Oct 24, 2021). I might look into the userspace impl later. Nonetheless the core of synchronize_rcu() is fairly simple: make sure a grace period has gone (e.g., all other CPUs have context switched). But a real efficient implementation is quite complicated, esp in Linux kernel.","title":"Code Reading"},{"location":"notes/linux/linux-rcu/#after-thought","text":"Finished code reading. So it appears that for normal kernel code, use call_rcu() to register a callback is better than synchronize_rcu() . The former simply register the callback (e.g., free an object) and returns. The callback will be invoked once a grace period has expired. On the other hand, synchronize_rcu() is synchronize, it waits a grace period has actually passed. For most code, this is not necessary, as most code just want to do some cleanup code, as long as it is done.","title":"After Thought"},{"location":"notes/linux/linux-resource/","text":"Linux Kernel Resource \u00b6 Version History Date Description Mar 13, 2020 add lkt, nice Oct 7, 2019 Feels like I need to start thi High-level \u00b6 Linux Kernel Teaching The Linux Storage Stack Diagram Linux kernel map Sched \u00b6 Evolution of the x86 context switch in Linux Memory Management \u00b6 Memory: the flat, the discontiguous, and the sparse Reducing page structures for huge pages Misc \u00b6 Why printk() is so complicated (and how to fix it) Slide . Special sections in Linux binaries, 2013 Storage \u00b6 i10, good NVMe code","title":"Linux Resource"},{"location":"notes/linux/linux-resource/#linux-kernel-resource","text":"Version History Date Description Mar 13, 2020 add lkt, nice Oct 7, 2019 Feels like I need to start thi","title":"Linux Kernel Resource"},{"location":"notes/linux/linux-resource/#high-level","text":"Linux Kernel Teaching The Linux Storage Stack Diagram Linux kernel map","title":"High-level"},{"location":"notes/linux/linux-resource/#sched","text":"Evolution of the x86 context switch in Linux","title":"Sched"},{"location":"notes/linux/linux-resource/#memory-management","text":"Memory: the flat, the discontiguous, and the sparse Reducing page structures for huge pages","title":"Memory Management"},{"location":"notes/linux/linux-resource/#misc","text":"Why printk() is so complicated (and how to fix it) Slide . Special sections in Linux binaries, 2013","title":"Misc"},{"location":"notes/linux/linux-resource/#storage","text":"i10, good NVMe code","title":"Storage"},{"location":"notes/linux/linux-rust/","text":"Rust in Linux \u00b6 Version History Date Description Nov 1, 2021 new Nov 1, 2021. I know very little about Rust, only has read its documentation. But I\u2019m curious as hell on how to develop a kernel module in Rust. There was a lot buzz last year. I will try to take a look some time soon.","title":"Rust in Linux"},{"location":"notes/linux/linux-rust/#rust-in-linux","text":"Version History Date Description Nov 1, 2021 new Nov 1, 2021. I know very little about Rust, only has read its documentation. But I\u2019m curious as hell on how to develop a kernel module in Rust. There was a lot buzz last year. I will try to take a look some time soon.","title":"Rust in Linux"},{"location":"notes/linux/linux-workqueue/","text":"Linux Work Queue \u00b6 Version History Date Description Oct 29, 2021 Initial NOTE: like a lot of my other notes. This is written for myself. The note is not a high-level summary. It documents my journery on reading the source code and gradually understand the workqueue subsystem. I wrote it sequentially and I ask questions. Most of the questions are answered in a later section. My simple testing code is here: https://github.com/lastweek/linux-sample-modules/tree/master/workqueue . Intro \u00b6 Work queue is a generic async execution with shared worker pool in linux kernel. It does what is designed to do, it runs \u201cyour function\u201d across a set of worker threads. The subsystem is huge. As of v5.9, the workqueue.c has more than 6K lines of code. The internal documentation is at Documentation/core-api/workqueue.rst . Think about how would you design the thread pool and interfaces to submit work to it. I have designed one in LegoOS. The basic infrastructure is not hard, basically playing around various queues. The tricky part is to get the concurrency right, and various corner cases. Also, NUMA affinity, multiple thread pools etc features add more complexity. But the important thing is to understand the core! Public APIs alloc_workqueue() queue_work() Key Data Structures and Functions \u00b6 Data Structures struct work_struct , the work item, including the func struct worker , the actual worker thread has a struct task_struct *task struct worker_pool , multiple workers can form a pool So it looks like there 2 worker pools per cpu, and it is accessed by macro. But can we create more pools? NR_STD_WORKER_POOLS = 2 /* the per-cpu worker pools */ static DEFINE_PER_CPU_SHARED_ALIGNED ( struct worker_pool [ NR_STD_WORKER_POOLS ], cpu_worker_pools ); #define for_each_cpu_worker_pool(pool, cpu) \\ for ((pool) = &per_cpu(cpu_worker_pools, cpu)[0]; \\ (pool) < &per_cpu(cpu_worker_pools, cpu)[NR_STD_WORKER_POOLS]; \\ (pool)++) workqueues is a list of all workqueues static LIST_HEAD ( workqueues ); /* PR: list of all workqueues */ Create workers \u00b6 The first is I want to understand is how workers are created, and how many of them are created. I think I will do a bottom-up fashion instead of top-down. So I started from the function to create a single worker, then I check who calls it. The create_worker() - creates a worker thread. The steps are straightforward. Calling into kthread_create , attach it to a worker_pool . So this is how worker and pool got connected. static struct worker * create_worker ( struct worker_pool * pool ) { ... worker -> task = kthread_create_on_node ( worker_thread , worker , pool -> node , \"kworker/%s\" , id_buf ); /* successful, attach the worker to the pool */ worker_attach_to_pool ( worker , pool ); /* start the newly created worker */ raw_spin_lock_irq ( & pool -> lock ); worker -> pool -> nr_workers ++ ; worker_enter_idle ( worker ); wake_up_process ( worker -> task ); raw_spin_unlock_irq ( & pool -> lock ); ... } The worker_attach_to_pool() is quite simple, just some list op. list_add_tail ( & worker -> node , & pool -> workers ); worker -> pool = pool ; Okay, now I want to see who calls create_worker() . It is a static function, so only called within this file. Cool. First off, it is called by workqueue_init() , during startup. So here looks like it is creating a worker for the per-cpu pools (2 pools per cpu). What are those workers for though? void __init workqueue_init ( void ) { ... /* create the initial workers */ for_each_online_cpu ( cpu ) { for_each_cpu_worker_pool ( pool , cpu ) { pool -> flags &= ~ POOL_DISASSOCIATED ; BUG_ON ( ! create_worker ( pool )); } } hash_for_each ( unbound_pool_hash , bkt , pool , hash_node ) BUG_ON ( ! create_worker ( pool )); ... } Anyways, it is also called within workqueue_prepare_cpu() , which is a callback for cpu hotplug. Skip. Also called by maybe_create_worker() , which seems to be called within worker thread itself to create another worker within a pool. I\u2019m not sure whether the initial workers we created in workqueue_init() will create those during runtime.. Anyways, the final caller is get_unbound_pool() . Looks promising. It does says start the initial worker . So follows the caller of get_unbound_pool() . /** * get_unbound_pool - get a worker_pool with the specified attributes * @attrs: the attributes of the worker_pool to get .. */ static struct worker_pool * get_unbound_pool ( const struct workqueue_attrs * attrs ) { ... /* create and start the initial worker */ if ( wq_online && ! create_worker ( pool )) goto fail ; ... } The get_unbound_pool() is called by alloc_unbound_pwq() only. It seems to be creating struct pool_workqueue . This structure, seems a wrapper around struct worker_pool ? Okay, seem this is it. I\u2019m going to do top-down. Start from the public API. apply_workqueue_attrs() is easy to understand. It gots the workqueue entry and some attributes and then do some work based on that. I just want to understand what will be created if one calls alloc_workqueue . Well, it looks like inside apply_wqattrs_prepare() , it is looping over nodes. So it appears end of the day, it is one create_worker per node? I thought it is per cpu? Well, I could try it out and see. alloc_workqueue () - Public API -> alloc_and_link_pwqs ( struct workqueue_struct * wq ) -> apply_workqueue_attrs ( workqueue_struct , workqueue_attrs ) -> apply_workqueue_attrs_locked ( workqueue_struct , workqueue_attrs ) -> apply_wqattrs_prepare () ***** -> alloc_unbound_pwq () -> get_unbound_pool () -> create_worker () Actually, look closely into get_unbound_pool() . It actually has quite some logic before calling into create_worker() . This logic is checking whether we already have a matching pool and return early. And this is why our alloc_workqueue() won\u2019t create kworker right away. But I\u2019m wondering whether it creates later on.. Any way, I\u2019m done! The worker \u00b6 The worker is created by the function create_worker() . Duh. The worker thread is fairly straightforward, it repeatly sleep, wakeup, check if there are any pending work, do it, sleep. It appears that workers get work from the struct worker_pool . So now I understand what the pool concept is used here. And, it sorts of also answered my earlier question: the workers are generic and it appears alloc_workqueue actually will not create new threads. New users reuse the old worker threads. Though the worker may create more depends on load (that func is simple too..). /** * worker_thread - the worker thread function * @__worker: self * * The worker thread function. All workers belong to a worker_pool - * either a per-cpu one or dynamic unbound one. These workers process all * work items regardless of their specific target workqueue. The only * exception is work items which belong to workqueues with a rescuer which * will be explained in rescuer_thread(). * * Return: 0 */ static int worker_thread ( void * __worker ) { struct worker * worker = __worker ; struct worker_pool * pool = worker -> pool ; ... do { // // Yizhou: // See, we are dequeuing work from the pool // So, we can check who/when enqueue into worklist // struct work_struct * work = list_first_entry ( & pool -> worklist , struct work_struct , entry ); pool -> watchdog_ts = jiffies ; if ( likely ( ! ( * work_data_bits ( work ) & WORK_STRUCT_LINKED ))) { /* optimization path, not strictly necessary */ process_one_work ( worker , work ); if ( unlikely ( ! list_empty ( & worker -> scheduled ))) process_scheduled_works ( worker ); } else { move_linked_works ( work , & worker -> scheduled , NULL ); process_scheduled_works ( worker ); } } while ( keep_working ( pool )); } So, checking out worklist . It is simply modified by __queue_work() . Now the last question, I guess, is to figure out how __queue_work() decide which pool to insert the new work into. The __queue_work() only gets the wq returned by alloc_workqueue() . Let\u2019s see. Ok, looks like there are quite a lot flags controlling these. WQ_UNBOUND , WORK_CPU_UNBOUND and so on. These flags control, sort of, which pool to use. TODO \u00b6 I need to try it out. References \u00b6 https://events.static.linuxfound.org/sites/events/files/slides/Async%20execution%20with%20wqs.pdf","title":"Linux workqueue"},{"location":"notes/linux/linux-workqueue/#linux-work-queue","text":"Version History Date Description Oct 29, 2021 Initial NOTE: like a lot of my other notes. This is written for myself. The note is not a high-level summary. It documents my journery on reading the source code and gradually understand the workqueue subsystem. I wrote it sequentially and I ask questions. Most of the questions are answered in a later section. My simple testing code is here: https://github.com/lastweek/linux-sample-modules/tree/master/workqueue .","title":"Linux Work Queue"},{"location":"notes/linux/linux-workqueue/#intro","text":"Work queue is a generic async execution with shared worker pool in linux kernel. It does what is designed to do, it runs \u201cyour function\u201d across a set of worker threads. The subsystem is huge. As of v5.9, the workqueue.c has more than 6K lines of code. The internal documentation is at Documentation/core-api/workqueue.rst . Think about how would you design the thread pool and interfaces to submit work to it. I have designed one in LegoOS. The basic infrastructure is not hard, basically playing around various queues. The tricky part is to get the concurrency right, and various corner cases. Also, NUMA affinity, multiple thread pools etc features add more complexity. But the important thing is to understand the core! Public APIs alloc_workqueue() queue_work()","title":"Intro"},{"location":"notes/linux/linux-workqueue/#key-data-structures-and-functions","text":"Data Structures struct work_struct , the work item, including the func struct worker , the actual worker thread has a struct task_struct *task struct worker_pool , multiple workers can form a pool So it looks like there 2 worker pools per cpu, and it is accessed by macro. But can we create more pools? NR_STD_WORKER_POOLS = 2 /* the per-cpu worker pools */ static DEFINE_PER_CPU_SHARED_ALIGNED ( struct worker_pool [ NR_STD_WORKER_POOLS ], cpu_worker_pools ); #define for_each_cpu_worker_pool(pool, cpu) \\ for ((pool) = &per_cpu(cpu_worker_pools, cpu)[0]; \\ (pool) < &per_cpu(cpu_worker_pools, cpu)[NR_STD_WORKER_POOLS]; \\ (pool)++) workqueues is a list of all workqueues static LIST_HEAD ( workqueues ); /* PR: list of all workqueues */","title":"Key Data Structures and Functions"},{"location":"notes/linux/linux-workqueue/#create-workers","text":"The first is I want to understand is how workers are created, and how many of them are created. I think I will do a bottom-up fashion instead of top-down. So I started from the function to create a single worker, then I check who calls it. The create_worker() - creates a worker thread. The steps are straightforward. Calling into kthread_create , attach it to a worker_pool . So this is how worker and pool got connected. static struct worker * create_worker ( struct worker_pool * pool ) { ... worker -> task = kthread_create_on_node ( worker_thread , worker , pool -> node , \"kworker/%s\" , id_buf ); /* successful, attach the worker to the pool */ worker_attach_to_pool ( worker , pool ); /* start the newly created worker */ raw_spin_lock_irq ( & pool -> lock ); worker -> pool -> nr_workers ++ ; worker_enter_idle ( worker ); wake_up_process ( worker -> task ); raw_spin_unlock_irq ( & pool -> lock ); ... } The worker_attach_to_pool() is quite simple, just some list op. list_add_tail ( & worker -> node , & pool -> workers ); worker -> pool = pool ; Okay, now I want to see who calls create_worker() . It is a static function, so only called within this file. Cool. First off, it is called by workqueue_init() , during startup. So here looks like it is creating a worker for the per-cpu pools (2 pools per cpu). What are those workers for though? void __init workqueue_init ( void ) { ... /* create the initial workers */ for_each_online_cpu ( cpu ) { for_each_cpu_worker_pool ( pool , cpu ) { pool -> flags &= ~ POOL_DISASSOCIATED ; BUG_ON ( ! create_worker ( pool )); } } hash_for_each ( unbound_pool_hash , bkt , pool , hash_node ) BUG_ON ( ! create_worker ( pool )); ... } Anyways, it is also called within workqueue_prepare_cpu() , which is a callback for cpu hotplug. Skip. Also called by maybe_create_worker() , which seems to be called within worker thread itself to create another worker within a pool. I\u2019m not sure whether the initial workers we created in workqueue_init() will create those during runtime.. Anyways, the final caller is get_unbound_pool() . Looks promising. It does says start the initial worker . So follows the caller of get_unbound_pool() . /** * get_unbound_pool - get a worker_pool with the specified attributes * @attrs: the attributes of the worker_pool to get .. */ static struct worker_pool * get_unbound_pool ( const struct workqueue_attrs * attrs ) { ... /* create and start the initial worker */ if ( wq_online && ! create_worker ( pool )) goto fail ; ... } The get_unbound_pool() is called by alloc_unbound_pwq() only. It seems to be creating struct pool_workqueue . This structure, seems a wrapper around struct worker_pool ? Okay, seem this is it. I\u2019m going to do top-down. Start from the public API. apply_workqueue_attrs() is easy to understand. It gots the workqueue entry and some attributes and then do some work based on that. I just want to understand what will be created if one calls alloc_workqueue . Well, it looks like inside apply_wqattrs_prepare() , it is looping over nodes. So it appears end of the day, it is one create_worker per node? I thought it is per cpu? Well, I could try it out and see. alloc_workqueue () - Public API -> alloc_and_link_pwqs ( struct workqueue_struct * wq ) -> apply_workqueue_attrs ( workqueue_struct , workqueue_attrs ) -> apply_workqueue_attrs_locked ( workqueue_struct , workqueue_attrs ) -> apply_wqattrs_prepare () ***** -> alloc_unbound_pwq () -> get_unbound_pool () -> create_worker () Actually, look closely into get_unbound_pool() . It actually has quite some logic before calling into create_worker() . This logic is checking whether we already have a matching pool and return early. And this is why our alloc_workqueue() won\u2019t create kworker right away. But I\u2019m wondering whether it creates later on.. Any way, I\u2019m done!","title":"Create workers"},{"location":"notes/linux/linux-workqueue/#the-worker","text":"The worker is created by the function create_worker() . Duh. The worker thread is fairly straightforward, it repeatly sleep, wakeup, check if there are any pending work, do it, sleep. It appears that workers get work from the struct worker_pool . So now I understand what the pool concept is used here. And, it sorts of also answered my earlier question: the workers are generic and it appears alloc_workqueue actually will not create new threads. New users reuse the old worker threads. Though the worker may create more depends on load (that func is simple too..). /** * worker_thread - the worker thread function * @__worker: self * * The worker thread function. All workers belong to a worker_pool - * either a per-cpu one or dynamic unbound one. These workers process all * work items regardless of their specific target workqueue. The only * exception is work items which belong to workqueues with a rescuer which * will be explained in rescuer_thread(). * * Return: 0 */ static int worker_thread ( void * __worker ) { struct worker * worker = __worker ; struct worker_pool * pool = worker -> pool ; ... do { // // Yizhou: // See, we are dequeuing work from the pool // So, we can check who/when enqueue into worklist // struct work_struct * work = list_first_entry ( & pool -> worklist , struct work_struct , entry ); pool -> watchdog_ts = jiffies ; if ( likely ( ! ( * work_data_bits ( work ) & WORK_STRUCT_LINKED ))) { /* optimization path, not strictly necessary */ process_one_work ( worker , work ); if ( unlikely ( ! list_empty ( & worker -> scheduled ))) process_scheduled_works ( worker ); } else { move_linked_works ( work , & worker -> scheduled , NULL ); process_scheduled_works ( worker ); } } while ( keep_working ( pool )); } So, checking out worklist . It is simply modified by __queue_work() . Now the last question, I guess, is to figure out how __queue_work() decide which pool to insert the new work into. The __queue_work() only gets the wq returned by alloc_workqueue() . Let\u2019s see. Ok, looks like there are quite a lot flags controlling these. WQ_UNBOUND , WORK_CPU_UNBOUND and so on. These flags control, sort of, which pool to use.","title":"The worker"},{"location":"notes/linux/linux-workqueue/#todo","text":"I need to try it out.","title":"TODO"},{"location":"notes/linux/linux-workqueue/#references","text":"https://events.static.linuxfound.org/sites/events/files/slides/Async%20execution%20with%20wqs.pdf","title":"References"},{"location":"notes/linux/linux-x86-fpu/","text":"Linux/LegoOS x86 Floating Point Unit \u00b6 Version History Date Description Jan 9, 2021 repolished after reading the why mmap is faster syscall post . Indeed, the difference is that mmap is using user-level AVX-aided memmove while kernel cannot. This reminded me of this post so I decided to move it to here. Feb 22, 2018 Initial Version This blog documents how kernel is dealing with x86 FPU at a high level. FPU is heavily used by user level code, but not kernel. You may not use it directly, but glibc is using it all over the place, e.g. the strcmp , memcpy . x86 FPU is really a super complex technology designed by Intel. Of course its performance is good and also widely used, but the legacy compatible feature? Hmm, not so yummy. Without Ingo Molnar\u2019s x86 FPU code rewrite , there is no way for me to easily understand it. In 2019, the FPU code received another huge improvement ( patch ). The current x86 FPU code is well-written. Even though I don\u2019t understand some of the low-level code, I do enjoy reading it. The naming convention, the code organization, the file organization, the header files, it is a nice piece of art. Below I will briefly list kernel subsystems that use FPU. My understanding is based on code before the 2019 FPU patch, so some facts may have changed already. Boot \u00b6 FPU detection and init happen during early boot. The struct fpu is a dynamically-sized structure. Its size depends on what features the underlying CPU support. Since struct fpu is part of struct task_struct , that implies task_struct is dynamically-sized as well ( task_struct -> thread_struct -> fpu ). The cpu_init() will also callback to init its local FPU. Context Switch \u00b6 FPU consists of a huge amount of registers. Each thread will have its own FPU context. However, the CPU itself will not save or restore any FPU registers automatically, it is software\u2019s duty to save and restore FPU context properly. And FPU context/registers are saved into struct fpu . Thus whenever we switch task, we also need to switch FPU context (note: not always, it is optional, kernel is using a lazy switching trick). Code : __visible struct task_struct * __switch_to ( struct task_struct * prev_p , struct task_struct * next_p ) { .. fpu_switch = switch_fpu_prepare ( prev_fpu , next_fpu , cpu ); .. switch_fpu_finish ( next_fpu , fpu_switch ); .. } SYSCALL \u00b6 fork() and clone(): When a new thread or process is created, the FPU context is copied from the calling thread. execve(): during this syscall, the FPU context will be cleared. exit(): When a thread exit, FPU will do cleanup based on whether eagerfpu or lazyfpu is used. Exceptions \u00b6 Like the device not available exception, which may be triggered if lazyfpu is used. The do_simd_exception() and do_coprocessor_error() are some math related exceptions. Signal \u00b6 Kernel needs to setup a sigframe for user level signal handlers. sigframe is a contiguous stack memory consists of the general purpose registers AND FPU registers. So signal handling part has to call back to FPU code to setup and copy the FPU registers to the in stack sigframe . Signal handling is another beast. Thoughts \u00b6 Compatibility is a heavy thing to carry. But it is also a nice thing for marketing. No one can deny the success of Intel on its backward compatibility. Bad for low-level system developers. References \u00b6 https://unix.stackexchange.com/questions/475956/why-can-the-kernel-not-use-sse-avx-registers-and-instructions 2019 FPU patch: https://lkml.org/lkml/2019/4/3/877","title":"Linux FPU"},{"location":"notes/linux/linux-x86-fpu/#linuxlegoos-x86-floating-point-unit","text":"Version History Date Description Jan 9, 2021 repolished after reading the why mmap is faster syscall post . Indeed, the difference is that mmap is using user-level AVX-aided memmove while kernel cannot. This reminded me of this post so I decided to move it to here. Feb 22, 2018 Initial Version This blog documents how kernel is dealing with x86 FPU at a high level. FPU is heavily used by user level code, but not kernel. You may not use it directly, but glibc is using it all over the place, e.g. the strcmp , memcpy . x86 FPU is really a super complex technology designed by Intel. Of course its performance is good and also widely used, but the legacy compatible feature? Hmm, not so yummy. Without Ingo Molnar\u2019s x86 FPU code rewrite , there is no way for me to easily understand it. In 2019, the FPU code received another huge improvement ( patch ). The current x86 FPU code is well-written. Even though I don\u2019t understand some of the low-level code, I do enjoy reading it. The naming convention, the code organization, the file organization, the header files, it is a nice piece of art. Below I will briefly list kernel subsystems that use FPU. My understanding is based on code before the 2019 FPU patch, so some facts may have changed already.","title":"Linux/LegoOS x86 Floating Point Unit"},{"location":"notes/linux/linux-x86-fpu/#boot","text":"FPU detection and init happen during early boot. The struct fpu is a dynamically-sized structure. Its size depends on what features the underlying CPU support. Since struct fpu is part of struct task_struct , that implies task_struct is dynamically-sized as well ( task_struct -> thread_struct -> fpu ). The cpu_init() will also callback to init its local FPU.","title":"Boot"},{"location":"notes/linux/linux-x86-fpu/#context-switch","text":"FPU consists of a huge amount of registers. Each thread will have its own FPU context. However, the CPU itself will not save or restore any FPU registers automatically, it is software\u2019s duty to save and restore FPU context properly. And FPU context/registers are saved into struct fpu . Thus whenever we switch task, we also need to switch FPU context (note: not always, it is optional, kernel is using a lazy switching trick). Code : __visible struct task_struct * __switch_to ( struct task_struct * prev_p , struct task_struct * next_p ) { .. fpu_switch = switch_fpu_prepare ( prev_fpu , next_fpu , cpu ); .. switch_fpu_finish ( next_fpu , fpu_switch ); .. }","title":"Context Switch"},{"location":"notes/linux/linux-x86-fpu/#syscall","text":"fork() and clone(): When a new thread or process is created, the FPU context is copied from the calling thread. execve(): during this syscall, the FPU context will be cleared. exit(): When a thread exit, FPU will do cleanup based on whether eagerfpu or lazyfpu is used.","title":"SYSCALL"},{"location":"notes/linux/linux-x86-fpu/#exceptions","text":"Like the device not available exception, which may be triggered if lazyfpu is used. The do_simd_exception() and do_coprocessor_error() are some math related exceptions.","title":"Exceptions"},{"location":"notes/linux/linux-x86-fpu/#signal","text":"Kernel needs to setup a sigframe for user level signal handlers. sigframe is a contiguous stack memory consists of the general purpose registers AND FPU registers. So signal handling part has to call back to FPU code to setup and copy the FPU registers to the in stack sigframe . Signal handling is another beast.","title":"Signal"},{"location":"notes/linux/linux-x86-fpu/#thoughts","text":"Compatibility is a heavy thing to carry. But it is also a nice thing for marketing. No one can deny the success of Intel on its backward compatibility. Bad for low-level system developers.","title":"Thoughts"},{"location":"notes/linux/linux-x86-fpu/#references","text":"https://unix.stackexchange.com/questions/475956/why-can-the-kernel-not-use-sse-avx-registers-and-instructions 2019 FPU patch: https://lkml.org/lkml/2019/4/3/877","title":"References"},{"location":"notes/rust/rust/","text":"Rust \u00b6 Version History Date Description Nov 5, 2021 Initial I starting to learn Rust again lol. I\u2019m learing Rust and Go at the same time.","title":"Learn Rust"},{"location":"notes/rust/rust/#rust","text":"Version History Date Description Nov 5, 2021 Initial I starting to learn Rust again lol. I\u2019m learing Rust and Go at the same time.","title":"Rust"},{"location":"notes/source_code/20200501-on-graphic-softwares/","text":"On Unix Graphic Softwares \u00b6 Version History Date Description Dec 4, 2020 Add high level libaries May 1, 2020 Initial Version Part I \u00b6 For work reason, I use VNC a lot recently. I need to login into our lab\u2019s servers and perform intensive graphic operations. Somehow I\u2019m not a fan of GUI-based systems, but it really got me wonder: how VNC works? Or, how graphics/GUI works in general? So I decided to look it up. The whole thing was very complex to me at the beginning. There are numerous layers of systems, and it not clear who is doing what. After getting a better understanding, I realize it is \u201cdo one thing and do it well\u201d works at its best: Each layer of the graphic stack is doing what it is supposed to do, nothing more and nothing less. Even though the line blurred over the years (i think), the principle persists. I like it. I\u2019m no where near explaing the whole thing well (still a bit confused myself :)). But you can find awesome references at: 1) Wiki Display Server , 2) Wayland Architecture 3) StackExchange Difference between Xorg and Gnome/KDE/Xfce 4) https://en.wikipedia.org/wiki/Free_and_open-source_graphics_device_driver Following are some figures I drew to show the architecture of all these softwares. In the graphic world, kernel\u2019s involvement is minimal, but a critical one. Kernel mainly need to deliver mouse/keyboard events, render frames via graphic cards, handle network. In other words, kernel provides a mechanism. The policy is left to userspace stacks. At the lowest level, we have Display Manager, or Display Server. Downstream, this layer interact with kernel, i.e., getting keyboard/mouse events from kernel evdev framework, rendering frames via DRM interfaces. Upstream, this layer accepts request from their clients (i.e., the widget layer) and make them happen in real displays. Typical systems at this layer are X.org server and Wayland. They follow the client-server model, communication has a certain protocol and is via socket (I guess?). Next up, is the widget toolkit , or UX library layer. The famous GTK/Qt belong to this layer. What this layer is doing? So this one is a collection of widgets, like buttons, menu, dropdown, i.e., GUI elements. Both GTK/Qt offer a lot such stuff (if you are using GNOME desktop, try run gtk3-widget-factory ). This layer ask the display manager layer (e.g. X.org server) to display stuff. GNOME/KDE are desktop envionment , they present the whole desktop experience, it includes many applications built based on GTK and Qt, respectively. You probably have seen gnome-shell , yup, this is GNOME\u2019s main program. The highest layer is user applications, like Chrome (which by default uses GTK on linux , code on ui/gtk ). All these linux GUI applications, they are usually built on top of either GTK or Qt\u2019s libraries. That being said, if you want to develop GUI-based apps on Linux, chances are, you will use either of the libraries. This is a landscape overview: But how VNC fits into the big picture? In short, VNC sits in the middle between X and GTK/Qt. On one hand, VNC appears as a client of X. On the other, VNC appears as an X server to GTK/Qt. Middleman works at its best lol. There are, however, many different implementation choices. If you have used TigerVNC, which in turn uses Xvnc, its man page says: Xvnc is the X VNC (Virtual Network Computing) server. It is based on a standard X server, but it has a \u201cvirtual\u201d screen rather than a physical one. X applications display themselves on it as if it were a normal X display, but they can only be accessed via a VNC viewer - see vncviewer(1). So Xvnc is really two servers in one. To the applications it is an X server, and to the remote VNC users it is a VNC server. Thus it looks like this with VNC: A machine have multiple such instances, thus multiple virtual and physical display can coexist. And for that, I think it\u2019s all because of the clear separation of layers and good engineering (man, those graphic framebuffer code is monstrous): This post remind me of \u201cWhat happens when you type google.com into your browser and press enter?\u201d ? As always, hope you enjoyed this blog. Part II \u00b6 This part wants to look at those high-level libaries used by developers every day. I somewhat got interested when I started playing Steam games and saw \u201cVulkan Shaders\u201d. Vulkan is an alternative system to OpenCL/Direct3D. Instead of hiding details, Vulkan expose quite a lot low-level details and let programmers do the tuning. So, what\u2019s the difference between Vulkan/OpenCL/Direct3D with gtk/Qt? I guess the former is for graphic development, any shape. While the latter is some predefined gadgets and a framework for developing standadrd GUI apps?","title":"Graphics"},{"location":"notes/source_code/20200501-on-graphic-softwares/#on-unix-graphic-softwares","text":"Version History Date Description Dec 4, 2020 Add high level libaries May 1, 2020 Initial Version","title":"On Unix Graphic Softwares"},{"location":"notes/source_code/20200501-on-graphic-softwares/#part-i","text":"For work reason, I use VNC a lot recently. I need to login into our lab\u2019s servers and perform intensive graphic operations. Somehow I\u2019m not a fan of GUI-based systems, but it really got me wonder: how VNC works? Or, how graphics/GUI works in general? So I decided to look it up. The whole thing was very complex to me at the beginning. There are numerous layers of systems, and it not clear who is doing what. After getting a better understanding, I realize it is \u201cdo one thing and do it well\u201d works at its best: Each layer of the graphic stack is doing what it is supposed to do, nothing more and nothing less. Even though the line blurred over the years (i think), the principle persists. I like it. I\u2019m no where near explaing the whole thing well (still a bit confused myself :)). But you can find awesome references at: 1) Wiki Display Server , 2) Wayland Architecture 3) StackExchange Difference between Xorg and Gnome/KDE/Xfce 4) https://en.wikipedia.org/wiki/Free_and_open-source_graphics_device_driver Following are some figures I drew to show the architecture of all these softwares. In the graphic world, kernel\u2019s involvement is minimal, but a critical one. Kernel mainly need to deliver mouse/keyboard events, render frames via graphic cards, handle network. In other words, kernel provides a mechanism. The policy is left to userspace stacks. At the lowest level, we have Display Manager, or Display Server. Downstream, this layer interact with kernel, i.e., getting keyboard/mouse events from kernel evdev framework, rendering frames via DRM interfaces. Upstream, this layer accepts request from their clients (i.e., the widget layer) and make them happen in real displays. Typical systems at this layer are X.org server and Wayland. They follow the client-server model, communication has a certain protocol and is via socket (I guess?). Next up, is the widget toolkit , or UX library layer. The famous GTK/Qt belong to this layer. What this layer is doing? So this one is a collection of widgets, like buttons, menu, dropdown, i.e., GUI elements. Both GTK/Qt offer a lot such stuff (if you are using GNOME desktop, try run gtk3-widget-factory ). This layer ask the display manager layer (e.g. X.org server) to display stuff. GNOME/KDE are desktop envionment , they present the whole desktop experience, it includes many applications built based on GTK and Qt, respectively. You probably have seen gnome-shell , yup, this is GNOME\u2019s main program. The highest layer is user applications, like Chrome (which by default uses GTK on linux , code on ui/gtk ). All these linux GUI applications, they are usually built on top of either GTK or Qt\u2019s libraries. That being said, if you want to develop GUI-based apps on Linux, chances are, you will use either of the libraries. This is a landscape overview: But how VNC fits into the big picture? In short, VNC sits in the middle between X and GTK/Qt. On one hand, VNC appears as a client of X. On the other, VNC appears as an X server to GTK/Qt. Middleman works at its best lol. There are, however, many different implementation choices. If you have used TigerVNC, which in turn uses Xvnc, its man page says: Xvnc is the X VNC (Virtual Network Computing) server. It is based on a standard X server, but it has a \u201cvirtual\u201d screen rather than a physical one. X applications display themselves on it as if it were a normal X display, but they can only be accessed via a VNC viewer - see vncviewer(1). So Xvnc is really two servers in one. To the applications it is an X server, and to the remote VNC users it is a VNC server. Thus it looks like this with VNC: A machine have multiple such instances, thus multiple virtual and physical display can coexist. And for that, I think it\u2019s all because of the clear separation of layers and good engineering (man, those graphic framebuffer code is monstrous): This post remind me of \u201cWhat happens when you type google.com into your browser and press enter?\u201d ? As always, hope you enjoyed this blog.","title":"Part I"},{"location":"notes/source_code/20200501-on-graphic-softwares/#part-ii","text":"This part wants to look at those high-level libaries used by developers every day. I somewhat got interested when I started playing Steam games and saw \u201cVulkan Shaders\u201d. Vulkan is an alternative system to OpenCL/Direct3D. Instead of hiding details, Vulkan expose quite a lot low-level details and let programmers do the tuning. So, what\u2019s the difference between Vulkan/OpenCL/Direct3D with gtk/Qt? I guess the former is for graphic development, any shape. While the latter is some predefined gadgets and a framework for developing standadrd GUI apps?","title":"Part II"},{"location":"notes/source_code/compilers/","text":"Compilers \u00b6 Version History Date Description Oct 16, 2021 Move compilers section from the summary file The general ones: Clang, LLVM, in C++ This is a collection of projects. Clang is the frontend, compiles C/C++ code into LLVM\u2019s own IR format. The the backend LLVM will take multiple Passes to optimize the IR and the finally generate the assembly. The beauty of Clang and LLVM is that they can be used as libraries, and we could invoke them to manipulate the compilation results, to do source-to-source transforms, modify Pass\u2019s IR etc. I found this super interesting! To get started, I strongly recommend LLVM for Grad Students OpenJDK CPython GNU GCC Rustc, in Rust PHP, in C Google V8, in C++ Apple Swift, in C++ TCL, in C Perl 5, in C Lua, in C Ruby, in C Scala SpinalHDL CPython \u00b6 Today (Oct 14, 201) I was reading Hacker News and came across this post A viable solution for Python concurrency . It was about removing the Global Interpreter Lock (GIL) in the cpython compilers. Quite interesting. The technique is to use Biased Atomic Reference Accounting. Basically, it uses non-atomic operation if it is single-thread so to avoid the cost of atomic instructions. But for multiple thread case, it will normal atomic instructions (which will be much better the original GIL implementation). So I decide to take another look at the cpython source code, which I have cloned ( repo )quite a while ago when I had a broken leg. Once I decided to read the code, I google some cpython internals and these links pop up quite nicely. There are A LOT good contents out there, I probably don\u2019t have time reading that now. I briefly read the code, a lot typedefs for sure. The PyStatus structure is interesting. And the way they organize the repo is also interesting. For a common python library, say csv, there will a python library file under Lib/csv.py , then optionally a C accelerated version in Modules/_csv.c . Essentially the whole thing is built like a Exokernel, the base is written in C for performance and portability among OSes. Then a more rich python wrapper on top of that, which will be the default built-in python libraries we use day-to-day. For those common built-in functions , they are organized here Your Guide to the CPython Source Code Exploring CPython\u2019s Internals Design of CPython\u2019s Compiler Yet another guided tour of CPython Java \u00b6 OpenJDK JRE = JVM + Runtime Classes => JVM is the one parsing the bytecode, along with some extra classes/libraries, they form JRE. JDK = JRE + Development Tools => JDK as in Development Kit therefore consists of some tools in addition to JRE. JDK is a monster collection of resources in one place. The JVM here is called HotSpot , a reference JVM implementation written in C++, Since JDK also has so many runtime support, it has a lot Java code. Personally I haven\u2019t written Java since 2013 or so. Although I\u2019m not using it anytime soon, I\u2019m curious how it performs nowadays. The repo is VERY WELL organized. see src/ HotSpot JVM This one is included in the OpenJDK Repo, written in C++. e.g., the GC code is under src/hotspot/share/gc . Eclipse Openj9 JVM A JVM for OpenJDK that\u2019s optimized for small footprint, fast start-up, and high throughput ASM ASM is an all purpose Java bytecode manipulation and analysis framework. It can be used to modify existing classes or to dynamically generate classes, directly in binary form. All these OpenJDK components follow the Java Language Spec and JVM Spec . An important note: Java is NOT the only language that can run on a JVM. A lot of other languages are using JVM as well! Such as Kotlin, Scala, Clojure etc. I think the reason is that JVM is production-ready and proven to be stable across platforms. If a new language compiles into JVM bytecode, then this new language can instantly run all architectures. Without it, the new language\u2019s compiler needs to emit different ISA\u2019s assembly, which is difficult and quite an effort. JVM-based Languages \u00b6 There is a List of JVM languages : This list of JVM Languages comprises notable computer programming languages that are used to produce computer software that runs on the Java virtual machine (JVM). Some of these languages are interpreted by a Java program, and some are compiled to Java bytecode and JIT-compiled during execution as regular Java programs to improve performance. The most popurlar ones are: 1) Java, 2) Groovy, 3) Scala, 4) Clojure, 5) Kotlin. So follow up on the Java section, I want to spend some time on JVM-based languages, the rationale and benefits behind it, and how should one create a new language on JVM. Great explanation here . JVM is a virtual MACHINE, with its own machine model and ISA. Hence it has assembly instructions and assmeblers (e.g., Jasmin ) compiling annoted assembly into Java class file / bytecode (or binary for the JVM, in some sense). Some people seem to use Java ASM tool to generate bytecode as well. Several blogs I found via google that try to build a new language on top of JVM. There must be more. 1) https://github.com/ftomassetti/LangSandbox , 2) http://jakubdziworski.github.io/categories.html#Enkel-ref","title":"Compilers"},{"location":"notes/source_code/compilers/#compilers","text":"Version History Date Description Oct 16, 2021 Move compilers section from the summary file The general ones: Clang, LLVM, in C++ This is a collection of projects. Clang is the frontend, compiles C/C++ code into LLVM\u2019s own IR format. The the backend LLVM will take multiple Passes to optimize the IR and the finally generate the assembly. The beauty of Clang and LLVM is that they can be used as libraries, and we could invoke them to manipulate the compilation results, to do source-to-source transforms, modify Pass\u2019s IR etc. I found this super interesting! To get started, I strongly recommend LLVM for Grad Students OpenJDK CPython GNU GCC Rustc, in Rust PHP, in C Google V8, in C++ Apple Swift, in C++ TCL, in C Perl 5, in C Lua, in C Ruby, in C Scala SpinalHDL","title":"Compilers"},{"location":"notes/source_code/compilers/#cpython","text":"Today (Oct 14, 201) I was reading Hacker News and came across this post A viable solution for Python concurrency . It was about removing the Global Interpreter Lock (GIL) in the cpython compilers. Quite interesting. The technique is to use Biased Atomic Reference Accounting. Basically, it uses non-atomic operation if it is single-thread so to avoid the cost of atomic instructions. But for multiple thread case, it will normal atomic instructions (which will be much better the original GIL implementation). So I decide to take another look at the cpython source code, which I have cloned ( repo )quite a while ago when I had a broken leg. Once I decided to read the code, I google some cpython internals and these links pop up quite nicely. There are A LOT good contents out there, I probably don\u2019t have time reading that now. I briefly read the code, a lot typedefs for sure. The PyStatus structure is interesting. And the way they organize the repo is also interesting. For a common python library, say csv, there will a python library file under Lib/csv.py , then optionally a C accelerated version in Modules/_csv.c . Essentially the whole thing is built like a Exokernel, the base is written in C for performance and portability among OSes. Then a more rich python wrapper on top of that, which will be the default built-in python libraries we use day-to-day. For those common built-in functions , they are organized here Your Guide to the CPython Source Code Exploring CPython\u2019s Internals Design of CPython\u2019s Compiler Yet another guided tour of CPython","title":"CPython"},{"location":"notes/source_code/compilers/#java","text":"OpenJDK JRE = JVM + Runtime Classes => JVM is the one parsing the bytecode, along with some extra classes/libraries, they form JRE. JDK = JRE + Development Tools => JDK as in Development Kit therefore consists of some tools in addition to JRE. JDK is a monster collection of resources in one place. The JVM here is called HotSpot , a reference JVM implementation written in C++, Since JDK also has so many runtime support, it has a lot Java code. Personally I haven\u2019t written Java since 2013 or so. Although I\u2019m not using it anytime soon, I\u2019m curious how it performs nowadays. The repo is VERY WELL organized. see src/ HotSpot JVM This one is included in the OpenJDK Repo, written in C++. e.g., the GC code is under src/hotspot/share/gc . Eclipse Openj9 JVM A JVM for OpenJDK that\u2019s optimized for small footprint, fast start-up, and high throughput ASM ASM is an all purpose Java bytecode manipulation and analysis framework. It can be used to modify existing classes or to dynamically generate classes, directly in binary form. All these OpenJDK components follow the Java Language Spec and JVM Spec . An important note: Java is NOT the only language that can run on a JVM. A lot of other languages are using JVM as well! Such as Kotlin, Scala, Clojure etc. I think the reason is that JVM is production-ready and proven to be stable across platforms. If a new language compiles into JVM bytecode, then this new language can instantly run all architectures. Without it, the new language\u2019s compiler needs to emit different ISA\u2019s assembly, which is difficult and quite an effort.","title":"Java"},{"location":"notes/source_code/compilers/#jvm-based-languages","text":"There is a List of JVM languages : This list of JVM Languages comprises notable computer programming languages that are used to produce computer software that runs on the Java virtual machine (JVM). Some of these languages are interpreted by a Java program, and some are compiled to Java bytecode and JIT-compiled during execution as regular Java programs to improve performance. The most popurlar ones are: 1) Java, 2) Groovy, 3) Scala, 4) Clojure, 5) Kotlin. So follow up on the Java section, I want to spend some time on JVM-based languages, the rationale and benefits behind it, and how should one create a new language on JVM. Great explanation here . JVM is a virtual MACHINE, with its own machine model and ISA. Hence it has assembly instructions and assmeblers (e.g., Jasmin ) compiling annoted assembly into Java class file / bytecode (or binary for the JVM, in some sense). Some people seem to use Java ASM tool to generate bytecode as well. Several blogs I found via google that try to build a new language on top of JVM. There must be more. 1) https://github.com/ftomassetti/LangSandbox , 2) http://jakubdziworski.github.io/categories.html#Enkel-ref","title":"JVM-based Languages"},{"location":"notes/source_code/dotconfigs/","text":"Dot Configs \u00b6 Version History Date Description Dec 17, 2020 started Like many others, I maintain my own dot-file repo: https://github.com/lastweek/dot-home . It helps me setup the terminal whenever I start using a new machine. I\u2019m a heavy terminal user. For whatever coding task (e.g., kernel, RDMA, FPGA, scala, C), I use terminal. I sometimes use terminal to write paper as well. There are several important tools I rely on: zsh, git, neovim, and tmux. And I\u2019m grateful for folks working on these tools and their plugins. For zsh, I use oh-my-zsh. For git, I use git alias . For tmux, I use tpm . I used to cook status line myself, but I have switched to powerline. For nvim, I use vundle . And I have several cooked keys. VIM \u00b6 I\u2019m using several popular tools: NERD Tree, NERD commenter, GitGutter, and Tagbar. I created the following mapped keys so that I could invoke them quite easily. Basically I press \\ first, and then press t , or f , or g . map \\l :TagbarToggle<Enter> => to toggle tagbar list map \\f :NERDTreeToggle<CR> => to toggle nerd file tree map \\g :GitGutterLineHighlightsToggle<Enter> :GitGutterSignsToggle<Enter> => to highlight git difference Besides, I have several extra syntax files, for C, ASM, scala, and verilog. I started this when I was hacking linux kernel. It has so many new awesome macros (e.g., BUG_ON , for_each_cpu ) and I want to diffrentiate them from normal functions. So I added those after/syntax files. Colorful Man Pages \u00b6 This is one thing I highly recommend. It was always a pain reading man pages, not until I found this trick. We can, in fact, redirect man outputs into vim, which in turn can present the text in a colorway. Add these to your shell dotconfig: vman () { man $* | col -b | vim -c 'set ft=man nomod nolist' - ; } alias man = \"vman\" Git \u00b6 For git, I\u2019m using git alias and a tool call tig. The git alias project has quite a lot shortcuts. Those are my most used ones: g s g l g ll g lll g d g dc g ds","title":"Dot-Configs"},{"location":"notes/source_code/dotconfigs/#dot-configs","text":"Version History Date Description Dec 17, 2020 started Like many others, I maintain my own dot-file repo: https://github.com/lastweek/dot-home . It helps me setup the terminal whenever I start using a new machine. I\u2019m a heavy terminal user. For whatever coding task (e.g., kernel, RDMA, FPGA, scala, C), I use terminal. I sometimes use terminal to write paper as well. There are several important tools I rely on: zsh, git, neovim, and tmux. And I\u2019m grateful for folks working on these tools and their plugins. For zsh, I use oh-my-zsh. For git, I use git alias . For tmux, I use tpm . I used to cook status line myself, but I have switched to powerline. For nvim, I use vundle . And I have several cooked keys.","title":"Dot Configs"},{"location":"notes/source_code/dotconfigs/#vim","text":"I\u2019m using several popular tools: NERD Tree, NERD commenter, GitGutter, and Tagbar. I created the following mapped keys so that I could invoke them quite easily. Basically I press \\ first, and then press t , or f , or g . map \\l :TagbarToggle<Enter> => to toggle tagbar list map \\f :NERDTreeToggle<CR> => to toggle nerd file tree map \\g :GitGutterLineHighlightsToggle<Enter> :GitGutterSignsToggle<Enter> => to highlight git difference Besides, I have several extra syntax files, for C, ASM, scala, and verilog. I started this when I was hacking linux kernel. It has so many new awesome macros (e.g., BUG_ON , for_each_cpu ) and I want to diffrentiate them from normal functions. So I added those after/syntax files.","title":"VIM"},{"location":"notes/source_code/dotconfigs/#colorful-man-pages","text":"This is one thing I highly recommend. It was always a pain reading man pages, not until I found this trick. We can, in fact, redirect man outputs into vim, which in turn can present the text in a colorway. Add these to your shell dotconfig: vman () { man $* | col -b | vim -c 'set ft=man nomod nolist' - ; } alias man = \"vman\"","title":"Colorful Man Pages"},{"location":"notes/source_code/dotconfigs/#git","text":"For git, I\u2019m using git alias and a tool call tig. The git alias project has quite a lot shortcuts. Those are my most used ones: g s g l g ll g lll g d g dc g ds","title":"Git"},{"location":"notes/source_code/firmware-softwares/","text":"Open-source Firmware and Bootloaders \u00b6 Version History Date Description Jun 17, 2021 some reorg Dec 7, 2020 add iPXE May 6, 2020 Initial Version In this blog post, I will review the current firmware and bootloader ecosystem. Note that this is very x86-centric. Landscape \u00b6 (Arrow from A to B means A can run after B. The combination and flow is very flexible.) There are a lot open-source firmware projects. I was trying to understand their relationship. After some research, I drew the above figure. This figure is very x86-centric. Other architecture have other firmwares. Bottom-up: Coreboot/Libreboot/UEFI: for motherboard init, e.g., init memory controller. UEFI/BIOS GRUB2/u-boot/iPXE: Bootloader u-boot implements some UEFI spec as well. OS Stages \u00b6 Stage 0: For some boards, some ROM code gets run first no matter what. Stage 1: coreboot/libreboot/UEFI. One of their major job is to initialize DRAM, processor, and other low level things, prepare HW so that later software can run. Their early stage code must ran from on-chip SRAM/Cache! They will init DRAM so that later firmware/bootloader/OS can use it. Once that is done, they will pass control to later stage software. Stage 2: UEFI/SeaBIOS for x86/OpenSBI for risc-v Those are the firmware in general sense. They will discover hardware, prepare the memory map, prepare device tree, and so on. Essentially, they gather info. Note that, some of them live even after they pass control to OS. E.g., UEFI is also a service that OS can use. Stage 3: U-boot/GRUB/iPXE This is the normal bootloader. Their responsibility is to load the OS kernel. They understand filesystem, network, and other stuff. They are a small OS in some sense. Stage 4: OS You can generally test all these firmware and bootloaders using QEMU. Different distro may choose different bootloaders. Project Details \u00b6 Coreboot and Libreboot Coreboot seems very interesting. It\u2019s only doing one job, which is initialize the very low-level memory controller and on-board resources. It uses cache as memory. We don\u2019t need it on QEMU. Image from here . It shows the Cache-as-RAM v.s. DRAM timeline, the coreboot timline, and where it hands over to next stage. SeaBIOS: the default BIOS used by QEMU This is good code to learn from. SeaBIOS also works on physical machines. qboot: an alternative and lightweight BIOS for QEMU Those are massive hackers, respect. My experience about BIOS is calling them while the kernel (LegoOS) is running at 16-bit. BIOS is the OS for a just-booted kernel. I remember the lower 1MB is never cleared, maybe we could invoke the BIOS at 32 or 64-bit mode? u-boot Generally u-boot is used as the primary bootloader after BIOS. But u-boot is much more. Based on its description, it can init HW just like coreboot. Besides, it also provides some UEFI interfaces. So a mix of different things. u-boot is used by Chromebook. UEFI UEFI EDK II \u201cEDK II is a firmware development environment for the UEFI and UEFI Platform Initialization (PI) specifications\u201d Part of the TianoCore project, an open-source UEFI platform The Unified Extensible Firmware Interface (UEFI) is a specification that defines a software interface between an operating system and platform firmware. UEFI is designed to replace the Basic Input/Output System (BIOS) firmware interface. OVMF : OVMF is an EDK II based project to enable UEFI support for Virtual Machines. OVMF contains sample UEFI firmware for QEMU and KVM. Microsoft Project Mu, a separate fork of EDK II \u201cProject Mu is a modular adaptation of TianoCore\u2019s edk2 tuned for building modern devices using a scalable, maintainable, and reusable pattern\u201d It\u2019s homepage explains the motivation behind it. Microsoft Surface is using it. A book: Beyond BIOS Developing with the Unified Extensible Firmware Interface . Then boot loaders such as GRUB and U-Boot iPXE , network bootloader, this is an open-source version. As their website says, iPXE allows you to: boot from a web server via HTTP boot from an iSCSI SAN boot from a Fibre Channel SAN via FCoE boot from an AoE SAN boot from a wireless network boot from a wide-area network boot from an Infiniband network control the boot process with a script LinuxBoot Use Linux as the firmware, directly runs after HW is initialized (e.g., after coreboot). If you are using a normal laptop or desktop, chances are, none of those firmware is used. Normally machines are shipped with commercial firmwares. To me, I like SeaBIOS project the most. It\u2019s simple and can boot everything we need. (For example, Linux, LegoOS as well). Thoughts \u00b6 I\u2019ve read most of the project source code. I do find a lot redundant code/steps. A lot of them will do some initial setup, do hardware probe etc. Device Tree \u00b6 There is a device tree specification . Quote A DTSpec-compliant devicetree describes device information in a system that cannot necessarily be dynamically detected by a client program. For example, the architecture of PCI enables a client to probe and detect attached devices, and thus devicetree nodes describing PCI devices might not be required. However, a device node is required to describe a PCI host bridge device in the system if it cannot be detected by probing. ==> So it is intended for devices that cannot be dynamically probed. Devices like PCIe that could be probed shouldn\u2019t be included in a device tree.","title":"Firmware & Bootloader"},{"location":"notes/source_code/firmware-softwares/#open-source-firmware-and-bootloaders","text":"Version History Date Description Jun 17, 2021 some reorg Dec 7, 2020 add iPXE May 6, 2020 Initial Version In this blog post, I will review the current firmware and bootloader ecosystem. Note that this is very x86-centric.","title":"Open-source Firmware and Bootloaders"},{"location":"notes/source_code/firmware-softwares/#landscape","text":"(Arrow from A to B means A can run after B. The combination and flow is very flexible.) There are a lot open-source firmware projects. I was trying to understand their relationship. After some research, I drew the above figure. This figure is very x86-centric. Other architecture have other firmwares. Bottom-up: Coreboot/Libreboot/UEFI: for motherboard init, e.g., init memory controller. UEFI/BIOS GRUB2/u-boot/iPXE: Bootloader u-boot implements some UEFI spec as well. OS","title":"Landscape"},{"location":"notes/source_code/firmware-softwares/#stages","text":"Stage 0: For some boards, some ROM code gets run first no matter what. Stage 1: coreboot/libreboot/UEFI. One of their major job is to initialize DRAM, processor, and other low level things, prepare HW so that later software can run. Their early stage code must ran from on-chip SRAM/Cache! They will init DRAM so that later firmware/bootloader/OS can use it. Once that is done, they will pass control to later stage software. Stage 2: UEFI/SeaBIOS for x86/OpenSBI for risc-v Those are the firmware in general sense. They will discover hardware, prepare the memory map, prepare device tree, and so on. Essentially, they gather info. Note that, some of them live even after they pass control to OS. E.g., UEFI is also a service that OS can use. Stage 3: U-boot/GRUB/iPXE This is the normal bootloader. Their responsibility is to load the OS kernel. They understand filesystem, network, and other stuff. They are a small OS in some sense. Stage 4: OS You can generally test all these firmware and bootloaders using QEMU. Different distro may choose different bootloaders.","title":"Stages"},{"location":"notes/source_code/firmware-softwares/#project-details","text":"Coreboot and Libreboot Coreboot seems very interesting. It\u2019s only doing one job, which is initialize the very low-level memory controller and on-board resources. It uses cache as memory. We don\u2019t need it on QEMU. Image from here . It shows the Cache-as-RAM v.s. DRAM timeline, the coreboot timline, and where it hands over to next stage. SeaBIOS: the default BIOS used by QEMU This is good code to learn from. SeaBIOS also works on physical machines. qboot: an alternative and lightweight BIOS for QEMU Those are massive hackers, respect. My experience about BIOS is calling them while the kernel (LegoOS) is running at 16-bit. BIOS is the OS for a just-booted kernel. I remember the lower 1MB is never cleared, maybe we could invoke the BIOS at 32 or 64-bit mode? u-boot Generally u-boot is used as the primary bootloader after BIOS. But u-boot is much more. Based on its description, it can init HW just like coreboot. Besides, it also provides some UEFI interfaces. So a mix of different things. u-boot is used by Chromebook. UEFI UEFI EDK II \u201cEDK II is a firmware development environment for the UEFI and UEFI Platform Initialization (PI) specifications\u201d Part of the TianoCore project, an open-source UEFI platform The Unified Extensible Firmware Interface (UEFI) is a specification that defines a software interface between an operating system and platform firmware. UEFI is designed to replace the Basic Input/Output System (BIOS) firmware interface. OVMF : OVMF is an EDK II based project to enable UEFI support for Virtual Machines. OVMF contains sample UEFI firmware for QEMU and KVM. Microsoft Project Mu, a separate fork of EDK II \u201cProject Mu is a modular adaptation of TianoCore\u2019s edk2 tuned for building modern devices using a scalable, maintainable, and reusable pattern\u201d It\u2019s homepage explains the motivation behind it. Microsoft Surface is using it. A book: Beyond BIOS Developing with the Unified Extensible Firmware Interface . Then boot loaders such as GRUB and U-Boot iPXE , network bootloader, this is an open-source version. As their website says, iPXE allows you to: boot from a web server via HTTP boot from an iSCSI SAN boot from a Fibre Channel SAN via FCoE boot from an AoE SAN boot from a wireless network boot from a wide-area network boot from an Infiniband network control the boot process with a script LinuxBoot Use Linux as the firmware, directly runs after HW is initialized (e.g., after coreboot). If you are using a normal laptop or desktop, chances are, none of those firmware is used. Normally machines are shipped with commercial firmwares. To me, I like SeaBIOS project the most. It\u2019s simple and can boot everything we need. (For example, Linux, LegoOS as well).","title":"Project Details"},{"location":"notes/source_code/firmware-softwares/#thoughts","text":"I\u2019ve read most of the project source code. I do find a lot redundant code/steps. A lot of them will do some initial setup, do hardware probe etc.","title":"Thoughts"},{"location":"notes/source_code/firmware-softwares/#device-tree","text":"There is a device tree specification . Quote A DTSpec-compliant devicetree describes device information in a system that cannot necessarily be dynamically detected by a client program. For example, the architecture of PCI enables a client to probe and detect attached devices, and thus devicetree nodes describing PCI devices might not be required. However, a device node is required to describe a PCI host bridge device in the system if it cannot be detected by probing. ==> So it is intended for devices that cannot be dynamically probed. Devices like PCIe that could be probed shouldn\u2019t be included in a device tree.","title":"Device Tree"},{"location":"notes/source_code/fpga/","text":"FPGA \u00b6 What is HDL? Hard and Difficult Language. :) This page reflects on various FPGA projects I came across. Code \u00b6 Tools \u00b6 Languages SpinalHDL Chisel Google XLS Simulators Verilator iVerilog Misc cocotb MyHDL gtkwave Network \u00b6 Alex Forencich\u2019s Verilog Ethernet This repo includes Ethernet PHY, MAC, IP, and UDP layer IPs. It works on various boards. THE BEST choice if you are trying to connect your board to network. Written in Verilog Alex Forencich\u2019s Corundum NIC This repo is a full-fledged NIC implementation including the above Verilog-Ethernet part, DMA engines, PCIe controller, interrupts, and so on. A NIC has more features than a basic FPGA Ethenet solution. You need a NIC if you are working with host softwares, otherwise you should consider using the verilog-ethernet version. Written in Verilog TCP/IP, RoCEv2 from ETH There are several papers published using this repo. It provides the basic TCP/IP and RoCE v2 stack (StRom, EuroSys\u201819). Personally I haven\u2019t used this repo so I don\u2019t have any comments. Written in Xilinx HLS. Memory \u00b6 TODO. Partial Reconfiguration \u00b6 TODO. Soft Cores \u00b6 VexRiscv, based on SpinalHDL ZipCPU, RISC CPU, written in Verilog OpenPOWER a2i and a2o MISC \u00b6 OpenWIFI NyuziProcessor, a GPGPU Processor HDMI FPGACosmacELF, based on SpinalHDL My Story with FPGA \u00b6 Back at late 2018, I started using FPGA to do datacenter research. More specific, we used FPGA to build a disaggregated memory component, which was intended as a follow-up to our prior work LegoOS, OSDI\u201818. Along the way, our idea spin-off a bit. I started looking into building an real OS into FPGA: we tried to build sched (temporal and spacial), mm , net , and various OS functionalties into FPGA (more than a traditional FPGA shell, and other FPGA OSs that a lot of acadamic papers claim!). This experiences enriched me with all sorts of low-level FPGA knowledge. I spent quit a lot of time digging into partial reconfiguration and various hacks to avoid its limitations (see Bitstream Explained , Morphous PR , Ultrascale SSI ). This FPGA OS project did not go well and we decided to suspend it.","title":"FPGA"},{"location":"notes/source_code/fpga/#fpga","text":"What is HDL? Hard and Difficult Language. :) This page reflects on various FPGA projects I came across.","title":"FPGA"},{"location":"notes/source_code/fpga/#code","text":"","title":"Code"},{"location":"notes/source_code/fpga/#tools","text":"Languages SpinalHDL Chisel Google XLS Simulators Verilator iVerilog Misc cocotb MyHDL gtkwave","title":"Tools"},{"location":"notes/source_code/fpga/#network","text":"Alex Forencich\u2019s Verilog Ethernet This repo includes Ethernet PHY, MAC, IP, and UDP layer IPs. It works on various boards. THE BEST choice if you are trying to connect your board to network. Written in Verilog Alex Forencich\u2019s Corundum NIC This repo is a full-fledged NIC implementation including the above Verilog-Ethernet part, DMA engines, PCIe controller, interrupts, and so on. A NIC has more features than a basic FPGA Ethenet solution. You need a NIC if you are working with host softwares, otherwise you should consider using the verilog-ethernet version. Written in Verilog TCP/IP, RoCEv2 from ETH There are several papers published using this repo. It provides the basic TCP/IP and RoCE v2 stack (StRom, EuroSys\u201819). Personally I haven\u2019t used this repo so I don\u2019t have any comments. Written in Xilinx HLS.","title":"Network"},{"location":"notes/source_code/fpga/#memory","text":"TODO.","title":"Memory"},{"location":"notes/source_code/fpga/#partial-reconfiguration","text":"TODO.","title":"Partial Reconfiguration"},{"location":"notes/source_code/fpga/#soft-cores","text":"VexRiscv, based on SpinalHDL ZipCPU, RISC CPU, written in Verilog OpenPOWER a2i and a2o","title":"Soft Cores"},{"location":"notes/source_code/fpga/#misc","text":"OpenWIFI NyuziProcessor, a GPGPU Processor HDMI FPGACosmacELF, based on SpinalHDL","title":"MISC"},{"location":"notes/source_code/fpga/#my-story-with-fpga","text":"Back at late 2018, I started using FPGA to do datacenter research. More specific, we used FPGA to build a disaggregated memory component, which was intended as a follow-up to our prior work LegoOS, OSDI\u201818. Along the way, our idea spin-off a bit. I started looking into building an real OS into FPGA: we tried to build sched (temporal and spacial), mm , net , and various OS functionalties into FPGA (more than a traditional FPGA shell, and other FPGA OSs that a lot of acadamic papers claim!). This experiences enriched me with all sorts of low-level FPGA knowledge. I spent quit a lot of time digging into partial reconfiguration and various hacks to avoid its limitations (see Bitstream Explained , Morphous PR , Ultrascale SSI ). This FPGA OS project did not go well and we decided to suspend it.","title":"My Story with FPGA"},{"location":"notes/source_code/gpu/","text":"GPU \u00b6 For research purpose, I started digging into GPU for the first time. Spent some time just learning the basics. And for now just want to know how large systems are using GPUs, esp. CUDA. Just get a basic sense. Systems \u00b6 tensorflow CUDA: tensorflow/core/common_runtime/gpu quite complicated. tvm CUDA: src/runtime/cuda OpenCL: src/runtime/opencl both seem quite small. And they have documentation: https://tvm.apache.org/docs/dev/codebase_walkthrough.html?highlight=cuda . Hooray! pytorch and caffee2 CUDA: over all the places. well. nvidia cuda samples","title":"GPU"},{"location":"notes/source_code/gpu/#gpu","text":"For research purpose, I started digging into GPU for the first time. Spent some time just learning the basics. And for now just want to know how large systems are using GPUs, esp. CUDA. Just get a basic sense.","title":"GPU"},{"location":"notes/source_code/gpu/#systems","text":"tensorflow CUDA: tensorflow/core/common_runtime/gpu quite complicated. tvm CUDA: src/runtime/cuda OpenCL: src/runtime/opencl both seem quite small. And they have documentation: https://tvm.apache.org/docs/dev/codebase_walkthrough.html?highlight=cuda . Hooray! pytorch and caffee2 CUDA: over all the places. well. nvidia cuda samples","title":"Systems"},{"location":"notes/source_code/misc/","text":"Misc \u00b6 EDB Debugger \u00b6 https://github.com/eteran/edb-debugger Blender \u00b6 The 3D creation suit. https://github.com/blender/blender","title":"Misc"},{"location":"notes/source_code/misc/#misc","text":"","title":"Misc"},{"location":"notes/source_code/misc/#edb-debugger","text":"https://github.com/eteran/edb-debugger","title":"EDB Debugger"},{"location":"notes/source_code/misc/#blender","text":"The 3D creation suit. https://github.com/blender/blender","title":"Blender"},{"location":"notes/source_code/os/","text":"Operating Systems \u00b6 Version History Date Description Oct 26, 2021 Add the Mach family references Dec 18, 2020 extracted from the summary doc My personal interest in CS starts from OS. I started by writing my own OS, it was such a rewarding and joyful journey. Since then, I\u2019m hooked with any OS related projects. This page, is my attempt to document the well-known and less well-known OSes. This list is not meant to be complete, a lot of acedemic OS papers are not mentioned here. This awsome-os has a more complete list. Mainstream \u00b6 Linux 0.0.1 This is the first linux source code released by Linus. Despite several designs are static or obsolete from today\u2019s point of view, it showcases a simple and elegant solution. Plan 9 OS Legendary OS. So many systems are influended by Plan 9 (e.g., Go, gVisor) illumos , a fork of the Oracle Solaris OS. seL4 Microkernel Mach Family Mach 3.0 the last version from CMU. Code in Github . GNU Mach and GNU Hurd MacOS Darwin XNU BSD Family BSD releases all the companion software packages along with the kernel. So there is a tighter relation between them. If you ever wondered how XXX is done, or how to get YYY from OS, this is where you can look into. FreeBSD OpenBSD NetBSD TrueOS Unikernel OSv. A lightweight unikernel. IncludeOS Rumprun Solo5. Unikernel as processes! Google Fuchsia TODO. (Image source: https://commons.wikimedia.org/wiki/File:Unix_timeline.en.svg ) Hobby \u00b6 Visopsys \u201cIt features a simple but functional graphical interface, pre-emptive multitasking, and virtual memory\u201d BootOS Academic \u00b6 Singularity. A research OS from MSR. Very interesting one. It leverages certain PL features to write secure and dependable OS. It also allows verification. It never landed as a commercial one, but it does inspire certain follow-up works. Several old research OSes have also used certain language features to carry out security measures (e.g., V++). MIT Corey I think the code itself is based on jos. Linux Distribution \u00b6 Ever thought about how to go from Linux Kernel to a full Linux Distribution? Read: Linux From Scratch systemd","title":"Operating System"},{"location":"notes/source_code/os/#operating-systems","text":"Version History Date Description Oct 26, 2021 Add the Mach family references Dec 18, 2020 extracted from the summary doc My personal interest in CS starts from OS. I started by writing my own OS, it was such a rewarding and joyful journey. Since then, I\u2019m hooked with any OS related projects. This page, is my attempt to document the well-known and less well-known OSes. This list is not meant to be complete, a lot of acedemic OS papers are not mentioned here. This awsome-os has a more complete list.","title":"Operating Systems"},{"location":"notes/source_code/os/#mainstream","text":"Linux 0.0.1 This is the first linux source code released by Linus. Despite several designs are static or obsolete from today\u2019s point of view, it showcases a simple and elegant solution. Plan 9 OS Legendary OS. So many systems are influended by Plan 9 (e.g., Go, gVisor) illumos , a fork of the Oracle Solaris OS. seL4 Microkernel Mach Family Mach 3.0 the last version from CMU. Code in Github . GNU Mach and GNU Hurd MacOS Darwin XNU BSD Family BSD releases all the companion software packages along with the kernel. So there is a tighter relation between them. If you ever wondered how XXX is done, or how to get YYY from OS, this is where you can look into. FreeBSD OpenBSD NetBSD TrueOS Unikernel OSv. A lightweight unikernel. IncludeOS Rumprun Solo5. Unikernel as processes! Google Fuchsia TODO. (Image source: https://commons.wikimedia.org/wiki/File:Unix_timeline.en.svg )","title":"Mainstream"},{"location":"notes/source_code/os/#hobby","text":"Visopsys \u201cIt features a simple but functional graphical interface, pre-emptive multitasking, and virtual memory\u201d BootOS","title":"Hobby"},{"location":"notes/source_code/os/#academic","text":"Singularity. A research OS from MSR. Very interesting one. It leverages certain PL features to write secure and dependable OS. It also allows verification. It never landed as a commercial one, but it does inspire certain follow-up works. Several old research OSes have also used certain language features to carry out security measures (e.g., V++). MIT Corey I think the code itself is based on jos.","title":"Academic"},{"location":"notes/source_code/os/#linux-distribution","text":"Ever thought about how to go from Linux Kernel to a full Linux Distribution? Read: Linux From Scratch systemd","title":"Linux Distribution"},{"location":"notes/source_code/rdma/","text":"On DPDK and RDMA Related Software \u00b6 Version History Date Description Feb 16, 2021 Some updates on Mellanox RDMA NICs Dec 14, 2020 More on DPDK May 28, 2020 Copied from summary This note mainly talks about how DPDK interacts with RDMA (libibverbs), and how libibverbs communicates with the kernel. I document some misc things about RDMA as well. RDMA NIC Latest Updates \u00b6 I sometimes read the MLNX_OFED to track the latest changes introduced in RDMA NICs. They are not sorted chronologically. Advanced Transport This section talks about XRC and Dynamically Connected Transport (DCT). Those are not new, they have been around for some time. I\u2019m really not sure whether anyone is using them. The RDMA scalability issue stems from the stateful RDMA QP/MR and limited on-chip SRAM cache. Many prior work tried to address them. The latest work in this space are: FLOCK, SOSP\u201821 that multiplex QPs in SW; LITE, SOSP\u201817; FaRM/FaSST/etc. Mellanox Zero Touch RoCE . Came across a thing called Zero Touch RoCE, looks like it essentially is RoCE w/o PFC. Based on the description, ConnectX-6 is actually using Selective Transmission to handle lossy RoCE! Wow, a lot of changes made to the CC algorithm. Apparently, they must be. So in all, they changed the retranmission mechanism and CC (the whole transport) to make RDMA NIC work with lossy links (i.e., no PFC). This seems a milestone to me. Out-of-Order (OOO) Data Placement Interesting. So they now will not drop out-of-sequence/order packets. This of course is not their original Go-Back-N retranmission protocol, but this mechanism works well with data center multi-path routing (e.g., ECMP) and helps improve network utilization. Looks like that this technique, along with the above Zero Touch RoCE, essentially transforms the original Go-Back-N based RDMA transport that best to work with PFC, into one that is Selective Retransmission-based and can work w/o lossless link layer. This is of course not impossible and not difficult. In their OOO placement scheme, they can directly move OoO packets into host DRAM without even caching them in on-chip memory/cache (not possible!). So the cost is really minimal, maybe a set of bitmaps. They probably use techniques in the IRN, SIGCOMM\u201819 paper to track the not-fully-received msgs. The end result is nice. The RDMA NIC can now get rid of its reliance on lossless link layer (IB or PFC-based Ethernet). So many PFC issues can be avoided if you are using RoCE. Just like the IRN paper mentioned, eventually, the iWRAP choice wins. Device Memory Programming (Thank you Stew for pointing me to this feature. It is used in the Sherman, SIGMOD\u201822 paper) The RDMA NIC on-device memory is exposed to user applications. RDMA verbs can directly access them. This avoids the PCIe trips to main memory. Great performance indeed. But I\u2019m not sure how large it is and how to properly manage it. Do note that it is quite easy for any FPGA-based SmartNICs to have this sort of feature implemented. DPDK and RDMA \u00b6 DPDK leverages VFIO to be able to directly access physical devices in the user space. Note that QEMU/Firecracker also use VFIO to directly assign devices to guest OSes (i.e., device passthrough mode). Although both DPDK and RDMA\u2019s data path bypass kernel, their control path are very different from each other. For most NIC drivers in DPDK, there are completely self-contained device drivers in the user space, and these drivers can directly communicate with the hardware device via MMIO (all possible thanks to VFIO). Specifically, once DPDK has done some VFIO ioctls, all data and control path can bypass kernel. Nice, right\uff1f However, for the rdma-core , a lot of the control-path IB verbs (e.g., create_pd , create_cq ) still communicate with the kernel via ioctl calls on Infiniband related device files. On the kernel side, the in-kernel uverb hanlders are located in drivers/infiniband/core/uverbs.c . Do note that this is a quite complicated way to build communicatation channels between user and kernel space, although it is quite efficient. This simple framework is used by several other kernel subsystems, such as io_uring . In details, the control verbs mmap some pages between user and kernel, then all the following data path IB verbs (e.g., post_send ) could just bypass kernel and talk to the device via MMIO directly. Though rdma-core also has some vendor-specific \u201cdrivers\u201d, this is really different from the above DPDK\u2019s userspace PCIe driver. Userspace \u201crdma-core\u201d vendor-driver deals with the kernel devel vendor-level driver details (same for the ones inside DPDK). FWIW, if you are using a Mellanox VPI card in Ethernet mode (e.g. CX3-5), DPDK will use its built-in mlx driver, which further use libibverbs, which further relies on kernel IB stack. It\u2019s not a complete user solution somehow. Note that DPDK built-in mlx driver uses RAW_PACKET QPs. DPDK Internal \u00b6 Top-down: The user-facing part is called Envionmemt Abstraction Layer (EAL) , which provides a set of portable interfaces among many OSes. We can think it of as a \u201cPOSIX\u201d interface. This EAL has quite a lot useful and handy APIs, e.g., multicore support where you can call a function on arbitray cores (like the linux on_each_cpu core), timers, atomic operations, memory management APIs. I have built all these components myself, still very pleased to see this. Poll Mode Driver - we cover the mlx ones above Various other drivers RDMA \u00b6 Below is a list of RDMA-based systems I have used or the ones I think are useful. For RDMA programming tricks, see this seminal work: Design Guidelines for High Performance RDMA Systems, ATC\u201816 Mellanox libvma An userspace IB verbs based layer providing POSIX socket APIs. (The SocketDirect, SIGCOMM\u201819 paper was building a similar thing). verbs perftest The collection contains a set of bandwidth and latency benchmark such as: Send - ib_send_bw and ib_send_lat RDMA Read - ib_read_bw and ib_read_lat RDMA Write - ib_write_bw and ib_wriet_lat RDMA Atomic - ib_atomic_bw and ib_atomic_lat Native Ethernet (when working with MOFED2) - raw_ethernet_bw , raw_ethernet_lat rdma-core This is the core userspace IB verbs library (e.g., libibverbs). Whenever you are writing userspace RDMA applications, you are using this library. It is interesting to learn how userspace IB layer communicates with kernel. It is using ioctl() and mmap() to do the trick, quite standard. Not sure how io_uring would help here. The ABI interface (i.e., data structures) are quite complex and has several versions. libibverbs/example asyncwatch.c device_list.c devinfo.c pingpong.c rc_pingpong.c srq_pingpong.c uc_pingpong.c ud_pingpong.c xsrq_pingpong.c infiniband-diags ibv_devinfo iblinkinfo ibping ibaddr Kernel Infiniband stack RPC gRPC eRPC, NSDI\u201819","title":"DPDK and RDMA"},{"location":"notes/source_code/rdma/#on-dpdk-and-rdma-related-software","text":"Version History Date Description Feb 16, 2021 Some updates on Mellanox RDMA NICs Dec 14, 2020 More on DPDK May 28, 2020 Copied from summary This note mainly talks about how DPDK interacts with RDMA (libibverbs), and how libibverbs communicates with the kernel. I document some misc things about RDMA as well.","title":"On DPDK and RDMA Related Software"},{"location":"notes/source_code/rdma/#rdma-nic-latest-updates","text":"I sometimes read the MLNX_OFED to track the latest changes introduced in RDMA NICs. They are not sorted chronologically. Advanced Transport This section talks about XRC and Dynamically Connected Transport (DCT). Those are not new, they have been around for some time. I\u2019m really not sure whether anyone is using them. The RDMA scalability issue stems from the stateful RDMA QP/MR and limited on-chip SRAM cache. Many prior work tried to address them. The latest work in this space are: FLOCK, SOSP\u201821 that multiplex QPs in SW; LITE, SOSP\u201817; FaRM/FaSST/etc. Mellanox Zero Touch RoCE . Came across a thing called Zero Touch RoCE, looks like it essentially is RoCE w/o PFC. Based on the description, ConnectX-6 is actually using Selective Transmission to handle lossy RoCE! Wow, a lot of changes made to the CC algorithm. Apparently, they must be. So in all, they changed the retranmission mechanism and CC (the whole transport) to make RDMA NIC work with lossy links (i.e., no PFC). This seems a milestone to me. Out-of-Order (OOO) Data Placement Interesting. So they now will not drop out-of-sequence/order packets. This of course is not their original Go-Back-N retranmission protocol, but this mechanism works well with data center multi-path routing (e.g., ECMP) and helps improve network utilization. Looks like that this technique, along with the above Zero Touch RoCE, essentially transforms the original Go-Back-N based RDMA transport that best to work with PFC, into one that is Selective Retransmission-based and can work w/o lossless link layer. This is of course not impossible and not difficult. In their OOO placement scheme, they can directly move OoO packets into host DRAM without even caching them in on-chip memory/cache (not possible!). So the cost is really minimal, maybe a set of bitmaps. They probably use techniques in the IRN, SIGCOMM\u201819 paper to track the not-fully-received msgs. The end result is nice. The RDMA NIC can now get rid of its reliance on lossless link layer (IB or PFC-based Ethernet). So many PFC issues can be avoided if you are using RoCE. Just like the IRN paper mentioned, eventually, the iWRAP choice wins. Device Memory Programming (Thank you Stew for pointing me to this feature. It is used in the Sherman, SIGMOD\u201822 paper) The RDMA NIC on-device memory is exposed to user applications. RDMA verbs can directly access them. This avoids the PCIe trips to main memory. Great performance indeed. But I\u2019m not sure how large it is and how to properly manage it. Do note that it is quite easy for any FPGA-based SmartNICs to have this sort of feature implemented.","title":"RDMA NIC Latest Updates"},{"location":"notes/source_code/rdma/#dpdk-and-rdma","text":"DPDK leverages VFIO to be able to directly access physical devices in the user space. Note that QEMU/Firecracker also use VFIO to directly assign devices to guest OSes (i.e., device passthrough mode). Although both DPDK and RDMA\u2019s data path bypass kernel, their control path are very different from each other. For most NIC drivers in DPDK, there are completely self-contained device drivers in the user space, and these drivers can directly communicate with the hardware device via MMIO (all possible thanks to VFIO). Specifically, once DPDK has done some VFIO ioctls, all data and control path can bypass kernel. Nice, right\uff1f However, for the rdma-core , a lot of the control-path IB verbs (e.g., create_pd , create_cq ) still communicate with the kernel via ioctl calls on Infiniband related device files. On the kernel side, the in-kernel uverb hanlders are located in drivers/infiniband/core/uverbs.c . Do note that this is a quite complicated way to build communicatation channels between user and kernel space, although it is quite efficient. This simple framework is used by several other kernel subsystems, such as io_uring . In details, the control verbs mmap some pages between user and kernel, then all the following data path IB verbs (e.g., post_send ) could just bypass kernel and talk to the device via MMIO directly. Though rdma-core also has some vendor-specific \u201cdrivers\u201d, this is really different from the above DPDK\u2019s userspace PCIe driver. Userspace \u201crdma-core\u201d vendor-driver deals with the kernel devel vendor-level driver details (same for the ones inside DPDK). FWIW, if you are using a Mellanox VPI card in Ethernet mode (e.g. CX3-5), DPDK will use its built-in mlx driver, which further use libibverbs, which further relies on kernel IB stack. It\u2019s not a complete user solution somehow. Note that DPDK built-in mlx driver uses RAW_PACKET QPs.","title":"DPDK and RDMA"},{"location":"notes/source_code/rdma/#dpdk-internal","text":"Top-down: The user-facing part is called Envionmemt Abstraction Layer (EAL) , which provides a set of portable interfaces among many OSes. We can think it of as a \u201cPOSIX\u201d interface. This EAL has quite a lot useful and handy APIs, e.g., multicore support where you can call a function on arbitray cores (like the linux on_each_cpu core), timers, atomic operations, memory management APIs. I have built all these components myself, still very pleased to see this. Poll Mode Driver - we cover the mlx ones above Various other drivers","title":"DPDK Internal"},{"location":"notes/source_code/rdma/#rdma","text":"Below is a list of RDMA-based systems I have used or the ones I think are useful. For RDMA programming tricks, see this seminal work: Design Guidelines for High Performance RDMA Systems, ATC\u201816 Mellanox libvma An userspace IB verbs based layer providing POSIX socket APIs. (The SocketDirect, SIGCOMM\u201819 paper was building a similar thing). verbs perftest The collection contains a set of bandwidth and latency benchmark such as: Send - ib_send_bw and ib_send_lat RDMA Read - ib_read_bw and ib_read_lat RDMA Write - ib_write_bw and ib_wriet_lat RDMA Atomic - ib_atomic_bw and ib_atomic_lat Native Ethernet (when working with MOFED2) - raw_ethernet_bw , raw_ethernet_lat rdma-core This is the core userspace IB verbs library (e.g., libibverbs). Whenever you are writing userspace RDMA applications, you are using this library. It is interesting to learn how userspace IB layer communicates with kernel. It is using ioctl() and mmap() to do the trick, quite standard. Not sure how io_uring would help here. The ABI interface (i.e., data structures) are quite complex and has several versions. libibverbs/example asyncwatch.c device_list.c devinfo.c pingpong.c rc_pingpong.c srq_pingpong.c uc_pingpong.c ud_pingpong.c xsrq_pingpong.c infiniband-diags ibv_devinfo iblinkinfo ibping ibaddr Kernel Infiniband stack RPC gRPC eRPC, NSDI\u201819","title":"RDMA"},{"location":"notes/source_code/risc-v/","text":"Explore RISC-V \u00b6 Version History Date Description Jun 17, 2021 Initial Architecture \u00b6 First of all, explore its architecture designs, such as ISA, virtual memory, virtualization support, devices, and so on. At the time of writing, RISC-V\u2019s hypervisor extension has not been defined yet (hence not IOMMU as well). ISA VM Virtualization I/O, I/O MMU Firmware/Bootloader \u00b6 This section discuss the boot flow and the firmware status. RISC-V has been ported to most of the major firmware and bootloaders, e.g., coreboot (first-stage-bootloader, prepare RAM), UEFI, U-Boot. RISC-V has a cleaner design compared to X86. Rather than relying on messed up ACPI interfaces, it relys on a layer defined by SBI (an open-source implementation called OpenSBI). The OpenSBI layer sits in Machine-Mode, i.e., the most priviledged mode. It directly manages hardware and exposes standard APIs to upperlayer OS. For example, it exposed send_IPI , reset APIs. Hence, in Linux, it could simply call SBI to send IPI rather than implementing on its own and concerns about hardware details. I like this separation of concerns. OpenSBI \u00b6 OpenSBI . This is the default firmware in QEMU for RISC-V. It replaces the old BBL. This one runs after ROM and coreboot (if any). This one will discover/probe hardware (I suppose). After that, it passes control to normal bootloaders like u-boot or GRUB, or just to linux kernel. Code Study \u00b6 firmware/fw_base.S is the entry point. mostly doing the usual, setting up envionment for C functions. It will save some critical information into a struct passed to C. In the end, it will call into C sbi_init(struct sbi_scratch *) . Note the sbi_scratch structure is filled with crutial info by fw_base.S. It seems every hart will do the same? lib/sbi/sbi_init.c is the C entry point after assembly. Reset: - See sbi_system.c and sbi_ipi.c . It looks like the reset is: send an IPI to target HART, which will then ran a sbi_ipi_process_halt handler to halt. - Is this warm or cold reboot? Or neither? Scripts \u00b6 make V = 1 CROSS_COMPILE = riscv64-linux-gnu- PLATFORM = generic FW_PAYLOAD_PATH = ../linux/arch/riscv/boot/Image QEMU \u00b6 Code in hw/riscv/ , hw/intc/*_clint_* . Kernel \u00b6 Toolchain \u00b6","title":"RISC-V"},{"location":"notes/source_code/risc-v/#explore-risc-v","text":"Version History Date Description Jun 17, 2021 Initial","title":"Explore RISC-V"},{"location":"notes/source_code/risc-v/#architecture","text":"First of all, explore its architecture designs, such as ISA, virtual memory, virtualization support, devices, and so on. At the time of writing, RISC-V\u2019s hypervisor extension has not been defined yet (hence not IOMMU as well). ISA VM Virtualization I/O, I/O MMU","title":"Architecture"},{"location":"notes/source_code/risc-v/#firmwarebootloader","text":"This section discuss the boot flow and the firmware status. RISC-V has been ported to most of the major firmware and bootloaders, e.g., coreboot (first-stage-bootloader, prepare RAM), UEFI, U-Boot. RISC-V has a cleaner design compared to X86. Rather than relying on messed up ACPI interfaces, it relys on a layer defined by SBI (an open-source implementation called OpenSBI). The OpenSBI layer sits in Machine-Mode, i.e., the most priviledged mode. It directly manages hardware and exposes standard APIs to upperlayer OS. For example, it exposed send_IPI , reset APIs. Hence, in Linux, it could simply call SBI to send IPI rather than implementing on its own and concerns about hardware details. I like this separation of concerns.","title":"Firmware/Bootloader"},{"location":"notes/source_code/risc-v/#opensbi","text":"OpenSBI . This is the default firmware in QEMU for RISC-V. It replaces the old BBL. This one runs after ROM and coreboot (if any). This one will discover/probe hardware (I suppose). After that, it passes control to normal bootloaders like u-boot or GRUB, or just to linux kernel.","title":"OpenSBI"},{"location":"notes/source_code/risc-v/#code-study","text":"firmware/fw_base.S is the entry point. mostly doing the usual, setting up envionment for C functions. It will save some critical information into a struct passed to C. In the end, it will call into C sbi_init(struct sbi_scratch *) . Note the sbi_scratch structure is filled with crutial info by fw_base.S. It seems every hart will do the same? lib/sbi/sbi_init.c is the C entry point after assembly. Reset: - See sbi_system.c and sbi_ipi.c . It looks like the reset is: send an IPI to target HART, which will then ran a sbi_ipi_process_halt handler to halt. - Is this warm or cold reboot? Or neither?","title":"Code Study"},{"location":"notes/source_code/risc-v/#scripts","text":"make V = 1 CROSS_COMPILE = riscv64-linux-gnu- PLATFORM = generic FW_PAYLOAD_PATH = ../linux/arch/riscv/boot/Image","title":"Scripts"},{"location":"notes/source_code/risc-v/#qemu","text":"Code in hw/riscv/ , hw/intc/*_clint_* .","title":"QEMU"},{"location":"notes/source_code/risc-v/#kernel","text":"","title":"Kernel"},{"location":"notes/source_code/risc-v/#toolchain","text":"","title":"Toolchain"},{"location":"notes/source_code/spdk/","text":"SPDK \u00b6 Version History Date Description Dec 14, 2020 More on DPDK May 28, 2020 Copied from summary The source code is here: https://github.com/spdk/spdk .","title":"SPDK"},{"location":"notes/source_code/spdk/#spdk","text":"Version History Date Description Dec 14, 2020 More on DPDK May 28, 2020 Copied from summary The source code is here: https://github.com/spdk/spdk .","title":"SPDK"},{"location":"notes/source_code/summary/","text":"Source Code Study \u00b6 Version History Date Description Oct 16, 2021 Move compilers section to a separate file Dec 7, 2020 add sanitizers section Sep 13, 2020 some notes for python; add tcpstat Jul 26, 2020 Add OpenJDK! Hinted by Hacker News :) Jun 2, 2020 Add librcu Apr 26, 2020 Add wayland, X, gnome, gtk etc Apr 10, 2020 add graphics section Apr 6, 2020 add verbs perftes Mar 3, 2020 add FreeBSD, some fpga stuff Feb 4, 2020 add io_uring, firecracker Jan 31, 2020 Add some good stuff Jan 18, 2020 Initial Beautiful code is art. This page documents all the interesting & practical software/hardware/firmware I came across during my work. Nutrition Operating Systems Network Virtualization Compilers Bootloader and Firmware Web Servers KVS Databases RDMA and More Graphics FPGA Sanitizers Nutrition \u00b6 Projects supporting our day-to-day work. GNU glibc: libc, elf, and dynamic linker It is the default C library used by almost everyone It includes ld.so , the dynamic linker I wrote some notes about GOT/PLT and explains what has happend before main() is called. GNU binutils: gas, static linker, and more This repo has a lot commands like as , ld , objdump , nm and so on ld is static linker and I like the magic of its linker script I guess another useful repo is elfutils C Library GNU glibc used by major Linux distributions musl libc is a small libc impl used by Alpine Linux. Clean code. uClibc is a small libc targeting embedded cases bionic is Android\u2019s C library, math library, and dynamic linker [C++ Library] NVIDIA libcu++ strace System call tracer at userspace I\u2019ve designed one for LegoOS in kernel space Unix Commands Of course almost all other listed repos in this section have some sort of commands. But they are not essential. The following repos have the essential UNIX commands like ls, cat. It\u2019s not possible to go through all of them. But rather, I think they serve as references when we want to know how certain things are implemented (e.g., how dmesg get kernel log). BusyBox GNU Coreutils util-linux FreeBSD and its friends Tools tmux git Editors vim neovim C for life Some small and useful C projects cJSON : A lightweight JSON parser in C. userspace-rcu : A userspace RCU implementation library. Outliers CRIU: Checkpoint and Restore in Userspace The reason I love this repo is because it has so many interesting pieces on how to interact with kernel, save states, and restore them. In addition, it shows how to properly use many less well known syscalls. GRUB2: bootloader Learn how modern bootloader works. Detailed analysis of Linux booting sequence (how it transit from real-mode to protected mode, and finally to 64-bit mode, how to navigate Linux source code etc.) FFmpeg FFmpeg project is famous for its clean and neat C code. Besides, this project is used by a lot online video service companies io uring user liburing kernel io_uring.c Operating Systems \u00b6 See here . Network \u00b6 iperf3 is a TCP, UDP, and SCTP network bandwidth measurement tool tcpdump iputils (arping, ping, etc) scapy : Python-based interactive packet manipulation program & library. Very neat tcpstat : C-based simple tool that could dump network traffic. Seems using pcap interface, the one used by tcpdump? Also checkout FreeBSD as it has tools like ifconfig , if . OpenSSH is our ssh! OpenSSL Virtualization \u00b6 Also see: http://lastweek.io/notes/source_code/virt/ . libvirt: virsh and more QEMU Firecracker rust-vmm cloud-hypervisor Containers runc in go. containerd in go. docker in go. k8s in go. Compilers \u00b6 See here . Bootloader and Firmware \u00b6 See here . The open-source firmware landscape: FPGA \u00b6 My own Collection My own Paper Readings Partial Reconfiguration Partial Reconfiguration Building Framework Intepret Xilinx Bitstream HLS-based ICAP Controller Network Corundum: an FPGA-based NIC This is THE BEST network stack out there. This is not simply a network stack, it is a NIC. So what makes a NIC? First, PHY and MAC are basic. Second, PCIe connection between host and board. Third, DMA using PCIe, for TX and RX packets between host and board. Fourth, a host NIC driver; Fifth, some opt modules at NIC. This project has it all. Most amazingly, it works on so many boards. They have an FCCM\u201820 paper (finally!) describing the small modules inside. Verilog-Ethernet Self-made PHY, MAC IPs, ARP, IP, UDP stack This is also used by the Corundum project. Limago, HLS-based 100 GbE TCP/IP FPGA Network Stack This one came from ETH as well. This one is used by many papers, as far as i know, StRoM, EuroSys\u201820. It\u2019s mostly HLS-based. And has ETH/IP/UDP/TCP, RoCE v2 stack. Simulation, Synthesis, and P&R Icarus iverilog . iverilog is a compiler that translates Verilog source code into executable programs for simulation, or other netlist formats for further processing man page . VMware Cascade . Just-in-time compilation for Verilog, what a brilliant idea. Verilog-to-routing . Synthesis ( ODIN II ) Logic Optimization & Technology Mapping ( ABC ) Placement and Route ( VPR ) Web Servers \u00b6 Apache httpd nginx Key Value Stores \u00b6 Point of interests: 1) in-memory, and can it extend to use disk/ssd? 2) persistence support 3) network support RocksDB: A persistent KVS for Flash and RAM Storage. C++ LevelDB. C++ Memcached. C Redis. C etcd: Distributed reliable KVS. Go Databases \u00b6 MySQL PostgresSQL Yugabyte, distributed SQL RDMA and More \u00b6 See here Graphics \u00b6 More here X Server and Wayland X is being replaced by Wayland now.. Wayland code seems clean xvnc xvnc and its friends, are sitting on top of display manager (i.e., X/Wayland). They are clients of X/Wayland, but they act as X/Wayland servers for upper layer application such as GTK/Qt. It\u2019s a middleman, bringing network between X and GTK. TigerVNC, TurboVNC and so on. GNOME Shell and GTK GTK\u2019s default backend is X. GNOME shell is a layer on top of GTK+. Similar for KDE/Qt. xRDP, an RDP server. In C FreeRDP, client and server. In C Took a brief read of the code, it\u2019s super neat. Should take a serious look sometime. Vulkan/OpenCL Proton The landscape: Sanitizers \u00b6 There are many tools in both user and kernel space helping programmers identify various issues early on. Those issues including memory safty issue, threading issue, and others. Personally I have not used these tools a lot. But I am very interested in them. I think they could greatly improve productivity. TODO: https://github.com/google/sanitizers","title":"Index"},{"location":"notes/source_code/summary/#source-code-study","text":"Version History Date Description Oct 16, 2021 Move compilers section to a separate file Dec 7, 2020 add sanitizers section Sep 13, 2020 some notes for python; add tcpstat Jul 26, 2020 Add OpenJDK! Hinted by Hacker News :) Jun 2, 2020 Add librcu Apr 26, 2020 Add wayland, X, gnome, gtk etc Apr 10, 2020 add graphics section Apr 6, 2020 add verbs perftes Mar 3, 2020 add FreeBSD, some fpga stuff Feb 4, 2020 add io_uring, firecracker Jan 31, 2020 Add some good stuff Jan 18, 2020 Initial Beautiful code is art. This page documents all the interesting & practical software/hardware/firmware I came across during my work. Nutrition Operating Systems Network Virtualization Compilers Bootloader and Firmware Web Servers KVS Databases RDMA and More Graphics FPGA Sanitizers","title":"Source Code Study"},{"location":"notes/source_code/summary/#nutrition","text":"Projects supporting our day-to-day work. GNU glibc: libc, elf, and dynamic linker It is the default C library used by almost everyone It includes ld.so , the dynamic linker I wrote some notes about GOT/PLT and explains what has happend before main() is called. GNU binutils: gas, static linker, and more This repo has a lot commands like as , ld , objdump , nm and so on ld is static linker and I like the magic of its linker script I guess another useful repo is elfutils C Library GNU glibc used by major Linux distributions musl libc is a small libc impl used by Alpine Linux. Clean code. uClibc is a small libc targeting embedded cases bionic is Android\u2019s C library, math library, and dynamic linker [C++ Library] NVIDIA libcu++ strace System call tracer at userspace I\u2019ve designed one for LegoOS in kernel space Unix Commands Of course almost all other listed repos in this section have some sort of commands. But they are not essential. The following repos have the essential UNIX commands like ls, cat. It\u2019s not possible to go through all of them. But rather, I think they serve as references when we want to know how certain things are implemented (e.g., how dmesg get kernel log). BusyBox GNU Coreutils util-linux FreeBSD and its friends Tools tmux git Editors vim neovim C for life Some small and useful C projects cJSON : A lightweight JSON parser in C. userspace-rcu : A userspace RCU implementation library. Outliers CRIU: Checkpoint and Restore in Userspace The reason I love this repo is because it has so many interesting pieces on how to interact with kernel, save states, and restore them. In addition, it shows how to properly use many less well known syscalls. GRUB2: bootloader Learn how modern bootloader works. Detailed analysis of Linux booting sequence (how it transit from real-mode to protected mode, and finally to 64-bit mode, how to navigate Linux source code etc.) FFmpeg FFmpeg project is famous for its clean and neat C code. Besides, this project is used by a lot online video service companies io uring user liburing kernel io_uring.c","title":"Nutrition"},{"location":"notes/source_code/summary/#operating-systems","text":"See here .","title":"Operating Systems"},{"location":"notes/source_code/summary/#network","text":"iperf3 is a TCP, UDP, and SCTP network bandwidth measurement tool tcpdump iputils (arping, ping, etc) scapy : Python-based interactive packet manipulation program & library. Very neat tcpstat : C-based simple tool that could dump network traffic. Seems using pcap interface, the one used by tcpdump? Also checkout FreeBSD as it has tools like ifconfig , if . OpenSSH is our ssh! OpenSSL","title":"Network"},{"location":"notes/source_code/summary/#virtualization","text":"Also see: http://lastweek.io/notes/source_code/virt/ . libvirt: virsh and more QEMU Firecracker rust-vmm cloud-hypervisor Containers runc in go. containerd in go. docker in go. k8s in go.","title":"Virtualization"},{"location":"notes/source_code/summary/#compilers","text":"See here .","title":"Compilers"},{"location":"notes/source_code/summary/#bootloader-and-firmware","text":"See here . The open-source firmware landscape:","title":"Bootloader and Firmware"},{"location":"notes/source_code/summary/#fpga","text":"My own Collection My own Paper Readings Partial Reconfiguration Partial Reconfiguration Building Framework Intepret Xilinx Bitstream HLS-based ICAP Controller Network Corundum: an FPGA-based NIC This is THE BEST network stack out there. This is not simply a network stack, it is a NIC. So what makes a NIC? First, PHY and MAC are basic. Second, PCIe connection between host and board. Third, DMA using PCIe, for TX and RX packets between host and board. Fourth, a host NIC driver; Fifth, some opt modules at NIC. This project has it all. Most amazingly, it works on so many boards. They have an FCCM\u201820 paper (finally!) describing the small modules inside. Verilog-Ethernet Self-made PHY, MAC IPs, ARP, IP, UDP stack This is also used by the Corundum project. Limago, HLS-based 100 GbE TCP/IP FPGA Network Stack This one came from ETH as well. This one is used by many papers, as far as i know, StRoM, EuroSys\u201820. It\u2019s mostly HLS-based. And has ETH/IP/UDP/TCP, RoCE v2 stack. Simulation, Synthesis, and P&R Icarus iverilog . iverilog is a compiler that translates Verilog source code into executable programs for simulation, or other netlist formats for further processing man page . VMware Cascade . Just-in-time compilation for Verilog, what a brilliant idea. Verilog-to-routing . Synthesis ( ODIN II ) Logic Optimization & Technology Mapping ( ABC ) Placement and Route ( VPR )","title":"FPGA"},{"location":"notes/source_code/summary/#web-servers","text":"Apache httpd nginx","title":"Web Servers"},{"location":"notes/source_code/summary/#key-value-stores","text":"Point of interests: 1) in-memory, and can it extend to use disk/ssd? 2) persistence support 3) network support RocksDB: A persistent KVS for Flash and RAM Storage. C++ LevelDB. C++ Memcached. C Redis. C etcd: Distributed reliable KVS. Go","title":"Key Value Stores"},{"location":"notes/source_code/summary/#databases","text":"MySQL PostgresSQL Yugabyte, distributed SQL","title":"Databases"},{"location":"notes/source_code/summary/#rdma-and-more","text":"See here","title":"RDMA and More"},{"location":"notes/source_code/summary/#graphics","text":"More here X Server and Wayland X is being replaced by Wayland now.. Wayland code seems clean xvnc xvnc and its friends, are sitting on top of display manager (i.e., X/Wayland). They are clients of X/Wayland, but they act as X/Wayland servers for upper layer application such as GTK/Qt. It\u2019s a middleman, bringing network between X and GTK. TigerVNC, TurboVNC and so on. GNOME Shell and GTK GTK\u2019s default backend is X. GNOME shell is a layer on top of GTK+. Similar for KDE/Qt. xRDP, an RDP server. In C FreeRDP, client and server. In C Took a brief read of the code, it\u2019s super neat. Should take a serious look sometime. Vulkan/OpenCL Proton The landscape:","title":"Graphics"},{"location":"notes/source_code/summary/#sanitizers","text":"There are many tools in both user and kernel space helping programmers identify various issues early on. Those issues including memory safty issue, threading issue, and others. Personally I have not used these tools a lot. But I am very interested in them. I think they could greatly improve productivity. TODO: https://github.com/google/sanitizers","title":"Sanitizers"},{"location":"notes/source_code/unix-tools/","text":"Unix Tools \u00b6 Version History Date Description Jun 21, 2021 Update Dec 23, 2020 extracted from the summary doc Alternative UNIX commands \u00b6 Old wine in new bottles. Those are moden rewrite of common commands. https://github.com/ibraheemdev/modern-unix Essential Commands \u00b6 The following repos have the essential UNIX commands like ls, cat, demsg. I don\u2019t think it is a good idea to blindly read the source code. Rather, I think they should be used as references whenever we need to check how something is implemented. Large Collections BusyBox This is a software suite that provides several Unix utilities in a single executable file . It has a large collection of commands. It probably has everything that GNU coreutils has. BuysBox is targeting embedded environment. GNU Coreutils This repo has the most used commands such as cp , dd , cat . See the full list here . GNU binutils: gas, static linker, and more This one has a set of programming tools for creating and managing binary programs, object files, libraries, profile data, and assembly source code. See the full list here util-linux This is a standard package distributed by the Linux Kernel Organization for use as part of the Linux operating system. See the full list here . FreeBSD Network Commands \u00b6 iperf3 is a TCP, UDP, and SCTP network bandwidth measurement tool arping tcpdump OpenSSH is our ssh! scapy : Python-based interactive packet manipulation program & library. Very neat tcpstat : C-based simple tool that could dump network traffic. Seems using pcap interface, the one used by tcpdump? Also checkout FreeBSD as it has tools like ifconfig , if and many more Misc \u00b6 Tools tmux git FFmpeg FFmpeg project is famous for its clean and neat C code. This project is used by a lot online video service companies CRIU: Checkpoint and Restore in Userspace The reason I love this repo is because it has so many interesting pieces on how to interact with kernel, save states, and restore them. In addition, it shows how to properly use many less well known syscalls. GRUB2: bootloader Learn how modern bootloader works. Detailed analysis of Linux booting sequence (how it transit from real-mode to protected mode, and finally to 64-bit mode, how to navigate Linux source code etc.) strace System call tracer at userspace I\u2019ve designed one for LegoOS in kernel space Editors vim neovim Libraries \u00b6 GNU glibc: libc, elf, and dynamic linker It is the default C library used by almost everyone It includes ld.so , the dynamic linker I wrote some notes about GOT/PLT and explains what has happend before main() is called. GNU binutils: gas, static linker, and more This repo has a lot commands like as , ld , objdump , nm and so on ld is static linker and I like the magic of its linker script I guess another useful repo is elfutils C Library GNU glibc used by major Linux distributions musl libc is a small libc impl used by Alpine Linux. Clean code. uClibc is a small libc targeting embedded cases bionic is Android\u2019s C library, math library, and dynamic linker C++ Library NVIDIA libcu++","title":"Unix Tools"},{"location":"notes/source_code/unix-tools/#unix-tools","text":"Version History Date Description Jun 21, 2021 Update Dec 23, 2020 extracted from the summary doc","title":"Unix Tools"},{"location":"notes/source_code/unix-tools/#alternative-unix-commands","text":"Old wine in new bottles. Those are moden rewrite of common commands. https://github.com/ibraheemdev/modern-unix","title":"Alternative UNIX commands"},{"location":"notes/source_code/unix-tools/#essential-commands","text":"The following repos have the essential UNIX commands like ls, cat, demsg. I don\u2019t think it is a good idea to blindly read the source code. Rather, I think they should be used as references whenever we need to check how something is implemented. Large Collections BusyBox This is a software suite that provides several Unix utilities in a single executable file . It has a large collection of commands. It probably has everything that GNU coreutils has. BuysBox is targeting embedded environment. GNU Coreutils This repo has the most used commands such as cp , dd , cat . See the full list here . GNU binutils: gas, static linker, and more This one has a set of programming tools for creating and managing binary programs, object files, libraries, profile data, and assembly source code. See the full list here util-linux This is a standard package distributed by the Linux Kernel Organization for use as part of the Linux operating system. See the full list here . FreeBSD","title":"Essential Commands"},{"location":"notes/source_code/unix-tools/#network-commands","text":"iperf3 is a TCP, UDP, and SCTP network bandwidth measurement tool arping tcpdump OpenSSH is our ssh! scapy : Python-based interactive packet manipulation program & library. Very neat tcpstat : C-based simple tool that could dump network traffic. Seems using pcap interface, the one used by tcpdump? Also checkout FreeBSD as it has tools like ifconfig , if and many more","title":"Network Commands"},{"location":"notes/source_code/unix-tools/#misc","text":"Tools tmux git FFmpeg FFmpeg project is famous for its clean and neat C code. This project is used by a lot online video service companies CRIU: Checkpoint and Restore in Userspace The reason I love this repo is because it has so many interesting pieces on how to interact with kernel, save states, and restore them. In addition, it shows how to properly use many less well known syscalls. GRUB2: bootloader Learn how modern bootloader works. Detailed analysis of Linux booting sequence (how it transit from real-mode to protected mode, and finally to 64-bit mode, how to navigate Linux source code etc.) strace System call tracer at userspace I\u2019ve designed one for LegoOS in kernel space Editors vim neovim","title":"Misc"},{"location":"notes/source_code/unix-tools/#libraries","text":"GNU glibc: libc, elf, and dynamic linker It is the default C library used by almost everyone It includes ld.so , the dynamic linker I wrote some notes about GOT/PLT and explains what has happend before main() is called. GNU binutils: gas, static linker, and more This repo has a lot commands like as , ld , objdump , nm and so on ld is static linker and I like the magic of its linker script I guess another useful repo is elfutils C Library GNU glibc used by major Linux distributions musl libc is a small libc impl used by Alpine Linux. Clean code. uClibc is a small libc targeting embedded cases bionic is Android\u2019s C library, math library, and dynamic linker C++ Library NVIDIA libcu++","title":"Libraries"},{"location":"notes/source_code/virt/","text":"Virtualization \u00b6 Moved to here: http://lastweek.io/notes/virt/ .","title":"Virtualization"},{"location":"notes/source_code/virt/#virtualization","text":"Moved to here: http://lastweek.io/notes/virt/ .","title":"Virtualization"},{"location":"rdma/rdma/","text":"Restless Dumb Memory Assassinate (RDMA) \u00b6 Q \u00b6 Atomic Operations: what exactly does the atomic mean in this context? RPC: SEND or RDMA Write with Immediate, which is better and why? Except \u00b6 One-sided v.s. Two sided SEND and RECV are two sided as the CPU at the responder needs to post a RECV in order for an incoming SEND to be processed. Unlike memory verbs, the responder\u2019s CPU is involved. One thing I do like to note is: the actual data transfer will not bother responder\u2019s CPU, the generated CQE will not bother it as well, only the pre-post action need CPU involvement. (HERD) CQE Generation Requester side: On completing a verb, the requester\u2019s NIC optionally signals completion by DMA-ing a completion entry (CQE) to a completion queue (CQ) associated with the QP. Of course, some WQE can be un-signaled. Responder side: NIC must DMA a CQE for completed RECV. (So I think this will not involve responder\u2019s CPU, right?) IB Specification \u00b6 The QP is the virtual interface that the hardware provides to an IBA consumer ; it serves as a virtual communication port for the consumer. Memory Region, L_Key, R_Key (sec 3.5.3/3.5.4) Used in RDMA requests. This is key in many design choices. Addressing (sec 3.5.10 and sec 4) Each QP has as queue pair number ( QPN ) assigned by the channel adapter which uniquely identifies the QP within the channel adapter . QPN GID, LID stuff IBA Semantic (sec 3.6) Channel (Send/Receive), classical I/O channel The message transmitted on the wire only names the destination\u2019s QP, the message does not describe where in the destination consumer\u2019s memory space the message content will be written. Instead, the destination QP contains addressing information used to deliver the message to the appropriate memory location. Pre-Post Receive Buffer (a channel semantic operation for SEND from remote.) Memory (RDMA) With memory semantics the initiating party directly reads or writes the virtual address space of a remote node. The remote party needs only communicate the location of the buffer; it is not involved with the actual transfer of the data. Hence, this style is sometimes referred to as single-ended communications. L_Key and R_Key used to validate access permission. Immediate Data RDMA Write and SEND can carry 4 bytes of Immediate data . sec 3.6 SEND can carry Immediate data for each send message. If included, the Immediate data is contained within an additional header field on the last packet of the SEND Operation (sec 9.4.1 SEND Operation). sec 3.7.4 An RDMA Write with immediate data will consume a receive WQE even though the QP did not place any data into the receive buffer since the IMMDT is placed in a CQE that references the receive WQE and indicates that the WQE has completed. sec 9.4.3 If specified by the verbs layer, Immediate data is included in the last packet of an RDMA WRITE message . The Immediate data is not written to the target virtual address range, but is passed to the client after the last RDMA WRITE packet is successfully processed. sec 10.7.2.2 C10-86: The responder\u2019s Receive Queue shall consume a Work Request when Immediate Data is specified in a successfully completed incoming RDMA Write. QP transport services RC RD UC UD IB Layers The network and link protocols deliver a packet to the desired destination. The transport portion of the packet delivers the packet to the proper QP and instructs the QP how to process the packet\u2019s data. Upper Layers (Consumer Operations). This is the layer most people focus on and try to optimize, right? IB Transaction Flow (sec 3.8) Describe the general flow. A nice read. So the WQE of RDMA Write/Read, the sender side\u2019s driver will create a CQE when sender get ACK from receiver? And that marks the end of a RDMA Read/Write? For RC, I think so. According to: When the originator receives an acknowledgment, it creates a CQE on the CQ and retires the WQE from the send queue. sec 3.2.1 Each time the remote consumer successfully executes a SEND operation, the hardware takes the next entry from the receive queue, places the received data in the memory location specified in that receive WQE, and places a CQE on the completion queue indicating to the consumer that the receive operation has completed. Thus the execution of a SEND operation causes a receive queue operation at the remote consumer. That is one important claim, the receiver side can poll the CQ to know if it has received a SEND or not. IB I/O Operations (sec 3.9) Interesting. So, instead of a Host Channel Adapter (HCA), we have Target Channel Adapter (TCA), which is attached to a IO device such as SSD. If we look from the IB layered architecture, everything below upper level protocols remain the same. In upper level protocols, which used to be Consumer, now is I/O controller. Do we have this kind of hardware on market? Fabric over NVMe? Transport Layer (sec 9) The transport header contains the information required by the endnode to complete the specified operation, e.g. delivery of data payload to the appropriate entity within the endnode such as a thread or IO controller . For a host platform, the client of the transport layer is the Verbs software layer . The client posts buffers or commands to these queues and hardware transfers data from or into the buffers. Reliable transport has response (acknowledge). Unreliable transport does not use acknowledgment messages. SEND can carry 4 bytes of Immediate data for each send message. If included, the Immediate data is contained within an additional header field on the last packet of the SEND Operation (sec 9.4.1 SEND Operation). WQ Packet Ordering Stuff (sec 9.5 Transaction Ordering): A requester shall transmit request messages in the order that the Work Queue Elements (WQEs) were posted. Reliable Service (sec 9.7) Before it can consider a WQE completed, the requester must wait for the necessary response(s) to arrive. If the requester requires an explicit response such that it can complete a given WQE, then the requester shall be responsible to take the necessary steps to ensure that the needed response is forthcoming. This section is still too much details on hardware behavior. But Mel must have more detailed stuff in house. Software Transport interface (sec 10) I think this section is trying to describe the various software concepts, such as HCA, Protection domain, and so on. The actual manipulations are carried out by Verbs, which are described in sec 11. A QP, which is a component of the channel interface, is NOT directly accessible by the Verbs consumer and can only be manipulated through the use of Verbs. A CQ can be used to multiplex work completions from multiple work queues across queue pairs on the same HCA. Shared Receive Queue (sec 10.2.9) (Is it used in Lego?) Memory Management (sec 10.6) Memory Region Able to register a virtually contiguous address range , even though the physical pages are not contiguous. Able to register a physically contiguous address range . Prior to invoking a Register Physical Memory Region or Reregister Physical Memory Region Verb, the Consumer should pin down in physical memory every physical buffer within the Memory Region. (But now Mellanox supports pgfault in their products, right?) Work Request (sec 10.7 and sec 10.8) Signaled Completion and Unsignaled Completion (sec 10.7.3.1) Finally meet these two description in tech documents. In Lego, we used to use unsignaled (polling), and then we change that to signaled handler. Submitting a list of Work Requests.. (10.8.2.1) .. the HCA is notified that one or more WQEs are ready to be processed. What is the mechanism of this notification? How does HCA got notified? HCA polling, or driver write something into HCA? Completion Queue Operations: poll a specified CQ for a Work Completion, that is ib_poll_cq() ! (sec 11.4.2) SG list Based on discussion with Shin-Yeh and Yiying. x3: if a sender uses one-sided RDMA write/read to send a sg-list to remote, the receiver side can only receive a consecutive memory buffer. x3: if a sender uses two-sided RDMA to SEND a sg-list to remote, the receiver can get a sg-list of buffers by pre-post RECV to receive queue. x4 and x5: looks like the User-Mode Memory Registration (UMR) can help to solve the one-sided RDMA issue (not verified).","title":"Restless Dumb Memory Assassinate (RDMA)"},{"location":"rdma/rdma/#restless-dumb-memory-assassinate-rdma","text":"","title":"Restless Dumb Memory Assassinate (RDMA)"},{"location":"rdma/rdma/#q","text":"Atomic Operations: what exactly does the atomic mean in this context? RPC: SEND or RDMA Write with Immediate, which is better and why?","title":"Q"},{"location":"rdma/rdma/#except","text":"One-sided v.s. Two sided SEND and RECV are two sided as the CPU at the responder needs to post a RECV in order for an incoming SEND to be processed. Unlike memory verbs, the responder\u2019s CPU is involved. One thing I do like to note is: the actual data transfer will not bother responder\u2019s CPU, the generated CQE will not bother it as well, only the pre-post action need CPU involvement. (HERD) CQE Generation Requester side: On completing a verb, the requester\u2019s NIC optionally signals completion by DMA-ing a completion entry (CQE) to a completion queue (CQ) associated with the QP. Of course, some WQE can be un-signaled. Responder side: NIC must DMA a CQE for completed RECV. (So I think this will not involve responder\u2019s CPU, right?)","title":"Except"},{"location":"rdma/rdma/#ib-specification","text":"The QP is the virtual interface that the hardware provides to an IBA consumer ; it serves as a virtual communication port for the consumer. Memory Region, L_Key, R_Key (sec 3.5.3/3.5.4) Used in RDMA requests. This is key in many design choices. Addressing (sec 3.5.10 and sec 4) Each QP has as queue pair number ( QPN ) assigned by the channel adapter which uniquely identifies the QP within the channel adapter . QPN GID, LID stuff IBA Semantic (sec 3.6) Channel (Send/Receive), classical I/O channel The message transmitted on the wire only names the destination\u2019s QP, the message does not describe where in the destination consumer\u2019s memory space the message content will be written. Instead, the destination QP contains addressing information used to deliver the message to the appropriate memory location. Pre-Post Receive Buffer (a channel semantic operation for SEND from remote.) Memory (RDMA) With memory semantics the initiating party directly reads or writes the virtual address space of a remote node. The remote party needs only communicate the location of the buffer; it is not involved with the actual transfer of the data. Hence, this style is sometimes referred to as single-ended communications. L_Key and R_Key used to validate access permission. Immediate Data RDMA Write and SEND can carry 4 bytes of Immediate data . sec 3.6 SEND can carry Immediate data for each send message. If included, the Immediate data is contained within an additional header field on the last packet of the SEND Operation (sec 9.4.1 SEND Operation). sec 3.7.4 An RDMA Write with immediate data will consume a receive WQE even though the QP did not place any data into the receive buffer since the IMMDT is placed in a CQE that references the receive WQE and indicates that the WQE has completed. sec 9.4.3 If specified by the verbs layer, Immediate data is included in the last packet of an RDMA WRITE message . The Immediate data is not written to the target virtual address range, but is passed to the client after the last RDMA WRITE packet is successfully processed. sec 10.7.2.2 C10-86: The responder\u2019s Receive Queue shall consume a Work Request when Immediate Data is specified in a successfully completed incoming RDMA Write. QP transport services RC RD UC UD IB Layers The network and link protocols deliver a packet to the desired destination. The transport portion of the packet delivers the packet to the proper QP and instructs the QP how to process the packet\u2019s data. Upper Layers (Consumer Operations). This is the layer most people focus on and try to optimize, right? IB Transaction Flow (sec 3.8) Describe the general flow. A nice read. So the WQE of RDMA Write/Read, the sender side\u2019s driver will create a CQE when sender get ACK from receiver? And that marks the end of a RDMA Read/Write? For RC, I think so. According to: When the originator receives an acknowledgment, it creates a CQE on the CQ and retires the WQE from the send queue. sec 3.2.1 Each time the remote consumer successfully executes a SEND operation, the hardware takes the next entry from the receive queue, places the received data in the memory location specified in that receive WQE, and places a CQE on the completion queue indicating to the consumer that the receive operation has completed. Thus the execution of a SEND operation causes a receive queue operation at the remote consumer. That is one important claim, the receiver side can poll the CQ to know if it has received a SEND or not. IB I/O Operations (sec 3.9) Interesting. So, instead of a Host Channel Adapter (HCA), we have Target Channel Adapter (TCA), which is attached to a IO device such as SSD. If we look from the IB layered architecture, everything below upper level protocols remain the same. In upper level protocols, which used to be Consumer, now is I/O controller. Do we have this kind of hardware on market? Fabric over NVMe? Transport Layer (sec 9) The transport header contains the information required by the endnode to complete the specified operation, e.g. delivery of data payload to the appropriate entity within the endnode such as a thread or IO controller . For a host platform, the client of the transport layer is the Verbs software layer . The client posts buffers or commands to these queues and hardware transfers data from or into the buffers. Reliable transport has response (acknowledge). Unreliable transport does not use acknowledgment messages. SEND can carry 4 bytes of Immediate data for each send message. If included, the Immediate data is contained within an additional header field on the last packet of the SEND Operation (sec 9.4.1 SEND Operation). WQ Packet Ordering Stuff (sec 9.5 Transaction Ordering): A requester shall transmit request messages in the order that the Work Queue Elements (WQEs) were posted. Reliable Service (sec 9.7) Before it can consider a WQE completed, the requester must wait for the necessary response(s) to arrive. If the requester requires an explicit response such that it can complete a given WQE, then the requester shall be responsible to take the necessary steps to ensure that the needed response is forthcoming. This section is still too much details on hardware behavior. But Mel must have more detailed stuff in house. Software Transport interface (sec 10) I think this section is trying to describe the various software concepts, such as HCA, Protection domain, and so on. The actual manipulations are carried out by Verbs, which are described in sec 11. A QP, which is a component of the channel interface, is NOT directly accessible by the Verbs consumer and can only be manipulated through the use of Verbs. A CQ can be used to multiplex work completions from multiple work queues across queue pairs on the same HCA. Shared Receive Queue (sec 10.2.9) (Is it used in Lego?) Memory Management (sec 10.6) Memory Region Able to register a virtually contiguous address range , even though the physical pages are not contiguous. Able to register a physically contiguous address range . Prior to invoking a Register Physical Memory Region or Reregister Physical Memory Region Verb, the Consumer should pin down in physical memory every physical buffer within the Memory Region. (But now Mellanox supports pgfault in their products, right?) Work Request (sec 10.7 and sec 10.8) Signaled Completion and Unsignaled Completion (sec 10.7.3.1) Finally meet these two description in tech documents. In Lego, we used to use unsignaled (polling), and then we change that to signaled handler. Submitting a list of Work Requests.. (10.8.2.1) .. the HCA is notified that one or more WQEs are ready to be processed. What is the mechanism of this notification? How does HCA got notified? HCA polling, or driver write something into HCA? Completion Queue Operations: poll a specified CQ for a Work Completion, that is ib_poll_cq() ! (sec 11.4.2) SG list Based on discussion with Shin-Yeh and Yiying. x3: if a sender uses one-sided RDMA write/read to send a sg-list to remote, the receiver side can only receive a consecutive memory buffer. x3: if a sender uses two-sided RDMA to SEND a sg-list to remote, the receiver can get a sg-list of buffers by pre-post RECV to receive queue. x4 and x5: looks like the User-Mode Memory Registration (UMR) can help to solve the one-sided RDMA issue (not verified).","title":"IB Specification"}]}