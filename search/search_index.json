{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Hello! I\u2019m Yizhou Shan (\u5355\u4e00\u821f), I\u2019m a Research Scientist at Huawei Cloud. I earned my PhD from University of California San Diego, CSE under the supervision of Prof. Yiying Zhang.</p> <p>I now run Serverless AI platform at Huawei Cloud, responsible for cost-efficient Model Serving (LLM, LMM, T2I, T2V, etc), Agent Serving, and Post-Training infrastructure. If you are interested in working with me (full-time or intern), we should talk.</p> <p>Contact: syzwhat AT gmail DOT com You can find my CV here.</p> Blogging <p>Latest</p> <ul> <li>Nov 2022 SSD 101</li> <li>Jul 2022 CXL</li> <li>Apr 2022 MLIR</li> <li>Mar 2022 Resource Disaggregation Spectrum</li> <li>Feb 2022 Distributed Transactions</li> <li>Dec 2021 Notes on Modern Data Center Networking</li> </ul> <p>Hot</p> <ul> <li>Oct 2019 FPGA Bitstream Explained</li> <li>May 2020 On DPDK and RDMA Related Software</li> <li>Jan 2020 Modern Virtualization</li> <li>Dec 2020 Dynamic Linking</li> <li>Jun 2019 Practical Cache Coherence</li> <li>Dec 2020 Architecture</li> <li>and more!</li> </ul> Research <ul> <li>[Nov 2024] I will serve as a PC for FAST\u201825, FAST\u201826, ATC\u201825.</li> <li>[Nov 2024] InstInfer accepted to HPCA\u201825.</li> <li>[Apr 2024] I will serve as a NSDI\u201825 PC.</li> <li>[Jan 2024] I will serve as a EuroSys\u201825 PC.</li> <li>[Jan 2024] I will serve as a ATC\u201824 PC.</li> <li>[Dec 2022] I will serve as a NSDI\u201824 PC.</li> <li>[Nov 2022] MARB accepted to DATE\u201823.</li> <li>[Oct 2022] HoPP accepted to HPCA\u201823.</li> <li>[Sep 2022] I will serve as an ATC\u201823 PC.</li> <li>[Jun 2022] A vision paper is accepted to APSys\u201822</li> <li>[Jun 2022] Serve as EuroSys\u201823 PC</li> <li>[Jun 2022] Serve as SoCC\u201822 PC</li> <li>[Mar 2022] Serve as APSys\u201822 PC</li> <li>[Mar 2022] Serve as ChinaSys\u201822 PC</li> <li>[Mar 2022] Defended. The full defense slide is here.</li> <li>[Oct 2021] Serve as EuroSys\u201822 Shadow PC</li> <li>[Sep 2021] We made our SuperNIC paper public.</li> <li>[Sep 2021] Serve as SOSP\u201821 Artifact Evaluation PC</li> <li>[Aug 2021] We made our Clio paper public.</li> <li>[Jun 2021] Start my final internship at Microsoft Research, working on Security + System.</li> <li>[Jun 2021] I proposed my thesis and became a Ph.D candidate.</li> <li>[Jan 2021] The DPM work is accepted to present at NVMW\u201821</li> <li>[Jan 2021] This summer, I\u2019m going to do my last internship at MSR Redmond on cloud confidential computing.</li> <li>[Dec 2020] Invited to join the 2021 JSys Student Editorial Board</li> <li>[Oct 2020] Serve as EuroSys\u201821 Shadow PC</li> <li>[Sep 2020] Serve as OSDI\u201820 Artifact Evaluation PC</li> <li>[Sep 2020] Serve as ASPLOS\u201821 External Reviewer. First major conference review!</li> <li>[Apr 2020] Disaggregated Persistent Memory accepted to ATC\u201820</li> <li>[Feb 2020] Talk about FPGA OS</li> <li>[Sep 2019] Moved to UCSD.</li> <li>[May 2019] Intern at VMware Research, with Marcos K. Aguilera</li> <li>[Apr 2019] Storm accpeted to SYSTOR\u201819. Awarded Best Paper.</li> <li>[Jan 2019] Short paper on Disaggregated Persistent Memory accpeted to NVMW\u201819</li> <li>[Jul 2018] LegoOS accepted to OSDI\u201818. Awarded Best Paper.</li> <li>[May 2018] Intern at VMware Research, with Stanko Novakovic.</li> </ul>"},{"location":"#research","title":"Research","text":"<p>My main research interests span machine learning systems, distributed systems, data center networking, OS, hardware (FPGA), disaggregated memory/storage systems, and their intersections.</p> <p>Serving LLMs at Cloud Scale</p> <ul> <li>EPIC, 2024 - Position-Independent KV caching</li> <li>InstInfer, HPCA\u201825 - Programmable Attention Offload</li> <li>MemServe, 2024 - Disaggregated PD w/ Context Caching</li> <li>TetriServe, 2024 - Disaggregated PD</li> <li>CaraServe, 2024 - Multi-LoRA Serving</li> <li>The CAP Principle for LLM Serving, 2024 - a survey</li> </ul> <p>Disaggregated Data Center Architecture</p> <ul> <li>Skadi, HotOS\u201823</li> <li>Fully Disaggregated Data Center, APSys\u201822</li> <li>LegoOS, OSDI\u201818</li> </ul> <p>Disaggregated Memory</p> <ul> <li>HoPP, HPCA\u201823 and MARB, DATE\u201823 - Hardware-accelerated Prefetching for DisaggMem</li> <li>Clio, ASPLOS\u201822 - An FPGA-based disaggregated memory device</li> <li>Clover, ATC\u201820 - Pure one-sided KVS on disaggregated PM</li> <li>Storm, SYSTOR\u201819 - Highly-efficient KVS on disaggregated memory</li> <li>Hotpot, SoCC\u201817 -  Transactional distributed PM over RDMA</li> </ul> <p>Networking Design</p> <ul> <li>Storm, SYSTOR\u201819 - RDMA Cards are evolving!</li> <li>SuperNIC, arXiv\u201821 - An FPGA-based Programmable Multi-Host NIC</li> <li>Clio, ASPLOS\u201822 - Rethinking RDMA NIC, congestion control</li> </ul>"},{"location":"#publications","title":"Publications","text":"<ol> <li>CaraServe: CPU-Assisted and Rank-Aware LoRA Serving for Generative LLM Inference  Suyi Li, Hanfeng Lu, Tianyuan Wu, Minchen Yu, Qizhen Weng, Xusheng Chen, Yizhou Shan, Binhang Yuan, Wei Wang    [Preprint] [Code]</li> <li>Inference without Interference: Disaggregate LLM Inference for Mixed Downstream Workloads  Cunchen Hu, Heyang Huang, Liangliang Xu, Xusheng Chen, Jiang Xu, Shuang Chen, Hao Feng, Chenxi Wang, Sa Wang, Yungang Bao, Ninghui Sun, Yizhou Shan [Preprint] [Code]</li> <li>Optimizing Hardware-Based Network Computation DAGs for Multiple Tenants with SuperNIC Yizhou Shan, Will Lin, Ryan Kosta, Arvind Krishnamurthy, Yiying Zhang    [Preprint] [Code]</li> <li>Skadi: Building a Distributed Runtime for Data Systems in Disaggregated Data Centers   Cunchen Hu, Chenxi Wang, Sa Wang, Ninghui Sun, Yungang Bao, Jieru Zhao, Sanidhya Kashyap, Pengfei Zuo, Xusheng Chen, Liangliang Xu, Qin Zhang, Hao Feng, Yizhou Shan HotOS 2023 [Paper]</li> <li>Core slicing: closing the gap between leaky confidential VMs and bare-metal cloud  Ziqiao Zhou, Yizhou Shan, Weidong Cui, Xinyang Ge, Marcus Peinado, Andrew Baumann    OSDI 2023 [Paper]</li> <li>MARB: Bridge the Semantic Gap between Operating System and Application Memory Access Behavior  Haifeng Li, Ke Liu, Ting Liang, Zuojun Li, Tianyue Lu, Hui Yuan, Yinben Xia, Yungang Bao, Mingyu Chen, Yizhou Shan DATE 2023</li> <li>HoPP: Hardware-Software Co-Designed Page Prefetching for Disaggregated Memory  Haifeng Li, Ke Liu, Ting Liang, Zuojun Li, Tianyue Lu, Hui Yuan, Yinben Xia, Yungang Bao, Mingyu Chen, Yizhou Shan HPCA 2023 [Paper]</li> <li>Towards a Fully Disaggregated and Programmable Data Center Yizhou Shan, Will Lin, Zhiyuan Guo, Yiying Zhang    APSys 2022 [Paper]</li> <li>Distributing and Disaggregating Hardware Resources in Data Centers  Yizhou Shan    UCSD Dissertation 2022</li> <li>Clio: A Hardware-Software Co-Designed Disaggregated Memory System Yizhou Shan, Zhiyuan Guo (co-first authors), Xuhao Luo, Yutong Huang, Yiying Zhang    ASPLOS 2022 [Paper] [Code] [Slide]</li> <li> <p>Disaggregating Persistent Memory and Controlling Them Remotely: An Exploration of Passive Disaggregated Key-Value Stores  Shin-Yeh Tsai, Yizhou Shan, Yiying Zhang    ATC 2020 [Paper] [Code] [Slide] [Short-Talk] [Full-Talk] [Keynote]</p> </li> <li> <p>Storm: a fast transactional dataplane for remote data structures  Stanko Novakovic, Yizhou Shan, Aasheesh Kolli, Michael Cui, Yiying Zhang, Haggai Eran, Liran Liss, Michael Wei, Dan Tsafrir, Marcos Aguilera    SYSTOR 2019 (Best Paper Award) [Paper] [Slide] [Talk]</p> </li> <li> <p>LegoOS: A Disseminated, Distributed OS for Hardware Resource Disaggregation Yizhou Shan, Yutong Huang, Yilun Chen, Yiying Zhang    OSDI 2018 (Best Paper Award) [Paper] [Code] [Slide] [Keynote-iCloud] [Talk]</p> </li> <li> <p>Distributed Shared Persistent Memory Yizhou Shan, Shin-Yeh Tsai, Yiying Zhang    SoCC 2017 [Paper] [Code] [Slide] [Poster]</p> </li> </ol>"},{"location":"#workshops","title":"Workshops","text":"<ol> <li> <p>Disaggregating Persistent Memory and Controlling Them Remotely: An Exploration of Passive Disaggregated Key-Value Stores  Shin-Yeh Tsai, Yizhou Shan, Yiying Zhang    12<sup>th</sup> Annual Non-Volatile Memories Workshop (NVMW 2021) [Paper]</p> </li> <li> <p>Challenges in Building and Deploying Disaggregated Persistent Memory Yizhou Shan, Yutong Huang, Yiying Zhang    10<sup>th</sup> Annual Non-Volatile Memories Workshop (NVMW 2019) [Paper]</p> </li> <li> <p>Disaggregating Memory with Software-Managed Virtual Cache Yizhou Shan, Yiying Zhang    2018 Workshop on Warehouse-scale Memory Systems (WAMS 2018) (co-located with ASPLOS \u201818) [Paper]</p> </li> <li> <p>Distributed Shared Persistent Memory Yizhou Shan, Shin-Yeh Tsai, Yiying Zhang    9<sup>th</sup> Annual Non-Volatile Memories Workshop (NVMW 2018) [Paper]</p> </li> <li> <p>Disaggregated Operating System  Yiying Zhang, Yizhou Shan, Sumukh Hallymysore    17<sup>th</sup> International Workshop on High Performance Transaction Systems (HPTS 2017) [Paper]</p> </li> </ol>"},{"location":"#professional-services","title":"Professional Services","text":"<p>Program Committee</p> <ul> <li>FAST    (2026, 2025)</li> <li>EuroSys (2025, 2024, 2023)</li> <li>ATC     (2025, 2024, 2023)</li> <li>NSDI    (2026, 2025, 2024)</li> <li>SoCC    (2023, 2022)</li> </ul> <p>Shadow/External Program Committee</p> <ul> <li>EuroSys (2022-shadow, 2021-shadow)</li> <li>ASPLOS  (2021-external)</li> </ul> <p>Journal Reviewer</p> <ul> <li>Journal of Systems Research: 2021 - Current</li> <li>ACM Transactions on Architecture and Code Optimization (TACO): 2021</li> <li>ACM Transactions on Storage (TOS): 2020</li> <li>IEEE/ACM Transactions on Networking: 2020</li> </ul> <p>Artifact Evaluation Committee</p> <ul> <li>SOSP (2021)</li> <li>OSDI (2020)</li> </ul>"},{"location":"#social","title":"Social","text":"<ul> <li>Google Scholar</li> <li>Github</li> <li>Twitter</li> <li>LinkedIn</li> <li>Goodreads</li> </ul>"},{"location":"vmware-intern/","title":"Vmware intern","text":"<ul> <li>Intel Xeon 6138p, integrated FPGA (check it out!)</li> <li>retpoline (perf impact?)</li> <li> <p>Intel Total Memory Encryption. Multi-Key Total Memory Encryption (MKTME).</p> </li> <li> <p>RDMA + NVM: An interesting topic. There are a lot interesting stuff to think about. I discussed this with Sanidhya today, he shared some very valuable findings:</p> <ul> <li>RDMA write: when does it mark a <code>persistent</code> point?</li> <li>RDMA write followed by a RDMA read, is kind of implicit memory barrier imposed by memory controller.</li> </ul> </li> </ul>"},{"location":"blog/20200404-on-read-once/","title":"On READ_ONCE and Compiler Opts","text":"Version History Date Description Apr 13, 2020 Initial Version <p>I decide to write this blog after I once again got tricked by GCC optimizations. I was designing a simple single-producer-single-consumer ring buffer. Since there is a small time gap between slot-being-allocated and slot-being-usable (i.e., data filled), the producer will set a non-atomic flag once the data is filled thus usable. The consumer, running on a seperate CPU, will repeatly checking the usable flag after it has grabbed the slot.</p> <p>Simple, right? Yet I ran into a lot random stuck during testing. I didn\u2019t even check the ring buffer design as I was so confident. There was no timeout checking either. After some digging, I realized I missed using <code>READ_ONCE</code> when consumer thread is polling for the usable flag.</p> <p>Yeah, once again, <code>gcc -O2</code> tricked me: it will optmize away repeated memory accesses if it thinks the accessed variable/data is thread-local. For instance, the following code snippet shows how gcc -O2 removes the memory access part. Without -O2, a simple assembly loop is generated. With -O2, gcc generates a deadlock itself.</p> <pre><code>          Original C                        Assembly                 Assembly\n                                            (gcc -S)               (gcc -S -O2)\nint x;                           |                            |\n                                 | .L2:                       | .L2:\n/* Spin until x becomes true */  |     movl    x(%rip), %eax  |     jmp .L2\nvoid wait_for_x(void)            |     cmpl    $1, %eax       |\n{                                |     je      .L2            |\n        while (x == 1)           |                            |\n                ;                |                            |\n}                                |                            |\n</code></pre> <p>Why this is happening? Because gcc thinks vairable <code>x</code> is thread-local and will not be accessed by multiple threads at the same time. Thus gcc thinks the above <code>while (x == 1) ;</code> check will never break, so generating an assembly deadlock jmp loop.</p> <p>Why does this matter? Assume <code>x</code> is a shared variable. In the following code snippet, there are two threads, A and B. Thread A wait until B change <code>x</code> to 1. If we compile with -O2, thread A will deadlock. And this was my bug above.</p> <pre><code>int x; /* a global shared variable*/\n\n           Thread A                         Thread B\n\n/* Spin until x becomes true */  |   /* Set x at some point */\nvoid wait_for_x(void)            |   x = 1;\n{                                | \n        while (x == 1)           | \n                ;                | \n}                                | \n</code></pre> <p>The common approach, is to add <code>volatile</code> modifier, to explicitly express the concurrency issue. But volatile is considered harmful by linux kernel, and I agree with it.</p> <p>I generally use <code>READ_ONCE</code>, <code>WRITE_ONCE</code>, <code>ACCESS_ONCE</code> macros. They \u201ctell\u201d gcc that the particualr variable is a shared global variable, thus for each time a C statment is running, the variable should be accessed once and exactly once. The fix for above case is: <code>while (READ_ONCE(x == 1)) ;</code>.</p> <p>I will not go into details about why and how those macros are implemented. For more information, refers to source code, ktsan wiki.</p> <p>Hope you enjoyed this simple bug-documentation blog.</p>"},{"location":"clio/story/","title":"The Research Story Behind the Clio Project","text":"Version History Date Description Nov 15, 2021 Draft <p>The Clio paper has recently been accepted to ASPLOS\u201822. We are all very excited about it and have a strong feeling on its final acceptance. This paper is just special to many of us in different ways. The whole thing started in late 2018 and it took so many different turns. Anyways, let me share the story bebind it.</p>"},{"location":"clio/story/#the-beginning-build-a-disaggregated-memory-device-oct-2018","title":"The Beginning: Build a Disaggregated Memory Device (Oct 2018)","text":""},{"location":"clio/story/#the-first-failure-may-2019","title":"The First Failure (May 2019)","text":""},{"location":"clio/story/#a-new-start-and-a-spin-off-sep-2019","title":"A New Start and a Spin-Off (Sep 2019)","text":""},{"location":"clio/story/#the-second-failure-the-fpga-os-dec-2019","title":"The Second Failure: The FPGA OS (Dec 2019)","text":""},{"location":"clio/story/#clios-submissions","title":"Clio\u2019s Submissions","text":""},{"location":"clio/story/#final-words","title":"Final Words","text":""},{"location":"clio/story/#future-work","title":"Future Work","text":""},{"location":"clio/story/#acknowledgements","title":"Acknowledgements","text":""},{"location":"ctf/basic/","title":"Basic","text":"<ul> <li>checksec</li> <li>rename in assembly</li> <li>pwn cyclic De Brujin Sequence</li> <li>ROP</li> </ul>"},{"location":"ctf/basic/#shell-code","title":"Shell code","text":"<ul> <li>Avoid NULL byte (\\x00) is bad.</li> <li>No hard coded addresses: use indirect references, e.g., short jumps and near calls.</li> <li>First portion of payload can be a bunch of NOPs, IP will slide into the real shellcode</li> <li>http://shell-storm.org/</li> <li> </li> </ul>"},{"location":"ctf/basic/#encrypt-shellcode","title":"encrypt shellcode","text":""},{"location":"financial/economics/","title":"Economics","text":"<p>TODO</p>"},{"location":"financial/economics_behavior/","title":"Economics behavior","text":"<p>TODO</p>"},{"location":"financial/stock/","title":"Stock","text":"<p>Anyone reading this should take it with a grain of salt. I\u2019m just documenting a few useful things to understand the stocks. But being able to reason the data does not give one the power to predict market, it only makes one feel more comfortable making choices (well, maybe).</p>"},{"location":"financial/stock/#resources","title":"Resources","text":"<ul> <li>This GamestonkTermial page lists a lot useful sources. </li> </ul>"},{"location":"financial/stock/#indicators","title":"Indicators","text":"<p>Important</p> <p>Trade what you see, not what you think. Avoid confirmation bias.</p> <p>TODO: 1. Catagorize by purposes. 2. also think about when to which ones. 3. what each indicator can tell you.</p> <ul> <li>Moving Average (MA)<ul> <li>Simple Moving Average (SMA)</li> <li>Exponential Moving Average (EMA)</li> </ul> </li> <li>RSI</li> <li>MACD</li> <li>Stoch</li> <li>Bias</li> <li>ATR</li> </ul>"},{"location":"financial/stock/#options","title":"Options","text":"<ul> <li>Options Playbook</li> <li>Option Profit Calculator</li> <li>Understanding NOPE</li> </ul> <p>Option is risky. Start with money you are okay losing.</p> <p>Option contract has value. It is a different market. It goes up or down more dramatically than the normal stock price: several parameters (e.g., IV, greeks) will amplify the change.</p> <p>One thing I realize after playing with options is that some people do not really wait until Expiry Day to close the position. They might sell the option contract before the expiry date, which might produce more profit (also loss more) than just exercising the options.</p> <p>It takes a seller and a buyer to complete a transction. For some low liquid stock/option, you might not be able to find a buyer. You must pay attention to this if you are betting able to re-sell the options.</p> <p>Market maker (MM) will sell whatever ridiculous options. But they will in turn use option/stock to hedge, which in turn create some volality in the stock market.</p>"},{"location":"financial/stock/#unusual-whales","title":"Unusual Whales","text":"<p>Some useful tips:</p> <ol> <li>Whales come and go, they gamble as well.</li> <li>Look for high VOL/OI ratio (maybe larger than 5?)</li> <li>The bid/ask spread should be small. Smaller the better. It also means more volumn.</li> <li>Pay attention to IV. Many people suggest IV &lt; 100%</li> <li>Pay attention to the strike price and date. I haven\u2019t fully grasp the core idea. Yet to learn.</li> <li>Mon/Fri close/mornings options somehow have  higher average max return.</li> </ol> <p>Before futures open, here's something neat.Take a look at this chart, it shows the average max return from 2020 and breaks it down to time and week day, and the option type from the whale.You can see that Friday after 12pm EST, Monday Morning, and Monday close have the ... pic.twitter.com/QRSIstpqsx</p>\u2014 unusual_whales (@unusual_whales) January 10, 2021 <ol> <li>Whale Winner and Loser MEGA Report</li> </ol> <p>Read more tactics here: https://unusualwhales.com/spears.</p>"},{"location":"financial/stock/#tools","title":"Tools","text":"<p>I\u2019m mostly using TradingView, half an hour is enough to learn the basics. I highly recommend it if you also know a bit programming. It allows you to express things in Python.</p> <p>I sometimes check https://unusualwhales.com/ for unusual options, which maybe potential insider tradings.</p> <p>I also use https://finviz.com/.</p>"},{"location":"financial/stock/#behavior-economics","title":"Behavior Economics","text":"<p>This topic is really interesting. I may able to document more later.</p>"},{"location":"fpga/bitstream/","title":"FPGA Bitstream Explained","text":"Version History Date Description Sep 18, 2020 add github link and usenix paper Dec 20, 2019 Update Oct 24, 2019 Created <p>The proof-of-concept code to decode Xilinx bitstream is here: https://github.com/lastweek/fpga_decode_bitstream.</p> <p>USENIX Security 2020 has a paper on decrypting Xilinx bitstream. They find a vulnerability in the 7-series chip and in turn able to decrypt a fully encrypted bitstream. WHAT A HACK!</p>"},{"location":"fpga/bitstream/#introduction","title":"Introduction","text":"<p>An FPGA bitstream can configure an FPGA. A bitstream includes the description of the hardware logic, routing, and initial values for both registers and on-chip memory (e.g., LUT). The common believe is that a bitstream has vendor-specific format thus cannot be reversed or understood. This is partially true.</p> <p>A bitstream file is more than the bits to configure an FPGA, it also has certain human-readable fields to describe those bits. In fact, it has an assembly-like instruction set to describe the FPGA configuration process. This note is trying to walk through this.</p> <p>At a high-level, a bitstream file is similar to an executable program. Analogous to the ELF format, a bistream has its own format to describe the contents. Note, the file format is publicly documented 1. Thus, you can analyze the contents of a bitstream file, meaning you can understand the steps taken to configure the FPGA. The un-documented part is the bits mapping: the format of the configuration bits, especially how the bitstream bits map to specific on-chip LUTs, wires etc. Think this way: given some assembly instructions, you can simply understand that, say some assembly instructions are doing Addition on certain registers, however, the instructions do not specify which registers they operate on.</p> <p>As a normal FPGA user, you mostly do not need to understand neither of these. You only need to understand this if you are planning to do bitstream readback, preemption scheduling, or similar stuff.</p> <p>After reading this note, I hope you could understand that a bitstream file is just a sequence of instructions and data. Nothing fancy.</p> <p>The FPGA chip usually has a simple state machine module to accept and parse the bitstream, then configure the chip (ICAP in Xilinx). As we mentioned earlier, the bistream file format is partially public, the mapping between the bitstream configuration bits and the actual physical resource is undocumented.</p>"},{"location":"fpga/bitstream/#bistream-related-files","title":"Bistream Related Files","text":"<p>In a normal flow, Vivado only generates a simple <code>.bit</code> file. When you click \u201cProgram Device\u201d, Vivado will use this file to configure your FPGA.</p> <p>In addition to generating this file, Vivado is capable of generating a bunch other files. You can find a complete coverage in this link. We give a high level summary here. Most of the files have the same content and have similar file size. For instance, the difference between a <code>.rbt</code> and a <code>.bit</code> is that the former one is in ASCII format while the latter is in binary format, but they have the same contents. As for a <code>.bit</code> and a <code>.bin</code> file, the latter does not have some ASCII headers at the beginning of the file.</p> <p><code>.ll</code>, the logical link file, is very interesting. It tells you the mapping between user logic and the actual bit offset in the bistream file data section. This file can be used to aid preemption scheduling. However, note that, this file only documents a very small part of the mapping. To the best of my knowledge, I think only the registers, on-chip memory are documented, but the routing information is missing. Thus, this file can help reserve engineer bitstream data section to some extend, but not full of it. Prjxray is an open source project working on cracking everything on 7-series FPGA.</p>"},{"location":"fpga/bitstream/#details","title":"Details","text":"<p>We use <code>.rbt</code> and <code>.bit</code> to demonstrate the file format. Note that they are essentially the same thing, except the former in human-readable ASCII format.</p> <p>The target board is VCU118, the one used by many cloud vendors.</p> <p>The following snippt is the first few lines of the <code>.rpt</code> file. The first few lines are human-readable ASCII contents describing some general information about the bitstream. Starting from line 8 is the actual bitstream file contents. Note that the <code>.bin</code> file starts directly from line 8, no general header info is attached. The interesting part is the 1s and 0s. Unless otherwise noted, when we refer to bitstream format, we focus on the 1s and 0s only and omit any general ASICC information headers.</p> <pre><code>Xilinx ASCII Bitstream\nCreated by Bitstream 2018.3 SW Build 2405991 on Thu Dec  6 23:36:41 MST 2018\nDesign name:    base_mb_wrapper;UserID=0XFFFFFFFF;Version=2018.3\nArchitecture:   virtexuplus\nPart:           xcvu9p-flga2104-2L-e\nDate:           Wed Nov 20 04:13:05 2019\nBits:           641272864\n11111111111111111111111111111111\n11111111111111111111111111111111\n11111111111111111111111111111111\n...\n</code></pre> <p>Note that each line has 32 bits, thus 4 bytes. In Xilinx bistream format, each four bytes is a packet (analogous to CPU instruction). Each packet has certain format, it could be a special header packet, or a normal data packet. The header packet follows a simple assembly-like instruction set to dictate the configuration process. The bitstream file is a sequence of these four bytes packets. </p> <p>Why it sounds so complicated, a sequence of instructions?! I think the short answer is that configuraing FPGA is not an easy task, and any wrong doings may permanently harm the chip. Natually, the designer would have a on-chip state machine to control the configuration process, not only to control the whole process but also to ensure safety.</p> <p>Each Xilinx FPGA has an on-chip configuration packet processor. All configuration methods such as JTAG, SelectMAP, ICAP merge into this final narrow bridge to carry out the configuration. The configuration packet processor has many internal registers (similar to x86 RAX, CRn, MSR registers). The bitstream usually interact with one of the registers at a time to do one thing. For a more detailed explanation, check out this blog, and UG570 chapter 9.</p> <p>To this end, a bitstream consits of three parts:</p> <ul> <li>1) Header packets to prepare the configuration process.</li> <li>2) The actual configuration bits in a contiguous sequence of data packets.      AN write to the <code>FDRI</code> register marks the beginning of this section.      The length of this section is described by the packet following the FDRI header packet.</li> <li>3) Header packets to clean up the configuration process.</li> </ul> <p>The actual configuration bits are the ones determine the FPGA functionality. Note that if you are using an SSI Xilinx device like VCU118, the bitstream format is a bit more complicated. Basically, each die has the above three parts. If an chip has N dies, it will have N above triplet. I have complained about this is not well documented here and here.</p> <p>I wrote a simple C program to parse the <code>.rbt</code> file and associate a human-reable syntax with each line. I didn\u2019t have a complete coverage of the header packet format. The following snippt shows a parsed <code>.rbt</code> file with header removed. Here, <code>0xffffffff</code> has no effect, like a NOP. <code>0x000000bb</code> and <code>0x11220044</code> are special bus detect words. <code>0xaa995566</code> is another special work marking the synchronization status. The last few lines mark the beginning of the configuration bits section.</p> <pre><code>Parsed from base_mb_wrapper.rbt\nffffffff \nffffffff \nffffffff \nffffffff \nffffffff \nffffffff \nffffffff \nffffffff \nffffffff \nffffffff \nffffffff \nffffffff \nffffffff \nffffffff \nffffffff \nffffffff \n000000bb Bus Width Sync\n11220044 Bus Width Detect\nffffffff \nffffffff \naa995566  SYNC\n20000000 \n20000000 \n30022001 Write to regs 17\n00000000 \n30020001 Write to regs 16\n00000000 \n30008001 Write to CMD\n00000000 \n20000000 \n30008001 Write to CMD\n00000007 \n20000000 \n20000000 \n30002001 Write to FAR\n00000000 \n30026001 Write to regs 19\n00000000 \n30012001 Write to regs 9\n38003fe5 Write to regs 1\n3001c001 Write to regs 14\n00400000 \n30018001 Write to IDCODE\n04b31093 IDCODE=4b31093\n30008001 Write to CMD\n00000009 \n20000000 \n3000c001 Write to regs 6\n00000001 \n3000a001 Write to regs 5\n00000101 \n3000c001 Write to regs 6\n00000000 \n30030001 Write to regs 24\n00000000 \n20000000 \n20000000 \n20000000 \n20000000 \n20000000 \n20000000 \n20000000 \n20000000 \n30002001 Write to FAR\n00000000 \n30008001 Write to CMD\n00000001 \n20000000 \n30004000 Write to FDRI\n5065eadc            &lt;- The length of configuration bits, follows a certain format\n00000000            &lt;- The first 4 bytes of the configuration bits!\n</code></pre> <p>Thank you for reading. Hope you enjoyed this post.</p>"},{"location":"fpga/bitstream/#references","title":"References","text":"<ol> <li>Xilinx UG570</li> <li>Xilinx bitstream files</li> <li>Another blog on Xilinx Bitstream Internals </li> <li>Source code to annotate bitstream</li> </ol>"},{"location":"fpga/hls_axi/","title":"High-performance AXI-MM in HLS","text":"<p>My personal experience: the native AXI-MM in HLS is horrible. It fails to generate efficient code. The best practice I found is the use an external Datamover. In HLS, all memory access is made via AXI-Stream. Using AXI-Stream means we can wait the result asynchronously, hence we can deal with long memory access in a more informed manner.</p> <p>Usually using AXI-Stream and Datamover delivers code with II=1.</p>"},{"location":"fpga/hls_axis/","title":"AXI-Stream Usage in HLS","text":"<p>How you should ultilize the AXI-Stream in HLS code to best describe your system.</p>"},{"location":"fpga/language/","title":"On-High-Level-Languages-For-FPGA-Design","text":"Version History Date Description May 31, 2020 Initial <p>With FPGA getting popular among system folks, it\u2019s crucial to pick up the right language for the project. Most folks will not use Verilog/VHDL directly, but use higher level languages like Xilinx HLS, Chisel, SpinalHDL etc.</p> <p>All my dicussions and opinions are based on my own limited experience with FPGA (since Oct 2018), it does not reflect any others\u2019 opinions.</p> <p>In short: for folks new to FPGA and want to start a medium- or large- sized network-oriented academic projects, I would recommend avoid using Xilinx HLS, but use SpinalHDL/Chisel or others instead. Of course, you still need to know a bit bout Verilog/VHDL and all the tools (e.g., Vivado) for the final project packaging.</p> <p>I started using HLS from 2018 Oct. I\u2019ve writtin more than 20K HLS code, including but not limited to RDMA-like modules, partial-reconfiguration ICAP3 controller. I pick it because it is C-like and expressive when first using it. However, along the way, me and my labmates have had a lot issues with HLS, some due to compiler, some are still non-explainable.</p> <p>My own opinions about HLS. The good part:</p> <ol> <li>HLS is easy to pick up and write. Its semantic is similar to C.</li> <li>Good for prototying small project.</li> <li>HLS has several useful AXI-Stream interfaces.</li> <li>HLS has many options allowing us control FPGA resource usage.</li> </ol> <p>The bad part:</p> <ol> <li>HLS is not designed around streaming interface, which is a crutial    part for network oriented projects. It\u2019s dataflow primitive is very restrictive,    hard to construct a system with clear flow.</li> <li>Compiler. Some code pattern generate undefined behaviours, even though totally    correct in turns of logic. Ugh, we have had so much trouble for this part,    and this is the most annoying part.</li> <li>Hard to control BRAM access, i.e., avoid false-dependency and track consistency.</li> <li>Hard to express bits related ops. HLS has <code>range</code> operators, but really hard to write,    a lot macros flying around.</li> <li>Streaming interface is a bit fragile, we found a lot random stucks during runtime    due to buffer issue.</li> <li>For code to be really useful, you have to write in a switch-case state machine way.    There is no difference with a verilog one, but with more complexity, especially    for large-scale projects.</li> <li>Simulation framework is not easy to use, a lot restritions too.</li> </ol> <p>We had a lot trouble with HLS. Not until recently, one of my labmate picked up SpinalHDL, and we found it amazing. I\u2019m not personally writing SpinalHDL code, but I felt it is super expressive and match hardware primitive, physically and mentally. Personally, I would use scala-based ones over HLS for my future projects.</p>"},{"location":"fpga/misc/","title":"Misc","text":"<p>If we want to do relocation, we need to be careful: - identical areas in terms of shape, resource distribution within - proxy logic (i.e., partition pins) location within the PR partition - the wire between proxy logic and static region.     - I think this might cause timing issue?</p> <p>The <code>lock_design</code> in Vivado is to ensure the routing between static region and all the PR partitions remain the same.</p> <p>Proxy Logic and Bus Macro - S1: Relocation of reconfigurable modules on Xilinx FPGA - S2: A Highly Flexible Reconfigurable System on a Xilinx FPGA</p> <p>Expansion of <code>CONTAIN_ROUTING Area</code></p>"},{"location":"fpga/pr/","title":"Morphous (Dynamic-sized) Partial Reconfiguration","text":"Version History Date Description Feb 6, 2020 Created <p>Traditional partital reconfiguration (PR) is limited to using fix-sized PR regions. With one particular static bitstream, users are restricted to only have few pre-defined PR regions. If you wish to extend the PR region size, a whole chip reprogram is needed to burn a new static bitstream.</p> <p>This practice is suggested by FPGA vendors, and there are reasons behind it.</p> <p>However, during our experiment, we found that it is possible to have dynamic-sized PR regions with one static design. The mechanism is quite straightforward with some simple hacks.</p> <p>I will use a MicroBlaze-based design to demonstrate the approach with a VCU118 board. Stay tuned.</p>"},{"location":"fpga/scratch/","title":"Scratch Commands","text":"<pre><code>get_property LOC [get_cells count_out_OBUF[3]_inst]\n\nget_property ROUTE $net\n\nThis returns a list of *nodes*. We can also see this in the GUI.\n% get_property ROUTE [get_nets inst_count/count_out[0]]\n\nManually lock a route:\nset_property FIXED_ROUTE [get_property ROUTE [get_nets inst_count/count_out[0]]] [get_nets inst_count/count_out[0]]\n</code></pre>"},{"location":"fpga/setup_hold/","title":"Setup and Hold Time","text":"<p>This is a few pages from the Digital Design and Computer Architecture book. It is well written and has explained the setup/hold feature so well.</p> <p>Link: http://lastweek.io/pubs/setup_hold.pdf</p>"},{"location":"fpga/vivado/","title":"Vivado Practice","text":"Version History Date Description Nov 5, 2019 More stuff Nov 4, 2019 Add UG903 Oct 31, 2019 Happy Halloween Sep 20, 2019 Created"},{"location":"fpga/vivado/#cheatsheet","title":"Cheatsheet","text":""},{"location":"fpga/vivado/#partition-pins","title":"Partition Pins","text":"<p>The partition pins are inserted by Vivado at the boundary of a PR region. <code>PartPin</code> is short for Partition Pins. <code>PPLOC</code> is short for Partpin LOC.</p> <p>Get the list of partition pins: <pre><code>get_pplocs -pins [get_pins -hier *]\n</code></pre></p> <p>Partition pin (seems) map to a NODE: <pre><code>% report_property [get_pplocs -pins [get_pins XXX]]\n% report_property [get_pplocs -pins [get_pins inst_count/count_out[0]]]\n\nINFO: [Vivado 12-4841] Found PartPin: INT_X17Y790/NN1_E_BEG3\nProperty           Type    Read-only  Value\nBASE_CLOCK_REGION  string  true       X0Y13\nCLASS              string  true       node\n</code></pre></p>"},{"location":"fpga/vivado/#pblocks","title":"Pblocks","text":""},{"location":"fpga/vivado/#semantic-of-exclude_placement","title":"Semantic of <code>EXCLUDE_PLACEMENT</code>","text":"<p>The document describe this as: Pblock property that prevents the placement of any logic not belonging to the Pblock inside the defined Pblock range.</p> <p>During my own simple experiment, I found that even Vivado will not place other logics into the Pblock, the routes of static region can still go across pblock.</p>"},{"location":"fpga/vivado/#semantic-of-contain_routing","title":"Semantic of <code>CONTAIN_ROUTING</code>","text":"<p>References: UG909 and UG905.</p> <p>The contained routing requirement of RP Pblocks for UltraScale and UltraScale+ devices has been relaxed to allow for improved routing and timing results. Instead of routing being confined strictly to the resources owned by the Pblock, the routing footprint is expanded.</p> <p>Note that this option is enabled by default. When this option is enabled, 1) not all interface ports receive a partition pin, 2) the RP will use routing resources outside its confined area. This is annonying in some way.</p> <p>If this option is disabled, the implications are: 1) each interface port (per bit) receivces a partition pin, 2) RP will only resources confined to its pblocks, 3) the generated PR bitstream will be smaller, 4) <code>hd_visual/</code> will not be generated.</p> <p>However, this option does not prevent routings from the static region from crossing RPs.</p> <p>This command is useful when you want to do some hacking about Partition Pins. Actually, you can also do this via GUI.</p> <pre><code>set_param hd.routingContainmentAreaExpansion false\n</code></pre> <p>But you wouldn\u2019t believe that: Static routing is still allowed to use resources inside of the Pblock. The implication is also obvious: all PR bitstreams and even blank bitstream will also have the static routing, if their targeted Pblocks happen to have static routing in the first place. This is also why we will need the static bitstream as the base to do PR bitstream generation.</p>"},{"location":"fpga/vivado/#clear-rm-and-lock-down-static","title":"Clear RM and Lock Down Static","text":"<p>These commands clear out the Reconfigurable Module logics from the whole design and then lock down the static region and static routing. (Reference: UG947)</p> <pre><code>update_design -cell XXX -black_box\n\nlock_design -level routing\n</code></pre>"},{"location":"fpga/vivado/#routing","title":"Routing","text":""},{"location":"fpga/vivado/#get-the-routing-of-a-net","title":"Get the routing of a net","text":"<pre><code>set net [get_nets XXX]\nget_property ROUTE $net\n</code></pre>"},{"location":"fpga/vivado/#lock-the-routing-of-a-net","title":"Lock the routing of a net","text":"<p>We need to lock both the net and the connected cells. Reference is UG903.</p> <p>Following commands lock a route of a net. This net is already routed. You could run one by one. After execution, the route will become dashed (means locked). Replace the net name with your interested one. <pre><code>set net [get_nets inst_count/count_out[0]]\nget_property ROUTE $net\nset_property FIXED_ROUTE [get_property ROUTE $net] $net\n\nset_property is_bel_fixed 1 [get_cells XXX]\nset_property is_loc_fixed 1 [get_cells XXX]\n</code></pre></p>"},{"location":"fpga/vivado/#manual-routing","title":"Manual routing","text":"<p>A great GUI-based manual routing tutorial can be found at UG986 Lab 3. The last step of manual routing, of course is to lock down the LOC and set <code>FIXED_ROUTE</code>.</p> <p>But how can we manually route an unrouted net? The difficulty is that we need to manually find out all the connection nodes/tiles etc.. This applies to LOC placement as well.</p>"},{"location":"fpga/vivado/#read-the-docs","title":"Read-the-docs","text":"<p>Basic</p> <ul> <li>UG912 Vivado Properties Reference Guide<ul> <li>Excellent resource on explaining cell, net, pin, port, and so on.</li> <li>Differentiate <code>Netlist Objects</code> and <code>Device Resource Objects</code>.<ul> <li><code>Netlist Objects</code><ul> <li><code>pin</code>: A pin is a point of logical connectivity on a primitive or     hierarchical cell. A pin allows the contents of a cell to be abstracted away,     and the logic simplified for ease-of-use. A pin is attached to a cell and can be connected to pins on other cells by a net.     <code>get_pins -of [get_cells XXX]</code>. <code>get_pins XXX</code></li> <li><code>port</code>: A port is a special type of hierarchical pin, providing an external connection point at the     top-level of a hierarchical design, or an internal connection point in a hierarchical cell or     block module to connect the internal logic to the pins on the hierarchical cell. </li> <li><code>cell</code>: A cell is an instance of a netlist logic object, which can either be a leaf-cell or a hierarchical     cell. A leaf-cell is a primitive, or a primitive macro, with no further logic detail in the netlist.     A hierarchical cell is a module or block that contains one or more additional levels of logic,     and eventually concludes at leaf-cells. .. cells have PINs which are connected to NETs to define the external     netlist\u2026 The CELL can be placed onto a BEL object in the case of basic logic such as flops, LUTs, and     MUXes; or can be placed onto a SITE object in the case of larger logic cells such as BRAMs and DSPs.</li> <li><code>net</code>: A net is a set of interconnected pins, ports, and wires. Every wire has a net name, which     identifies it. Two or more wires can have the same net name. All wires sharing a common net     name are part of a single NET, and all pins or ports connected to these wires are electrically connected. ..     In the design netlist, a NET can be connected to the PIN of a CELL, or to a PORT. ..     As the design is mapped onto the target Xilinx FPGA, the NET is mapped to routing     resources such as WIREs, NODEs, and PIPs on the device, and is connected to BELs through     BEL_PINs, and to SITEs through SITE_PINs. </li> <li><code>pblock</code>: A Pblock is a collection of cells, and one or more rectangular areas or regions that specify     the device resources contained by the Pblock. Pblocks are used during floorplanning     placement to group related logic and assign it to a region of the target device.<ul> <li> Example create_pblock Pblock_usbEngine add_cells_to_pblock [get_pblocks Pblock_usbEngine] [get_cells -quiet [listusbEngine1]] resize_pblock [get_pblocks Pblock_usbEngine] -add {SLICE_X8Y105:SLICE_X23Y149} resize_pblock [get_pblocks Pblock_usbEngine] -add {DSP48_X0Y42:DSP48_X1Y59} resize_pblock [get_pblocks Pblock_usbEngine] -add {RAMB18_X0Y42:RAMB18_X1Y59} resize_pblock [get_pblocks Pblock_usbEngine] -add {RAMB36_X0Y21:RAMB36_X1Y29} </li> </ul> </li> </ul> </li> <li><code>Device Resource Objects</code><ul> <li><code>BEL</code>: 1) leaf-level cells from the netlist design can be mapped onto bels on the target part     2) Bels are grouped in sites. 3) Each bel has bel_pins that map to pins on the cells.     4) <code>get_bels -of [get_cells XX]</code>, <code>get_bels -of [get_nets XX]</code>, and so on.</li> <li><code>BEL_PIN</code>: 1) a pin or connection point on a BEL object. 2) BEL_PIN is a device object,     associated with netlist objects such as the PIN on a CELL, which is the connection point for the NET.     3) <code>get_bel_pins -of_objects [get_pins -of [get_cells XXX]]</code></li> <li><code>TILE</code></li> <li><code>SITE</code></li> <li><code>NODE</code></li> <li><code>WIRE</code></li> <li><code>PIP</code></li> </ul> </li> </ul> </li> <li><code>CONTAIN_ROUTING</code>: The <code>CONTAIN_ROUTING</code> property restricts the routing of signals contained within a Pblock to use routing resources within the area defined by the Pblock. This prevents signals inside the Pblock from being routed outside the Pblock, and increases the reusability of the design.<ul> <li>This is useful when you are trying to do advanced PR hacks.</li> </ul> </li> </ul> </li> <li>UG835 Vivado TCL Reference Guide<ul> <li>aka. Vivado TCL Man Page. Read this with the above UG912.</li> </ul> </li> <li>UG894 Vivado Using TCL scripting<ul> <li>Get you started with Vivado TCL</li> </ul> </li> <li> <p>UG903 Using Constraints</p> <ul> <li>About Xilinx XDC files. You will need to understand UG912 first.</li> <li>Physical Constraints<ul> <li><code>DONT_TOUCH</code>. Prevent netlist optimizations. 1) prevent a net from being optimized away. 2) Prevent merging of manually replicated logic.</li> <li>Placement constraints</li> <li>Routing constraints</li> </ul> </li> </ul> </li> <li> <p>Book: Practical Programming in Tcl and Tk</p> </li> </ul> <p>Partial Reconfiguration Related</p> <ul> <li>UG909 Partial Reconfiguration<ul> <li><code>Partition Pins</code><ul> <li>Interface points called partition pins are automatically created within the Pblock ranges defined for the Reconfigurable Partition. These virtual I/O are established within interconnect tiles as the anchor points that remain consistent from one module to the next.</li> <li>In UltraScale or UltraScale+ designs, not all interface ports receive a partition pin. With the routing expansion feature, as explained in Expansion of <code>CONTAIN_ROUTING</code> Area, some interface nets are completely contained within the expanded region. When this happens, no partition pin is inserted; the entire net, including the source and all loads, is contained within the area captured by the partial bit file. Rather than pick an unnecessary intermediate point for the route, the entire net is rerouted, giving the Vivado tools the flexibility to pick an optimal solution.</li> <li> Exmaple set_property HD.PARTPIN_LOCS INT_R_X4Y153 [get_ports ] set_property HD.PARTPIN_RANGE SLICE_X4Y153:SLICE_X5Y157 [get_ports ] set_property HD.PARTPIN_RANGE {SLICE_Xx0Yx0:SLICE_Xx1Yy1 SLICE_XxNYyN:SLICE_XxMYyM} [get_pins /*] <li>These pins can be manually relocated and locked.</li> <li>UG905 Hierarchical Design<ul> <li>Add the <code>CONTAIN_ROUTING</code> property to all OOC Pblocks. Without this property, <code>lock_design</code> cannot lock the routing of an imported module because it cannot be guaranteed that there are no routing conflicts</li> </ul> </li>"},{"location":"fpga/vivado/#some-ips","title":"Some IPs","text":"<ul> <li>UG947 has the sample code for the PR Controller IP<ul> <li>It does not support simulation. Thus we can not probe any ICAP related signals.</li> </ul> </li> <li>Ultrascale+ SEM does not have any useful ICAP usage signals in Simulation.</li> <li>xapp1230 has some TCL scripts to perform JTAG readback.</li> </ul>"},{"location":"general_log/0719/","title":"Jul 2019","text":""},{"location":"general_log/0719/#0727-sat","title":"0727 Sat","text":"<p>bug fixed, we need to do the \u201cprep_new_page\u201d before return the page back into our lists. Obviously, pages in our lists are in \u201callocated\u201d state.</p> <p>Okay. Eval perf also. Looks like the direct invocation of cb_alloc_zero_page is not good..</p> <p>Although the perf stat show that using pgadvance help to reduce the handlemmfault overhead by 15%, the actual runtime is the same.. weird.</p>"},{"location":"general_log/0719/#0726-friday","title":"0726 Friday","text":"<p>Stuck at the BUG: bad mm counter and <code>print_bad_pte</code>. Issues identified: looks like I must use pcp lists?</p>"},{"location":"general_log/0719/#0725","title":"0725","text":"<p>HA. I leaned about <code>perf lock</code>, which requies a kernel with <code>CONFIG_LOCKDEP</code> and <code>CONFIG_LOCK_STAT</code>. Not sure exactly how these options work, but they should insert some code inside each lock acquire and release. Anyway, with <code>perf lock</code>, we are able to know what specific locks are hot. This is fantastic.</p> <p>Note that normal <code>perf record -e 'cycles:k'</code> can tell use how much time is spent on <code>spin_lock</code>, but it does not say how much time each specific lock uses. Cool.</p> <p>Ah, side note, <code>make nconfig</code> is really powerful!! Even though I\u2019ve been playing with Linux for many years, I haven\u2019t actually played with linux config manually.</p> <p>Tried once. Our spinlock for pgadvance list shouldn\u2019t be the issue. Now disable it and reboot.</p> <p>254 pg 252 nopg</p> <p>37.140</p>"},{"location":"general_log/0719/#0724","title":"0724","text":"<p>Bagel Day.</p> <p>First replot the figrue, adding an avg/95P/99P figure. Very long tails. Yeah! </p> <p>Then tune page advance. The key is to find a not busy CPU. I\u2019m first trying Round-Robin.</p> <p>Try TF Cifar. First run without pgadvance, see how the first 100 step performs in different runs. They seem to be very stable. <pre><code>1)\n    step = 100 (167.432 sec)\n2)\n    step = 100 (168.021 sec)\n    step = 200 (167.467 sec)\n3)\n    step = 100 (167.903 sec)\n</code></pre></p> <p>DAMN. Forgot to turn off huge page. Now use <code>perf</code> to make sure <code>do_anonymous_page</code> got enough cycles..</p> <p>22/23 down, no pgadvance, 163, 161, 161 22/23 down, no pgadvance, no perf, 159</p>"},{"location":"general_log/0719/#0723","title":"0723","text":"<p>11:59pm</p> <p>End of day. Learned how to plot Violin. Very long tail, and does not scale well even with PCP opt!</p> <p> </p> <p>9pm</p> <p>I\u2019m using my own benchmark to measure buddy allocator. I\u2019m testing order-0 alloc performance. Something weird happen during test. The 16<sup>th</sup> line is very costly. And after that, suddenly the perf improves nealy 50%. I\u2019m reporting CPU cycles, CPU frequency change shouldn\u2019t matter, right?</p> <p>Linux has Per-CPU Pages (pcp), which is intended to optimize 0-order allocation. In my test case, each CPU keep 7 free pages. The patten is reflected in the measurement. Note that, the refill is sync.</p> <pre><code>\"\"\" (latency in CPU cycles. 2.4GHz Xeon E5 v3) \"\"\"\n...\n[ 1043.789257] idx=11956    order=0        latency=3128\n[ 1043.789257] idx=11957    order=0        latency=376 \n[ 1043.789258] idx=11958    order=0        latency=376 \n[ 1043.789258] idx=11959    order=0        latency=368 \n[ 1043.789258] idx=11960    order=0        latency=376 \n[ 1043.789259] idx=11961    order=0        latency=400 \n[ 1043.789259] idx=11962    order=0        latency=384 \n[ 1043.789260] idx=11963    order=0        latency=3080\n[ 1043.789260] idx=11964    order=0        latency=408 \n[ 1043.789260] idx=11965    order=0        latency=400 \n[ 1043.789261] idx=11966    order=0        latency=392 \n[ 1043.789261] idx=11967    order=0        latency=360 \n[ 1043.789262] idx=11968    order=0        latency=360 \n[ 1043.789262] idx=11969    order=0        latency=376 \n[ 1043.789262] idx=11970    order=0        latency=2992\n[ 1043.789263] idx=11971    order=0        latency=29930\n[ 1043.789263] idx=11972    order=0        latency=171\n[ 1043.789264] idx=11973    order=0        latency=156\n[ 1043.789264] idx=11974    order=0        latency=177\n[ 1043.789264] idx=11975    order=0        latency=174\n[ 1043.789265] idx=11976    order=0        latency=174\n[ 1043.789265] idx=11977    order=0        latency=1419\n[ 1043.789265] idx=11978    order=0        latency=156\n[ 1043.789266] idx=11979    order=0        latency=174\n[ 1043.789266] idx=11980    order=0        latency=171\n[ 1043.789267] idx=11981    order=0        latency=171\n[ 1043.789267] idx=11982    order=0        latency=171\n[ 1043.789267] idx=11983    order=0        latency=156\n[ 1043.789268] idx=11984    order=0        latency=1362\n[ 1043.789268] idx=11985    order=0        latency=174\n[ 1043.789269] idx=11986    order=0        latency=168\n[ 1043.789269] idx=11987    order=0        latency=156\n[ 1043.789269] idx=11988    order=0        latency=168\n[ 1043.789270] idx=11989    order=0        latency=174\n[ 1043.789270] idx=11990    order=0        latency=171\n[ 1043.789270] idx=11991    order=0        latency=1266\n...\n</code></pre>"},{"location":"general_log/0819/","title":"Aug 2019","text":""},{"location":"general_log/0819/#aug-14","title":"Aug 14","text":"<p>Back to sweet WL. Helping out for asplos submission. I was trying to run Octopus. Its cmake report that <code>MPI_C</code> is missing, so I run <code>yum install openmpi-devel</code>. However, this failed due to some broken dependency on <code>rdma-core</code> and others. It seems these packages have been updated by mlx-ofed.. what a mess.</p>"},{"location":"general_log/0919/","title":"Sep 2019","text":"<p>Log range 0920 - 0930.</p>"},{"location":"general_log/0919/#92619","title":"9/26/19","text":"<p>Check out PR today.</p> <pre><code>create_pblock\n</code></pre>"},{"location":"general_log/0919/#92519","title":"9/25/19","text":"<p>Singularity and Helios</p> <pre><code>- I've been reading Singularity today. It has many insights on extension and isolation. Something we might be interested: 1) application has a manifest. We may want to have a similar one for each FPGA app. 2) Seal OS architecture, where the OS or app remain invariant after install. This is the nature of FPGA..\n- Also, I think it's important to figure out a way to do IP sharing. The same thing is also beneficial for PR.\n- Scheduling: preemptive or non-preemptive..\n</code></pre> <p>Thoughts after reading Singularity papers     - The contract-based channel is promising     - The manifest-based program approach is also promising. Similarly, the AmoghOS has some Resource Vector associated with each FPGA application. I think it\u2019s valid and beneficial to attach such a spec with FPGA applications.</p> <p>I think I need to think more on the applications. Cannot wait till its too late!</p> <p>If an app is too big to fit into a FPGA, can we do \u201cbitstream\u201d swap?     - App need to conform to some sort of model (e.g., msg-based)     - Fast PR     - Must be slow from app\u2019s point, but a solution.,</p>"},{"location":"general_log/0919/#0923-monday","title":"0923 Monday","text":"<p>Continue working on FPGA stuff. Let\u2019s focus on writing possible design ideas. I should also read some related work. </p>"},{"location":"general_log/0919/#0921-weekends","title":"0921 Weekends","text":"<p>Spent some time reading ATC papers, came across quite some interesting ones.</p> <ul> <li>Distributed actor runtime<ul> <li>I came across actors many times recently. Like the iPipe, ST-Accel.</li> <li>There are some open-source frameworks. Erlang and akka.</li> <li>It\u2019s model that I should consider in the future</li> </ul> </li> <li>SSD Related<ul> <li>Alibaba has a study paper about SSD reliability in their datacenters.</li> <li>Amy Tai has an interesting paper, they enable distributed storage systems to run on high error rate SSDs. Traditionally, if an SSD has a high error rate, it will impact local file system perf thus higher level system perf. Their idea is neat: utilize the remote replicas to recover local SSD errors! Thus they could use those SSDs!</li> <li>File system on SSD study. Paper from Toronto. I haven\u2019t read it yet.</li> </ul> </li> </ul>"},{"location":"general_log/0919/#0920-fri","title":"0920 Fri","text":"<p>Well.. I should continue on this.</p> <p>We moved to UCSD recently. Everything is setup except desktop and server stuff.</p> <p>Started using F1 recently. Porting our code from VCU108 to VCU118. The migration between boards and between different vivado versions is a REAL headache. (VCU108 -&gt; VCU118 &amp;&amp; 2018.2 -&gt; 2018.3)</p> <p>So for those TCL scripts generated by vivado, i found it will use hardcoded IP version. Upgrading vivado means possibly updated IP versions, thus broken TCL scripts. I\u2019ve found a way to workaround. But if the IP interface changed, it has to be modified manually.</p> <p>Many things left on the table - Merge LegoOS code - Think about and finish design doc - Tons of papers to read</p> <p>Life wise: sea is nearby, although UCSD gym sucks, it has jiu jitsu courses.</p> <p>Let\u2019s do the work.</p> <ul> <li>Try make PCIe work first. Checking out xtp444, the VCU118 PCIe reference design.</li> </ul> <p>Okay. Finished patching the XDC file, basically went through the example designs and check couple design docs, same old shit. Synthesis can pass. Implementation failed because Disk is full (?!).</p> <p>Anyway, next step is: - Resize Disk size - Run implementation, check it can pass - Run simulation, functionality check of RDM! </p>"},{"location":"general_log/1019/","title":"Oct 2019","text":"<p>Writing a research journal here has its advantages: simple and version-control. But I\u2019m moving to Google Docs.</p>"},{"location":"howto/qemu-iommu/","title":"How to add an IOMMU device in QEMU?","text":"Version History Date Description Aug 2, 2021 Initial <p>TL;DR This blog explains how QEMU simulate IOMMU device and how you can add one of your own. We will take a brief read of Intel IOMMU, ARM SMMU, and Virtio-IOMMU. Finally we will add a new one to RISC-V virt machine mode.</p> <p>The plan is to write this doc at the end of Sep 2021.</p>"},{"location":"lego/driver/ib/","title":"Infiniband Subsystem","text":""},{"location":"lego/driver/ib/#current-status","title":"Current Status","text":"<p>Lego\u2019s IB stack is ported based on <code>linux-3.11.1</code>. We ported:</p> <ul> <li><code>ib_core</code></li> <li><code>mlx4_ib</code></li> <li><code>mlx4_core</code></li> </ul> <p>Lego does not support uverbs. At the time of writing, Lego IB stack has only been tested on <code>Mellanox Technologies MT27500 Family [ConnectX-3]</code>.</p>"},{"location":"lego/driver/ib/#random-summary","title":"Random summary","text":"<p>The stack is SUPER complex, a lot data structures and pointers fly all over. Good thing is the whole stack is layered clearly.</p> <p>Top down</p>"},{"location":"lego/driver/ib/#ib_core","title":"<code>ib_core</code>","text":"<ul> <li>IB core code is in <code>driver/infiniband/core</code>, which exposes the major IB API to both user and kernel applications. Inside, it has two parts. The first part is function callback, that call back to underlying device-specific functions. The second part is the management stack, including communication manager (cm), management datagram (mad), and so on.</li> <li>In IB, each port\u2019s QP0 and QP1 are reserved for management purpose. They will receive/send MAD from/to subnet manager, who typically runs on switch. All the IB management stuff is carried out by exchanging MAD.</li> <li>There are several key data structures: ib_client, ib_device, and mad_agent. MAD, CM, and some others are ib_client, which means they use IB device, and will be called back whenever a device has been added. mad_agent is something that will be called back whenever a device received a MAD message from switch (see <code>ib_mad_completion_handler()</code>). A lot layers, huh?</li> <li><code>ib_mad_completion_handler()</code>: we changed the behavior of it. we use busy polling instead of interrupt. Originally, it will be invoked by mlx4_core/eq.c</li> </ul>"},{"location":"lego/driver/ib/#mlx4_ib-and-mlx4_core","title":"<code>mlx4_ib and mlx4_core</code>","text":"<ul> <li> <p>mlx4_core is actually the Ethernet driver for Mellanox NIC device (drivers/net/ethernet/mellanox/hw/mlx4), which do the actual dirty work of talking with device. On the other hand, mlx4_ib is the glue code between ib_core and mlx4_core, who do the translation.</p> </li> <li> <p>A lot IB verbs are ultimately translated into <code>fw.c __mlx4_cmd()</code>, which actually send commands to device and get the result. There are two ways of getting result: 1) polling: after writing to device memory the command, the same thread keep polling. 2) sleep and wait for interrupt. By default, the interrupt way is used (obviously). But, at the time of writing (Aug 20, 2018), we don\u2019t really have a working IRQ subsystem, so we use polling instead. I\u2019m still a little concerned that without interrupt handler, we might lose some events and the NIC may behavave incorrectly if interrupts are not handled.</p> </li> </ul>"},{"location":"lego/driver/ib/#init-sequence","title":"Init Sequence","text":"<ol> <li>Init PCI subsystem, build data structures</li> <li>Core IB layer register <code>ib_client</code></li> <li><code>mlx4_init()</code>: register PCI driver, provide a callback</li> <li><code>__mlx4_init_one()</code>: initialize the hardware itself, register interrupt handler.</li> <li><code>mlx4_ib_init()</code>: allocate a ib_device, and register, which will callback through all <code>ib_client</code> registered at step 1.</li> </ol> <p>\u2013 Yizhou Shan Created: Aug 20, 2018 Last Updated: Aug 20, 2018</p>"},{"location":"lego/driver/pci/","title":"PCI Subsystem","text":""},{"location":"lego/driver/pci/#what-we-have-ported-so-far","title":"What we have ported so far","text":"<ul> <li>PCI data structures such as <code>pci_dev</code>, <code>pci_bus</code>, and so on.</li> <li>Mechanism to scan bus and build data structures during boot. Performed by <code>pci_scan_root_bus()</code>, and most code is in <code>driver/pci/probe.c</code></li> </ul>"},{"location":"lego/driver/pci/#unfinished-business","title":"Unfinished business","text":"<ul> <li>Ways to go through all PCI device.</li> <li><code>pci_init_capabilities()</code>: for each PCI device</li> <li><code>pci_fixup_device()</code>: a lot quicks, maybe not useful</li> <li><code>pcie_aspm_init_link_state()</code>: PCIe link state</li> <li><code>pci_iov_bus_range</code>: all SR-IOV support</li> </ul> <p>\u2013 Yizhou Shan Created: July 5, 2018 Last Updated: July 5, 2018</p>"},{"location":"lego/kernel/boot/","title":"Notes on GRUB2 and Boot Sequence","text":"Version History Date Description Mar 31, 2020 Copied from https://github.com/lastweek/source-grub2."},{"location":"lego/kernel/boot/#about-grub2","title":"About GRUB2","text":"<p>GRUB2: https://www.gnu.org/software/grub/manual/grub/grub.html#Introduction</p> <p>Source code: https://github.com/lastweek/source-grub2</p>"},{"location":"lego/kernel/boot/#linux-vs-linux16","title":"linux v.s. linux16","text":"<p>An interesting thing is that there are two ways to load an kernel image in <code>grub.cfg</code>, either <code>linux vmlinuz-3.10.0</code> or <code>linux16 vmlinuz-3.10.0</code>. They have different effects, but not sure what are those differences. I remember only the linux16 one works for me, but not remembering why either. At least on CentOS 7, it\u2019s all linux16.</p> <p>The <code>linux16</code> and <code>initrd16</code> in <code>grub-core/loader/i386/pc/linux.c</code>: <pre><code>GRUB_MOD_INIT(linux16)\n{\n  cmd_linux =\n    grub_register_command (\"linux16\", grub_cmd_linux,\n               0, N_(\"Load Linux.\"));\n  cmd_initrd =\n    grub_register_command (\"initrd16\", grub_cmd_initrd,\n               0, N_(\"Load initrd.\"));\n  my_mod = mod;\n}\n</code></pre></p> <p>The <code>linux</code> and <code>initrd</code> in <code>grub-core/loader/i386/linux.c</code>: <pre><code>static grub_command_t cmd_linux, cmd_initrd;\n\nGRUB_MOD_INIT(linux)\n{\n  cmd_linux = grub_register_command (\"linux\", grub_cmd_linux,\n                     0, N_(\"Load Linux.\"));\n  cmd_initrd = grub_register_command (\"initrd\", grub_cmd_initrd,\n                      0, N_(\"Load initrd.\"));\n  my_mod = mod;\n}\n</code></pre></p>"},{"location":"lego/kernel/boot/#boot-protocol-and-sequence","title":"Boot Protocol and Sequence","text":"<p>This was written for https://github.com/lastweek/source-grub2. I just copied it here.</p> <p>Linux (x86) has a boot protocol, described by https://www.kernel.org/doc/html/latest/x86/boot.html. Essentially, it is a contiguous memory region, just like a big C <code>struct</code>: some fields are filled by kernel duing compile time (<code>arch/x86/boot/tools/build.c</code> and some in code), some fields are filled by GRUB2 during boot time to tell kernel some important addresses, e.g., kernel parameters, ramdisk locations etc.</p> <p>GRUB2 code follows the protocol, and you can partially tell from the <code>grub_cmd_linux()</code> function.</p> <p>Last time I working on this was late 2016, I truly spent a lot investigating how GRUB and linux boot works. I will try to document a bit, if my memory serves:</p> <ol> <li> <p>In the Linux kernel, file <code>arch/x86/boot/header.S</code> is the first file got run after GRUB2. This file is a bit complicated but not hard to understand! It has 3 parts. For the first part, it detects if it was loaded by a bootloader, if not, just by printing an error message and reboot. It the kernel was loaded by a bootloader like GRUB2, the first part will never execute. The bootload will directly jump to the second part. This is part of the boot protocol. For the second part, it lists all the fields described by the boot protocol. And finally the third part is real-mode instructions that got run after the GRUB2 jumo. The starting function is called <code>start_of_setup</code>, which will do some stack checking, and then jump to C code in <code>arch/x86/boot/main.c</code>.</p> </li> <li> <p><code>arch/x86/boot/main.c</code> runs on real-mode, it will do some setup and jump to protected-mode (32-bit). It is running after BIOS but before the actual Linux kernel. Thus this piece of code must rely on BIOS to do stuff, which makes it very unique. The major task of the setup code is to prepare the <code>struct boot_params</code>, which has all the boot information, some of them were extracted from the <code>header.S</code>. The <code>struct boot_params</code> will be passed down and used by many kernel subsystems later on. The final jump happens in <code>arch/x86/boot/pmjump.S</code> <pre><code>        #\n        # Jump to protected-mode kernel, 0x100000\n        # which is the compressed/head_$(BITS).o\n        #\n        jmp     *%eax\n</code></pre></p> </li> <li> <p>Then, we are in <code>arch/x86/boot/compressed/head_64.S</code>. Above pmjump jumps to <code>startup_32</code>, it will enable paging, tweak GDT table etc, setup pagetable, and transition to 64-bit entry point <code>startup_64</code>.  And finally, we are in 64-bit. The final jump will go to <code>arch/x86/kernel/head_64.S</code>. We are close!</p> </li> <li> <p>Now we are in <code>arch/x86/kernel/head_64.S</code>. We are in 64-bit. But some further setup is needed. This part is really low-level and engaging. I would never know I how managed to understand and port all this shit. It setup a lot GDT, IDT stuff, and some pgfault handlers. It turns out those early pgfault handlers are NECESSARY and I remember they played an very interesting role! Finally, this assembly will jump to <code>arch/x86/kernel/head64.c</code>, the C code!</p> <ul> <li>I guess an interesting part is <code>secondary_startup_64</code>. This code is actually run by non-booting CPUs, or secondary CPUs.   After the major boot CPU is up and running (already within <code>start_kernel()</code>), I believe its the <code>smp_init()</code> that will send IPI wakeup interrupts to all present secondary CPUs.   The secondary CPUs will start from real-mode, obviously. Then they will transition from 16bit to 32bit, from 32bit to 64bit. That code is in <code>arch/x86/realmode/rm/trampoline.S</code>!</li> <li><code>arch/x86/realmode</code> is interesting. It uses piggyback technique. All the real-mode and 32bit code are in <code>arch/x86/realmode/rm/*</code>, a special linker script is used to construct the code in a specific way! Think about mix 16bit, 32bit, 64bit code together, nasty!</li> </ul> </li> <li> <p>Hooray, C world. We are in <code>arch/x86/kernel/head64.c</code>. The starting function is <code>x86_64_start_kernel</code>! And the end is the <code>start_kernel</code>, the one in <code>init/main.c</code>.</p> </li> </ol> <p>In all, there are a lot jumps after GRUB2 load the kernel, and its a long road before we can reach <code>start_kernel()</code>. It probably should not be this complex, but the x86 architecture really makes it worse. Happy hacking!</p>"},{"location":"lego/kernel/debug/","title":"Debug Facility in Lego","text":"<p>Lego provides several handy debug helpers to ease our coding pain. We category them by layers, namely 1) <code>Core Kernel</code>, the lowest level of Lego, which is shared by all managers. 2) <code>Processor Manager</code>, which controls processor components. 3) <code>Memory Manager</code>, which controls memory components.</p>"},{"location":"lego/kernel/debug/#core-kernel","title":"Core Kernel","text":"<p><pre><code>void dump_pte(pte_t *ptep, const char *reason);\nvoid dump_page(struct page *page, const char *reason);\n</code></pre> These two helpers will dump a given pte entry or a page. Use this function if you are developing core related to physical memory allocation or pcache.</p> <p><pre><code>void ptdump_walk_pgd_level(pgd_t *pgd);\n</code></pre> This debug helper will dump the whole pgtable ranges. Contiguous page table entries that share the same property will be merged together and will be printed once. Use this function if you are developing code related to user page tables.</p> <p><pre><code>void show_state_filter(unsigned long state_filter, bool print_rq);\nvoid sched_show_task(struct task_struct *p);\nvoid sysrq_sched_debug_show(void);\n</code></pre> This set of functions are debug helpers for local scheduler. They will print all the tasks running in the system, and detailed information about percpu <code>runqueue</code>. Use this set of functions if you are developing code related to scheduler.</p>"},{"location":"lego/kernel/debug/#processor-manager","title":"Processor Manager","text":"<p><pre><code>void dump_pcache_meta(struct pcache_meta *pcm, const char *reason);\nvoid dump_pcache_victim(struct pcache_victim_meta *victim, const char *reason);\nvoid dump_pcache_rmap(struct pcache_rmap *rmap, const char *reason);\nvoid dump_pcache_line(struct pcache_meta *pcm, const char *reason);\n</code></pre> These functions dump a given pcache line, a victim line, or a given reserve mapping. The last one will print the pcache line content, which generates a lot messages, you are warned. Use these functions if you are developing pcache or victim cache code.</p>"},{"location":"lego/kernel/debug/#memory-manager","title":"Memory Manager","text":"<p><pre><code>void dump_lego_mm(const struct lego_mm_struct *mm);\nvoid dump_vma(const struct vm_area_struct *vma);\n</code></pre> These two functions are used to dump the virtual address space of a process. Use these functions if you developing process VM related things.</p>"},{"location":"lego/kernel/fpu/","title":"x86 Floating Point Unit","text":"<p>This is not a document about the FPU technology, this is just a simple note on FPU code and my debugging lesson.</p> <p>FPU is heavily used by user level code. You may not use it directly, but glibc library is using it a lot, e.g. the <code>strcmp</code> function. x86 FPU is really another complex thing designed by Intel. Of course its performance is good and widely used, but the legacy compatible feature? Hmm.</p> <p>I would say, without Ingo Molnar\u2019s x86 FPU code rewrite, there is no way for me to easily understand it. The current x86 FPU code is well-written. Even though I don\u2019t quite understand what and why the code is, but I enjoy reading it. The naming convention, the code organization, the file organization, the header files, it is a nice piece of art.</p> <p>Anyway, Lego ported this low-level FPU code from Linux without any change. The porting is painful because it requires a lot other related features. And it also deals with compatible syscalls a little bit. Below I will just briefly list other subsystems that are using FPU, and talk about my thoughts.</p>"},{"location":"lego/kernel/fpu/#boot","title":"Boot","text":"<p>FPU detection and init happen during early boot. You should know the <code>struct fpu</code> is a dynamically-sized structure. The size of it depends on what features the underlying CPU support. Since <code>struct fpu</code> is part of <code>task_struct</code>, that implies <code>task_struct</code> is dynamically-sized too. Apparently, <code>cpu_init()</code> will also callback to init its local FPU.</p>"},{"location":"lego/kernel/fpu/#context-switch","title":"Context Switch","text":"<p>FPU consists a lot registers, and each thread has its own FPU context. However, CPU will not save the FPU registers for us, it is software\u2019s duty to save and restore FPU context properly. FPU context is saved in <code>struct fpu</code>.</p> <p>Thus whenever we switch task, we also need to switch FPU context: <pre><code>__visible struct task_struct *\n__switch_to(struct task_struct *prev_p, struct task_struct *next_p)\n{\n        ..\n        fpu_switch = switch_fpu_prepare(prev_fpu, next_fpu, cpu);\n        ..\n        switch_fpu_finish(next_fpu, fpu_switch);\n        ..\n}\n</code></pre></p>"},{"location":"lego/kernel/fpu/#syscall","title":"SYSCALL","text":"<ul> <li> <p>fork() and clone(): When a new thread or process is created, the FPU context is copied from the calling thread.</p> </li> <li> <p>execve(): When <code>execve()</code> is called, the FPU context will be cleared.</p> </li> <li> <p>exit(): When a thread exit,, FPU will do cleanup based on if <code>eagerfpu</code> or <code>lazyfpu</code> is used.</p> </li> </ul>"},{"location":"lego/kernel/fpu/#exceptions","title":"Exceptions","text":"<p>Like the <code>device not available</code> exception, which may be triggered if lazyfpu is used. Also, <code>do_simd_exception</code> and <code>do_coprocessor_error</code>, which are some math related exceptions.</p>"},{"location":"lego/kernel/fpu/#signal","title":"Signal","text":"<p>Kernel needs to setup a <code>sigframe</code> for user level signal handlers. <code>sigframe</code> is a contiguous stack memory consists the general purpose registers and FPU registers. So signal handling part will also call back to FPU to setup and copy the FPU registers to <code>sigframe</code> in stack.</p>"},{"location":"lego/kernel/fpu/#thoughts","title":"Thoughts","text":"<p>I\u2019ve been debugging this FPU introduced bugs for over a month. And during this month, I\u2019m always not sure if it is FPU\u2019s bug, or some other code that corrupts memory. So I\u2019m lazy to re-port FPU again. But after rule out every other possibilities, I turned back to FPU. At first I did not port all FPU code, cause I don\u2019t think I need all of it.</p> <p>One stupid thing is I forgot to turn on DEBUG_FPU, which should help me in the first place. I kind of lost myself in various engineering work during this debugging. I really need some big context switch in the middle to fresh my mind. Anyway, glad it is all done today (Feb 23), and I\u2019m able to move to next stage.</p> <p>Compatibility is a heavy thing to carry. But it is also a nice thing for marketing. No one can deny the success of Intel on its backward compatibility. Bad for programmers.</p> <p>\u2013 Yizhou Shan Created: Feb 22, 2018 Last Updated: Feb 23, 2018</p>"},{"location":"lego/kernel/grub/","title":"Use GRUB2 to boot Lego","text":"<p>Last Updated: 02/02/2018</p> <p>This document explains: 1) how Lego itself is written to pretend as a Linux kernel, 2) how to boot Lego kernel with GRUB2, 3) GRUB2 configurations specific to Lego.</p>"},{"location":"lego/kernel/grub/#how-lego-pretend-as-a-linux-kernel","title":"How Lego pretend as a Linux kernel","text":"<p>asdsad</p>"},{"location":"lego/kernel/grub/#how-to-config-grub2-for-lego","title":"How to config GRUB2 for Lego","text":"<p>asdsa</p>"},{"location":"lego/kernel/irq/","title":"IRQ","text":"<p>IRQ is majorly ported based on <code>linux-4.4</code>. The decision of porting of whole IRQ stack from linux was made at early stage of Lego, when I\u2019m not so familiar with this stuff. This technique decision has pros and cons.</p> <p>The whole thing is made complicated by having IRQ domain. IRQ domain is introduced to address the multiple interrupt controller issue. And in x86, we kind of have mutiple as well: IO-APIC, REMAP, LAPIC. Although we are not supporting IRQ remap now.</p>"},{"location":"lego/kernel/irq/#init","title":"Init","text":"<ul> <li>The first part of initialization is <code>trap_init()</code> at early <code>setup_arch()</code>.</li> <li>The second major entry point is <code>irq_init()</code> at <code>start_kernel()</code>. This <code>irq_init()</code> is actually a combination of linux\u2019s:<ul> <li><code>early_irq_init()</code>: 1) setup <code>irq_desc[]</code> array, and then call <code>arch_early_irq_init()</code>, which will register two IRQ domains (x86_vector_domain, msi_domain).</li> <li><code>init_IRQ()</code>: is actually a callback to low-level x86 interrupt setup. It mainly setup the desc\u2019s data/chip etc, and register all different handlers.</li> <li>In Lego, you will be able to find all the functionalitis are moved into <code>arch_irq_init()</code>. And, to this point, we have a complete setup.</li> </ul> </li> <li>The third (and last) entry point is <code>smp_prepare_cpus()</code>: <pre><code>smp_prepare_cpus()\n-&gt; apic_bsp_setup()\n   -&gt; setup_local_APIC()\n   -&gt; setup_IO_APIC()\n   -&gt; x86_init.timers.setup_percpu_clockev()\n</code></pre></li> </ul>"},{"location":"lego/kernel/irq/#irq-domain","title":"IRQ Domain","text":"<p>We should have at least 2 or 3 IRQ domains:</p> <ul> <li>x86_vector</li> <li>x86_msi</li> <li>x86_ioapic-N (each ioapic has one)</li> </ul> <p>The first two guys are created during <code>arch_irq_init()</code>. While the latter ioapic ones are created during <code>setup_IO_APIC()</code>. All of them are allocated eventually by <code>__irq_domain_add()</code>, and linked at <code>LIST_HEAD(irq_domain_list)</code>.</p> <p>So....  Lego or Linux maintains its own IRQ numbers, starting from 0 to NR_IRQs. However, this IRQ number MAY not have a identical mapping to hardware\u2019s own IRQ number (let us call it hwirq). Given this, we want to know the mapping between IRQ and hwirq. That\u2019s the purpose of having <code>linear_revmap</code> and <code>revmap_tree</code> within each domain, it is used to translate hwirq to IRQ.</p> <p>Why two different data structures? <code>linear_revmap</code> is fairly simple, an array, which is indexed by hwirq. However, the hwirq maybe very large, we don\u2019t want to waste memory, that\u2019s how we want to use trees.</p> <p>These two can be used together. If we fail to insert into <code>linear_revmap</code>, we insert into tree. During search time, we need to look up both.</p> <p>By default, <code>x86_vector</code> and <code>x86_msi</code> use radix tree only. <code>x86_ioapic-N</code> uses a mix of linear and radix tree.</p> <p>To dump all IRQ domains, call <code>dump_irq_domain_list()</code>, which give you something like this: <pre><code>[  118.308544]  name              mapped  linear-max  direct-max  devtree-node\n[  118.316114]  x86_ioapic-2          24          24           0    \n[  118.322707]  x86_ioapic-1          24          24           0    \n[  118.329299]  x86_ioapic-0          24          24           0    \n[  118.335893]  x86_msi               25           0           0    \n[  118.342486] *x86_vector            40           0           0    \n[  118.349078] irq    hwirq    chip name        chip data           active  type            domain\n[  118.358775]     1  0x00001  IO-APIC          0xffff88107fcae000        LINEAR          x86_ioapic-0\n[  118.368858]     3  0x00003  IO-APIC          0xffff88107fc8f000        LINEAR          x86_ioapic-0\n[  118.378940]     4  0x00004  IO-APIC          0xffff88107fc6e000        LINEAR          x86_ioapic-0\n[  118.389025]     5  0x00005  IO-APIC          0xffff88107fc6f000        LINEAR          x86_ioapic-0\n[  118.399109]     6  0x00006  IO-APIC          0xffff88107fc4e000        LINEAR          x86_ioapic-0\n[  118.409192]     7  0x00007  IO-APIC          0xffff88107fc4f000        LINEAR          x86_ioapic-0\n[  118.419276]     8  0x00008  IO-APIC          0xffff88107fc2e000        LINEAR          x86_ioapic-0\n[  118.429358]     9  0x00009  IO-APIC          0xffff88107fc2f000        LINEAR          x86_ioapic-0\n[  118.439442]    10  0x0000a  IO-APIC          0xffff88107fc0e000        LINEAR          x86_ioapic-0\n[  118.449525]    11  0x0000b  IO-APIC          0xffff88107fc0f000        LINEAR          x86_ioapic-0\n[  118.459609]    12  0x0000c  IO-APIC          0xffff88107fff0000        LINEAR          x86_ioapic-0\n[  118.469692]    13  0x0000d  IO-APIC          0xffff88107fff1000        LINEAR          x86_ioapic-0\n[  118.479776]    14  0x0000e  IO-APIC          0xffff88107fff2000        LINEAR          x86_ioapic-0\n[  118.489860]    15  0x0000f  IO-APIC          0xffff88107fff3000        LINEAR          x86_ioapic-0\n[  118.499943]    24  0x300000  PCI-MSI                      (null)     *     RADIX          x86_msi\n[  118.509833]    25  0x300001  PCI-MSI                      (null)     *     RADIX          x86_msi\n[  118.519722]    26  0x300002  PCI-MSI                      (null)     *     RADIX          x86_msi\n[  118.529612]    27  0x300003  PCI-MSI                      (null)     *     RADIX          x86_msi\n[  118.539501]    28  0x300004  PCI-MSI                      (null)           RADIX          x86_msi\n</code></pre></p>"},{"location":"lego/kernel/irq/#aug-20-2018","title":"Aug 20, 2018","text":"<p>Well, I\u2019ve ported the IRQ stuff at early days of Lego. At that time, I mainly ported the low-level APIC, IO-APIC, and ACPI stuff, along with the upper layer irqchip, irqdesc stuff.</p> <p>These days, I was verifying our IB code and tried to add back mlx4en\u2019s interrupt handler, somehow, there is no interrupt after <code>request_irq()</code>.</p> <p>Two possible reasons: 1) I missed something during PCI setup, 2) underlying APIC and IO-APIC need more work.</p> <p>\u2013 Last Updated: Aug 28, 2018</p>"},{"location":"lego/kernel/kconfig/","title":"Lego Kconfig","text":""},{"location":"lego/kernel/kconfig/#network","title":"Network","text":"<ul> <li>Enable <code>CONFIG_INFINIBAND</code></li> <li>Enable <code>CONFIG_FIT</code></li> <li>Set <code>CONFIG_FIT_INITIAL_SLEEP_TIMEOUT</code>: boot time connection timeout</li> <li>Set <code>CONFIG_FIT_NR_NODES</code>: number of Lego nodes in this run</li> <li>Set <code>CONFIG_FIT_LOCAL_ID</code>: current node id</li> <li> <p>In <code>net/lego/fit_machine.c</code>, modify the <code>lego_cluster_hostnames</code> array to match the machines you are using.</p> </li> <li> <p>Set <code>CONFIG_DEFAULT_MEM_NODE</code> in processor manager</p> </li> <li>Set <code>CONFIG_DEFAULT_STORAGE_NODE</code> if you are running with storage component.</li> </ul> <p>Network configuration is crucial, please make sure all Lego nodes have consistent configurations. Otherwise the system may panic or fail to connect.</p>"},{"location":"lego/kernel/kconfig/#processor","title":"Processor","text":"<ul> <li>Enable <code>CONFIG_COMP_PROCESSOR</code><ul> <li>open <code>.config</code></li> <li>remove line <code># CONFIG_COMP_PROCESSOR is not set</code></li> <li>close <code>.config</code></li> <li>do <code>make</code>, you will see <code>Configure Lego as processor component (COMP_PROCESSOR) [N/y/?] (NEW)</code>, select Y</li> <li>Choose default configuration for all new config options</li> </ul> </li> <li>Enable <code>CONFIG_USE_RAMFS</code> if you are not using storage components</li> </ul>"},{"location":"lego/kernel/kconfig/#memory","title":"Memory","text":"<ul> <li>Enable <code>CONFIG_COMP_MEMORY</code><ul> <li>open <code>.config</code></li> <li>remove line <code># CONFIG_COMP_MEMORY is not set</code></li> <li>close <code>.config</code></li> <li>do <code>make</code>, you will see <code>Configure Lego as memory component manager (COMP_MEMORY) [N/y/?] (NEW)</code>, select Y</li> <li>Choose default configuration for all new config options</li> </ul> </li> <li>Enable <code>CONFIG_USE_RAMFS</code> if you are not using storage components<ul> <li>Set <code>CONFIG_RAMFS_OBJECT_FILE</code>: points to static-linked ELF file that you want to execute.</li> <li>tips: you can put your test code under <code>usr/</code> directory, and a simple <code>make</code> will compile everything under.</li> </ul> </li> </ul>"},{"location":"lego/kernel/kconfig/#run-without-storage-component","title":"Run without Storage Component","text":"<p>To run Lego just with one processor component and one memory component, you need to:</p> <ul> <li>Enable <code>CONFIG_USE_RAMFS</code> at both sides. And in memory side, you need to set the <code>CONFIG_RAMFS_OBJECT_FILE</code>, which points to the ELF binary you want to test.</li> <li>make sure <code>CONFIG_DEFAULT_MEM_NODE</code> at processor component is pointing to memory component\u2019s node id.</li> </ul> <p>A typical code snippet and configuration would be: <pre><code>static const char *lego_cluster_hostnames[CONFIG_FIT_NR_NODES] = {\n        [0]     =       \"wuklab00\",\n        [1]     =       \"wuklab01\",\n};\n</code></pre></p> <pre><code>wuklab00 Processor\n\n#\n# Lego Processor Component Configurations\n#\nCONFIG_COMP_PROCESSOR=y\nCONFIG_CHECKPOINT=y\nCONFIG_MEMMAP_MEMBLOCK_RESERVED=y\n# CONFIG_PCACHE_EVICT_RANDOM is not set\n# CONFIG_PCACHE_EVICT_FIFO is not set\nCONFIG_PCACHE_EVICT_LRU=y\nCONFIG_PCACHE_EVICT_GENERIC_SWEEP=y\n# CONFIG_PCACHE_EVICTION_WRITE_PROTECT is not set\n# CONFIG_PCACHE_EVICTION_PERSET_LIST is not set\nCONFIG_PCACHE_EVICTION_VICTIM=y\nCONFIG_PCACHE_EVICTION_VICTIM_NR_ENTRIES=8\nCONFIG_PCACHE_PREFETCH=y\n\n#\n# Processor DEBUG Options\n#\n\n#\n# Lego Memory Component Configurations\n#\n# CONFIG_COMP_MEMORY is not set\n\n#\n# DRAM Cache Options\n#\nCONFIG_PCACHE_LINE_SIZE_SHIFT=12\nCONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3\n\n#\n# General Manager Config/Debug Options\n#\nCONFIG_DEFAULT_MEM_NODE=1\nCONFIG_DEFAULT_STORAGE_NODE=2\nCONFIG_USE_RAMFS=y\n\n#\n# Networking\n#\n# CONFIG_LWIP is not set\nCONFIG_FIT=y\n# CONFIG_FIT_DEBUG is not set\nCONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30\nCONFIG_FIT_NR_NODES=2\nCONFIG_FIT_LOCAL_ID=0\n</code></pre> <pre><code>wuklab01 Memory\n\n#\n# Lego Memory Component Configurations\n#\nCONFIG_COMP_MEMORY=y\n\n#\n# Memory DEBUG Options\n#\n# CONFIG_MEM_PREFETCH is not set\n\n#\n# DRAM Cache Options\n#\nCONFIG_PCACHE_LINE_SIZE_SHIFT=12\nCONFIG_PCACHE_ASSOCIATIVITY_SHIFT=3\n\n#\n# General Manager Config/Debug Options\n#\nCONFIG_DEFAULT_MEM_NODE=1\nCONFIG_DEFAULT_STORAGE_NODE=2\nCONFIG_USE_RAMFS=y\nCONFIG_RAMFS_OBJECT_FILE=\"usr/pcache_conflict.o\"\n\n#\n# Networking\n#\n# CONFIG_LWIP is not set\nCONFIG_FIT=y\n# CONFIG_FIT_DEBUG is not set\nCONFIG_FIT_INITIAL_SLEEP_TIMEOUT=30\nCONFIG_FIT_NR_NODES=2\nCONFIG_FIT_LOCAL_ID=1\n</code></pre>"},{"location":"lego/kernel/loader/","title":"Lego Program Loader","text":"<p>This document explains the high-level workflow of Lego\u2019s program loader, and how we change the normal loader to fit the disaggregated operating system model. Background on linking and loading is recommended.</p>"},{"location":"lego/kernel/loader/#status","title":"Status","text":"Formats Supported ELF (static-linked) ELF (dynamic-linked)"},{"location":"lego/kernel/loader/#overall","title":"Overall","text":"<p>In order to support different executable formats, Lego has a <code>virtual loader layer</code> above all specific formats, which is quite similar to <code>virtual file system</code>. In Lego, <code>execve()</code> is divided into two parts: <code>1)</code> syscall hook at processor side, <code>2)</code> real loader at memory side. Combined together, they provide the same semantic of <code>execve()</code> as described in Linux man page. Also for the code, we divide the Linux implementation into parts. But our emulation model introduces several interesting workarounds.</p>"},{"location":"lego/kernel/loader/#legos-loader","title":"Lego\u2019s Loader","text":"<p>Lego basically divide the Linux loader into two parts, one in memory manager and other in processor manager. Most dirty work is done by memory manager. Processor manager only needs to make sure the new execution has a fresh environment to start.</p>"},{"location":"lego/kernel/loader/#entry-point","title":"Entry Point","text":"<p>So the normal entry point is <code>do_execve()</code>. Above that, it can be invoked by syscall from user space, or from kernel space by calling <code>do_execve()</code> directly. There are not too many places that will call <code>do_execve</code> within kernel. One notable case is how kernel starts the <code>pid 1</code> user program. This happens after kernel finished all initialization. The code is: <pre><code>static int run_init_process(const char *init_filename)                                                    \n{\n        argv_init[0] = init_filename;\n        return do_execve(init_filename, argv_init, envp_init);\n}\n</code></pre></p>"},{"location":"lego/kernel/loader/#memory-managers-job","title":"Memory Manager\u2019s Job","text":"<p>Memory manager side will do most of the dirty loading work. It will parse the ELF image, create new VMAs based on ELF information. After that, it only pass <code>start_ip</code> and <code>start_stack</code> back to processor manager. Once processor manager starts running this new execution, pages will be fetched from memory component on demand.</p>"},{"location":"lego/kernel/loader/#load-ld-linux","title":"Load ld-linux","text":"<p>For dynamically-linked images, kernel ELF loader needs to load the <code>ld-linux.so</code> as well. It will first try to map the <code>ld-linux.so</code> into this process\u2019s virtual address space. Furthermore, the first user instruction that will run is no longer <code>__libc_main_start</code>, kernel will transfer the kernel to <code>ld-linux.so</code> instead. Thus, for a normal user program, <code>ld-linux.so</code> will load all the shared libraries before running glibc.</p> <pre><code>static int load_elf_binary(struct lego_task_struct *tsk, struct lego_binprm *bprm,\n                           u64 *new_ip, u64 *new_sp, unsigned long *argv_len, unsigned long *envp_len)\n{\n\n        ...\n        /* Dynamically-linked */\n        if (elf_interpreter) {\n                unsigned long interp_map_addr = 0;\n\n                elf_entry = load_elf_interp(tsk, &amp;loc-&gt;interp_elf_ex,\n                                            interpreter,\n                                            &amp;interp_map_addr,\n                                            load_bias, interp_elf_phdata);\n                if (!IS_ERR((void *)elf_entry)) {\n                        /*\n                         * load_elf_interp() returns relocation\n                         * adjustment\n                         */\n                        interp_load_addr = elf_entry;\n                        elf_entry += loc-&gt;interp_elf_ex.e_entry;\n                }\n                if (BAD_ADDR(elf_entry)) {\n                        retval = IS_ERR((void *)elf_entry) ?\n                                        (int)elf_entry : -EINVAL;\n                        goto out_free_dentry;\n                }\n                reloc_func_desc = interp_load_addr;\n\n                put_lego_file(interpreter);\n                kfree(elf_interpreter);\n        } else {\n        /* Statically-linked */\n                /*\n                 * e_entry is the VA to which the system first transfers control\n                 * Not the start_code! Normally, it is the &lt;_start&gt; function.\n                 */\n                elf_entry = loc-&gt;elf_ex.e_entry;\n                if (BAD_ADDR(elf_entry)) {\n                        retval = -EINVAL;\n                        goto out_free_dentry;\n                }\n        }\n        ...\n}\n</code></pre>"},{"location":"lego/kernel/loader/#processor-managers-job","title":"Processor Manager\u2019s Job","text":"<p>It needs to flush old execution environment, and setup the new execution environment, such as signal, FPU. Notably, processor manager need to run <code>flush_old_exec()</code>, and <code>setup_new_exec()</code>.</p>"},{"location":"lego/kernel/loader/#destroy-old-context-flush_old_exec","title":"Destroy old context: flush_old_exec()","text":""},{"location":"lego/kernel/loader/#zap-other-threads","title":"Zap other threads","text":"<p><code>de_thread</code> is used to kill other threads within the same thread group, thus make sure this process has its own signal table. Furthermore, A <code>exec</code> starts a new thread group with the same TGID of the previous thread group, so we probably also need to switch PID if calling thread is not a leader.</p>"},{"location":"lego/kernel/loader/#switch-to-new-address-space","title":"Switch to new address space","text":"<p>We also need to release the old mm, and allocate a new mm. The new mm only has the high address kernel mapping established. Do note that in Lego, pgtable is used to emulate the processor cache: <pre><code>static int exec_mmap(void)\n{\n        struct mm_struct *new_mm;\n        struct mm_struct *old_mm;\n        struct task_struct *tsk;\n\n        new_mm = mm_alloc();\n        if (!new_mm)\n                return -ENOMEM;\n\n        tsk = current;\n        old_mm = current-&gt;mm;\n        mm_release(tsk, old_mm);\n\n        task_lock(tsk);\n        tsk-&gt;mm = new_mm;\n        tsk-&gt;active_mm = new_mm;\n        activate_mm(old_mm, new_mm);\n        task_unlock(tsk);\n\n        if (old_mm)\n                mmput(old_mm);\n        return 0;\n}\n</code></pre></p>"},{"location":"lego/kernel/loader/#clear-architecture-specific-state","title":"Clear Architecture-Specific state","text":"<p>This is performed by <code>flush_thread()</code>, which is an architecture-specific callback. In x86, we need to clear FPU state, and reset TLS array: <pre><code>void flush_thread(void)\n{\n        struct task_struct *tsk = current;\n        memset(tsk-&gt;thread.tls_array, 0, sizeof(tsk-&gt;thread.tls_array));\n\n        fpu__clear(&amp;tsk-&gt;thread.fpu);\n}\n</code></pre></p>"},{"location":"lego/kernel/loader/#setup-new-context-setup_new_exec","title":"Setup new context: setup_new_exec()","text":"<p>Lego\u2019s <code>setup_new_exec()</code> is quite different from Linux\u2019s default implementation. Lego moves several functions to memory component, like the <code>arch_pick_mmap_layout</code> stuff. Thus, Lego only flush the signal handlers and reset the signal stack stuff: <pre><code>static void setup_new_exec(const char *filename)\n{\n        /* This is the point of no return */\n        current-&gt;sas_ss_sp = current-&gt;sas_ss_size = 0;\n\n        set_task_comm(current, kbasename(filename));\n\n        flush_signal_handlers(current, 0);\n}\n</code></pre></p>"},{"location":"lego/kernel/loader/#change-return-frame-in-stack","title":"Change return frame in stack","text":"<p>We do not return to user mode here, we simply replace the return IP of the regs frame. While the kernel thread returns, it will simply merge to syscall return path (check ret_from_fork() in entry.S for detail). <pre><code>/**\n * start_thread - Starting a new user thread\n * @regs: pointer to pt_regs\n * @new_ip: the first instruction IP of user thread\n * @new_sp: the new stack pointer of user thread\n */\nvoid start_thread(struct pt_regs *regs, unsigned long new_ip,\n                  unsigned long new_sp)\n{\n        loadsegment(fs, 0);\n        loadsegment(es, 0);\n        loadsegment(ds, 0);\n        load_gs_index(0);\n        regs-&gt;ip                = new_ip;\n        regs-&gt;sp                = new_sp;\n        regs-&gt;cs                = __USER_CS;\n        regs-&gt;ss                = __USER_DS;\n        regs-&gt;flags             = X86_EFLAGS_IF;\n}\n</code></pre></p> <p>If calling <code>execve()</code> from userspace, the return frame is saved in the stack, we can simply do <code>start_thread</code> above, and merge to syscall return path. However, if calling <code>execve()</code> from a kernel thread, things changed. As you can see, all forked threads will run from <code>ret_from_fork</code> when it wakes for the first time. If it is a kernel thread, it jumps to <code>line 23</code>, to execute the kernel function. Normally, the function should not return. If it does return, it normally has called an <code>execve()</code>, and return frame has been changed by <code>start_thread()</code>. So we jump to <code>line 16</code> to let it merge to syscall return path.</p> <pre><code>/*\n * A newly forked process directly context switches into this address.\n *\n * rax: prev task we switched from\n * rbx: kernel thread func (NULL for user thread)\n * r12: kernel thread arg\n */\nENTRY(ret_from_fork)\n        movq    %rax, %rdi\n        call    schedule_tail           /* rdi: 'prev' task parameter */\n\n        testq   %rbx, %rbx              /* from kernel_thread? */\n        jnz     1f                      /* kernel threads are uncommon */\n\n2:\n        movq    %rsp, %rdi\n        call    syscall_return_slowpath /* return with IRQs disabled */\n        SWAPGS                          /* switch to user gs.base */\n        jmp     restore_regs_and_iret\n\n1:\n        /* kernel thread */\n        movq    %r12, %rdi\n        call    *%rbx\n        /*  \n         * A kernel thread is allowed to return here after successfully\n         * calling do_execve().  Exit to userspace to complete the execve()\n         * syscall:\n         */\n        movq    $0, RAX(%rsp)\n        jmp     2b  \nEND(ret_from_fork)\n</code></pre> <p>This is such a typical control flow hijacking. :-)</p>"},{"location":"lego/kernel/loader/#features","title":"Features","text":"<p>This section lists various features, or behaviors and Lego\u2019s program loader.</p>"},{"location":"lego/kernel/loader/#virtual-address-space-range","title":"Virtual Address Space Range","text":"<p>User\u2019s virtual address falls into this range: <pre><code>[sysctl_mmap_min_addr, TASK_SIZE)\n</code></pre></p> <p>By default, <pre><code>unsigned long sysctl_mmap_min_addr = PAGE_SIZE;\n\n/*\n * User space process size. 47bits minus one guard page.  The guard\n * page is necessary on Intel CPUs: if a SYSCALL instruction is at\n * the highest possible canonical userspace address, then that\n * syscall will enter the kernel with a non-canonical return\n * address, and SYSRET will explode dangerously.  We avoid this\n * particular problem by preventing anything from being mapped\n * at the maximum canonical address.\n */                                                                                                       \n#define TASK_SIZE       ((1UL &lt;&lt; 47) - PAGE_SIZE)\n</code></pre></p> <p>Essentially: <pre><code>[0x1000, 0x7ffffffff000)\n</code></pre></p>"},{"location":"lego/kernel/loader/#pre-populated-bss-and-brk","title":"Pre-Populated <code>.bss</code> and <code>.brk</code>","text":"<p>The heap vma created at loading time is a combination of <code>.bss</code> and <code>.brk</code> segments. Since brk usage is 0 (will it be non-zero?) at this moment, so the heap vma is essentially just <code>.bss</code> pages. Normally, Linux kernel does not populate pages for this vma during loading, but Lego does. It can save several page allocation cost for heap pcache miss. It is controlled by <code>vm_brk()</code>. <pre><code>int vm_brk(struct lego_task_struct *tsk,\n           unsigned long start, unsigned long len)\n{\n        int ret;\n        struct lego_mm_struct *mm = tsk-&gt;mm;\n\n        if (down_write_killable(&amp;mm-&gt;mmap_sem))\n                return -EINTR;\n\n        ret = do_brk(tsk, start, len);\n        up_write(&amp;mm-&gt;mmap_sem);\n\n        /* Prepopulate brk pages */\n        if (!ret)\n                lego_mm_populate(mm, start, len);\n\n        return ret;\n}\n</code></pre></p>"},{"location":"lego/kernel/loader/#un-populated-stack","title":"Un-Populated stack","text":"<p>Stack vma is manually expanded to <code>32 pages + pages for argv info</code> by loader to accommodate future usage. Only pages for argv are populated by default, the extra 32 pages are not. A typical program may need 1 page for saving argv info, plus the 32 extra, the layout will be: <pre><code>7ffffffde000-7ffffffff000 rw-p 00000000 [stack]\n</code></pre></p> <p>The code to expand stack is done when ELF loader tries to finalize the stack vma, by calling <code>setup_arg_pages()</code>: <pre><code>int setup_arg_pages(struct lego_task_struct *tsk, struct lego_binprm *bprm,\n                    unsigned long stack_top, int executable_stack)\n{\n        ...\n        /*\n         * 32*4k (or 2*64k) pages\n         */\n        stack_expand = 131072UL;\n        stack_size = vma-&gt;vm_end - vma-&gt;vm_start;\n        stack_base = vma-&gt;vm_start - stack_expand;\n\n        mm-&gt;start_stack = bprm-&gt;p;\n        ret = expand_stack(vma, stack_base);\n        ...\n}\n</code></pre></p>"},{"location":"lego/kernel/loader/#un-populated-text-and-data","title":"Un-Populated <code>.text</code> and <code>.data</code>","text":"<p>In essence, all PT_LOAD segments of ELF image are not pre-populated. They will be fetched from storage on demand. This is the traditional on-demand paging way. If we want to reduce the overhead of code and data\u2019s on-demand paging, we can prefault them in the future.</p>"},{"location":"lego/kernel/loader/#disabled-randomized-top-of-stack","title":"Disabled Randomized Top of Stack","text":"<p>Lego currently does not randomize the stack top. The stack vma is allocated by <code>bprm_mm_init()</code> at early execve time. There is no randomization at the allocation time, and this applies to all exectuable formats. The end of vma is just <code>TASK_SIZE</code>: <pre><code>static int __bprm_mm_init(struct lego_binprm *bprm)\n{\n        ...\n        vma-&gt;vm_end = TASK_SIZE;\n        ...\n}\n(managers/memory/loader/elf.c)\n</code></pre></p> <p>Top of stack randomization happens within each specific format loader. They do this by calling back to virtual loader layer\u2019s <code>setup_arg_pages()</code> function, which is used to finalize the top of stack: <pre><code>int setup_arg_pages(struct lego_task_struct *tsk, struct lego_binprm *bprm,\n                    unsigned long stack_top, int executable_stack);\n</code></pre></p> <p>So, to actually randomize the top of stack, you can simply do the following: <pre><code>static unsigned long randomize_stack_top(unsigned long stack_top)\n{                                \n        unsigned long random_variable = 0;\n\n        if ((current-&gt;flags &amp; PF_RANDOMIZE) &amp;&amp;\n                !(current-&gt;personality &amp; ADDR_NO_RANDOMIZE)) {\n                random_variable = get_random_long();\n                random_variable &amp;= STACK_RND_MASK;\n                random_variable &lt;&lt;= PAGE_SHIFT;\n        }\n#ifdef CONFIG_STACK_GROWSUP\n        return PAGE_ALIGN(stack_top) + random_variable;\n#else           \n        return PAGE_ALIGN(stack_top) - random_variable;\n#endif\n}\n\nstatic int load_elf_binary(struct lego_task_struct *tsk, struct lego_binprm *bprm,\n                           u64 *new_ip, u64 *new_sp, unsigned long *argv_len, unsigned long *envp_len)\n{\n        ...\n        retval = setup_arg_pages(bprm, randomize_stack_top(TASK_SIZE),\n                                 executable_stack);\n        ...\n}\n</code></pre></p> <p>However, current Lego disables randomization by passing <code>TASK_SIZE</code>: <pre><code>static int load_elf_binary(struct lego_task_struct *tsk, struct lego_binprm *bprm,\n                           u64 *new_ip, u64 *new_sp, unsigned long *argv_len, unsigned long *envp_len)\n{\n        ...\n        retval = setup_arg_pages(tsk, bprm, TASK_SIZE, executable_stack);\n        ...\n}\n(managers/memory/loader/elf.c)\n</code></pre></p>"},{"location":"lego/kernel/loader/#no-vdso","title":"No vDSO","text":"<p>Currently, Lego does not have <code>vDSO</code> support. There are not too many syscalls mapped in the vDSO, for x86-64:</p> <ul> <li>clock_gettime</li> <li>getcpu</li> <li>gettimeofday</li> <li>time</li> </ul> <p>The reason to add it back is simple: if those syscalls are used <code>a lot</code> and hurt overall performance. Do note that when we add it back, it will be different from the common design: vDSO <code>must</code> be mapped at processor side, mapped in our emulated pgtable.</p> <p>Below is the original part where loader maps vDSO: <pre><code>static int load_elf_binary(struct lego_task_struct *tsk, struct lego_binprm *bprm,\n                           u64 *new_ip, u64 *new_sp, unsigned long *argv_len, unsigned long *envp_len)\n{\n        ...\n#ifdef ARCH_HAS_SETUP_ADDITIONAL_PAGES\n        /*\n         * TODO: vdso\n         * x86 can map vdso vma here\n         */\n#endif\n        ...\n}\nmanagers/memory/loader/elf.c\n</code></pre></p> <p>For lego, we should move it to processor right before <code>start_thread()</code>: <pre><code>int do_execve(const char *filename,\n              const char * const *argv,\n              const char * const *envp)\n{\n        ...\n        /* Should be here */\n\n        start_thread(regs, new_ip, new_sp);\n        ...\n}\n</code></pre></p> <p>Besides, don\u2019t forget to report the <code>vDSO</code> address in the aux vector: <pre><code>static int create_elf_tables(struct lego_task_struct *tsk, struct lego_binprm *bprm,\n                struct elfhdr *exec, unsigned long load_addr, unsigned long interp_load_addr,\n                unsigned long *argv_len, unsigned long *envp_len)\n{\n        ...\n#ifdef ARCH_DLINFO\n        /*\n         * ARCH_DLINFO must come first so PPC can do its special alignment of\n         * AUXV.\n         * update AT_VECTOR_SIZE_ARCH if the number of NEW_AUX_ENT() in\n         * ARCH_DLINFO changes\n         */\n        ARCH_DLINFO;\n#endif\n        ...\n}\n</code></pre></p> <p>\u2013 Yizhou Shan Created: Feb 16, 2018 Last Updated: Feb 27, 2018</p>"},{"location":"lego/kernel/net_thpool/","title":"Thread Pool Model for Handling Network Requests","text":"<ul> <li><code>Passive</code>: whenever a network request comes in, callback to thpool.</li> <li><code>Active</code>: thpool keep polling if there is new network requests queued.</li> </ul> <p>Previously, our memory side use the Active mode to handle requests, which has very bad latency. Several days ago we changed to the Passive mode, which has a very good latency! One <code>ib_send_reply</code> RRT drops from <code>~20us</code> to a normal <code>~6us</code> for a TensorFlow run.</p> <p>Never thought this could make such a big difference (~3x slowdown)! Dark network!</p> <p>\u2013 Yizhou Shan Created: April 29, 2018 Last Updated: April 29, 2018</p>"},{"location":"lego/kernel/pagefault_disable/","title":"The story of pagefault_disable/enable","text":"<p><code>pagefault_disable()</code> is not really disabling the whole pgfault handling code. It is used to disable only the handling of pgfault that landed from <code>user virtual address</code>. Please note the difference between <code>user virtual address</code> and <code>user mode fault</code>. The first means the faulting address belongs to user virtual address space, while it can come from either user mode (CPL3) or kernel mode (CPL0). The second is a fault come from user mode (CPL3).</p> <p>If pgfault is disabled, then <code>do_page_fault()</code> function will NOT try to solve the pgfault by calling into <code>pcache</code>, instead, it will go straight to <code>fixup</code> code (in no_context()).</p> <p>This function is not intended to be used standalone. Normally, we do 1) <code>pagefault_disable()</code>, 2) then use some functions that have <code>fixup</code> code, 3) then <code>pagefault_enable()</code>. (The <code>fixup</code> code is another magic inside kernel. We will cover it in another document.)</p> <p>Currently in Lego, this is only used by <code>futex</code>, which needs something like <code>atomic_cmpxchg()</code> with an user virtual address. If pgfault happens in the middle, then this will not be atomic since kernel need to do pcache operations, which further needs to through network.</p> <p>However, do note the difference with <code>uaccess</code> family functions. Most <code>uaccess</code> functions will not disable pgfault handling, which means pcache will be invoked. If pcache returns a <code>SEGFAULT</code>, pgfault code will go into <code>fixup</code> code. And that, my friend, is where <code>uaccess</code> returns <code>-EFAULT</code> to caller.</p> <p>\u2013 Yizhou Shan Feb 01, 2018</p>"},{"location":"lego/kernel/profile/","title":"Lego Profilers","text":"<p>Lego has three runtime profilers in kernel:</p> <ul> <li>strace</li> <li>heatmap</li> <li>profile points</li> </ul> <p>Combined together, they can provide the following information. Sweet, huh? <pre><code>[ 1017.047366] Kernel strace\n[ 1017.050276] Task: 20:20 nr_accumulated_threads: 46\n[ 1017.055837] % time        seconds  usecs/call     calls    errors syscall\n[ 1017.063213] ------ -------------- ----------- --------- --------- ----------------\n[ 1017.071648]  98.16   33.839597842     1879978        18         0 sys_futex\n[ 1017.079406]   0.26    0.260143997      260144         1         0 sys_execve\n[ 1017.087260]   0.18    0.185456860        7133        26         0 sys_write\n[ 1017.095017]   0.50    0.050189546         913        55         0 sys_munmap\n[ 1017.102870]   0.25    0.025223661         255        99         0 sys_mmap\n[ 1017.110531]   0.50    0.000505134          12        45         0 sys_clone\n[ 1017.118288]   0.20    0.000202327          26         8         0 sys_read\n[ 1017.125947]   0.14    0.000144065          17         9         0 sys_open\n[ 1017.133608]   0.67    0.000067251           7        11         0 sys_brk\n[ 1017.141171]   0.30    0.000030361           7         5         0 sys_newfstat\n[ 1017.149219]   0.64    0.000006410           1         9         0 sys_close\n[ 1017.156976]   0.48    0.000004842           1        45         0 sys_madvise\n[ 1017.164927]   0.34    0.000003443           1        47         0 sys_set_robust_list\n[ 1017.173653]   0.21    0.000002137           1        52         0 sys_mprotect\n[ 1017.181702]   0.71    0.000000717           1         4         0 sys_gettimeofday\n[ 1017.190137]   0.60    0.000000608           1         3         0 sys_time\n[ 1017.197797]   0.51    0.000000513           1         2         0 sys_getrlimit\n[ 1017.205942]   0.49    0.000000498           1         2         0 sys_rt_sigprocmask\n[ 1017.214572]   0.46    0.000000469           1         4         0 sys_rt_sigaction\n[ 1017.223008]   0.45    0.000000453           1         2         0 sys_arch_prctl\n[ 1017.231249]   0.27    0.000000272           1         2         0 sys_newuname\n[ 1017.239298]   0.13    0.000000135           1         2         0 sys_set_tid_address\n[ 1017.248025] ------ -------------- ----------- --------- --------- ----------------\n[ 1017.256460] 100.00   34.361581541                   451         0 total\n[ 1017.263830]\n[ 1017.308295]\n[ 1017.309754] Kernel Heatmap (top #10)\n[ 1017.313731]          Address              Function          NR          %\n[ 1017.321294] ----------------  --------------------  ----------  ---------\n[ 1017.328858] ffffffff8101a600              cpu_idle      112082      73.11\n[ 1017.336421] ffffffff810666f0            __schedule       19192      12.95\n[ 1017.343983] ffffffff8104f500       mlx4_ib_poll_cq        5551       3.99\n[ 1017.351546] ffffffff8103bf50             delay_tsc        5393       3.83\n[ 1017.359110] ffffffff81034a10    victim_flush_async        3766       2.72\n[ 1017.366673] ffffffff8102b220   slob_alloc.constpro        1992       1.47\n[ 1017.374235] ffffffff810668d0              schedule        1519       0.15\n[ 1017.381800] ffffffff810648f0   fit_send_reply_with         956       0.95\n[ 1017.389362] ffffffff81062370   ibapi_send_reply_ti         307       0.30\n[ 1017.396925] ffffffff8105a0d0   ib_mad_completion_h         232       0.23\n[ 1017.404487] ----------------  --------------------  ----------  ---------\n[ 1017.412052]                                             151994     100.00\n[ 1017.419613]\n[ 1017.421267]\n[ 1017.422911] Kernel Profile Points\n[ 1017.426594]  status                  name             total                nr            avg.ns\n[ 1017.436292] -------  --------------------  ----------------  ----------------  ----------------\n[ 1017.445988]     off      flush_tlb_others       0.000153470                55              2791\n[ 1017.455685]     off     pcache_cache_miss      16.147020152            274698             58781\n[ 1017.465381] -------  --------------------  ----------------  ----------------  ----------------\n</code></pre></p>"},{"location":"lego/kernel/profile_heatmap/","title":"Lego Profile Kernel Heatmap","text":"<p>To get a sense of what is the hottest function within kernel, Lego adds a  counter based heatmap. It is the same with Linux\u2019s <code>/proc/profile</code>.</p>"},{"location":"lego/kernel/profile_heatmap/#mechanism","title":"Mechanism","text":"<p>General idea: for each possible function/instruction byte in the kernel, we attach to a counter to it. Once we detect this function/instruction was executed, we increment its associated counter.</p> <p>However, fine granularity counting will need a lot extra memory, and it is not necessary to track each single instruction byte. Besides, it is hard to track down every time the function was executed. Furthermore, we only need an approximate heatmap.</p> <p>Thus, kernel\u2019s solutions are:</p> <ul> <li>Coarse granularity: maintain a counter for each <code>1&lt;&lt;prof_shift</code> bytes.</li> <li>Update counter on timer interrupt tick, which is a constant stable entry.</li> </ul>"},{"location":"lego/kernel/profile_heatmap/#supported-features","title":"Supported Features","text":"<p>Currently, we only support <code>CPU_PROFILING</code>, which profile on each timer interrupt tick. We could also add <code>SCHED_PROFILING</code>, or <code>SLEEP_PROFILING</code>. But we are fine with current setting.</p> <p>Of course, we also have a simple dump function <code>void print_profile_heatmap_nr(int nr)</code>, which is similar to userspace tool <code>readprofile</code>.</p>"},{"location":"lego/kernel/profile_heatmap/#example-output","title":"Example Output","text":"<p>Workload is: MT-Phoenix word count, with 1GB data. (We probably want to rule out <code>cpu_idle()</code>) <pre><code>[ 1017.309754] Kernel Heatmap (top #10)\n[ 1017.313731]          Address              Function          NR          %\n[ 1017.321294] ----------------  --------------------  ----------  ---------\n[ 1017.328858] ffffffff8101a600              cpu_idle      112082      73.11\n[ 1017.336421] ffffffff810666f0            __schedule       19192      12.95\n[ 1017.343983] ffffffff8104f500       mlx4_ib_poll_cq        5551       3.99\n[ 1017.351546] ffffffff8103bf50             delay_tsc        5393       3.83\n[ 1017.359110] ffffffff81034a10    victim_flush_async        3766       2.72\n[ 1017.366673] ffffffff8102b220   slob_alloc.constpro        1992       1.47\n[ 1017.374235] ffffffff810668d0              schedule        1519       0.15\n[ 1017.381800] ffffffff810648f0   fit_send_reply_with         956       0.95\n[ 1017.389362] ffffffff81062370   ibapi_send_reply_ti         307       0.30\n[ 1017.396925] ffffffff8105a0d0   ib_mad_completion_h         232       0.23\n[ 1017.404487] ----------------  --------------------  ----------  ---------\n[ 1017.412052]                                             151994     100.00\n[ 1017.419613]\n</code></pre></p> <p>\u2013 Yizhou Shan Created: April 06, 2018 Last Updated: April 06, 2018</p>"},{"location":"lego/kernel/profile_points/","title":"Lego Profile Points","text":"<p>Lego profile points facility is added to trace specific functions, or even a small piece of code. It is added in the hope that it can help to find performance bottleneck. It is added in the hope that it can reduce the redundant coding chore.</p>"},{"location":"lego/kernel/profile_points/#example","title":"Example","text":"<p>To trace TLB shootdown cost. <pre><code>DEFINE_PROFILE_POINT(flush_tlb_others)\n\nvoid flush_tlb_others(const struct cpumask *cpumask, struct mm_struct *mm,\n                      unsigned long start, unsigned long end)\n{       \n        struct flush_tlb_info info;\n        PROFILE_POINT_TIME(flush_tlb_others)\n\n        if (end == 0)\n                end = start + PAGE_SIZE;\n        info.flush_mm = mm;\n        info.flush_start = start;\n        info.flush_end = end;\n\n        profile_point_start(flush_tlb_others);\n        smp_call_function_many(cpumask, flush_tlb_func, &amp;info, 1);\n        profile_point_leave(flush_tlb_others);\n}\n</code></pre></p> <p>Explanation: <code>DEFINE_PROFILE_POINT()</code> will define a local structure, that contains the profile point name, number of invoked times, and total execution time. <code>PROFILE_POINT_TIME()</code> will define a stack local variable, to save the starting time. <code>profile_point_start()</code> will save the current time in nanosecond, while <code>profile_point_leave()</code> will calculate the execution of this run, and update the global counters defined by <code>DEFINE_PROFILE_POINT()</code>.</p> <p>System-wide profile points will be printed together if you invoke <code>print_profile_points()</code>: <pre><code>[ 1017.422911] Kernel Profile Points\n[ 1017.426594]  status                  name             total                nr            avg.ns\n[ 1017.436292] -------  --------------------  ----------------  ----------------  ----------------\n[ 1017.445988]     off      flush_tlb_others       0.000153470                55              2791\n[ 1017.455685]     off     pcache_cache_miss      16.147020152            274698             58781\n[ 1017.465381] -------  --------------------  ----------------  ----------------  ----------------\n</code></pre></p>"},{"location":"lego/kernel/profile_points/#mechanism","title":"Mechanism","text":"<p>Once again, the profile points are aggregated by linker script. Each profile point will be in a special section <code>.profile.point</code>. The linker will merge them into one section, and export the starting and ending address of this section.</p> <p>Part I. Annotate. <pre><code>#define __profile_point         __section(.profile.point)\n\n#define DEFINE_PROFILE_POINT(name)                                                      \\\n        struct profile_point _PP_NAME(name) __profile_point = {\n        ...\n        ...\n        };\n</code></pre></p> <p>Part II. Link script merge. <pre><code>. = ALIGN(L1_CACHE_BYTES);\n.profile.point : AT(ADDR(.profile.point) - LOAD_OFFSET) {\n    __sprofilepoint = .;\n    *(.profile.point)\n    __eprofilepoint = .;\n}\n</code></pre></p> <p>Part III. Walk through. <pre><code>void print_profile_points(void)\n{\n        struct profile_point *pp;\n\n        for (pp = __sprofilepoint; pp &lt; __eprofilepoint; pp++) {\n                print_profile_point(pp);\n        ...\n    }  \n</code></pre></p> <p>I really love the linker script. ;-)</p> <p>\u2013 Yizhou Shan Created: April 06, 2018 Last Updated: April 06, 2018</p>"},{"location":"lego/kernel/profile_strace/","title":"Lego Profile strace","text":"<p>Lego has a built-in kernel-version syscall tracer, similar to <code>strace</code> utility in the user space. Below we will just call our Lego\u2019s syscall tracer as strace for simplicity.</p>"},{"location":"lego/kernel/profile_strace/#design","title":"Design","text":"<p>There are essentially three important metrics to track for each syscall</p> <ul> <li>number of times invoked</li> <li>number of times error happened</li> <li>total execution, or per-call latency</li> </ul> <p>Besides, there is another important design decision: 1) should all threads within a process share one copy of data to maintain bookkeeping, or 2) should each thread do its bookkeeping on its own set of data? Our answer is 2). For two reasons:</p> <ul> <li>Performance: set of counters are <code>atomic_t</code>, updating is performed by a locked instruction. The first solution will add huge overhead while tracing heavily multithreaded applications.</li> <li>Simplicity: in order to track the latency of each syscall, we need to know when it enter and when it finish. As threads come and go, it is hard to maintain such information. To make it worse, a preemptable kernel, or schedule-related syscalls will move threads around cores.</li> </ul> <p>Below is our simple design, where each thread has a <code>struct strace_info</code>, which include a set of counters for each syscall. All <code>strace_info</code> within a process are chained together by a doubly-linked list.</p> <p></p> <p>When we want to look at the strace statistic numbers, we need to <code>accumulate</code> counters from all threads within a process, including those dead threads. We do the <code>accumulate</code> when the last thread of this process is going to exit.</p> <p>The benefit of doubly-linked <code>strace_info</code> is we can walk through the list starting anywhere. There is really no list head here. In fact, everyone can be the head. See how we respect equality? Besides, even if <code>task_struct</code> is reaped, <code>strace_info</code> is still there and linked.</p> <p>For example, assume thread_3 has a SIGSEGV, and did a <code>zap_other_threads</code>. And he is the last standing live thread of this process. When it is going to exit, it will accumulate all the statistic and do the necessary printing. </p>"},{"location":"lego/kernel/profile_strace/#details","title":"Details","text":"<p>There are essentially three hooks in core kernel:</p> <ul> <li>syscall: before and after <code>sys_call_table</code></li> <li>fork/clone: create <code>strace_info</code> for each thread</li> <li>do_exit(): when group_dead(signal-&gt;live==1), accumulate</li> </ul>"},{"location":"lego/kernel/profile_strace/#example-output","title":"Example Output","text":"<pre><code>[ 1017.047366] Kernel strace\n[ 1017.050276] Task: 20:20 nr_accumulated_threads: 46\n[ 1017.055837] % time        seconds  usecs/call     calls    errors syscall\n[ 1017.063213] ------ -------------- ----------- --------- --------- ----------------\n[ 1017.071648]  98.16   33.839597842     1879978        18         0 sys_futex\n[ 1017.079406]   0.26    0.260143997      260144         1         0 sys_execve\n[ 1017.087260]   0.18    0.185456860        7133        26         0 sys_write\n[ 1017.095017]   0.50    0.050189546         913        55         0 sys_munmap\n[ 1017.102870]   0.25    0.025223661         255        99         0 sys_mmap\n[ 1017.110531]   0.50    0.000505134          12        45         0 sys_clone\n[ 1017.118288]   0.20    0.000202327          26         8         0 sys_read\n[ 1017.125947]   0.14    0.000144065          17         9         0 sys_open\n[ 1017.133608]   0.67    0.000067251           7        11         0 sys_brk\n[ 1017.141171]   0.30    0.000030361           7         5         0 sys_newfstat\n[ 1017.149219]   0.64    0.000006410           1         9         0 sys_close\n[ 1017.156976]   0.48    0.000004842           1        45         0 sys_madvise\n[ 1017.164927]   0.34    0.000003443           1        47         0 sys_set_robust_list\n[ 1017.173653]   0.21    0.000002137           1        52         0 sys_mprotect\n[ 1017.181702]   0.71    0.000000717           1         4         0 sys_gettimeofday\n[ 1017.190137]   0.60    0.000000608           1         3         0 sys_time\n[ 1017.197797]   0.51    0.000000513           1         2         0 sys_getrlimit\n[ 1017.205942]   0.49    0.000000498           1         2         0 sys_rt_sigprocmask\n[ 1017.214572]   0.46    0.000000469           1         4         0 sys_rt_sigaction\n[ 1017.223008]   0.45    0.000000453           1         2         0 sys_arch_prctl\n[ 1017.231249]   0.27    0.000000272           1         2         0 sys_newuname\n[ 1017.239298]   0.13    0.000000135           1         2         0 sys_set_tid_address\n[ 1017.248025] ------ -------------- ----------- --------- --------- ----------------\n[ 1017.256460] 100.00   34.361581541                   451         0 total\n</code></pre> <p>\u2013 Yizhou Shan Created: April 05, 2018 Last Updated: April 05, 2018</p>"},{"location":"lego/kernel/stop_machine/","title":"The highest priority thread in kernel","text":"<p>This document is about <code>migration/N</code> kernel threads, <code>stop_sched</code> schdueling class, and the interesting source file <code>kernel/stop_machine.c</code>. Background on kernel scheduler design is recommended.</p> <p>Scheduler uses the following code to pick the next runnable task: <pre><code>static inline struct task_struct *\npick_next_task(struct rq *rq, struct task_struct *prev)\n{\n        struct task_struct *p;\n        const struct sched_class *class;\n\nagain:\n        for_each_class(class) {\n                p = class-&gt;pick_next_task(rq, prev);\n                if (p) {\n                        if (unlikely(p == RETRY_TASK))\n                                goto again;\n                        return p;\n                }    \n        }\n        BUG();\n}\n</code></pre></p> <p>while the class is linked together as: <pre><code>#define sched_class_highest     (&amp;stop_sched_class)                                                       \n#define for_each_class(class) \\                                                                           \n   for (class = sched_class_highest; class; class = class-&gt;next)\n</code></pre></p> <p>Clearly, the highest priority class is <code>stop_sched_class</code>. Whenever this scheduling has class runnable threads, scheduler will always run them first. So what kernel threads are using this scheduling class? Well, you must have seen something like <code>migration/0</code> when you do <code>ps aux</code> in Linux. And yes, these kernel threads are the only users.</p> <p>These threads are sleeping most of their lifetime, they will be invoked to do some very urgent stuff. For example, when a user thread that is currently running on CPU0 calls <code>sched_setaffinity()</code> to bind to CPU1, kernel is not able to do this because this user thread is currently running (runqueue can not move a running task out, it can only move queued task out). Then, scheduler has to ask <code>migration/0</code> for help. Once there is a job enqueued, <code>migration/0</code> will be invoked. Since it has the highest-priority, it will start execution immediately. Thus the migration from CPU0 to CPU1 is performed safely and fast.</p> <p><code>migration</code> code is defined in <code>kernel/stop_machine.c</code>. They are created during early boot. They use the <code>smpboot_register_percpu_thread</code> to create threads. They are written in this way because Linux supports cpu hotplug. To simplify we can also create them manually through <code>kthread_create</code>. Since Lego does not support cpu hotplug, and this <code>cpu_stop_init</code> is called after SMP is initialized, so Lego has slight different initialiaztion: <pre><code>void __init cpu_stop_init(void)\n{\n        unsigned int cpu;\n\n        for_each_possible_cpu(cpu) {\n                struct cpu_stopper *stopper = &amp;per_cpu(cpu_stopper, cpu);\n\n                spin_lock_init(&amp;stopper-&gt;lock);\n                INIT_LIST_HEAD(&amp;stopper-&gt;works);\n        }\n\n        BUG_ON(smpboot_register_percpu_thread(&amp;cpu_stop_threads));\n\n        /*\n         * smpboot_create_threads use kthread_create_on_cpu() to\n         * create new threads. And they are parked, too.\n         * Since we call this function after smp_init(), all CPUs\n         * are already online, thus we need to unpark them manually.\n         */\n        for_each_online_cpu(cpu)\n                stop_machine_unpark(cpu);\n</code></pre></p> <p>Internally, it also use a list to keep enqueued jobs. Once the thread is waken up, it tries to lookup this list and dequeue jobs (similar to kthread creation, kworker etc.): <pre><code>static void cpu_stopper_thread(unsigned int cpu)\n{\n        struct cpu_stopper *stopper = &amp;per_cpu(cpu_stopper, cpu);\n        struct cpu_stop_work *work;\n\nrepeat:\n        work = NULL;\n        spin_lock_irq(&amp;stopper-&gt;lock);\n        if (!list_empty(&amp;stopper-&gt;works)) {\n                work = list_first_entry(&amp;stopper-&gt;works,\n                                        struct cpu_stop_work, list);\n                list_del_init(&amp;work-&gt;list);\n        }   \n        spin_unlock_irq(&amp;stopper-&gt;lock);\n\n        if (work) {\n                ...\n                ret = fn(arg);\n                ...\n                goto repeat;\n        }   \n}\n</code></pre></p> <p>It has several interesting public APIs that are quite similar to <code>smp_call_functions</code>, but the difference is: this set of APIs provide a guaranteed time-to-execute waiting time, because it will simply preempt anything running on CPU.</p> <pre><code>int stop_one_cpu(unsigned int cpu, cpu_stop_fn_t fn, void *arg);\nint stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);\nint try_stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg);\n</code></pre> <p>They are used only when there are some very urgent things to do. So, please use with caution.</p> <p>\u2013 Yizhou Shan Created: Feb 12, 2018 Last Updated: Feb 12, 2018</p>"},{"location":"lego/kernel/tlbflush/","title":"TLB Flush","text":"<p>\u2013 Yizhou Shan Created: March 01, 2018 Last Updated: March 01, 2018</p>"},{"location":"lego/kernel/trampoline/","title":"How trampoline works in Lego","text":""},{"location":"lego/kernel/trampoline/#what-is-trampoline-code","title":"What is trampoline code?","text":"<p>Trampoline code is used by <code>BSP</code> to boot other secondary CPUs. At startup, <code>BSP</code> wakeup secondary CPUs by sending a <code>APIC INIT</code> command, which carry the <code>[start_ip]</code> where the secondary CPUs should start to run.</p> <p>The trampoline code is the code starting from <code>[start_ip]</code>. Used by the secondary CPU to jump from <code>16-bit realmode</code> to <code>64-bit</code> code (the first instruction of 64-bit code will be in <code>arch/x86/kernel/head_64.S</code>).</p>"},{"location":"lego/kernel/trampoline/#where-is-the-trampoline-source-code","title":"Where is the trampoline source code?","text":"<p>The source files are all in <code>arch/x86/realmode/</code>. There are two parts: 1) <code>arch/x86/realmode/rm/trampoline.S</code>: which is the code that will run. And it is a mix of 16-bit, 32-bit, 64-bit code (ugh..). 2) <code>arch/x86/realmode/piggy.S</code>: Since the trampoline code can not to linked into kernel image directly. So we have to piggyback the trampoline.bin binary code into a section, which is described by <code>trampoline_start</code> and <code>trampoline_end</code>. So the kernel can address the trampoline code via these two symbols.</p> <p>The compile flow is: <pre><code>    arch/x86/realmode/rm/trmapoline.S\n    -&gt; CC__ arch/x86/realmode/rm/trmapoline.o\n       -&gt; LD arch/x86/realmode/rm/trampoline\n          -&gt; OBJCOPY arch/x86/realmode/rm/trampoline.bin\n             -&gt; This bin goes into piggy.o\n            -&gt; piggy.o goes into vmImage\n</code></pre></p>"},{"location":"lego/kernel/trampoline/#what-happened-at-runtime","title":"What happened at runtime?","text":"<p>The setup code was loaded by GRUB below 1MB. Inside <code>arch/x86/boot/main.c</code>, we will save the <code>cs()</code> into the <code>boot_params</code> and pass it to kernel. In <code>setup_arch()</code>, we will copy the trampoline.bin code to the <code>cs()</code> address reported by <code>boot_param</code>. This means we will override setup code, which is okay.</p> <p>At last, we wake up the secondary CPUs inside <code>smp_init()</code>.</p>"},{"location":"lego/kernel/trampoline/#compare-with-linux","title":"Compare with Linux","text":"<p>I vaguely remember how Linux implement this. The only thing I remember is that Linux use some sort of structure, which is filled by BSP and then passed, or used by secondary CPUs. The mechanism has no difference, though. Linux just has more robust debugging facilities.</p> <p>\u2013 Yizhou Shan Mar 3, 2017</p>"},{"location":"lego/kernel/vDSO/","title":"vDSO and vsyscall","text":"<p>We have choice but port vDSO and vsyscall for Lego, because some dynamic-linked ELF images will use these features.</p> <p>References:</p> <ul> <li>https://0xax.gitbooks.io/linux-insides/content/SysCall/syscall-3.html</li> </ul> <p>\u2013 Yizhou Shan Created: March 01, 2018 Last Updated: March 01, 2018</p>"},{"location":"lego/kernel/vfs/","title":"Processor Manager\u2019s Virtual File System","text":"<p>Lego processor manager has an virtual file system layer to accommodate the famous legacy <code>Everything is a file</code> philosophy. But we implement this in a very dirty way.</p> <p>Cover later.</p> <p>\u2013 Yizhou Shan Created: Feb 20, 2018 Last Updated: Feb 20, 2018</p>"},{"location":"lego/kernel/vm/","title":"Process Virtual Memory","text":""},{"location":"lego/kernel/vm/#limits","title":"Limits","text":""},{"location":"lego/kernel/vm/#max-number-of-vmas","title":"Max Number of VMAs","text":"<p>By default, the maximum number of VMAs is: <code>65530</code>. It is defined by the following variable: <pre><code>#define MAPCOUNT_ELF_CORE_MARGIN        (5)\n#define DEFAULT_MAX_MAP_COUNT   (USHRT_MAX - MAPCOUNT_ELF_CORE_MARGIN)\n\nint sysctl_max_map_count __read_mostly = DEFAULT_MAX_MAP_COUNT;\n</code></pre></p>"},{"location":"lego/kernel/vm/#facts","title":"Facts","text":""},{"location":"lego/kernel/vm/#munmap-can-split-vma","title":"<code>munmap</code> can split vma","text":"<p><code>munmap</code> can create a hole with an existing vma, thus divide one existing vma to two new vmas. Do note that, <code>munmap</code> can create hole for both anonymous vma and file-backed vma.</p>"},{"location":"lego/kernel/vm/#msync-is-not-atomic","title":"<code>msync()</code> is not atomic","text":"<p>During <code>msync()</code>, pages are being written back to disk one by one (or batched). Consider the case where few pages have been flushed back, while some other few pages are still in the memory. This premature writeback is not atomic and will be affected by failure.\u000b\u000b</p>"},{"location":"lego/kernel/vm/#msync-need-concurrency-control","title":"<code>msync()</code> need concurrency control","text":"<p>With a multi-threaded application, does msync() provide the synchronization semantic? The answer is NO. Other threads within the same process are able to write to pages currently under <code>msync()</code>. This implies that application need to handle concurrency by themselves, e.g., rwlocks.</p> <p>\u2013 Yizhou Shan Created: Feb 19, 2018 Last Updated: Feb 19, 2018</p>"},{"location":"lego/log/TODO/","title":"TODO","text":"<p>Last Updated: July 18, 2018</p>"},{"location":"lego/log/TODO/#planned","title":"Planned","text":"<ul> <li>Try <code>fully-associative</code> pcache, to see how many conflict misses can be removed (got the idea from HPCA18 google search paper)</li> <li>kmem_cache</li> <li><code>TSC deadline mode (one-shot tick)</code>. What is the performance comparison with periodic mode?</li> <li><code>batched TLB flush</code></li> <li><code>__unhash_process()</code>: in exit, release pid etc.</li> <li> <p><code>de_thread()</code>: in exec, change pid etc.</p> </li> <li> <p><code>posix timers</code>: used by exit(), wait() and others. Functions like <code>posix_cpu_timers_exit_group</code>.</p> </li> <li> <p><code>vDSO</code>: if later we find applications are using <code>gettimeofday</code>, <code>time</code>, and <code>getcpu</code> a lot, and it truly hurt performance, then we should consider adding this in the processor side. (Check Processor Loader document for code that needs to be patched). (02/27/18)</p> </li> <li> <p><code>VA randomization</code>: our loader does not add any randomization. For security reasons, we probably want to add this.</p> </li> <li> <p><code>VM Organization</code>: multiple vm choice at M side, on a per-vma basis.</p> </li> <li> <p><code>fork: dup free pool</code>: duplicate the free VA pool at both P and M.</p> </li> <li> <p><code>pcache</code>: send each page\u2019s type back. something like PcacheAnon, PcacheFile. So the pcache_evict/do_exit routine can be optimized.</p> </li> <li> <p><code>mm alloc</code>: don\u2019t use the kmalloc to get a new mm_struct. This is a hot data structure, use get_free_page instead maybe. Like task_struct.</p> </li> <li> <p><code>fork_dup_pcache</code>: have real <code>vm_flags</code> to guide write-protect. Get vm ranges from memory to optimize the duplication. Currently, all pages will be downgraded to read-only.</p> </li> <li> <p><code>P side mm sem</code>: check if we need the sem in P side. pgfault need read, fork and others need W. Even though M side also serialize this, but  out ops are divided.</p> </li> <li> <p><code>mprotect</code>: it is empty now. We assume applications are well-written. But does any of them rely on this COW feature?</p> </li> <li> <p><code>CPU_NO_HZ</code>: disable timer for some cores, to reduce the overhead of timer interrupts. This is named <code>CPU_NO_HZ</code> and some similar Kconfigs.</p> </li> <li> <p><code>SYSCALL</code>: compared with linux, we are always using the slow path, which pass all arguments. We should consider optimize this. OS-intensive applications may hurt.</p> </li> <li> <p><code>IB</code>: reply is a sg list. Esp benefit pcache.</p> </li> </ul>"},{"location":"lego/log/TODO/#finished","title":"Finished","text":"<ul> <li>-<code>vsyscall</code>: mostly emulation-</li> </ul>"},{"location":"lego/log/log-02-2018/","title":"Feb 2018","text":""},{"location":"lego/log/log-02-2018/#0228-wed","title":"02/28 Wed","text":"<ul> <li>patch fork, and cow handler</li> <li>debug pcache, while running python hello world</li> <li>add vDSO, gettimeofday</li> </ul> <p>So, it is end of the day. After adding wp handler, I now have the whole picture of pcache activities, and the interactions between them. The reclaim, zap, move, copy, add, operations needs to be carefully synchronized. Also the refcount etc. I feel the ground rule is we need to make sure a PCM that a function is currently using, can not suddenly become invalid due to other operations. This has to be synced by: refcount, lock, flags. Oh well, mm is hard with SMP, but also fun.</p> <p>We are very close to have a fully working OS.</p> <p>I did not have time to look into the python hello world bug issue. It is a very serious one. It may also rule out some root bugs.</p>"},{"location":"lego/log/log-02-2018/#0227-tue","title":"02/27 Tue","text":"<p>Spent two days on CS527 source project, implemented a small SSHD and SSD client. And we have to inject exactly five bugs, or vulnerabilities into the systems. Lol, it is really hard to intentionally plant BUGs!</p> <p>Anyway, back to Lego. Since others are having a hard time compile program statically, I will try to add dynamic loader today.</p> <p>The interpreter: <code>/lib64/ld-linux-x86-64.so.2</code>.</p> <pre><code>Linux seq.c maps (no randomization):\n00400000-00401000 r-xp 00000000 fd:00 18752683                           /root/ys/LegoOS/usr/a.out\n00600000-00601000 r--p 00000000 fd:00 18752683                           /root/ys/LegoOS/usr/a.out\n00601000-00602000 rw-p 00001000 fd:00 18752683                           /root/ys/LegoOS/usr/a.out\n00602000-00604000 rw-p 00000000 00:00 0                                  [heap]\n7ffff7a18000-7ffff7bd0000 r-xp 00000000 fd:00 55051990                   /usr/lib64/libc-2.17.so\n7ffff7bd0000-7ffff7dd0000 ---p 001b8000 fd:00 55051990                   /usr/lib64/libc-2.17.so\n7ffff7dd0000-7ffff7dd4000 r--p 001b8000 fd:00 55051990                   /usr/lib64/libc-2.17.so\n7ffff7dd4000-7ffff7dd6000 rw-p 001bc000 fd:00 55051990                   /usr/lib64/libc-2.17.so\n7ffff7dd6000-7ffff7ddb000 rw-p 00000000 00:00 0\n7ffff7ddb000-7ffff7dfc000 r-xp 00000000 fd:00 55051983                   /usr/lib64/ld-2.17.so\n7ffff7fde000-7ffff7fe1000 rw-p 00000000 00:00 0\n7ffff7ff9000-7ffff7ffa000 rw-p 00000000 00:00 0\n7ffff7ffa000-7ffff7ffc000 r-xp 00000000 00:00 0                          [vdso]\n7ffff7ffc000-7ffff7ffd000 r--p 00021000 fd:00 55051983                   /usr/lib64/ld-2.17.so\n7ffff7ffd000-7ffff7ffe000 rw-p 00022000 fd:00 55051983                   /usr/lib64/ld-2.17.so\n7ffff7ffe000-7ffff7fff000 rw-p 00000000 00:00 0\n7ffffffde000-7ffffffff000 rw-p 00000000 00:00 0                          [stack]\nffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]\n</code></pre> <pre><code>lego after loading\n00400000-00401000 r-xp 00000000 /root/ys/LegoOS/usr/a.out\n00600000-00602000 rw-p 00000000 /root/ys/LegoOS/usr/a.out\n00602000-00604000 rw-p 00000000 [heap]\n7ffff7ddb000-7ffff7dfc000 r-xp 00000000 /lib64/ld-linux-x86-64.so.2\n7ffff7ffc000-7ffff7ffe000 rw-p 00021000 /lib64/ld-linux-x86-64.so.2\n7ffff7ffe000-7ffff7fff000 rw-p 00000000\n7ffffffde000-7ffffffff000 rw-p 00000000 [stack]\n\n\n[ 2066.379224] ****    Finish dump final mm\n[ 2066.426023] handle_p2m_execve(): reply_status: OKAY, new_ip: 0x7ffff7ddc170, new_sp: 0x7fffffffede0\n[ 2066.628949] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:150 vaddr:0x7ffff7ddc170\n[ 2066.732034] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:150 vaddr:0x7ffff7ddc170\n[ 2066.934947] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:51 vaddr:0x7fffffffedd8\n[ 2067.036978] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:51 vaddr:0x7fffffffedd8\n[ 2067.238842] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7ffce00\n[ 2067.340880] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7ffce00\n[ 2067.542747] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:51 vaddr:0x7ffff7ffd9a8\n[ 2067.644774] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:51 vaddr:0x7ffff7ffd9a8\n[ 2067.846640] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7ddb8e0\n[ 2067.948679] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7ddb8e0\n[ 2068.355424] ------------[ cut here ]------------\n[ 2068.408568] WARNING: CPU: 4 PID: 31 at managers/memory/handle_pcache/fault.c:54 handle_p2m_pcache_miss+0x29d/0x380\n[ 2068.532327] src_nid:0,pid:32,vaddr:0x7ffff7e0e000\n[ 2068.588487] CPU: 4 PID: 31 Comm: mc-manager 4.0.0-lego-ys+ #100\n[ 2068.659207] Stack:\n</code></pre> <pre><code>[root@wuklab13: lib64] $ ll ld-*\n-rwxr-xr-x 1 root root 164112 Nov 30 13:53 ld-2.17.so\nlrwxrwxrwx 1 root root     10 Jan  8 12:34 ld-linux-x86-64.so.2 -&gt; ld-2.17.so\n[root@wuklab13: lib64]\n</code></pre> <p>It turns out there is a bug in mmap code: forgot to increment the file ref count when a file-backed vma is created. Some put_file in loader accidentally free the ld-linux file. Bug fixed, dyloader works like a charm.</p>"},{"location":"lego/log/log-02-2018/#0224-sat","title":"02/24 Sat","text":"<p>Well. PhDs do not have weekends. Anyway, it is Saturday after all, relaxed a little bit. I was looking into the pcache issue. Also added our own kernel version strace.</p>"},{"location":"lego/log/log-02-2018/#0223-fri","title":"02/23 Fri","text":""},{"location":"lego/log/log-02-2018/#solved-fpu-bug","title":"Solved FPU BUG","text":"<p><code>current</code> is fine. I should not compare the old implementation with the new per-cpu current. I forgot that the kernel stack is switched in the <code>__switch_to_asm</code>. This means in <code>__switch_to()</code>, we are actually using the <code>next_p</code>\u2019s kernel stack. So there is small time frame, where <code>current_thread_info()</code> points to <code>next_p</code>, while <code>current_task</code> is still <code>prev_p</code>. Since interrupts are disabled during context switch, we are good with this mismatch.</p> <p>Rule out current, the only thing left is <code>fpu__copy</code> warning, which happens during <code>copy_process()</code>. One weird thing is this function has been called multiple times before it showed a warning. System itself use this function to create a lot background threads, which are fine. Only when it was triggered by <code>sys_clone</code> then we have the warning: <pre><code>[ 3213.055639] CPU: 6 PID: 17 sys_clone+0x0/0x30\n[ 3213.056584] new task_struct: ffff88083e4c9838\n[ 3213.057530] arch_dup_task_struct cpu6 dst:ffff88083e4c9838 17 word_count-seq src:ffff88083e457838 17 word_count-seq\n[ 3213.059536] TRAP do_general_protection in CPU6, error_code: 0 current:ffff88083e457838 17 word_count-seq\n[ 3213.061289] fixup_exception pid(17) cpu(6) insn:0xffffffff81009a21(fpu__copy+0x81/0x260) fixup:0xffffffff8105d9b2(__fixup_text_start+0xc2/0x322) handler:ex_handler_default+0x0/0x20\n[ 3213.064114] ------------[ cut here ]------------\n[ 3213.065040] WARNING: CPU: 6 PID: 17 at ./arch/x86/include/asm/fpu/internal.h:354 fpu__copy+0xc3/0x260\n[ 3213.066760] CPU: 6 PID: 17 Comm: word_count-seq 4.0.0-lego+ #6\n[ 3213.067855] Stack:\n[ 3213.068424] ffff88083e4c7dd0 ffffffff810124b5 ffff88083e4c9bf8 ffff88083e4c9c38\n[ 3213.070133] ffff88083e4c9838 00007ffff7ffd700 ffff88083e4c7de0 ffffffff8101258f\n[ 3213.071775] ffff88083e4c7e08 ffffffff81009a63 ffff88083e457838 ffff88083e4c9838\n[ 3213.073419] ffff88083e457838 ffff88083e4c7e40 ffffffff81000ebb ffff88083e457838\n[ 3213.075057] ffff880800000011 ffff88083e457a68 00000000003d0f00 ffff88083e457838\n[ 3213.076703] Call Trace:\n[ 3213.077295] &lt;TSK&gt;\n[ 3213.077828] [&lt;ffffffff810124c1&gt;] __warn.constprop.0+0x91/0xd0\n[ 3213.078855] [&lt;ffffffff8101258f&gt;] warn_slowpath_null+0xf/0x20\n[ 3213.081653] [&lt;ffffffff81009a63&gt;] fpu__copy+0xc3/0x260\n[ 3213.082543] [&lt;ffffffff81000ebb&gt;] arch_dup_task_struct+0x7b/0x90\n[ 3213.083667] [&lt;ffffffff8101d32e&gt;] copy_process+0x14e/0x10e0\n[ 3213.084618] [&lt;ffffffff8103a3c6&gt;] ? n_tty_write+0x166/0x3c0\n[ 3213.085564] [&lt;ffffffff8101e2e6&gt;] do_fork+0x26/0x140\n[ 3213.086439] [&lt;ffffffff8101e4a0&gt;] ? sys_vfork+0x40/0x40\n[ 3213.087333] [&lt;ffffffff8101e4a0&gt;] ? sys_vfork+0x40/0x40\n[ 3213.088232] [&lt;ffffffff8101e4c9&gt;] sys_clone+0x29/0x30\n[ 3213.089109] [&lt;ffffffff8100e719&gt;] do_syscall_64+0x69/0xf0\n[ 3213.090030] [&lt;ffffffff8100d5ec&gt;] entry_SYSCALL64_slow_path+0x25/0x25\n[ 3213.091078] &lt;EOT&gt;\n[ 3213.091580] ---[ end trace 0000000000000000 ]---\n[ 3213.093250] TRAP do_general_protection in CPU7, error_code: 0 current:ffff88083fd0f008 0 swapper/7\n[ 3213.096526] fixup_exception pid(0) cpu(7) insn:0xffffffff81000c62(__switch_to+0x452/0x630) fixup:0xffffffff8105d922(__fixup_text_start+0x32/0x322) handler:ex_handler_default+0x0/0x20\n[ 3213.101241] ------------[ cut here ]------------\n[ 3213.103285] WARNING: CPU: 7 PID: 0 at ./arch/x86/include/asm/fpu/internal.h:369 __switch_to+0x47e/0x630\n</code></pre></p> <p>So, dig into <code>fpu__copy()</code>, find out why it fails at this certain point. Glad I have something to dig into. </p> <p>The instruction leads to GP is: <pre><code>ffffffff8100b0f5:       48 0f ae 27             xsave64 (%rdi)\n</code></pre></p> <p>which is generated by: <pre><code>#define XSTATE_XSAVE(st, lmask, hmask, err)                             \\\n        asm volatile(ALTERNATIVE_2(XSAVE,                               \\\n                                   XSAVEOPT, X86_FEATURE_XSAVEOPT,      \\\n                                   XSAVES,   X86_FEATURE_XSAVES)        \\\n                     \"\\n\"                                               \\\n                     \"xor %[err], %[err]\\n\"                             \\\n                     \"3:\\n\"                                             \\\n                     \".pushsection .fixup,\\\"ax\\\"\\n\"                     \\\n                     \"4: movl $-2, %[err]\\n\"                            \\\n                     \"jmp 3b\\n\"                                         \\\n                     \".popsection\\n\"                                    \\\n                     _ASM_EXTABLE(661b, 4b)                             \\\n                     : [err] \"=r\" (err)                                 \\\n                     : \"D\" (st), \"m\" (*st), \"a\" (lmask), \"d\" (hmask)    \\\n                     : \"memory\")\nstatic inline void copy_xregs_to_kernel(struct xregs_state *xstate)\n{\n        u64 mask = -1;\n        u32 lmask = mask;\n        u32 hmask = mask &gt;&gt; 32;\n        int err;\n\n        WARN_ON(!alternatives_patched);\n\n        XSTATE_XSAVE(xstate, lmask, hmask, err);\n\n        /* We should never fault when copying to a kernel buffer: */\n        WARN_ON_FPU(err);\n}\n</code></pre></p> <p>From SDM on <code>XSAVE</code>: Use of a destination operand not aligned to 64-byte boundary (in either 64-bit or 32-bit modes) results in a general-protection (#GP) exception. In 64-bit mode, the upper 32 bits of RDX and RAX are ignored.</p> <p><code>%rdi</code> is <code>struct xregs_state *xstate</code> in above code. Thus, check if <code>xstate</code> if 64-bytes aligned. Of course, it is not: <pre><code>[10894.999997] copy_xregs_to_kernel CPU6 xstate: ffff88083e4c8c38\n</code></pre></p> <p>Hehe. Criminal identified. But why? The xstate structure is already marked as <code>__attribute__(aliged 64)</code> in the code. It is the task_struct, which is NOT 0x40 aligned. But god why? Because we currently use <code>kmalloc</code> to allocate new task_struct, whose minimum alignment is <code>8 bytes</code>. Anyway, use <code>__alloc_pages</code> instead.</p> <p>Such an deeply hidden bug. Took me almost a month to find out.</p>"},{"location":"lego/log/log-02-2018/#ib","title":"IB","text":"<p>Seen this during boot (at both P and M, although lego continue running correctly): <pre><code>[54017.712533] ***    NodeID    Hostname    LID    QPN\n[54017.770776] ***    -------------------------------------\n[54017.834220] ***         0    wuklab12     13     72\n[54017.892462] ***         1    wuklab14     16     72 &lt;---\n[54017.955906] ***         2    wuklab16     20     74\n[54018.014149] ***\n[54074.552844] ***  Start establish connection (mynodeid: 1)\n[54102.554407] ib_process_mad mad_ifc fails\n[54130.960691] ***  recvpollcq runs on CPU2\n[54131.070918] ***  Successfully built QP for node  0 [LID: 13 QPN: 72]\n[54131.152936] ***  Successfully built QP for node  2 [LID: 20 QPN: 74]\n[54161.228245] ***  FIT layer ready to go!\n[54161.272034] ***\n</code></pre> Another one: <pre><code>[ 1966.930409] ***\n[ 1966.951210] ***  FIT_initial_timeout_s:   30\n[ 1967.002168] ***  FIT_local_id:            0\n[ 1967.052087] ***\n[ 1967.072887] ***    NodeID    Hostname    LID    QPN\n[ 1967.131126] ***    -------------------------------------\n[ 1967.194567] ***         0    wuklab12     13     72 &lt;---\n[ 1967.258005] ***         1    wuklab14     16     72\n[ 1967.316244] ***         2    wuklab16     20     74\n[ 1967.374484] ***\n[ 2032.926448] ***  Start establish connection (mynodeid: 0)\n[ 2032.996068] Fail to modify qp[6]\n[ 2033.032572] Fail to do client_init_ctx\n[ 2033.077287] client_establish_conn: ctx           (null) fail to init_interface\n[ 2033.164646] ibapi_establish_conn: ctx           (null) fail to init_interface\n[ 2033.250967] ***\n[ 2035.620167] BUG: unable to handle kernel NULL pointer dereference at 0000000000000004\n[ 2035.713763] IP: [&lt;ffffffff8105c589&gt;] client_send_reply_with_rdma_write_with_imm+0x69/0x3b0\n[ 2035.812562] PGD 0\n[ 2035.836482] Oops: 0002 [#1] SMP PROCESSOR\n[ 2035.884321] CPU: 0 PID: 1 Comm: kernel_init 4.0.0-lego-ys+ #253\n[ 2035.955041] RIP: 0010:[&lt;ffffffff8105c589&gt;]  [&lt;ffffffff8105c589&gt;] client_send_reply_with_rdma_write_with_imm+0x69/0x3b0\n...\n[ 2037.313267] &lt;TSK&gt;\n[ 2037.336146] [&lt;ffffffff8105a377&gt;] ibapi_send_reply_timeout+0x57/0x70\n[ 2037.411025] [&lt;ffffffff81033d24&gt;] ? net_send_reply_timeout+0x94/0x132\n[ 2037.486944] [&lt;ffffffff81033d24&gt;] net_send_reply_timeout+0x94/0x132\n</code></pre></p>"},{"location":"lego/log/log-02-2018/#pcache","title":"pcache","text":"<p>Running word_count-pthread, with 100MB dataset, finally got some reasonable bug: <pre><code>[54211.243181] pcache_evict_line(): pset: ffff88207f86e3c0, for uva: 0x7ffff1b8f000\n[54211.385654] pcache:ffff88207f86e3a8 mapcount:8 refcount:0 flags:()\n[54211.510447] pcache dumped because: PCACHE_BUG_ON_PCM(!PcacheLocked(pcm))\n[54212.080336] BUG: failure at managers/processor/pcache/evict.c:240/pcache_evict_line()!\n[54212.664785] Kernel Panic - not syncing: BUG!\n[54212.715742] CPU: 8 PID: 81 Comm: word_count-pthr 4.0.0-lego-ys+ #252\n...\n[54213.391706] &lt;TSK&gt;\n[54213.414584] [&lt;ffffffff81024180&gt;] panic+0xc2/0xeb\n[54213.524818] [&lt;ffffffff8101b81c&gt;] ? task_tick_rt+0x2c/0xd0\n[54213.589295] [&lt;ffffffff81018f75&gt;] ? scheduler_tick+0x55/0x60\n[54213.655850] [&lt;ffffffff81016625&gt;] ? tick_handle_periodic+0x45/0x70\n[54213.728647] [&lt;ffffffff81006634&gt;] ? apic_timer_interrupt+0x54/0x90\n[54213.801443] [&lt;ffffffff8100e22a&gt;] ? smp__apic_timer_interrupt+0x6a/0x70\n[54213.879439] [&lt;ffffffff8101256d&gt;] ? printk+0x11d/0x1b0\n[54214.103027] [&lt;ffffffff8102ecf4&gt;] pcache_evict_line+0x134/0x220\n[54214.172703] [&lt;ffffffff8102c6ae&gt;] pcache_alloc+0x22e/0x2e0\n[54214.237179] [&lt;ffffffff8102be0a&gt;] common_do_fill_page+0x2a/0x1f0\n[54214.307895] [&lt;ffffffff8102baf0&gt;] ? move_page_tables+0x4c0/0x4c0\n[54214.378612] [&lt;ffffffff8102c172&gt;] pcache_handle_fault+0x1a2/0x3a0\n[54214.450367] [&lt;ffffffff8100fc02&gt;] do_page_fault+0xa2/0x1a0\n[54214.514843] [&lt;ffffffff8100d85f&gt;] page_fault+0x1f/0x30\n[54214.575161] [&lt;ffffffff81034842&gt;] ? copy_user_enhanced_fast_string+0x2/0x10\n[54214.657316] [&lt;ffffffff81032368&gt;] ? seq_read+0x248/0x360\n[54214.719714] [&lt;ffffffff810307af&gt;] sys_read+0x3f/0xc0\n[54214.777949] [&lt;ffffffff81030770&gt;] ? sweep_pset_lru+0x220/0x220\n[54214.846587] [&lt;ffffffff8100e619&gt;] do_syscall_64+0x69/0xf0\n[54214.910022] [&lt;ffffffff8100d4ec&gt;] entry_SYSCALL64_slow_path+0x25/0x25\n[54214.985939] &lt;EOT&gt;\n</code></pre></p> <p>Another one: <pre><code>[  735.393244] pcache_evict_line(): pset: ffff88207f86e3c0, for uva: 0x7ffff1b8fd90\n[  735.537804] pcache:ffff88207f86e3a8 mapcount:8 refcount:0 flags:()\n[  735.663642] pcache dumped because: PCACHE_BUG_ON_PCM(!PcacheLocked(pcm))\n</code></pre></p> <p>Do note this happens after computation. This happens when phoenix create a lot threads to sort the results.</p> <p>Both bug happen to the same set, same user page. The pcache is clearly corrupted: <code>mapcount:8, refcount:0, flags:().</code></p> <p>Come back after dinner. Remember to check altenative, cause the XSAVE above should be XSAVEOPT. Make sure it does not override other memory. Also, check linker script. Do not forget to link any sections.</p> <p>Another several bug logs in wuklab13 and wuklab15: <code>022318-*</code>. I\u2019m really tired today after fixing the FPU bug. But I\u2019m also pretty confident pcache is something I\u2019m able to debug. Even thought it is hard in SMP case.</p> <p>Anyway, I gonna call for the day.</p>"},{"location":"lego/log/log-02-2018/#0222-thur","title":"02/22 Thur","text":"<ul> <li>context switch fpu</li> <li>signal compat check, all good.</li> <li> make <code>current</code> use percpu current_task, so all code in Lego is consistent.</li> <li>checked <code>entry_SYSCALL-64</code> again, which looks good to me.</li> <li>The only concern is <code>rsp_scratch</code> and <code>current_top_of_stack</code>, which are per-cpu variables. If these per-cpu is setup wrong, then we are doomed.</li> <li>Also check if per-cpu is all cleared up?</li> <li>try big syscall lock</li> <li>does x86 has to use different kernel stacks? Interrupt is using different stack in Linux, has to do so???</li> <li>check current is correct. compare with old implementation.</li> </ul> <p>First of all, FPU is definitely functional for now. Since I replaced the current macro today, I add some code to check if this current matches our old implementation: <pre><code>static __always_inline struct task_struct *get_current(void)                                                           \n{                                                                                                                      \n        return this_cpu_read_stable(current_task);                                                                     \n}\n\n//#define current get_current()\n\n#define current                                                 \\\n({                                                              \\\n        struct task_struct *old = current_thread_info()-&gt;task;  \\\n        struct task_struct *new = get_current();                \\\n                                                                \\\n        if (old != new) {                                       \\\n                printk(\"%s:%d() cpu:%d old:%pS %d %s new:%pS %d %s\\n\",  \\\n                        __func__, __LINE__, smp_processor_id(), old, old-&gt;pid, old-&gt;comm, \\\n                        new, new-&gt;pid, new-&gt;comm);              \\\n                BUG();                                          \\\n        }                                                       \\\n        get_current();                                          \\\n})\n</code></pre></p> <p>Combined with some FPU warning, it is now like this: <pre><code>[ 3273.748819] CPU:5 PID:32   sys_clone+0x0/0x30\n[ 3273.800808] alloc_task_struct_node: size:740 ffff88107e831838\n[ 3273.869451] arch_dup_task_struct() CPU5 current:32 new: ffff88107e831838 old: ffff88107e827838 32\n[ 3273.975533] ------------[ cut here ]------------\n[ 3274.030651] WARNING: CPU: 5 PID: 32 at ./arch/x86/include/asm/fpu/internal.h:354 fpu__copy+0xe2/0x310\n[ 3274.140895] CPU: 5 PID: 32 Comm: word_count-pthr 4.0.0-lego-ys-gdbe6dbe-dirty #249\n[ 3274.231377] Stack:\n[ 3274.255298] ffff88107e82fd68 ffffffff81016dbf 00000000ffffffff 0000000000000000\n[ 3274.342659] 00000000ffffffff 0000000000000000 ffff88107e831bf8 ffff88107e831c38\n[ 3274.430021] ffff88107e831838 000000207fe64000 ffff88107e82fd78 ffffffff810170af\n[ 3274.517382] ffff88107e82fdc0 ffffffff8100b052 0000000000000020 ffff88107e831838\n[ 3274.604745] ffff88107e827838 ffff88107e827838 ffff88107e831838 ffff88107e827838\n[ 3274.692106] Call Trace:\n[ 3274.721229] &lt;TSK&gt;\n[ 3274.744109] [&lt;ffffffff81016dd8&gt;] __warn.constprop.0+0xe8/0x3b0\n[ 3274.813790] [&lt;ffffffff810170af&gt;] warn_slowpath_null+0xf/0x20\n[ 3274.881391] [&lt;ffffffff8100b052&gt;] fpu__copy+0xe2/0x310\n[ 3274.941713] [&lt;ffffffff810012e4&gt;] arch_dup_task_struct+0x84/0x120\n[ 3275.013475] [&lt;ffffffff81022c10&gt;] copy_process+0x160/0x1e60\n[ 3275.078996] [&lt;ffffffff81024936&gt;] do_fork+0x26/0x140\n[ 3275.137238] [&lt;ffffffff81024af0&gt;] ? sys_vfork+0x40/0x40\n[ 3275.198599] [&lt;ffffffff81024af0&gt;] ? sys_vfork+0x40/0x40\n[ 3275.259960] [&lt;ffffffff81024b19&gt;] sys_clone+0x29/0x30\n[ 3275.319242] [&lt;ffffffff81012314&gt;] do_syscall_64+0x84/0x240\n[ 3275.383723] [&lt;ffffffff8101106c&gt;] entry_SYSCALL64_slow_path+0x25/0x25\n[ 3275.459645] &lt;EOT&gt;\n[ 3275.482526] ---[ end trace 0000000000000000 ]---\n[ 3275.537648] wake_up_new_task CPU5 task:ffff88107e831838, dest_cpu:6 current:32\n[ 3275.623970] SMP IPI: reschedule_interrupt() CPU(6) PID(0)\n[ 3275.739412] do_general_protection:186() cpu:6 old:0xffff88107e831838 33 word_count-pthr new:0xffff88107fcaf008 0 swapper/6\n\n[ 3275.871493] ------------[ cut here ]------------\n[ 3275.926614] BUG: failure at arch/x86/kernel/traps.c:186/do_general_protection()!\n[ 3276.015018] Kernel Panic - not syncing: BUG!\n[ 3276.065978] panic:107() cpu:6 old:0xffff88107e831838 33 word_count-pthr new:0xffff88107fcaf008 0 swapper/6\n</code></pre></p> <p>Based on the switch code: <pre><code>__switch_to(struct task_struct *prev_p, struct task_struct *next_p)\n{\n        this_cpu_write(current_task, next_p);\n\n        /* Reload sp0 This changes current_thread_info(). */\n        load_sp0(tss, next);\n}\n</code></pre></p> <p>Based on log line 30, <code>load_sp0()</code> already happened, which means <code>this_cpu_write(..)</code> happened too. If <code>this_cpu_write(..)</code> happened, then log line 30\u2019s new should have been updated to <code>0xffff88107e831838</code>. Something wrong with percpu?</p>"},{"location":"lego/log/log-02-2018/#0221-wed","title":"02/21 Wed","text":"<ul> <li>irq_regs, old code, check</li> <li>signal frame, and fpu hook together Done</li> <li><code>in_interrupt()</code>, it is empty, TODO</li> <li>check arch/x86/Makefile, it introduce a lot FPU flags.</li> <li>added more than 4K lines today. Damn FPU. Ugh go home sleep.</li> </ul>"},{"location":"lego/log/log-02-2018/#0220-tue-cloudy","title":"02/20 Tue Cloudy","text":"<p>Not too many Sunny days recently. Well, continue yesterday\u2019s work. I don\u2019t think I can easily find out why so many <code>/proc/memoinfo</code> open happened. Instead, I\u2019m trying to enable the <code>flush_thread</code> in P\u2019s exec code.</p> <p>During the way, I found some issue related to <code>__ARCH_HAS_SA_RESTORER</code> in signal code. I need to check if these x86 macros are defined, but lego does not port them.</p> <p>Well, it turns out flush_thread does not make too much difference. Next I\u2019m going to try to disable <code>exit_thread</code>, which uses <code>fpu__drop()</code>.</p> <p>Hmm, disable <code>exit_thread</code> also does not work.</p>"},{"location":"lego/log/log-02-2018/#0219-mon-rainy","title":"02/19 Mon Rainy","text":"<p>It is another week. I can not deny I\u2019m a little tired about the bug. Tried so many possible solutions, but none of them work. Well, today I first need to test the vma changes (pgoff and anon_vma) thing. Especially the vma merge and split.</p> <p>This morning I fixed a bug in kernel_init process: make kernel_init able to run all possible CPUs. Because the first user process is forked from kernel_init, it is quite important that it gets the right cpu affinity: <pre><code>static int kernel_init(void *unused)\n{\n        ...\n        set_cpus_allowed_ptr(current, cpu_possible_mask);\n        ...\n}\n</code></pre></p> <p>Well, interestingly, the unmodified word_count-pthread succeed with 50MB dataset\u2026 with or without any DEBUG option! Amazing! I need to find out why the cpus_allowed becomes 0 at the beginning of kernel_init. Because <code>init_task</code> actually has: <pre><code>    .cpus_allowed   = CPU_MASK_ALL,\n    .nr_cpus_allowed= NR_CPUS,\n</code></pre></p> <p>Things to do next:</p> <ul> <li>check why the cpus_allowed changed</li> <li>check why word_count-pthread open <code>/dev/../cpu</code> so many times. Anything wrong with our <code>copy_files</code>, or open, close?</li> <li>here is an idea, to verify if FPU code is correct, run some scientific benchmarks.</li> </ul> <p>Okay, findings:</p> <ul> <li> <p>cpus_allowd is fine, it is reset inside <code>sched_init()</code>, when it tries make the <code>init_task</code> as the <code>idle</code> thread. Thus it is reasonable to set cpus_allowed again at <code>kernel_init</code> thread. And it should NOTHING to do with the bug.</p> </li> <li> <p>about the second, check the following log: <pre><code>[11838.364543] STDOUT: ---[\nWordcount: Running...\n]---\n[11838.422886] STDOUT: ---[\n\n\n]---\n[11838.463445] SYSC_open(cpu5 pid:32): f_name: /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_50MB.txt, flags: 0, mode: 900\n[11838.619460] SYSC_open(cpu5 pid:32): fd: 3\n[11838.667406] SYSC_open(cpu5 pid:32): f_name: /sys/devices/system/cpu/online, flags: 80000, mode: 0\n[11838.773351] SYSC_open(cpu5 pid:32): fd: 4\n[11838.821239] seq_file:\n  dest_uva: 00007fffffffc8d0, nr_chars: 5\n  string: [0-23\n]\n[11838.913791] SYSC_close(cpu5 pid:32): fd: 4\n[11838.962622] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[11840.223255] STDOUT: ---[\nWord Count: Computation Completed 1.555581 sec\n\n]---\n[11840.309678] SYSC_open(cpu5 pid:32): f_name: /sys/devices/system/cpu/online, flags: 80000, mode: 0\n[11840.415754] SYSC_open(cpu5 pid:32): fd: 4\n[11840.463593] seq_file:\n  dest_uva: 00007fffffffc8a0, nr_chars: 5\n  string: [0-23\n]\n[11840.556147] SYSC_close(cpu5 pid:32): fd: 4\n[11840.605024] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[11840.677821] STDOUT: ---[\nTHe number of processors is 24\n\n\u00f4\n]---\n[11840.753769] SYSC_open(cpu7 pid:80): f_name: /proc/meminfo, flags: 80000, mode: 1b6\n[11840.844212] SYSC_open(cpu19 pid:92): f_name: /proc/meminfo, flags: 80000, mode: 1b6\n[11840.935728] SYSC_open(cpu7 pid:80): fd: 4\n[11840.983567] SYSC_open(cpu19 pid:92): fd: 5\n[11841.032444] seq_file:\n  dest_uva: 00007ffff444c000, nr_chars: 172\n  string: [MemTotal:       115355128 kB\nMemFree:        115355128 kB\nMemAvailable:   115355128 kB\nDirectMap4k:        5812 kB\nDirectMap2M:     1861632 kB\nDirectMap1G:    134217728 kB\n]\n[11841.305953] seq_file:\n  dest_uva: 00007ffff444b000, nr_chars: 172\n  string: [MemTotal:       115355128 kB\nMemFree:        115355128 kB\nMemAvailable:   115355128 kB\nDirectMap4k:        5812 kB\nDirectMap2M:     1861632 kB\nDirectMap1G:    134217728 kB\n]\n[11841.579460] SYSC_close(cpu7 pid:80): fd: 4\n[11841.628339] SYSC_close(cpu19 pid:92): fd: 5\n[11841.678257] SYSC_close(): [4] -&gt; [/proc/meminfo]\n[11841.733375] SYSC_close(): [5] -&gt; [/proc/meminfo]\n[11841.788493] SYSC_open(cpu18 pid:91): f_name: /proc/meminfo, flags: 80000, mode: 1b6\n[11841.880008] SYSC_open(cpu6 pid:102): f_name: /proc/meminfo, flags: 80000, mode: 1b6\n[11841.971523] SYSC_open(cpu12 pid:85): f_name: /proc/meminfo, flags: 80000, mode: 1b6\n[11842.063040] SYSC_open(cpu0 pid:97): f_name: /proc/meminfo, flags: 80000, mode: 1b6\n[11842.153516] SYSC_open(cpu14 pid:87): f_name: /proc/meminfo, flags: 80000, mode: 1b6\n[11842.245032] SYSC_open(cpu16 pid:89): f_name: /proc/meminfo, flags: 80000, mode: 1b6\n[11842.336548] SYSC_open(cpu4 pid:100): f_name: /proc/meminfo, flags: 80000, mode: 1b6\n[11842.428064] SYSC_open(cpu16 pid:89): fd: 9\n[11842.476942] SYSC_open(cpu4 pid:100): fd: 10\n[11842.526860] seq_file:\n  dest_uva: 00007ffff444c000, nr_chars: 172\n  string: [MemTotal:       115355128 kB\nMemFree:        115355128 kB\nMemAvailable:   115355128 kB\nDirectMap4k:        5812 kB\nDirectMap2M:     1861632 kB\nDirectMap1G:    134217728 kB\n]\n[11842.800368] seq_file:\n  dest_uva: 00007ffff444b000, nr_chars: 172\n  string: [MemTotal:       115355128 kB\nMemFree:        115355128 kB\nMemAvailable:   115355128 kB\nDirectMap4k:        5812 kB\nDirectMap2M:     1861632 kB\nDirectMap1G:    134217728 kB\n]\n[11843.073877] SYSC_close(cpu16 pid:89): fd: 9\n</code></pre></p> </li> <li> <p>However, in a normal Linux exeution: <pre><code>strace -C -o strace_2 ./word_count-pthread ./word_count_datafiles/word_50MB.txt\n\n% time     seconds  usecs/call     calls    errors syscall\n------ ----------- ----------- --------- --------- ----------------\n 86.41    0.052074        1736        30           futex\n  6.89    0.004151          67        62           munmap\n  2.47    0.001490          17        88           mmap\n  2.12    0.001278          14        93           clone\n  1.51    0.000912          14        64           mprotect\n  0.19    0.000117           7        16           write\n  0.15    0.000092          46         2           open\n\n$ cat strace_2 | grep open\n  open(\"./word_count_datafiles/word_50MB.txt\", O_RDONLY) = 3\n  open(\"/sys/devices/system/cpu/online\", O_RDONLY|O_CLOEXEC) = 4\n</code></pre></p> </li> <li> <p>It opened the <code>/proc/meminfo</code> for way too many times. In the normal Linux execution, this should not happen. Is it because our meminfo is faked, so glibs is complaining? But why it does not open meminfo while running in Linux? Or does our entry assembly messed up some stuff in stack, so the return path changed?</p> </li> <li> <p>oh, about the FPU. It reminds our <code>flush_thread</code> function actually has an issue before. When I enabled this function during loading in P, the P will crash. Within <code>flush_thread</code>, there is a <code>fpu_clear</code>!!! So, check this tomorrow! (12:00am, need to go home)</p> </li> </ul>"},{"location":"lego/log/log-02-2018/#0218-sun-sunny","title":"02/18 Sun Sunny","text":"<p>It is a nice day. Yesterday I\u2019ve changed one line of code in mmap code path: change anonymous vma\u2019s pgoff from some value to 0. The result is I got several succeed work-count-pthread(bind to one core) testing. However, it still fail with unmodified word-count-pthread.</p> <p>It brings me to inspect pgoff manipulation code and all mmap.c code. We ported everything from linux without almost zero modification. That means we ported all those useless <code>anon_vma</code> and pgoff code, which is used a lot by vma_merge, vma_split code. The thing is: our memory manager, our vma code do not need such <code>anon_vma</code> structure, and do not maintain pgoff. Thus, I\u2019m a little bit worried linux code may doing some crazy behind our back: mess vma and pages, then pcache miss gets some wrong pages</p> <p>Well. Lego does not use <code>anon_vma</code>, and pgoff should only be used by file-backed vma. So, I decided to remove <code>anon_vma</code> from our code, and make sure pgoff is used properly. Of course, the goal is to make vma_merge, split, copy, do the things we intended.</p> <p>Lesson learned.</p>"},{"location":"lego/log/log-02-2018/#0217-sat-snowy","title":"02/17 Sat Snowy","text":"<p>Fixed the bss bug. It comes from loader. We did not implement the <code>lego_clear_user</code> function, so some part of bss is non-zero.</p> <p>Bad news is word_count-pthread still fail at same fpu instruction. Have to look into memory code more.</p> <p>This is actually a fun debugging story. We should always add TODO or XXX or some warnings to unfinished code, no matter what. Lesson learned.</p>"},{"location":"lego/log/log-02-2018/#0216-fri-cloudy","title":"02/16 Fri Cloudy","text":"<p>Yilun found a major loader bug yesterday: the <code>.bss</code> section variables are not 0, in the <code>iozone</code> benchmark. I did not encounter this issue before with simple test program. This is pretty serious.</p>"},{"location":"lego/log/log-02-2018/#0215-thur-rainy","title":"02/15 Thur Rainy","text":"<p>Today is Chinese New Year.</p> <p>Line 7 and 8 show the uva belong to the same page. Need to revisit <code>get_arg_pages</code> etc functions.</p> <pre><code>[  108.393991] handle_p2m_execve(): pid:22,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  108.395255]     argc[0] (len: 65):  /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  108.396329]     argc[1] (len: 82):  /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt\n[  108.397530]     envc[0] (len:  7):  HOME=/\n[  108.398069]     envc[1] (len: 11):  TERM=linux\n[  108.398640] __bprm_mm_init vma: ffff88083effe6b8\n[  108.399226] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffefed\n[  108.399949] faultin_page vma: ffff88083effe6b8 uva: 0x7fffffffef94\n</code></pre> <p>Well, this is 100% fine. I wrote this loader code long time ago and need some time to pickup. So, after I read the loader code, especially the <code>copy_strings</code> function, I found this is okay. Because copy_strings will be invoked three times, so the <code>faultin_page</code> basically will be invoked at least three times. That is why it went to that pte fault handling code.</p> <p>Although actually I think <code>copy_strings</code> should not use <code>faultin_page</code>, instead, it should use <code>get_user_pages</code>, which will walk through the pgtable first, then went to <code>handle_lego_mm_fault</code>.</p>"},{"location":"lego/log/log-02-2018/#0214-wed-rainy","title":"02/14 Wed Rainy","text":"<p>Hmm, tried to make kmalloc behave as kzalloc, and bind all threads to one core, still gave the same old bug: <pre><code>  42731a:       f3 0f 6f 16             movdqu (%rsi),%xmm2\n\n  [93182.657376] word_count-pthr[85] general protection ip:42731a sp:7fffe3ffed28 error:0\n  [93182.747959] CPU: 8 PID: 85 Comm: word_count-pthr 4.0.0-lego+ #170\n  [93182.820758] RIP: 0033:[&lt;000000000042731a&gt;]  [&lt;000000000042731a&gt;] 0x42731a\n  [93182.901878] RSP: 002b:00007fffe3ffed28  EFLAGS: 00010283\n  [93182.965317] RAX: 000000000000001f RBX: 00007ffff001b010 RCX: 0000000000000005\n  [93183.050596] RDX: 0000000000000000 RSI: 5345485355420045 RDI: 00007ffff294791f\n  [93183.135876] RBP: 00007ffff294791f R08: 000000000000ffff R09: 0000000000000008\n  [93183.221156] R10: fffffffffffff048 R11: 00000000004acfc0 R12: 0000000000001cde\n  [93183.306435] R13: 00000000006e4a8c R14: 0000000000001cd7 R15: 0000000000001cda\n  [93183.391716] FS:  00007fffe3fff700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000\n  [93183.488434] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n  [93183.557075] CR2: 00007ffff27a4000 CR3: 000000107e924000 CR4: 00000000000406a0\n</code></pre></p> <pre><code>  427377:       66 0f 6f 17             movdqa (%rdi),%xmm2\n\n  [93180.527248] word_count-pthr[93]: segfault at 0x0 ip 0000000000427377 sp 00007fffdfff6d28 error 4\n  [93180.630314] CPU: 8 PID: 93 Comm: word_count-pthr 4.0.0-lego+ #170\n  [93180.703114] RIP: 0033:[&lt;0000000000427377&gt;]  [&lt;0000000000427377&gt;] 0x427377\n  [93180.784234] RSP: 002b:00007fffdfff6d28  EFLAGS: 00010297\n  [93180.847674] RAX: 0000000000000000 RBX: 000000000073c4c0 RCX: 000000000000000d\n  [93180.932953] RDX: 000000000000ffff RSI: 00007ffff4999070 RDI: 0000000000000000\n  [93181.018233] RBP: 00007ffff499907d R08: 000000000000ffff R09: 0000000000000000\n  [93181.103513] R10: 0000000000427760 R11: 00007ffff49982c0 R12: 0000000000000118\n  [93181.188791] R13: 00000000006e4aac R14: 0000000000000116 R15: 0000000000000117\n  [93181.274072] FS:  00007fffdfff7700(0000) GS:ffff88107fc80000(0000) knlGS:0000000000000000\n  [93181.370790] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n  [93181.439430] CR2: 0000000000000000 CR3: 000000107e924000 CR4: 00000000000406a0\n</code></pre> <p>Tried several ways to ensure memory safety. It still failed even if I enabled all of them. So, I guess the memory safety is ensured? Still some other things?</p> <ul> <li>force <code>alloc_pages</code> to use <code>__GFP_ZERO</code></li> <li>make <code>kmalloc</code> behave as <code>kzalloc</code></li> <li>make <code>kfree</code> empty</li> </ul> <p>I also suspect <code>munmap</code> may free extra wrong pgtable entries. Although I\u2019ve went through all the code and checked, but in addition to the above things, I\u2019m going to:</p> <ul> <li>make munmap dummy (no p2m_munmap, return 0 directly)</li> </ul> <p>Failed.</p> <p>Next, I\u2019m going to:</p> <ul> <li>add checksum for every page transferred across network.</li> <li>add warning for unnormal cases</li> </ul> <p>Bang! I found something while running P+M: <pre><code>[  115.727597] Memory-component manager is up and running.\n[  116.691723] handle_p2m_fork(): nid:0,pid:22,tgid:22,parent_tgid:1\n[  116.697038] handle_p2m_fork(): reply: 0:OKAY\n[  116.791088] handle_p2m_execve(): pid:22,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  116.792357]     argc[0] (len: 65):  /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  116.793439]     argc[1] (len: 82):  /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt\n[  116.794653]     envc[0] (len:  7):  HOME=/\n[  116.795196]     envc[1] (len: 11):  TERM=linux\n[  116.795772] __bprm_mm_init vma: ffff88083effe6b8\n[  116.796209] faultin_page vma: ffff88083effe6b8\n[  116.796729] faultin_page vma: ffff88083effe6b8\n[  116.797150] handle_pte_fault vma: ffff88083effe6b8 entry: 0xffff88083e8c1067\n[  116.798044] pte:ffff88083e8c0ff0 pfn:0x8083e8c1 flags:(present|writable|user|accessed|dirty|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000)\n[  116.799462] ------------[ cut here ]------------\n[  116.800049] WARNING: CPU: 4 PID: 15 at managers/memory/vm/fault.c:148 handle_lego_mm_fault+0x4d8/0x550\n[  116.801148] CPU: 4 PID: 15 Comm: mc-manager 4.0.0-lego+ #78\n[  116.801818] Stack:\n[  116.802179] ffff88083e893c50 ffffffff8100e827 00007fffffffef94 ffff88083effe6b8\n[  116.803283] ffff88083e894008 ffff88083e8c1067 ffff88083e893c60 ffffffff8100e91f\n[  116.804387] ffff88083e893cf0 ffffffff8102b008 0000000000000031 ffff88083e893cf0\n[  116.805488] 0000000000000296 00003fffffe00000 ffff800000000067 ffff88083e893d50\n[  116.806590] ffff880000000001 ffffffff81066798 ffff88083effe6b8 ffff88083e893d50\n[  116.807691] Call Trace:\n[  116.808087] &lt;TSK&gt;\n[  116.808448] [&lt;ffffffff8100e836&gt;] __warn.constprop.0+0xa6/0x100\n[  116.809126] [&lt;ffffffff8100e91f&gt;] warn_slowpath_null+0xf/0x20\n[  116.809802] [&lt;ffffffff8102b008&gt;] handle_lego_mm_fault+0x4d8/0x550\n[  116.810505] [&lt;ffffffff8102cfe3&gt;] faultin_page+0x43/0xb0\n[  116.811131] [&lt;ffffffff8102dab1&gt;] copy_strings.isra.1+0xe1/0x130\n[  116.811819] [&lt;ffffffff8102dd1e&gt;] exec_loader+0x21e/0x350\n[  116.812457] [&lt;ffffffff8102680a&gt;] handle_p2m_execve+0x1aa/0x290\n</code></pre></p> <p>This is a temporary stack vma that loader created for saving argv and envp. So, this vma was created here:</p> <pre><code>static int __bprm_mm_init(struct lego_binprm *bprm)\n{\n        ...\n        bprm-&gt;vma = vma = kzalloc(sizeof(*vma), GFP_KERNEL);\n        ...\n}\n</code></pre> <p>And then <code>copy_strings</code> will call <code>faultin_page</code> to populate a page for a specific user virtual adddress:</p> <pre><code>int faultin_page(struct vm_area_struct *vma, unsigned long start,\n                 unsigned long flags, unsigned long *kvaddr)\n{\n        ...\n        ret = handle_lego_mm_fault(vma, start, flags, kvaddr);\n        ...\n}\n</code></pre> <p>Eventually, the <code>handle_lego_mm_fault</code> will call <code>handle_pte_fault</code>:</p> <pre><code>static int handle_pte_fault(struct vm_area_struct *vma, unsigned long address,\n                            unsigned int flags, pte_t *pte, pmd_t *pmd,\n                            unsigned long *mapping_flags)\n{\n        ...\n        if (!pte_present(entry)) {\n                ...\n        }\n\n        pr_info(\"%s vma: %p entry: %#lx\\n\", FUNC, vma, entry.pte);\n        dump_pte(pte, NULL);\n        WARN_ON_ONCE(1);\n        ...\n}\n</code></pre> <p>Apparently, pte is wrong! But I don\u2019t have time today. Continue tomorrow. Hmm forgot that we are saving kernel virtual addresses in the pte. Just take a quick look at the lego_pud_alloc things, seems will have some issues. I defenitly need to check all these stuff tomorrow. I\u2019ve not touch this part for too long!</p>"},{"location":"lego/log/log-02-2018/#0213-tue-sunny","title":"02/13 Tue Sunny","text":"<p>Checking our SLOB allocator today. So I found Yutong\u2019s code is using <code>set_page_private</code> when slob get a new page from buddy. This private field is only intended to be used by buddy to record the <code>order</code>. This mixed usage will confuse buddy and create bug.</p> <p>Even though I removed the <code>set_page_private(page, 0)</code> after <code>free_page</code>, word_count-pthread still fails. Damn.</p>"},{"location":"lego/log/log-02-2018/#0212-mon-cloudy","title":"02/12 Mon Cloudy","text":"<p>Add this commit <code>4cb3a8b6a943c90714fd9bb5e5465ee315f0aa30</code>: <pre><code>    memory: Use kzalloc instead of kmalloc in __bprm_mm_init (loader)\n\n    This was an potentionl bug that was not triggered previously.\n    It is simply because kmalloc'ed vma contains some garbage area,\n    while later in the pgfault code, we use\n            if (vma-&gt;vm_ops &amp;&amp; vma-&gt;vm_ops-&gt;fault)\n                    ...\n    to check if it is an file-backed fault.\n\n    Fortunately the vma-&gt;vm_ops happens to have some leftover value.\n    So this bug was triggered.\n\n    This actually reminds me that this is a series of potential bugs!\n    Even though before I've added things like force GFP_ZERO in all\n    physical page allocation, I missed the kmalloc's case!\n</code></pre></p> <p>The story is:</p> <p>I patched the stop_machine code today, and tried to run code with P+M on VM, everything works fine. However, when I tried to run the new code with P+M+S on physical machine, M crashed at a very weird point: <pre><code>[ 7791.998168] handle_p2m_execve(): pid:81,argc:2,envc:2,file:/root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[ 7792.129312] BUG: unable to handle kernel NULL pointer dereference at 0000000000000031\n[ 7792.222889] IP: [&lt;ffffffff8102c180&gt;] handle_lego_mm_fault+0x160/0x4b0\n[ 7792.299842] PGD 0\n[ 7792.323760] Oops: 0000 [#1] PREEMPT SMP MEMORY\n[ 7792.376794] CPU: 4 PID: 79 Comm: mc-manager 4.0.0-lego+ #29\n[ 7792.443349] RIP: .. [&lt;ffffffff8102c180&gt;] handle_lego_mm_fault+0x160/0x4b0\n......\n....\n[ 7793.750506] Call Trace:\n[ 7793.779623] &lt;TSK&gt;\n[ 7793.802501] [&lt;ffffffff810053f4&gt;] ? apic_timer_interrupt+0x54/0x90\n[ 7793.875295] [&lt;ffffffff8102e469&gt;] faultin_page+0x9/0x70\n[ 7793.936649] [&lt;ffffffff8102ef01&gt;] copy_strings.isra.1+0xe1/0x130\n[ 7794.007362] [&lt;ffffffff8102f11e&gt;] exec_loader+0x1ce/0x340\n[ 7794.070796] [&lt;ffffffff81027def&gt;] handle_p2m_execve+0x12f/0x200\n[ 7794.140469] [&lt;ffffffff810274fb&gt;] mc_manager+0x1ab/0x2b0\n[ 7794.202864] [&lt;ffffffff81027350&gt;] ? bitmap_fill+0x33/0x33\n[ 7794.266298] [&lt;ffffffff8101c6b7&gt;] kthread+0x107/0x130\n[ 7794.325572] [&lt;ffffffff8101c5b0&gt;] ? __kthread_parkme+0x90/0x90\n[ 7794.394205] [&lt;ffffffff8100b462&gt;] ret_from_fork+0x22/0x30\n</code></pre></p> <p>So faulting source code is: <pre><code>static int handle_pte_fault(struct vm_area_struct *vma, unsigned long address,\n                            unsigned int flags, pte_t *pte, pmd_t *pmd)\n{\n    ....\n        if (vma-&gt;vm_ops &amp;&amp; vma-&gt;vm_ops-&gt;fault)\n                return do_linear_fault(vma, address, flags,\n                                       pte, pmd, entry)\n    ....\n</code></pre></p> <p>Something wrong with <code>vma</code>? At this loader stage, this vma is a temporaty stack vma created for saving <code>argv</code> and <code>envp</code>. So I look back into the code that created this vma: <pre><code>managers/memory/loader/core.c:\nstatic int __bprm_mm_init(struct lego_binprm *bprm)\n{\n        int err;\n        struct vm_area_struct *vma = NULL;\n        struct lego_mm_struct *mm = bprm-&gt;mm;\n\n        bprm-&gt;vma = vma = kmalloc(sizeof(*vma), GFP_KERNEL);\n        if (!vma)\n                return -ENOMEM;\n</code></pre></p> <p>The code after this does NOT do necessary cleanup. The <code>vm_ops</code> happens to have some garbage value from last user. So it is not 0, so the above <code>vma-&gt;vm_ops</code> is true, and it will try to read <code>vma-&gt;vm_ops-&gt;fault</code>. And that, my friend, is where garbage turns into crash.</p> <p>This presents a series of potential bugs. Ugh, <code>memory safety</code>!</p>"},{"location":"lego/log/log-02-2018/#0209-fri-cloudy","title":"<code>02/09 Fri Cloudy</code>","text":"<p>Tried to modify Phoneix code: replace <code>realloc</code> with <code>malloc+mempcy</code>. Thus the <code>mremap</code> syscall is avoided, but it still has general protection fault. Same with yesterday, corrupted at <code>__strcmp_sse42</code>, with corrupted <code>RSI</code> or <code>RDI</code>. So I guess it is not about <code>mremap</code> itself at all. I will follow yesterday\u2019s checking list.</p>"},{"location":"lego/log/log-02-2018/#0208-thur-cloudy","title":"<code>02/08 Thur Cloudy</code>","text":"<pre><code>00000000004272d0 &lt;__strcmp_sse42&gt;:\n\n  4272d0:       89 f1                   mov    %esi,%ecx\n  4272d2:       89 f8                   mov    %edi,%eax\n  4272d4:       48 83 e1 3f             and    $0x3f,%rcx\n  4272d8:       48 83 e0 3f             and    $0x3f,%rax\n  4272dc:       83 f9 30                cmp    $0x30,%ecx\n  4272df:       77 3f                   ja     427320 &lt;__strcmp_sse42+0x50&gt;\n  4272e1:       83 f8 30                cmp    $0x30,%eax\n  4272e4:       77 3a                   ja     427320 &lt;__strcmp_sse42+0x50&gt;\n  4272e6:       f3 0f 6f 0f             movdqu (%rdi),%xmm1\n* 4272ea:       f3 0f 6f 16             movdqu (%rsi),%xmm2\n  4272ee:       66 0f ef c0             pxor   %xmm0,%xmm0\n  4272f2:       66 0f 74 c1             pcmpeqb %xmm1,%xmm0\n  4272f6:       66 0f 74 ca             pcmpeqb %xmm2,%xmm1\n  4272fa:       66 0f f8 c8             psubb  %xmm0,%xmm1\n  4272fe:       66 0f d7 d1             pmovmskb %xmm1,%edx\n  427302:       81 ea ff ff 00 00       sub    $0xffff,%edx\n  427308:       0f 85 42 0d 00 00       jne    428050 &lt;__strcmp_sse42+0xd80&gt;\n  42730e:       48 83 c6 10             add    $0x10,%rsi\n  427312:       48 83 c7 10             add    $0x10,%rdi\n  427316:       66 2e 0f 1f 84 00 00    nopw   %cs:0x0(%rax,%rax,1)\n  42731d:       00 00 00  \n  427320:       48 83 e6 f0             and    $0xfffffffffffffff0,%rsi\n  427324:       48 83 e7 f0             and    $0xfffffffffffffff0,%rdi\n  427328:       ba ff ff 00 00          mov    $0xffff,%edx\n  42732d:       45 31 c0                xor    %r8d,%r8d\n  427330:       83 e1 0f                and    $0xf,%ecx\n  427333:       83 e0 0f                and    $0xf,%eax\n  427336:       66 0f ef c0             pxor   %xmm0,%xmm0\n  42733a:       39 c1                   cmp    %eax,%ecx\n  42733c:       74 32                   je     427370 &lt;__strcmp_sse42+0xa0&gt;\n  42733e:       77 07                   ja     427347 &lt;__strcmp_sse42+0x77&gt;\n  427340:       41 89 d0                mov    %edx,%r8d\n  427343:       91                      xchg   %eax,%ecx\n  427344:       48 87 f7                xchg   %rsi,%rdi\n* 427347:       66 0f 6f 17             movdqa (%rdi),%xmm2\n  (RDI: 0000000000000000)\n</code></pre> <p>Frustrating! What is wrong with multithread program? Because of broken FPU-switch code? of inappropriate TLB flush? of IB corrupts memory? of what? ugh?</p> <p>I\u2019m done with this random guess and frustrated general protection or segfault, I need to first make sure underlying kernel is 100%  percent correct, this is a checking list:</p> <ul> <li>fpu save/restore<ul> <li>always fail at some XMM instruction</li> <li>always with corrupted RDI or RSI</li> </ul> </li> <li>switch_to_asm<ul> <li>%gs and %fs</li> <li>switch_mm (pgd)</li> <li>stack frame</li> </ul> </li> <li>set_arch_tls (%fs)<ul> <li>glibc\u2019s way of using per thread data</li> </ul> </li> <li>some cpu may miss tlb flush</li> <li>kernel entry/exit assembly<ul> <li>current_task macro</li> <li>stack_stratch</li> <li>per-cpu data in entry.S</li> </ul> </li> <li>futex<ul> <li>clear_tid</li> <li>set_tid</li> <li>shared mm</li> <li>robust list</li> </ul> </li> <li>interrupts<ul> <li>vector array</li> <li>APIC setup</li> <li>IO-APIC</li> <li>timer interrupt</li> </ul> </li> <li>cpu_init and Trampoline</li> <li>faked kernel version</li> <li>P side pgfault handling code (SMP)</li> <li>and M side pgfault handling (SMP)</li> <li>mremap, munmap<ul> <li>check pgtable boundary</li> </ul> </li> <li>In all, check SMP implications</li> </ul> <p>Is there any code, that is solely used to test if the underlying kernel has appropriate behaviors? Like glibc test code?</p> <p>How to protect kernel virtual memory? Any existing solutions in Linux?</p> <p>What is the implication of multiple CPU entering kernel at the same time? How can it corrupt user pages? Maybe: kernel entry code, per-cpu data in entry code, fpu code, switch_to, scheduler.</p> <p>Why it always fail at those FPU code i.e. the strcmp function? I failed to compile without those sse, any solution? How it hurt performance?</p>"},{"location":"lego/log/log-02-2018/#0207-wed-cloudy","title":"<code>02/07 Wed Cloudy</code>","text":"<p><code>20:07</code> Pushed a small patch on mremap issue. Hope it will work. mremap really makes the whole thing very interesting, will be a very good research finding on combing virtual cache and operating system. Need to go gym with a friend, will be back on debugging late tonight.</p> <p><code>9:30</code> Have two meetings to do today, and an security class, won\u2019t have too much time coding during daytime.</p>"},{"location":"lego/log/log-02-2018/#0206-tue-sunny","title":"<code>02/06 Tue Sunny</code>","text":"<p>Well. We\u2019ve ruled out both <code>smp_call_function</code> and <code>workqueue</code> yesterday with Yiying\u2019s help. But the multi-thread word-count still fails <code>:-(</code> Single thread word-count just finished 4GB dataset (with 8GB pcache). So what could be still wrong with multithread one????</p> <ul> <li>chill</li> <li>check exit code</li> <li><code>(Checked)</code> check pcache\u2019s usage of task_struct, should always use the group_leader</li> <li>check cpu boot code and check the switch code again</li> <li>I believe pinpoint the issue in multithread word-count can solve a lot issues, it must be some thread creation, removal, schedule things.</li> <li>How about adding a lock for ibapi, make it sequential? Sweet, I tried, finally it is <code>a bug that we are able to debug</code>.</li> </ul> <p><code>22:39</code> Done for today. I\u2019m trying to patch <code>move_pte</code> and <code>pcache_move_pte</code>. Although in theory we defenitly need to patch it, I keep thinking the code before should not trigger any serious bus or memory corruption. Ugh. Maybe it is concurrent <code>mremap</code> that one of them remap from A to B, while another one remap from C to A. It is possible. But my dead brain can not think of this anymore. I\u2019m going to hit the gym and do some squats.</p> <p><code>17:01</code> Criminal found: <code>mremap()</code> and <code>virtual cache</code> did the crime. Interesting, I have not seen any research paper, tech-reports, writeup, code about this, not even the OVC paper, which, by the way, I think they must consider this case. Otherwise, a mremap will simply crash its virtual cache. Many thanks went to my smoke-and-think time.</p> <p><code>15:14</code> Something new came up! After adding a spinlock for ibapi, this showed up (I tried one more time after this, which does not show up). We are lucky to catch this. At least I know where to look at. Also, this is defenitly triggered by <code>mremap</code>. It is seems it is overlapped <code>mremap()</code>. One thing I did not know is which thread trigger this bug, the sweep thread? Cause mremap related pcache rmap functions do not use <code>rmap_get_locked_pte</code>.</p> <pre><code>[ 3826.048774] normal_p2s_open(): f_name: word_100MB.txt, mode: 04400, flags: 0\n[ 3827.891622] SYSC_mremap(cpu18): move: [0x7fffe5788000 - 0x7fffe5806000] -&gt; [0x7fffe531b000 - 0x7fffe5399000]\n[ 3828.178643] SYSC_mremap(cpu14): move: [0x7fffe5941000 - 0x7fffe5980000] -&gt; [0x7fffe57c7000 - 0x7fffe5806000]\n\n****    ERROR: mismatched PTE and rmap\n****    rmap-&gt;owner_process: word_count-pthr uva: 0x7fffe57c8000 ptep: ffff88107efe0e40, rmap-&gt;page_table: ffff88107efe0e40\n****    pcache_pfn: 0x1257c8, pte_pfn: 0x125942\n</code></pre> <p><code>14:00</code> <code>word_count-pthread</code>: 100MB dataset <code>pcache</code>: 8GB, 8-way <code>victim</code>: 8 entries <pre><code>[ 1294.845313] STDOUT: ---[\nWordcount: Running...\n]---\n[ 1294.903661] STDOUT: ---[\n\no;\n]---\n[ 1294.946301] normal_p2s_open(): f_name: /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt, mode: 04400, flags: 0\n[ 1295.100517] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[ 1295.594658] word_count-pthr[59] general protection ip:4272ea sp:7ffff1b8ed28 error:0\n[ 1295.685236] CPU: 10 PID: 59 Comm: word_count-pthr 4.0.0-lego+ #113\n[ 1295.759070] RIP: 0033:[&lt;00000000004272ea&gt;]  [&lt;00000000004272ea&gt;] 0x4272ea\n[ 1295.840184] RSP: 002b:00007ffff1b8ed28  EFLAGS: 00010283\n[ 1295.903621] RAX: 000000000000000f RBX: 00007fffe5a3d010 RCX: 0000000000000001\n[ 1295.988893] RDX: 0000000000000000 RSI: 4854005942004441 RDI: 00007ffff1c1e80f\n[ 1296.074166] RBP: 00007ffff1c1e80f R08: 0000000000000000 R09: 0000000000000010\n[ 1296.211435] R10: 0000000000427ce0 R11: 00007ffff1bbb3ba R12: 0000000000001de4\n[ 1296.296711] R13: 00000000006e4a80 R14: 0000000000001d9e R15: 0000000000001dc1\n[ 1296.433978] FS:  00007ffff1b8f700(0000) GS:ffff88107fca0000(0000) knlGS:0000000000000000\n[ 1296.582686] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 1296.963297] CR2: 00007ffff1c1e000 CR3: 000000207fd8a000 CR4: 00000000000406a0\n</code></pre> So what is this <code>ip:4272ea</code>, let us objdump the binary: <pre><code>0000000000425e60 &lt;strcmp&gt;:\n  425e60:       48 8d 05 69 14 00 00    lea    0x1469(%rip),%rax        # 4272d0 &lt;__strcmp_sse42&gt;\n  425e67:       f7 05 5f b8 2b 00 00    testl  $0x100000,0x2bb85f(%rip)        # 6e16d0 &lt;_dl_x86_cpu_features+0x10&gt;\n  425e6e:       00 10 00\n  425e71:       75 1a                   jne    425e8d &lt;strcmp+0x2d&gt;\n  425e73:       48 8d 05 46 b0 00 00    lea    0xb046(%rip),%rax        # 430ec0 &lt;__strcmp_ssse3&gt;\n  425e7a:       f7 05 4c b8 2b 00 00    testl  $0x200,0x2bb84c(%rip)        # 6e16d0 &lt;_dl_x86_cpu_features+0x10&gt;\n  425e81:       02 00 00\n  425e84:       75 07                   jne    425e8d &lt;strcmp+0x2d&gt;\n  425e86:       48 8d 05 03 00 00 00    lea    0x3(%rip),%rax        # 425e90 &lt;__GI_strcmp&gt;\n  425e8d:       c3                      retq\n  425e8e:       66 90                   xchg   %ax,%ax\n .. ..\n .. ..\n00000000004272d0 &lt;__strcmp_sse42&gt;:\n  4272d0:       89 f1                   mov    %esi,%ecx\n  4272d2:       89 f8                   mov    %edi,%eax\n  4272d4:       48 83 e1 3f             and    $0x3f,%rcx\n  4272d8:       48 83 e0 3f             and    $0x3f,%rax\n  4272dc:       83 f9 30                cmp    $0x30,%ecx\n  4272df:       77 3f                   ja     427320 &lt;__strcmp_sse42+0x50&gt;\n  4272e1:       83 f8 30                cmp    $0x30,%eax\n  4272e4:       77 3a                   ja     427320 &lt;__strcmp_sse42+0x50&gt;\n  4272e6:       f3 0f 6f 0f             movdqu (%rdi),%xmm1\n* 4272ea:       f3 0f 6f 16             movdqu (%rsi),%xmm2\n  4272ee:       66 0f ef c0             pxor   %xmm0,%xmm0\n</code></pre> You can see <code>%rsi</code> has some garbage value <code>RSI: 4854005942004441</code>. Something went wrong. Will it be our FPU? I\u2019m not quite sure. If FPU code has error, why single-thread one succeed? Why it only shows up at multithread ones?</p>"},{"location":"lego/log/log-02-2018/#0205-mon-sunny","title":"<code>02/05 Mon Sunny</code>","text":"<p>From yesterday\u2019s testing of Phoenix, it looks like something is wrong in <code>smp_call_functions()</code>. They are invoked through <code>tlb flush</code>, which was further invoked by <code>mremap</code>, or <code>munmap</code>. The warning from smp is:</p> <pre><code>[ 1260.586696] WARNING: CPU: 0 PID: 73 at kernel/smp.c:129 generic_smp_call_function_single_interrupt+0xb8/0x160\n[ 1260.705251] CPU: 0 PID: 73 Comm: word_count-pthr 4.0.0-lego+ #99\n[ 1260.777008] Stack:\n[ 1260.800927] ffff88207fdffef8 ffffffff8100ec67 ffff88107fc00000 ffff88107fc00000\n[ 1260.888283] ffffffff8100d410 ffff88207fe23df0 ffff88207fdfff08 ffffffff8100ed5f\n[ 1260.975639] ffff88207fdfff38 ffffffff8100fe68 00007fffe58c3010 0000000000000f96\n[ 1261.062995] 000000000000f960 0000000000000f95 ffff88207fdfff48 ffffffff810020dd\n[ 1261.150351] 00007ffff58869c1 ffffffff8100b2e9 0000000000000f96 0000000000000f95\n[ 1261.237707] Call Trace:\n[ 1261.266825] &lt;TSK&gt;\n[ 1261.289704] [&lt;ffffffff8100ec76&gt;] __warn.constprop.0+0xa6/0x100\n[ 1261.359381] [&lt;ffffffff8100d410&gt;] ? pgd_free+0x90/0x90\n[ 1261.419699] [&lt;ffffffff8100ed5f&gt;] warn_slowpath_null+0xf/0x20\n[ 1261.487295] [&lt;ffffffff8100fe68&gt;] generic_smp_call_function_single_interrupt+0xb8/0x160\n[ 1261.581931] [&lt;ffffffff810020dd&gt;] call_function_interrupt+0x1d/0x20\n[ 1261.655767] [&lt;ffffffff8100b2e9&gt;] smp__call_function_interrupt+0x69/0x70\n</code></pre> <p>So I decided to look into smp.c a little bit to find out if there is something wrong (I wrote it long time ago). The warning itself is true, it means some inconsistent behavior.. I saw <code>alloc_percpu</code> stuff during <code>call_function_init</code>, hence probably I also need to check percpu code a little code cause I\u2019m not sure if I port all the functionalities.</p> <p>In all, today\u2019s task, check <code>percpu</code> and <code>smp_call_function</code> code. Esp, <code>percpu</code> code, they are crucial and very hard to relate real bugs to it.</p> <p>Well\u2026 things changed. I found a more serious bug: something about <code>cpuhotplug</code>, even though lego is not using it. <code>cpuhotplug</code> is a set of implict callbacks to all different subsystems who want to do some initialization work on each <code>offline-&gt;online</code> cpu.</p> <p>Let us dig into how secondary cpu boots: <pre><code>Trampoline.. setup 64bit mode\nstart_secondary()\n  smp_callin()\n        notify_cpu_starting()\n              ...\n              while (st-&gt;state &lt; target) {\n                      st-&gt;state++;\n                      cpuhp_invoke_callback(cpu, st-&gt;state, true, NULL);\n              }\n          cpuhp_invoke_callback()\n</code></pre></p> <p>See? There will be some callbacks! What are those callbacks exactly? Well, they are predefined at the <code>kernel/cpu.c</code>. To save the trouble of reading code, I just print what functions are executed, the log is: <pre><code>[    0.118235] cpuhp_invoke_callback(): 136  CPU:0  page_writeback_cpu_online+0x0/0x20\n\n[    0.368478] cpuhp_invoke_callback(): 136  CPU:1  smpboot_create_threads+0x0/0x90\n[    0.370196] cpuhp_invoke_callback(): 136  CPU:1  perf_event_init_cpu+0x0/0xa0\n[    0.370403] cpuhp_invoke_callback(): 136  CPU:1  workqueue_prepare_cpu+0x0/0x80\n[    0.371112] cpuhp_invoke_callback(): 136  CPU:1  hrtimers_prepare_cpu+0x0/0x60\n[    0.371339] cpuhp_invoke_callback(): 136  CPU:1  smpcfd_prepare_cpu+0x0/0x80\n[    0.371584] cpuhp_invoke_callback(): 136  CPU:1  relay_prepare_cpu+0x0/0xe0\n[    0.371794] cpuhp_invoke_callback(): 136  CPU:1  rcutree_prepare_cpu+0x0/0x170\n[    0.372333] cpuhp_invoke_callback(): 136  CPU:1  notify_prepare+0x0/0xa0\n[    0.372744] cpuhp_invoke_callback(): 136  CPU:1  bringup_cpu+0x0/0x100\n[    0.008000] cpuhp_invoke_callback(): 136  CPU:1  sched_cpu_starting+0x0/0x60\n[    0.926124] cpuhp_invoke_callback(): 136  CPU:1  smpboot_unpark_threads+0x0/0x90\n[    0.926124] cpuhp_invoke_callback(): 136  CPU:1  perf_event_init_cpu+0x0/0xa0\n[    0.927028] cpuhp_invoke_callback(): 136  CPU:1  workqueue_online_cpu+0x0/0x2a0\n[    0.927768] cpuhp_invoke_callback(): 136  CPU:1  rcutree_online_cpu+0x0/0x70\n[    0.928045] cpuhp_invoke_callback(): 136  CPU:1  notify_online+0x0/0x20\n[    0.928256] cpuhp_invoke_callback(): 136  CPU:1  page_writeback_cpu_online+0x0/0x20\n[    0.928527] cpuhp_invoke_callback(): 136  CPU:1  sched_cpu_activate+0x0/0x190\n\n[    0.929084] cpuhp_invoke_callback(): 136  CPU:2  smpboot_create_threads+0x0/0x90\n[    0.930240] cpuhp_invoke_callback(): 136  CPU:2  perf_event_init_cpu+0x0/0xa0\n[    0.930434] cpuhp_invoke_callback(): 136  CPU:2  workqueue_prepare_cpu+0x0/0x80\n[    0.931070] cpuhp_invoke_callback(): 136  CPU:2  hrtimers_prepare_cpu+0x0/0x60\n[    0.931264] cpuhp_invoke_callback(): 136  CPU:2  smpcfd_prepare_cpu+0x0/0x80\n[    0.931464] cpuhp_invoke_callback(): 136  CPU:2  relay_prepare_cpu+0x0/0xe0\n[    0.931649] cpuhp_invoke_callback(): 136  CPU:2  rcutree_prepare_cpu+0x0/0x170\n[    0.932245] cpuhp_invoke_callback(): 136  CPU:2  notify_prepare+0x0/0xa0\n[    0.932475] cpuhp_invoke_callback(): 136  CPU:2  bringup_cpu+0x0/0x100\n[    0.008000] cpuhp_invoke_callback(): 136  CPU:2  sched_cpu_starting+0x0/0x60\n[    1.005023] cpuhp_invoke_callback(): 136  CPU:2  smpboot_unpark_threads+0x0/0x90\n[    1.005065] cpuhp_invoke_callback(): 136  CPU:2  perf_event_init_cpu+0x0/0xa0\n[    1.005408] cpuhp_invoke_callback(): 136  CPU:2  workqueue_online_cpu+0x0/0x2a0\n[    1.005729] cpuhp_invoke_callback(): 136  CPU:2  rcutree_online_cpu+0x0/0x70\n[    1.006029] cpuhp_invoke_callback(): 136  CPU:2  notify_online+0x0/0x20\n[    1.006206] cpuhp_invoke_callback(): 136  CPU:2  page_writeback_cpu_online+0x0/0x20\n[    1.006549] cpuhp_invoke_callback(): 136  CPU:2  sched_cpu_activate+0x0/0x190\n</code></pre></p> <p>Interesting! Currently, Lego need to add the <code>smpboot_create_threads()</code>, <code>workqueue_prepare_cpu()</code>, <code>workqueue_prepare_cpu()</code>, <code>bringup_cpu()</code>, <code>smpboot_unpark_threads()</code>, <code>workqueue_online_cpu()</code>.</p> <p>This hidden things is really hard to find and not easy to track during boot. Especially during boot, they should do something like <code>for_each_online_cpu</code> and init one by one. But I guess, after adding support of cpu hotplug, code kind of merged. Some stuff will be executed whenever a cpu has been teardown or bought up. And bang, why not use the same set of hotplug during boot, right? Well.</p>"},{"location":"lego/log/log-03-2018/","title":"March 2018","text":""},{"location":"lego/log/log-03-2018/#0331-sat","title":"03/31 Sat","text":"<p>Stay humble. Be real.</p>"},{"location":"lego/log/log-03-2018/#0330-fri","title":"03/30 Fri","text":"<p>Our scheduling, or IB do have issues. I must revisit this.</p> <p>The case is: in P, we boot only 12 cores, and three of them are used by flush, sweep, and IB. So there are 9 cores left for user. Phoenix create 24 threads. During the run, a lot ib timeout will happen. If we have a good scheduling, this should never happen. I probably need to check more on this.</p> <p>Anyway. Today I reorganized the opcode things. And now I\u2019m adding the final large piece of Lego: replication. It should be much simpler than the pcache part. I will first write down what code I need to add, e.g., opcode, handler, buffer mgmt etc.</p> <p>End of day. Want to write down some simple thoughts on building system. Building system is fun, but you have to know that devil is in the details. And, you may end up debugging for many many hours on a very very little issue. But that is how it is. Building system does not mean you are always working on fantastic beautiful ideas. It is always about those little bugs, little things, trivial fixes, that make your system robust and usable. For example, the patch Yilun sent me today is about handling special cases of stat and lseek. The patch does not improve any performance or adding fancy features, it is a minor fix to make user progam run. But this enable us to run TF. I think it is a great patch and it stands for 90% of building systems in middle or late stage.</p> <p>Of course, there are other trivial things on building systems: 1) initialize every possible used variables, can be local variables, malloced buffers. 2) have decent cleanup, which is a counterpart of your initialization, like dequeue list, decrease counter etc. 3) Clear coding style, write code for others, for yourself when you read the code two weeks later. This one is hard, need experience. But can be learned. I think Yilun and Yutong both improved a lot during this project. Me? I learned this from NVM emulator protect. It is a painful one, but also a valuable one. 4) Decent protect source file organization. 5) Remember, draw, the connections between subsystems. By adding this new feature to this subsystem A, will it broke subsystem B, which is using subsystem A. Something like this. 6) clear mind on lock usage, multithread issue. This is the most difficult one. I would say I learned this by coding pcache, or mm. I would say, mm is the most difficult multithread issue one can encounter.</p>"},{"location":"lego/log/log-03-2018/#0326-mon","title":"03/26 Mon","text":"<p>Spent several days on replication design. Now I\u2019m back on coding and debuging track.</p> <p>Fixed a bug introduced by per-pte lock. A one hided by previous one big giant page table lock.</p> <p>Also add an option to boot socket 0 only if Processor is configured. This is because pcache is normally registered at socket 0, if we schedule user threads to sockets other than socket 0, that will have bad performance.</p>"},{"location":"lego/log/log-03-2018/#0322-thur","title":"03/22 Thur","text":""},{"location":"lego/log/log-03-2018/#clear-registers-for-execve","title":"Clear Registers for execve()","text":"<p>Want to figure out execve problem today.</p> <ol> <li>Check if pcache is clean after process_exit.</li> <li>Check if pgtable is clean.</li> </ol> <p>Well. Checked, both are clean.</p> <p>The bug looks like the return of main, evevntually does not go to library\u2019s exit. Is it because library pages are not loaded properly? Since the number of pgfault equals to normal setting, I guess it may originate from Memory side.</p> <p>TLB is also flushed, so TLB should not be a hidden issue.</p> <p>Going to check checsum. Well, checsum is okay too.</p> <p>Syscall execve will change ip, sp, flags registers. So it will use <code>iretq</code> instead of <code>sysexit</code> to return to userspace.</p> <p>Got an insteresting IB bug after execve. The CPU5 seems fail to return to userspace, and the CPU0 has the IB bug followed: <pre><code>[ 1201.940681] CPU: 5 PID: 32 Comm: seq.o 4.0.0-lego-ys+ #609\n[ 1202.006200] RIP: 0033:[&lt;0000000000401d1d&gt;]  [&lt;0000000000401d1d&gt;] 0x401d1d\n[ 1202.087320] RSP: 002b:00007fffffffedb0  EFLAGS: 00000200\n[ 1202.150760] RAX: 0000000000000000 RBX: 00000000004002e0 RCX: 000000000043b2c7\n[ 1202.236041] RDX: 00007fffffffedc8 RSI: 00007fffffffeb40 RDI: 000000000048f9f0\n[ 1202.321320] RBP: 00007fffffffeb60 R08: 00000000006ba4a0 R09: 00000000006bc880\n[ 1202.406601] R10: 000000000000000f R11: 0000000000000246 R12: 0000000000000000\n[ 1202.491881] R13: 0000000000401930 R14: 00000000004019c0 R15: 0000000000000006\n[ 1202.577161] FS:  0000000000000000(0000) GS:ffff88207fc40000(0000) knlGS:0000000000000000\n[ 1202.673880] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 1202.742521] CR2: 000000000042c9a0 CR3: 000000207fc2f000 CR4: 00000000000406a0\n\n[ 1220.465601] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020\n[ 1220.557225] IP: [&lt;ffffffff810591ef&gt;] ib_mad_completion_handler+0x6f/0x7c0\n[ 1220.638344] PGD 0\n[ 1220.662265] Oops: 0000 [#1] SMP PROCESSOR\n[ 1220.710105] CPU: 0 PID: 27 Comm: ib_mad_completi 4.0.0-lego-ys+ #609\n[ 1220.786025] RIP: 0010:[&lt;ffffffff810591ef&gt;]  [&lt;ffffffff810591ef&gt;] ib_mad_completion_handler+0x6f/0x7c0\n[ 1220.896265] RSP: 0000:ffff88103eea7e30  EFLAGS: 00010246\n[ 1220.959704] RAX: 0000000000000000 RBX: ffff88103eeac728 RCX: 0000000000000001\n[ 1221.044985] RDX: 0000000028000000 RSI: ffff88103ee8f000 RDI: ffff88107ff841d8\n[ 1221.130265] RBP: ffff88103eea7ec0 R08: 0000000000000000 R09: ffff88103eea03c0\n[ 1221.215545] R10: ffff88103eea7ea0 R11: 0000000000000001 R12: ffff88103ee8c3f0\n[ 1221.300825] R13: ffff88103ee8c4e8 R14: ffff88103eeac620 R15: ffff88103eeac5f8\n[ 1221.386106] FS:  0000000000000000(0000) GS:ffff88107fc00000(0000) knlGS:0000000000000000\n[ 1221.482825] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 1221.551466] CR2: 0000000000000020 CR3: 000000000113d000 CR4: 00000000000406b0\n[ 1221.636746] Stack:\n[ 1221.660666] ffff88103eeaac10 ffff881000000001 ffff88103eeaac10 ffff88103eeaab50\n[ 1221.748026] ffff88107fc05d80 ffff88103eea0000 ffff88103eeac728 0000008000000000\n[ 1221.835386] 000001283eea7ea8 ffff88103ee8c9a8 000000007fcf2000 ffff000000000000\n[ 1221.922746] ffff88107fcf0000 ffff88207ff6cbd8 ffff88107fcf76e8 ffff88103ee8c3f0\n[ 1222.010106] ffffffff81059180 0000000000000000 ffff88103eea7f48 ffffffff81020866\n[ 1222.097466] Call Trace:\n[ 1222.126586] &lt;TSK&gt;\n[ 1222.149466] [&lt;ffffffff81059180&gt;] ? ib_mad_send_done_handler.isra.21+0x1d0/0x1d0\n[ 1222.236826] [&lt;ffffffff81020866&gt;] kthread+0xf6/0x120\n[ 1222.295066] [&lt;ffffffff81020770&gt;] ? __kthread_parkme+0x70/0x70\n[ 1222.363707] [&lt;ffffffff8100e4b2&gt;] ret_from_fork+0x22/0x30\n</code></pre></p> <pre><code>[root@wuklab12: LegoOS git:(master)] $ addr2line -e vmImage  -i ffffffff810591ef\n/root/ys/LegoOS/drivers/infiniband/core/mad.c:1899\n/root/ys/LegoOS/drivers/infiniband/core/mad.c:2324\n\nIt is ib_mad_recv_done_handler()\n</code></pre> <p>Well\u2026</p> <p>Eventually, at 22:09, I figured out..</p> <p>After I cleaned up all registers (except IP, SP, CS, SS, FLAGS) within start_thread, the execve\u2019ed program can run to end successfully.</p> <p>I did not clear the registers because linux does not clear it. I thought this is fine. Glibc should clear it anyway, right?</p> <p>But anyway, this works.</p>"},{"location":"lego/log/log-03-2018/#0321-wed","title":"03/21 Wed","text":"<ul> <li>Task 1: add some checking in ib, flush, sweep thread. 1) If cpu changed, 2) if nr_threads on this core &gt; 1.</li> </ul> <p>Had an issue while testing: execve(). I ran a exec.o first, then do execve to run seq.o: <pre><code>wuklab13 0321-10\n[  970.380252] STDOUT: ---[\nuname():\n\n---\n[  970.431212] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x44605d flags:0x150\n[ 1101.862429] mlx4_ib_handle_error_cqe syndrome 21\n[ 1101.915570] mlx4_ib_handle_error_cqe syndrome 5\n[ 1101.969649] send request failed at connection 4 as 12\n[ 1102.029968] mlx4_ib_handle_error_cqe syndrome 5\n[ 1102.084046] mlx4_ib_handle_error_cqe syndrome 5\n[ 1102.138125] mlx4_ib_handle_error_cqe syndrome 5\n[ 1102.192203] fit_poll_cq: failed status (5) for wr_id 1054\n[ 1102.256681] fit_poll_cq: failed status (5) for wr_id 1055\n[ 1102.321160] csum: 442a97c0, reply-&gt;csum: 2d352c33\n[ 1102.377319] fit_poll_cq: connection 4 Recv weird event as -1\n[ 1102.444916] pcache:ffff880180011180 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880100446000\n[ 1102.558273] fit_poll_cq: failed status (5) for wr_id 1056\n[ 1102.622751] pcache dumped because: csum mismatch\n[ 1102.677871] fit_poll_cq: connection 4 Recv weird event as -30704\n[ 1102.749627] ------------[ cut here ]------------\n[ 1102.804746] fit_poll_cq: failed status (5) for wr_id 1057\n[ 1102.869225] BUG: failure at managers/processor/pcache/fault.c:237/__pcache_do_fill_page()!\n[ 1102.968022] fit_poll_cq: connection 4 Recv weird event as -30704\n[ 1103.039780] Kernel Panic - not syncing: BUG!\n[ 1103.090739] CPU: 5 PID: 32 Comm: seq.o 4.0.0-lego-ys+ #599\n[ 1103.156256] Stack:\n[ 1103.180177] ffff88103e85be18 ffffffff8102676c ffffffff00000008 ffff88103e85be28\n[ 1103.267533] ffff88103e85bde0 0000000021475542 0000000000000296 ffff88103e85ba10\n[ 1103.354892] ffffffff810195c5 ffff88207fc44980 0000000000000005 ffff88103e85ba28\n[ 1103.442249] ffffffff81016c75 ffff88103e85ba40 ffff88103e85ba50 ffffffff810065d4\n[ 1103.529607] ffffffff811d36e0 0000000000000039 ffffffff81081718 ffff88103e85bb80\n[ 1103.616964] Call Trace:\n</code></pre></p>"},{"location":"lego/log/log-03-2018/#0320-tue","title":"03/20 Tue","text":"<ul> <li>Task 1: calculate failure numbers</li> <li>Task 2: read 0319-4 Log</li> <li>Task 3: opt pte lock</li> </ul> <p>Hmm, I finished the per-pte per-pmd lock patch. I think it works. But I do found an issue. When I run MT+2GB, it will create 24 threads. Since I marked 3 CPUs inactive, so all new 24 threads will be scheduled to other cores (I may need to check this!). At some point, Lego P either stuck, or a lot ibapi_send_reply timeout.</p> <p>When I change the cpu_online to may <code>0-6</code>, it finished. When I change it to <code>0-18</code>, also succeed. I really doubt if actually those pinned threads are not pinned. Need to check.</p>"},{"location":"lego/log/log-03-2018/#ib-bug-again","title":"IB Bug again","text":"<p>Running MT-phoenix, 2GB, somehow crashed in the middle: <pre><code>[60095.857381] SYSC_close() CPU6 PID:33 [fd: 4] -&gt; [/proc/stat]\n\n[60286.127359] mlx4_ib_handle_error_cqe syndrome 21\n[60286.180503] mlx4_ib_handle_error_cqe syndrome 5\n[60286.234582] send request failed at connection 4 as 12\n[60286.294903] mlx4_ib_handle_error_cqe syndrome 5\n[60286.348981] mlx4_ib_handle_error_cqe syndrome 5\n[60286.403062] mlx4_ib_handle_error_cqe syndrome 5\n[60286.457141] mlx4_ib_handle_error_cqe syndrome 5\n[60286.511221] send request failed at connection 4 as 5\n[60286.570500] fit_poll_cq: failed status (5) for wr_id 1056\n[60286.634980] mlx4_ib_handle_error_cqe syndrome 5\n[60286.689059] fit_poll_cq: failed status (5) for wr_id 1057\n[60286.753539] send request failed at connection 4 as 5\n[60286.812819] fit_poll_cq: failed status (5) for wr_id 1058\n[60286.877298] mlx4_ib_handle_error_cqe syndrome 5\n[60286.931378] fit_poll_cq: failed status (5) for wr_id 1059\n[60286.995857] send request failed at connection 4 as 5\n[60287.055138] mlx4_ib_handle_error_cqe syndrome 5\n[60287.109217] mlx4_ib_handle_error_cqe syndrome 5\n[60287.163297] mlx4_ib_handle_error_cqe syndrome 5\n[60287.217376] mlx4_ib_handle_error_cqe syndrome 5\n[60287.271456] mlx4_ib_handle_error_cqe syndrome 5\n[60287.325536] send request failed at connection 4 as 5\n[60287.384815] fit_poll_cq: failed status (5) for wr_id 1060\n[60287.449294] mlx4_ib_handle_error_cqe syndrome 5\n[60287.503375] BUG: unable to handle kernel NULL pointer dereference at           (null)\n[60287.596973] IP: [&lt;ffffffff81063ffd&gt;] fit_poll_cq+0x4dd/0x530\n[60287.664574] send request failed at connection 4 as 5\n[60287.723853] PGD 0\n[60287.747772] mlx4_ib_handle_error_cqe syndrome 5\n[60287.801852] Oops: 0002 [#1] PREEMPT SMP PROCESSOR\n[60287.858013] send request failed at connection 4 as 5\n[60287.917292] CPU: 2 PID: 29 Comm: recvpollcq 4.0.0-lego-ys+ #569\n[60287.988010] RIP: 0010:[&lt;ffffffff81063ffd&gt;]  [&lt;ffffffff81063ffd&gt;] fit_poll_cq+0x4dd/0x530\n[60288.084731] RSP: 0000:ffff88103e84fd88  EFLAGS: 00010206\n[60288.148170] RAX: 0000000000001008 RBX: ffff88103e848438 RCX: 0000000000000014\n[60288.233450] RDX: 0000000000000000 RSI: ffffffff811d36e0 RDI: ffffffff811dac08\n[60288.318728] RBP: ffff88103e84fea8 R08: 0000000000000000 R09: 0000000000000000\n[60288.404008] R10: 0000000000000002 R11: 0000000000000004 R12: 0000000000000000\n[60288.489288] R13: ffff88207fd6e008 R14: 0000000000000004 R15: ffff88103e84fda0\n[60288.574568] mlx4_ib_handle_error_cqe syndrome 5\n[60288.628647] FS:  0000000000000000(0000) GS:ffff88107fc20000(0000) knlGS:0000000000000000\n[60288.725367] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[60288.794006] CR2: 0000000000000000 CR3: 000000000113d000 CR4: 00000000000406a0\n[60288.879285] send request failed at connection 4 as 5\n[60288.938565] Stack:\n[60288.962484] ffffffff810031d9 000801d43e84fda0 0000000000000007 0000000000000424\n[60289.049844] 0000008100000005 00001008000000f9 ffff88103e848868 00616e6440000014\n[60289.137204] 0020004000000002 ffff88207fc00000 0000000000000425 0000008100000005\n[60289.224563] 00001008000000f9 ffff88103e848868 007370654000000d 0010004000000002\n[60289.311922] ffffffff81010000 0000000000000426 0000008100000005 00001008000000f9\n[60289.399282] Call Trace:\n[60289.428402] mlx4_ib_handle_error_cqe syndrome 5\n[60289.482482] &lt;TSK&gt;\n[60289.505361] [&lt;ffffffff810031d9&gt;] ? native_smp_send_reschedule+0x39/0x50\n[60289.584400] send request failed at connection 4 as 5\n[60289.643680] [&lt;ffffffff81010000&gt;] ? __ioremap_caller+0x170/0x570\n[60289.714400] [&lt;ffffffff81060000&gt;] ? cm_work_handler+0x270/0x1450\n[60289.785119] [&lt;ffffffff81064050&gt;] ? fit_poll_cq+0x530/0x530\n[60289.850639] [&lt;ffffffff81064064&gt;] fit_poll_cq_pass+0x14/0x30\n[60289.917198] [&lt;ffffffff81020c06&gt;] kthread+0xf6/0x120\n[60289.975438] mlx4_ib_handle_error_cqe syndrome 5\n[60290.029518] [&lt;ffffffff81020b10&gt;] ? __kthread_parkme+0x70/0x70\n[60290.098157] [&lt;ffffffff8100e722&gt;] ret_from_fork+0x22/0x30\n</code></pre></p> <p>Uuh: <pre><code>[ 1002.803051] mlx4_ib_handle_error_cqe syndrome 1\n[ 1002.855153] mlx4_ib_handle_error_cqe syndrome 5\n[ 1002.909232] mlx4_ib_handle_error_cqe syndrome 5\n[ 1002.963310] mlx4_ib_handle_error_cqe syndrome 5\n[ 1003.017390] fit_poll_cq: failed status (1) for wr_id 512\n[ 1003.080829] BUG: unable to handle kernel NULL pointer dereference at 0000000000000200\n[ 1003.174425] IP: [&lt;ffffffff8105d499&gt;] fit_poll_cq+0x179/0x510\n[ 1003.242024] PGD 0\n[ 1003.265943] Oops: 0000 [#1] SMP MEMORY\n[ 1003.310661] CPU: 2 PID: 29 Comm: recvpollcq 4.0.0-lego-ys+ #149\n[ 1003.381380] RIP: 0010:[&lt;ffffffff8105d499&gt;]  [&lt;ffffffff8105d499&gt;] fit_poll_cq+0x179/0x510\n[ 1003.478098] RSP: 0000:ffff88104e84fd88  EFLAGS: 00010246\n[ 1003.541537] RAX: ffff880000000000 RBX: ffff88104e848008 RCX: 0000000000000080\n[ 1003.626814] RDX: 0000000000000200 RSI: ffffffff811c76e0 RDI: ffffffff811d0988\n[ 1003.712092] RBP: ffff88104e84fea8 R08: 0000000000000000 R09: 0000000000000000\n[ 1003.797369] R10: 0000000000000002 R11: 0000000000000004 R12: 0000000000000000\n[ 1003.882648] R13: ffff88207ff75008 R14: 0000000000000004 R15: ffff88104e84fda0\n[ 1003.967925] FS:  0000000000000000(0000) GS:ffff88107fc20000(0000) knlGS:0000000000000000\n[ 1004.064644] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 1004.133282] CR2: 0000000000000200 CR3: 0000000001131000 CR4: 00000000000406a0\n[ 1004.218559] Stack:\n[ 1004.242479] ffffffff810031a9 ffff88104e84fda0 ffffffff81018ef4 0000000000000200\n[ 1004.329837] 0000008000000001 00000048000000d7 ffff88104e848c98 0000000081019302\n[ 1004.417194] 0014000000000000 ffff88207fc00000 0000000000000201 ffffffff00000005\n[ 1004.504552] ffff8810000000f9 ffff88104e848c98 0000000000000000 ffff88104e84fe38\n[ 1004.591910] ffffffff810195a4 0000000000000202 ffff881000000005 ffff8810000000f9\n[ 1004.679268] Call Trace:\n[ 1004.708388] &lt;TSK&gt;\n[ 1004.731267] [&lt;ffffffff810031a9&gt;] ? native_smp_send_reschedule+0x39/0x50\n[ 1004.810305] [&lt;ffffffff81018ef4&gt;] ? resched_curr+0x34/0x40\n[ 1004.874783] [&lt;ffffffff810195a4&gt;] ? try_to_wake_up+0xe4/0x1f0\n[ 1004.942382] [&lt;ffffffff8105f458&gt;] ? __schedule+0xf8/0x1e0\n[ 1005.005820] [&lt;ffffffff8105d830&gt;] ? fit_poll_cq+0x510/0x510\n[ 1005.071338] [&lt;ffffffff8105d844&gt;] fit_poll_cq_pass+0x14/0x30\n[ 1005.137897] [&lt;ffffffff8101fdc6&gt;] kthread+0xf6/0x120\n[ 1005.196135] [&lt;ffffffff8101fcd0&gt;] ? __kthread_parkme+0x70/0x70\n[ 1005.264773] [&lt;ffffffff8100e472&gt;] ret_from_fork+0x22/0x30\n</code></pre></p>"},{"location":"lego/log/log-03-2018/#0319-mon","title":"03/19 Mon","text":"<p>Not too many days left!!! Got to design full replication mechanism and algorithm today.</p> <p>Merged pull request for <code>pipe</code>, <code>pipe2</code> and <code>/dev/null</code> from Yilun. Our simple file op mgmt concerns me. I left a note at kernel/fork.c.</p> <p>Got a bug report from Yilun, syscall execv failed. To be honest, I\u2019ve never tried this syscall, always call it directly within kernel. <pre><code>[  943.650712] CPU6 PID17 sys_execve+0x0/0x10\n[  943.701899] BUG: unable to handle kernel paging request at 0000000000490523\n[  943.702776] IP: [&lt;ffffffff8103db86&gt;] strrchr+0x6/0x20\n[  943.711501] PGD 0\n[  943.711911] Oops: 0000 [#1] SMP PROCESSOR\n[  943.712433] CPU: 6 PID: 17 Comm: word_count-pthr 4.0.0-lego+ #64\n[  943.713126] RIP: 0010:[&lt;ffffffff8103db86&gt;]  [&lt;ffffffff8103db86&gt;] strrchr+0x6/0x20\n[  943.714090] RSP: 0018:ffff88083e4bfe98  EFLAGS: 00010246\n[  943.714724] RAX: 0000000000000000 RBX: ffff88083e4b3780 RCX: 0000000000000000\n[  943.715511] RDX: 00000000ffffffff RSI: 000000000000002f RDI: 0000000000490523\n[  943.716297] RBP: ffff88083e4bfe98 R08: 0000160000000000 R09: ffff88083e4b8400\n[  943.717085] R10: ffff880000000000 R11: 6db6db6db6db6db7 R12: ffff88083e4b8000\n[  943.717871] R13: ffff88083e4e6290 R14: 0000000000490523 R15: ffff88083e4b3920\n[  943.718683] FS:  0000000000000000(0000) GS:ffff88083fd80000(0000) knlGS:0000000000000000\n[  943.719650] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[  943.720319] CR2: 0000000000490523 CR3: 000000083e4e7000 CR4: 00000000000406a0\n[  943.721106] Stack:\n[  943.721459] ffff88083e4bff18 ffffffff8102c6bf ffff880800000000 0000000000000e10\n[  943.722541] 00007fffffffedb0 0000000000400d0d ffff88083e4c0000 0000000000490523\n[  943.723624] ffff88083e4b9008 00007fffffffed30 0000008400000084 ffff88083e4bff58\n[  943.724706] 000000000000003b 00000000004019d0 0000000000401a60 0000000000000000\n[  943.725789] ffff88083e4bff28 ffffffff8102c989 ffff88083e4bff48 ffffffff8100e5f5\n[  943.726870] Call Trace:\n[  943.727260] &lt;TSK&gt;\n[  943.727619] [&lt;ffffffff8102c6bf&gt;] do_execve+0x4af/0x770\n[  943.728236] [&lt;ffffffff8102c989&gt;] sys_execve+0x9/0x10\n[  943.728868] [&lt;ffffffff8100e5f5&gt;] do_syscall_64+0x45/0xd0\n[  943.729499] [&lt;ffffffff8100d4ec&gt;] entry_SYSCALL64_slow_path+0x25/0x25\n[  943.730222] &lt;EOT&gt;\n[  943.730570] Code: d2 74 18 40 38 f2 89 f1 75 06 eb 0f 38 ca 74 0b 48 83 c0 01 0f b6 10 84 d2 75 f1 5d c3 0f 1f 84 00 00 00 00 00 55 31 c0 48 89 e5 &lt;0f&gt; b6 17 40 38 f2 48 0f 44 c7 48 83 c7 01 84 d2 75 ee 5d c3 66\n[  943.735455] RIP  [&lt;ffffffff8103db86&gt;] strrchr+0x6/0x20\n[  943.736120]  RSP &lt;ffff88083e4bfe98&gt;\n[  943.736598] CR2: 0000000000490523\n</code></pre></p> <p>It is <code>setup_new_exec() -&gt; set_task_comm()</code>. I passed the user pointer to <code>set_task_comm()</code>, which I should pass a kernel pointer.</p> <p>And I actually found we missed a function: <code>do_close_on_exec()</code>. I also add a note above.</p>"},{"location":"lego/log/log-03-2018/#random-ib-bug","title":"Random IB Bug","text":"<p>Another weird bug after pathing loader. Actually, I tried the same setting twice, the second time it works. I guess this is some random IB bug. (Setting: 1P, 1M, 1S. Running a simple exec.c testing program, this have not reach that point yet.) <pre><code>wuklab13 0319-2\n[  496.288272] p2m_fork(cpu0): I cur:1-kernel_init new:31\n[  496.349624] BUG: unable to handle kernel NULL pointer dereference at 0000000000000004\n[  496.443216] IP: [&lt;ffffffff81064935&gt;] fit_send_reply_with_rdma_write_with_imm+0x65/0x3b0\n[  496.538892] PGD 0\n[  496.562811] Oops: 0002 [#1] PREEMPT SMP PROCESSOR\n[  496.618968] CPU: 0 PID: 1 Comm: kernel_init 4.0.0-lego-ys+ #559\n[  496.689684] RIP: 0010:[&lt;ffffffff81064935&gt;]  [&lt;ffffffff81064935&gt;] fit_send_reply_with_rdma_write_with_imm+0x65/0x3b0\n[  496.814478] RSP: 0000:ffff88107fcf7d00  EFLAGS: 00010202\n[  496.877915] RAX: 000000000000004c RBX: 0000000000000004 RCX: 000000000000002c\n[  496.963190] RDX: 0000000000000004 RSI: 0000000000000001 RDI: ffff88207ff6d008\n[  497.048466] RBP: ffff88107fcf7d98 R08: ffff88107fcf7e3c R09: 0000000000000004\n[  497.133742] R10: ffffffff81145fe0 R11: 000000000000001c R12: 000000000000002c\n[  497.219018] R13: 0000000000000001 R14: ffff88107fcf7e40 R15: ffff88207ff6d008\n[  497.304293] FS:  0000000000000000(0000) GS:ffff88107fc00000(0000) knlGS:0000000000000000\n[  497.401009] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[  497.469645] CR2: 0000000000000004 CR3: 000000000113d000 CR4: 00000000000406b0\n[  497.554922] Stack:\n[  497.578840] ffff88107fcf7d08 0000000000000000 0000000000000282 ffffffff81077b10\n[  497.666195] 000000000000003a 000000047fcf7e18 ffff88107fcf7e3c ffff88107fd5ed88\n[  497.753552] 000000010000002c ffffff9b00000040 0000000000000034 ffffffff81145fe0\n[  497.840906] ffff88107fcf7db0 0000000000000297 ffff88107fd5ed88 000000000000002c\n[  497.928263] ffff88107fcf7e3c ffff88107fcf7e40 0000000000000039 ffff88107fcf7dc8\n[  498.015618] Call Trace:\n[  498.044736] &lt;TSK&gt;\n[  498.067615] [&lt;ffffffff810622ff&gt;] ibapi_send_reply_timeout+0x3f/0x50\n[  498.142492] [&lt;ffffffff8103b0d4&gt;] ? net_send_reply_timeout+0x94/0x132\n[  498.218408] [&lt;ffffffff8103b0d4&gt;] net_send_reply_timeout+0x94/0x132\n[  498.292244] [&lt;ffffffff8102c683&gt;] p2m_fork+0xd3/0x200\n[  498.351521] [&lt;ffffffff8101f490&gt;] do_fork+0xf0/0x150\n[  498.409758] [&lt;ffffffff8101f514&gt;] kernel_thread+0x24/0x30\n[  498.473195] [&lt;ffffffff8115bf21&gt;] processor_manager_init+0x21/0x50\n[  498.545991] [&lt;ffffffff81000354&gt;] kernel_init+0x94/0x120\n[  498.608388] [&lt;ffffffff810002c0&gt;] ? 0xffffffff810002c0\n[  498.668706] [&lt;ffffffff81019b0a&gt;] ? schedule_tail+0xa/0x40\n[  498.733182] [&lt;ffffffff810002c0&gt;] ? 0xffffffff810002c0\n[  498.793499] [&lt;ffffffff8100e762&gt;] ret_from_fork+0x22/0x30\n[  498.856936] &lt;EOT&gt;\n</code></pre></p>"},{"location":"lego/log/log-03-2018/#0318-sun","title":"03/18 Sun","text":"<p>Got a bug report after enable preempt and sweep thread <pre><code>[  582.545444] pcache:ffff8801812cb680 mapcount:1 refcount:2 flags:(locked|allocated|usable|valid|reclaim) kva: ffff88014b2da000\n[  582.678677] pcache dumped because: PCACHE_BUG_ON_PCM(pcache_mapped(pcm))\n[  582.758760] rmap:ffff88207e5e37e8 flags:0x0 owner-tgid:33 user_va:0x7fff0b2da000 ptep:ffff88207e4a86d0\n[  582.870046] pte:ffff88207e4a86d0 pfn:0x0 flags:()\n[  582.926210] ------------[ cut here ]------------\n[  582.981333] BUG: failure at managers/processor/pcache/victim.c:604/victim_finish_insert()!\n[  583.080137] Kernel Panic - not syncing: BUG!\n...\n...\n[  588.847239] nr_pgfault: 591101\n[  588.883641] nr_clflush: 66176\n[  588.919003] nr_pgfault_wp: 0\n[  588.953325] nr_pgfault_wp_cow: 0\n[  588.991806] nr_pgfault_wp_reuse: 0\n[  589.032368] nr_pgfault_due_to_concurrent_eviction: 0\n[  589.091651] nr_pcache_fill_from_memory: 587057\n[  589.144694] nr_pcache_fill_from_victim: 4038\n[  589.195656] nr_pcache_eviction_triggered: 439562\n[  589.250780] nr_pcache_eviction_eagain_freeable: 373382\n[  589.312143] nr_pcache_eviction_eagain_concurrent: 0\n[  589.370386] nr_pcache_eviction_failure_find: 0\n[  589.423429] nr_pcache_eviction_failure_evict: 0\n[  589.477512] nr_pcache_eviction_succeed: 66176\n[  589.529514] nr_victim_eviction_triggered: 733361\n[  589.584638] nr_victim_eviction_eagain: 671227\n[  589.636640] nr_victim_eviction_succeed: 62134\n[  589.688642] nr_victim_prepare_insert: 66180\n[  589.738566] nr_victim_finish_insert: 66176\n[  589.787447] nr_victim_flush_submitted: 66176\n[  589.838411] nr_victim_flush_finished: 66176\n[  589.888332] nr_victim_flush_async_run: 0\n[  589.935135] nr_victim_flush_sync: 0\n[  589.976738] nr_sweep_run: 50580\n[  590.014179] nr_sweep_nr_pset: 116770383\n[  590.059943] nr_sweep_nr_moved_pcm: 100686435\n</code></pre></p> <p>This is an interesting bug. Two threads, one doing munmap or mremap, one doing eviction. They are using the same pcm. munmap and mremap will use <code>pte_get_and_clear()</code> to get the pcm.  While eviction will call <code>pcache_try_to_unamp</code>, which will further call <code>rmap_get_locked_pte()</code>, in which we check if the pte is none, if it is, then we know this is under munmap or mremap, then we skip. This is absolutely wrong. When <code>pcache_try_to_unamp</code> is called by eviction, it should always unmap ALL rmap. The above case is triggered because both two threads skip the final <code>__pcache_remove_rmap</code>.</p> <p>Hmm, looks like open/close filename is wrong. I need to check.</p> <p>Last Log from MT+2GB, computation finished: <pre><code>wuklab13 0318-10\n[  627.280016]\n****    ERROR:\n***     current: 32:kevict_sweepd caller:           (null)\n****    [pte == rmap-&gt;page_table] &amp;&amp; [pcache_pfn != pte_pfn]\n****    rmap-&gt;owner_process: word_count-pthr uva: 0x7fff78f52000 ptep: ffff88107e87fa90, rmap-&gt;page_table: ffff88107e87fa90\n****    pcache_pfn: 0x168f52, pte_pfn: 0x178f52\n\n[  627.624239] rmap:ffff88107dc73740 flags:0x0 owner-tgid:33 user_va:0x7fff78f52000 ptep:ffff88107e87fa90\n[  627.735513] pte:ffff88107e87fa90 pfn:0x0 flags:()\n[  627.791670] pcache_rmap dumped because: Corrupted RMAP\n[  627.853026] pcache:ffff880181a3d480 mapcount:1 refcount:2 flags:(locked|allocated|usable|valid) kva: ffff880168f52000\n[  627.979901] pcache dumped because: Corrupted RMAP\n[  628.036057] ------------[ cut here ]------------\n[  628.091175] BUG: failure at managers/processor/pcache/rmap.c:109/report_bad_rmap()!\n[  628.182691] Kernel Panic - not syncing: BUG!\n[  628.233647] CPU: 5 PID: 32 Comm: kevict_sweepd 4.0.0-lego-ys+ #543\n[  628.307483] Stack:\n[  628.331401] ffff88107e85bd00 ffffffff81026d24 0000000000000008 ffff88107e85bd10\n[  628.418756] ffff88107e85bcc8 0000000021475542 0000000000000000 0000000000000000\n[  628.506113] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[  628.593468] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[  628.680823] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[  628.768179] Call Trace:\n[  628.797299] &lt;TSK&gt;\n[  628.820176] [&lt;ffffffff81026d30&gt;] panic+0xc2/0x102\n[  628.876334] [&lt;ffffffff8101c6ac&gt;] ? task_tick_rt+0x2c/0xd0\n[  628.940811] [&lt;ffffffff8101c6ac&gt;] ? task_tick_rt+0x2c/0xd0\n[  629.005288] [&lt;ffffffff81019bfc&gt;] ? scheduler_tick+0x5c/0x70\n[  629.071843] [&lt;ffffffff81017195&gt;] ? tick_handle_periodic+0x45/0x70\n[  629.144639] [&lt;ffffffff81006704&gt;] ? apic_timer_interrupt+0x54/0x90\n[  629.217436] [&lt;ffffffff8100e4da&gt;] ? smp__apic_timer_interrupt+0x6a/0x70\n[  629.295432] [&lt;ffffffff81012d94&gt;] ? printk+0x124/0x1c0\n[  629.355748] [&lt;ffffffff8103ad1f&gt;] report_bad_rmap+0x144/0x144\n[  629.423345] [&lt;ffffffff81031046&gt;] pcache_referenced_trylock_one+0x1c6/0x2c0\n[  629.505500] [&lt;ffffffff8100e4da&gt;] ? smp__apic_timer_interrupt+0x6a/0x70\n[  629.583497] [&lt;ffffffff810328a1&gt;] rmap_walk+0x71/0xe0\n[  629.642774] [&lt;ffffffff81033329&gt;] pcache_referenced_trylock+0x59/0xd0\n</code></pre></p>"},{"location":"lego/log/log-03-2018/#0317-sat","title":"03/17 Sat","text":"<p>I\u2019m too tired today.</p> <p>Coding side, I will only optimize sweep. Besides, I will book tickets for Iceland trip.</p>"},{"location":"lego/log/log-03-2018/#0316-friday","title":"03/16 Friday","text":"<p>Task 1: Add physical memory counter. It is a per-zone based counter, even though there is also some global counters. In Linux, per-cpu counter is first accumlated, global counter is updated only when per-cpu ones overflow. Lego\u2019s initial version save the trouble of per-cpu counter, I only port one global counter today, because I\u2019m not quite confident about our percpu_alloc\u2026</p> <p>Anway, the info is reported in the format of <code>manager_sysinfo</code>. Do note this is different from the oirginal <code>sysinfo</code> structure, which is used by sysinfo syscall.</p> <p>Task 2: Patch get_random_number and /dev/urandom /dev/random. Others wrote the code, but he did not stick to the tradition of format naming. So I have to rewrite some of them. Sigh.</p> <p>Task 3: optimize sweep</p>"},{"location":"lego/log/log-03-2018/#0315-thur","title":"03/15 Thur","text":"<p>Forgot to write the log yesterday. I actually solved the major bug, the refcount and eviction one. That is really nasty. I basically used pte lock, pcache_lock, and refcount to synchronize between eviction routine and other users such as munmap, mremap, write-protected-handler.</p> <p>I\u2019m really not sure if this mode can be reproduced if I have any other similar systems. But I\u2019m glad that I find a way to do this.</p> <p>Today I got few tasks going on. First merge storage syscall branch, then add sched_yield syscall, add zone/node counters, and probably patch get_random_number.</p> <p>Task 1: Merge Yilun\u2019s storage pull request, has bunch syscalls. I\u2019m reviewing now.</p> <ul> <li>truncate</li> <li>ftruncate</li> <li>getdents</li> <li>getcwd</li> <li>mkdir</li> <li>rmdir</li> <li>creat</li> <li>unlink</li> <li>unlinkat</li> <li>readlink</li> <li>statfs</li> <li>sync</li> </ul> <p>Task 2: Add <code>sched_yield()</code>. Fairly simple.</p> <p>Task 3: Add physical memory counter. Fairly complex. The underlying is built long time ago. Need to pick up some. Well some facts:</p> <ul> <li>pg_data_t (and zone) is allcoated by alloc_node_data if NUMA is configured.</li> <li>all zones are built and initliazed in memory_init() in Lego</li> <li>stats are reset to 0 when pg_data_t allocated (DUH?). Played directly in page_alloc.c</li> </ul> <p>Have to continue tomorrow.</p> <p>Task 4: Patch get_random_number and /dev/urandom</p>"},{"location":"lego/log/log-03-2018/#0313-wed","title":"03/13 Wed","text":"<p>The slow victim flush issue is solved by pinning the thread to a core and remove that core from active_cpu mask.</p> <p>Today I\u2019m going to solve the SMP object issue. I\u2019m hoping by solving this, we can have a complete working pcache and victim cache.</p> <p>Continue yesterday\u2019s log: <pre><code>wuklab13 0313-12\n[ 1073.616269] pcache:ffff880180777a80 mapcount:0 refcount:3 flags:(locked|allocated|usable) kva: ffff88011ddea000\n[ 1073.734941] __clflush_one(): EFAULT:bad address tsk: 32 user_va: 0x7fff4ddea000\n[ 1073.822304] pcache dumped because: evict/ref bug\n\n[ 1073.987667] BUG: failure at managers/processor/pcache/evict.c:301/pcache_evict_line()!\n\n[ 1074.082308] BUG: failure at managers/processor/pcache/rmap.c:763/pcache_zap_pte()!\n[ 1074.172789] Kernel Panic - not syncing: BUG!\n[ 1074.223751] CPU: 23 PID: 50 Comm: word_count-pthr 4.0.0-lego-ys+ #476\n</code></pre></p> Time CPU0 CPU1 0 pcache_evict_line() zap_pte_range() 1 find @pcm to evict prepare to unmap pte which points to @pcm 2 lock_pcache() .. 3 pcache_try_to_unmap() pte_offset_lock() 4 try to lock pte pcache_zap_pte() 5 ..spin.. trylock_pcache (failed) 6 ..spin.. unlock pte 7 lock pte trylock pcache 8 clear pte ..spin.. 9 unlock pte ..spin.. 10 unlock pcache ..spin.. 11 .. lock pcache 12 .. lock pte 13 .. HERE, should check if pte changed! <p>Huh, patched both eviction and other code. Use refcount, pcache lock, pte lock to synchronize between all users. Make sure a going-to-be-evicted pcm will not be used by others. And others will not have a chance to use such line.</p>"},{"location":"lego/log/log-03-2018/#0312-tue","title":"03/12 Tue","text":"<p>Continue victim cache. The current conclusion is victim has a unbalanced input and output rate. That is why some cores timeout and abort.</p> <p>Got some more clean log. The log told us that the flushd_victim is too slow at flushing content. Next I going to print the current flush queue content. Make sure that they are really not flushed. If so, I want to add code to flush sync.</p> <pre><code>[  318.193591] CPU4 PID:54 Abort victim alloc (10010ms) nr_usable_victims: 8 req from pset:ffff88207f81d340, pset_idx:1869, nr_lru:7\n[  318.330986]   --   Start Dump Victim Cache     --\n[  318.388190]   --   CPU4 [word_count-pthr][pid=54, tgid=32] --\n[  318.456835] victim:ffff88207ff71000 index:0 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d200\n[  318.627406]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff90748000\n[  318.707492]     pset:ffff88207f81d200 set_idx: 1864 nr_lru:8\n[  318.775096]\n[  318.792778] victim:ffff88207ff71048 index:1 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d240\n[  318.963349]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff90749000\n[  319.043435]     pset:ffff88207f81d240 set_idx: 1865 nr_lru:8\n[  319.111040]\n[  319.128721] victim:ffff88207ff71090 index:2 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d180\n[  319.299292]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff90746000\n[  319.379378]     pset:ffff88207f81d180 set_idx: 1862 nr_lru:8\n[  319.446983]\n[  319.464664] victim:ffff88207ff710d8 index:3 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d280\n[  319.635237]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff9074a000\n[  319.715321]     pset:ffff88207f81d280 set_idx: 1866 nr_lru:8\n[  319.782927]\n[  319.800608] victim:ffff88207ff71120 index:4 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d140\n[  319.971179]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff90745000\n[  320.051265]     pset:ffff88207f81d140 set_idx: 1861 nr_lru:8\n[  320.118870]\n[  320.136551] victim:ffff88207ff71168 index:5 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d300\n[  320.307123]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff9074c000\n[  320.387208]     pset:ffff88207f81d300 set_idx: 1868 nr_lru:8\n[  320.454813]\n[  320.472494] victim:ffff88207ff711b0 index:6 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d1c0\n[  320.643066]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff90747000\n[  320.723152]     pset:ffff88207f81d1c0 set_idx: 1863 nr_lru:8\n[  320.790756]\n[  320.808438] victim:ffff88207ff711f8 index:7 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d2c0\n[  320.979009]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff9074b000\n[  321.059096]     pset:ffff88207f81d2c0 set_idx: 1867 nr_lru:8\n[  321.126700]\n[  321.144381]   --   End Dump Victim Cache       --\n[  321.200545] CPU4 PID:54 fail to allocate pcache or victim cache lines.\n[  321.278552] word_count-pthr[54]: segfault at 0x74d000 ip 000000000040249d sp 00007fff7674cd80 error 6\n[  321.511925] nr_pgfault: 551908\n[  321.546357] nr_clflush: 33449\n[  321.581718] nr_pgfault_wp: 0\n[  321.616040] nr_pgfault_wp_cow: 0\n[  321.654523] nr_pgfault_wp_reuse: 0\n[  321.695087] nr_pgfault_due_to_concurrent_eviction: 0\n[  321.754371] nr_pcache_fill_from_memory: 546067\n[  321.807414] nr_pcache_fill_from_victim: 5750\n[  321.858378] nr_pcache_eviction_triggered: 38689\n[  321.912461] nr_pcache_eviction_eagain: 5239\n[  321.962385] nr_pcache_eviction_succeed: 33449\n[  322.014389] nr_victim_eviction_triggered: 41887455\n[  322.071592] nr_victim_eviction_eagain: 41859764\n[  322.125676] nr_victim_eviction_succeed: 27691\n[  322.177680] nr_victim_prepare_insert: 33450\n[  322.227603] nr_victim_finish_insert: 33449\n[  322.276487] nr_victim_flush_submitted: 33449\n[  322.327451] nr_victim_flush_finished: 33449\n[  322.377374] nr_victim_flush_async_run: 26989\n[  322.428338] nr_victim_flush_sync: 0\n</code></pre> <p>Yes, this victims are truly not being flushed. They are inside the flush_queue. No bug, hoo! Just some performance coding issues. But god why the flushd does not get a chance to run in 10 seconds? Hmm\u2026 <pre><code>[ 5520.236187] __clflush_one(): EFAULT:bad address tsk: 32 user_va: 0x7fff464fa000\n[ 5530.404269] CPU4 PID:54 Abort victim alloc (10010ms) nr_usable_victims: 8 req from pset:ffff88207f81d340, pset_idx:1869, nr_lru:7\n[ 5530.541664] CPU4 PID54   --   Start Dump Victim Cache [0]\n[ 5530.606147] CPU4 PID54  victim:ffff88207ff71000 index:0 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d1c0\n[ 5530.789194] CPU4 PID54     hit[0] owner: [word_count-pthr][32] addr: 0x7fff90747000\n[ 5530.880717] CPU4 PID54     rmap to pset:ffff88207f81d1c0 set_idx: 1863 nr_lru:8\n[ 5530.968080] CPU4 PID54  victim:ffff88207ff71048 index:1 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d280\n[ 5531.151128] CPU4 PID54     hit[0] owner: [word_count-pthr][32] addr: 0x7fff9074a000\n[ 5531.242652] CPU4 PID54     rmap to pset:ffff88207f81d280 set_idx: 1866 nr_lru:8\n[ 5531.330015] CPU4 PID54  victim:ffff88207ff71090 index:2 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d300\n[ 5531.513063] CPU4 PID54     hit[0] owner: [word_count-pthr][32] addr: 0x7fff9074c000\n[ 5531.604586] CPU4 PID54     rmap to pset:ffff88207f81d300 set_idx: 1868 nr_lru:8\n[ 5531.691950] CPU4 PID54  victim:ffff88207ff710d8 index:3 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d2c0\n[ 5531.874997] CPU4 PID54     hit[0] owner: [word_count-pthr][32] addr: 0x7fff9074b000\n[ 5531.966521] CPU4 PID54     rmap to pset:ffff88207f81d2c0 set_idx: 1867 nr_lru:8\n[ 5532.053885] CPU4 PID54  victim:ffff88207ff71120 index:4 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d200\n[ 5532.236932] CPU4 PID54     hit[0] owner: [word_count-pthr][32] addr: 0x7fff90748000\n[ 5532.328456] CPU4 PID54     rmap to pset:ffff88207f81d200 set_idx: 1864 nr_lru:8\n[ 5532.415819] CPU4 PID54  victim:ffff88207ff71168 index:5 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d240\n[ 5532.598867] CPU4 PID54     hit[0] owner: [word_count-pthr][32] addr: 0x7fff90749000\n[ 5532.690390] CPU4 PID54     rmap to pset:ffff88207f81d240 set_idx: 1865 nr_lru:8\n[ 5532.777753] CPU4 PID54  victim:ffff88207ff711b0 index:6 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d180\n[ 5532.960802] CPU4 PID54     hit[0] owner: [word_count-pthr][32] addr: 0x7fff90746000\n[ 5533.052325] CPU4 PID54     rmap to pset:ffff88207f81d180 set_idx: 1862 nr_lru:8\n[ 5533.139689] CPU4 PID54  victim:ffff88207ff711f8 index:7 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d140\n[ 5533.322736] CPU4 PID54     hit[0] owner: [word_count-pthr][32] addr: 0x7fff90745000\n[ 5533.414259] CPU4 PID54     rmap to pset:ffff88207f81d140 set_idx: 1861 nr_lru:8\n[ 5533.501623] CPU4 PID54   --   End Dump Victim Cache [0]\n\n[ 5533.566106] CPU4 PID54   --  Start Dump Victim Flush Queue [0]\n[ 5533.635789] CPU4 PID54  victim:ffff88207ff711f8 index:7 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d140\n[ 5533.818837] CPU4 PID54  victim:ffff88207ff711b0 index:6 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d180\n[ 5534.001884] CPU4 PID54  victim:ffff88207ff71000 index:0 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d1c0\n[ 5534.184931] CPU4 PID54  victim:ffff88207ff71120 index:4 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d200\n[ 5534.367978] CPU4 PID54  victim:ffff88207ff71168 index:5 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d240\n[ 5534.551025] CPU4 PID54  victim:ffff88207ff71048 index:1 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d280\n[ 5534.734074] CPU4 PID54  victim:ffff88207ff710d8 index:3 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d2c0\n[ 5534.917120] CPU4 PID54  victim:ffff88207ff71090 index:2 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d300\n[ 5535.100168] CPU4 PID54   --  End Dump Victim Flush Queue [0]\n\n[ 5535.169851] CPU4 PID:54 fail to allocate pcache or victim cache lines.\n[ 5535.247854] word_count-pthr[54]: segfault at 0x74d000 ip 000000000040249d sp 00007fff7674cd80 error 6\n[ 5535.480513] nr_pgfault: 549578\n[ 5535.514943] nr_clflush: 31822\n[ 5535.550304] nr_pgfault_wp: 0\n[ 5535.584625] nr_pgfault_wp_cow: 0\n[ 5535.623107] nr_pgfault_wp_reuse: 0\n[ 5535.663669] nr_pgfault_due_to_concurrent_eviction: 0\n[ 5535.722952] nr_pcache_fill_from_memory: 544279\n[ 5535.775993] nr_pcache_fill_from_victim: 5201\n[ 5535.826955] nr_pcache_eviction_triggered: 37437\n[ 5535.881038] nr_pcache_eviction_eagain: 5614\n[ 5535.930960] nr_pcache_eviction_succeed: 31822\n[ 5535.982963] nr_victim_eviction_triggered: 42000029\n[ 5536.040165] nr_victim_eviction_eagain: 41973416\n[ 5536.094247] nr_victim_eviction_succeed: 26613\n[ 5536.146249] nr_victim_prepare_insert: 31823\n[ 5536.196171] nr_victim_finish_insert: 31822\n[ 5536.245052] nr_victim_flush_submitted: 31822\n[ 5536.296015] nr_victim_flush_finished: 31822\n[ 5536.345937] nr_victim_flush_async_run: 26718\n[ 5536.396899] nr_victim_flush_sync: 0\n</code></pre></p> <p>Hmm, got some interesting bug, which never happened before. We did a <code>unmap</code> before <code>finish_insert</code>, so the mapcount must be zero. Since we have the <code>Reclaim</code> set for the candidate. But it looks like other code does not too much about the Reclaim bit. I need to check. <pre><code>[ 1009.676839] victim_flush_async CPU4 jobs 1\n[ 1009.725830] victim_flush_async CPU4 jobs 1\n[ 1009.774423] victim_flush_async CPU4 jobs 1\n[ 1009.823147] __clflush_one(): EFAULT:bad address tsk: 32 user_va: 0x7fff465fc000\n[ 1009.910479] pcache:ffff88018098d740 mapcount:1 refcount:3 flags:(locked|allocated|usable|valid|reclaim) kva: ffff88012635d000\n[ 1010.045652] pcache dumped because: PCACHE_BUG_ON_PCM(pcache_mapped(pcm))\n[ 1010.125725] victim_flush_async CPU4 jobs 1\n[ 1010.174602] ------------[ cut here ]------------\n[ 1010.229717] BUG: failure at managers/processor/pcache/victim.c:601/victim_finish_insert()!\n[ 1010.328509] victim_flush_async CPU4 jobs 1\n[ 1010.377385] Kernel Panic - not syncing: BUG!\n[ 1010.428341] CPU: 20 PID: 47 Comm: word_count-pthr 4.0.0-lego-ys+ #468\n[ 1010.505294] Stack:\n[ 1010.529212] ffff881f2040fe08 ffffffff810259f4 0000000000000008 ffff881f2040fe18\n[ 1010.616565] ffff881f2040fdd0 0000000021475542 0000000000000000 0000000000000000\n[ 1010.703918] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[ 1010.791270] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[ 1010.878623] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[ 1010.965976] Call Trace:\n[ 1010.995095] &lt;TSK&gt;\n[ 1011.017972] [&lt;ffffffff81025a00&gt;] panic+0xc2/0x102\n[ 1011.074127] [&lt;ffffffff81063a8a&gt;] ? client_internal_poll_sendcq+0x2a/0x80\n[ 1011.154202] [&lt;ffffffff81063c2d&gt;] ? client_send_message_with_rdma_write_with_imm_request+0x14d/0x360\n[ 1011.262351] [&lt;ffffffff8101bffc&gt;] ? task_tick_rt+0x2c/0xd0\n[ 1011.326827] [&lt;ffffffff81019755&gt;] ? scheduler_tick+0x55/0x60\n[ 1011.393382] [&lt;ffffffff81016e25&gt;] ? tick_handle_periodic+0x45/0x70\n[ 1011.466175] [&lt;ffffffff810066e4&gt;] ? apic_timer_interrupt+0x54/0x90\n[ 1011.538969] [&lt;ffffffff8100e4aa&gt;] ? smp__apic_timer_interrupt+0x6a/0x70\n[ 1011.616964] [&lt;ffffffff81012cfd&gt;] ? printk+0x11d/0x1b0\n[ 1011.677279] [&lt;ffffffff81032a19&gt;] victim_finish_insert+0x89/0x230\n[ 1011.749032] [&lt;ffffffff81031a99&gt;] pcache_evict_line+0x79/0x280\n[ 1011.817667] [&lt;ffffffff8102f00a&gt;] pcache_alloc+0x23a/0x340\n[ 1011.882141] [&lt;ffffffff8102e4da&gt;] common_do_fill_page+0x2a/0x1b0\n[ 1011.952856] [&lt;ffffffff8102e160&gt;] ? pcache_meta_to_kva+0x30/0x30\n[ 1012.023570] [&lt;ffffffff8102e802&gt;] pcache_handle_fault+0x1a2/0x660\n[ 1012.095324] [&lt;ffffffff810102b2&gt;] do_page_fault+0xa2/0x1a0\n[ 1012.159799] [&lt;ffffffff8100dadf&gt;] page_fault+0x1f/0x30\n</code></pre></p> <p>Interesting. Memory consistency issue? Actually, I\u2019m not sure if it is the <code>v-&gt;flags = 0</code> issue. Others use atomic bit operations to play with this flag, while the reset is a simple store. I checked the list operations,  all of them are protected by spinlock. So the below should never happen in theory. I\u2019m changing the <code>v-&gt;flags = 0</code> to <code>smp_store_mb(v-&gt;flags, 0)</code>, which is a <code>xchg</code> in x86. Same for pcache. <pre><code>[ 1773.814490] CPU17 PID44  victim:ffff88207ff71000 index:0 refcount:1 nr_fill:0 locked:0 flags:(allocated|usable) pcm:          (null) pset:          (null)\n[ 1773.979705] CPU17 PID44     hit[0] owner: [word_count-pthr][32] addr: 0x7fff95b1c000\n[ 1774.072260] CPU17 PID44     rmap to pset:ffff88207f96c700 set_idx: 23324 nr_lru:8\n[ 1774.161694] CPU17 PID44     victim dumped because: PCACHE_BUG_ON_VICTIM(!VictimUsable(v))\n[ 1774.259451] ------------[ cut here ]------------\n[ 1774.314567] BUG: failure at managers/processor/pcache/victim.c:231/find_victim_to_evict()!\n[ 1774.413363] Kernel Panic - not syncing: BUG!\n[ 1774.464320] CPU: 17 PID: 44 Comm: word_count-pthr 4.0.0-lego-ys+ #47\n...\n[ 1781.363348] nr_pcache_fill_from_victim: 2\n</code></pre></p> <p>Did another run. I added an explicit <code>wake_up_victim_flushd</code> if victim failed to evict any line. But this fails with IB failure.. <pre><code>[ 2336.950087] CPU4 PID:54 Abort victim alloc (20010ms) nr_usable_victims: 8 req from pset:ffff88207f81d340, pset_idx:1869, nr_lru:7\n[ 2337.087474] CPU4 PID54   --   Start Dump Victim Cache [0]\n[ 2337.151955] CPU4 PID54  victim:ffff88207ff71000 index:0 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d280\n[ 2337.334999] CPU4 PID54     hit[0] owner: [word_count-pthr][32] addr: 0x7fff9074a000\n[ 2337.426521] CPU4 PID54     rmap to pset:ffff88207f81d280 set_idx: 1866 nr_lru:8\n[ 2337.513883] CPU4 PID54  victim:ffff88207ff71048 index:1 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d2c0\n[ 2337.696927] CPU4 PID54     hit[0] owner: [word_count-pthr][32] addr: 0x7fff9074b000\n[ 2337.788450] CPU4 PID54     rmap to pset:ffff88207f81d2c0 set_idx: 1867 nr_lru:8\n...\n...\n[ 2340.111861] CPU4 PID54   --  Start Dump Victim Flush Queue [0]\n[ 2340.181543] CPU4 PID54  victim:ffff88207ff71090 index:2 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d140\n[ 2340.364587] CPU4 PID54  victim:ffff88207ff71120 index:4 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d180\n[ 2340.547632] CPU4 PID54  victim:ffff88207ff711f8 index:7 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d1c0\n[ 2340.730675] CPU4 PID54  victim:ffff88207ff71168 index:5 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d200\n[ 2340.913720] CPU4 PID54  victim:ffff88207ff711b0 index:6 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d240\n[ 2341.096763] CPU4 PID54  victim:ffff88207ff71000 index:0 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d280\n[ 2341.279808] CPU4 PID54  victim:ffff88207ff71048 index:1 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d2c0\n[ 2341.462851] CPU4 PID54  victim:ffff88207ff710d8 index:3 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207f81d300\n[ 2341.645895] CPU4 PID54   --  End Dump Victim Flush Queue [0]\n\n[ 2341.715577] CPU4 PID:54 fail to allocate pcache or victim cache lines.\n[ 2341.793579] word_count-pthr[54]: segfault at 0x74d000 ip 000000000040249d sp 00007fff7674cd80 error 6\n[ 2476.201442] mlx4_ib_handle_error_cqe syndrome 21\n[ 2476.254590] mlx4_ib_handle_error_cqe syndrome 5\n[ 2476.308670] send request failed at connection 4 as 12\n[ 2476.368991] mlx4_ib_handle_error_cqe syndrome 5\n[ 2476.423073] mlx4_ib_handle_error_cqe syndrome 5\n[ 2476.477153] mlx4_ib_handle_error_cqe syndrome 5\n[ 2476.531236] client_poll_cq: failed status (5) for wr_id 1051\n[ 2476.598837] client_poll_cq: failed status (5) for wr_id 1052\n[ 2476.666438] __clflush_one(): EPERM:Operation not permitted tsk: 32 user_va: 0x7fff90745000\n[ 2476.765240] client_poll_cq: connection 4 Recv weird event as -30704\n[ 2476.840122] client_poll_cq: failed status (5) for wr_id 1053\n[ 2476.907724] client_poll_cq: connection 4 Recv weird event as -30704\n[ 2476.982605] client_poll_cq: failed status (5) for wr_id 1054\n[ 2477.050207] client_poll_cq: connection 4 Recv weird event as -30704\n[ 2477.125089] mlx4_ib_handle_error_cqe syndrome 5\n[ 2477.179169] mlx4_ib_handle_error_cqe syndrome 5\n[ 2477.233251] mlx4_ib_handle_error_cqe syndrome 5\n[ 2477.287332] mlx4_ib_handle_error_cqe syndrome 5\n[ 2477.341414] client_poll_cq: failed status (5) for wr_id 1055\n[ 2477.409016] client_poll_cq: failed status (5) for wr_id 1056\n..\n..\n[ 2477.761583] client_poll_cq: connection 4 Recv weird event as -30704\n[ 2477.836464] mlx4_ib_handle_error_cqe syndrome 5\n[ 2477.890545] mlx4_ib_handle_error_cqe syndrome 5\n[ 2477.944626] mlx4_ib_handle_error_cqe syndrome 5\n[ 2477.998707] mlx4_ib_handle_error_cqe syndrome 5\n[ 2478.052789] client_poll_cq: failed status (5) for wr_id 1059\n[ 2478.120392] BUG: unable to handle kernel NULL pointer dereference at           (null)\n[ 2478.213992] IP: [&lt;ffffffff81064894&gt;] client_poll_cq+0x1f4/0x6c0\n[ 2478.284714] PGD 0\n[ 2478.308635] Oops: 0002 [#1] SMP PROCESSOR\n[ 2478.356476] CPU: 2 PID: 29 Comm: recvpollcq 4.0.0-lego-ys+ #473\n[ 2478.427197] RIP: 0010:[&lt;ffffffff81064894&gt;]  [&lt;ffffffff81064894&gt;] client_poll_cq+0x1f4/0x6c0\n[ 2478.527040] RSP: 0000:ffff88107e143d90  EFLAGS: 00010246\n[ 2478.590481] RAX: 0000000000000000 RBX: ffff88207fc6e000 RCX: 0000000000000000\n[ 2478.675762] RDX: 0000000000001008 RSI: ffffffff811d36e0 RDI: ffffffff811dab08\n[ 2478.761044] RBP: ffff88107e143eb0 R08: 0000000000000000 R09: 0000000000000000\n[ 2478.846327] R10: 0000000000000002 R11: 0000000000000004 R12: ffff88207fd4f000\n[ 2478.931609] R13: 0000000000000004 R14: ffff88107e143da8 R15: 0000000000000000\n[ 2479.016890] FS:  0000000000000000(0000) GS:ffff88107fc20000(0000) knlGS:0000000000000000\n[ 2479.113613] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 2479.182254] CR2: 0000000000000000 CR3: 000000000113d000 CR4: 00000000000406a0\n[ 2479.267536] Stack:\n[ 2479.291457] ffff88107e143da0 0010129c81019794 0000000000000001 0000000000000423\n[ 2479.378818] 0000008100000005 00001008000000f9 ffff88207fd39000 0000000040000000\n[ 2479.466180] 000f004000000002 ffff88107e140000 0000000000000424 ffff881000000005\n[ 2479.553542] 00000000000000f9 ffff88207fd39000 ffff88107e143e38 ffffffff81019e44\n[ 2479.640904] 0000000000000001 0000000000000425 ffff881000000005 ffffffff000000f9\n[ 2479.728266] Call Trace:\n[ 2479.757386] &lt;TSK&gt;\n[ 2479.780268] [&lt;ffffffff81019e44&gt;] ? try_to_wake_up+0xe4/0x1f0\n[ 2479.847869] [&lt;ffffffff81066d78&gt;] ? __schedule+0xf8/0x1e0\n[ 2479.911311] [&lt;ffffffff81064d60&gt;] ? client_poll_cq+0x6c0/0x6c0\n[ 2479.979952] [&lt;ffffffff81064d70&gt;] client_poll_cq_pass+0x10/0x20\n[ 2480.049634] [&lt;ffffffff81020336&gt;] kthread+0xf6/0x110\n[ 2480.107875] [&lt;ffffffff81020240&gt;] ? __kthread_parkme+0x70/0x70\n[ 2480.176516] [&lt;ffffffff8100e732&gt;] ret_from_fork+0x22/0x30\n</code></pre></p> <p>A classical SMP bug. Lucky to find this one. Let me try to describe this. There are two CPU1. CPU0 and CPU1. CPU0 is doing eviction while CPU1 is doing munmap-&gt;pcache_zap_pte. The CPU0 slected a pcm, while this pcm happen to be zapped at the same time by CPU1. There are not enough actions to either 1) prevent CPU0 from selecting this pcm, 2) prevent CPU1 from using this pcm. Both solutions might be work. But we need as least one.</p> <pre><code>wuklab13 0313-12\n[ 1073.616269] pcache:ffff880180777a80 mapcount:0 refcount:3 flags:(locked|allocated|usable) kva: ffff88011ddea000\n[ 1073.734941] __clflush_one(): EFAULT:bad address tsk: 32 user_va: 0x7fff4ddea000\n[ 1073.822304] pcache dumped because: evict/ref bug\n\n[ 1073.987667] BUG: failure at managers/processor/pcache/evict.c:301/pcache_evict_line()!\n\n[ 1074.082308] BUG: failure at managers/processor/pcache/rmap.c:763/pcache_zap_pte()!\n[ 1074.172789] Kernel Panic - not syncing: BUG!\n[ 1074.223751] CPU: 23 PID: 50 Comm: word_count-pthr 4.0.0-lego-ys+ #476\n</code></pre>"},{"location":"lego/log/log-03-2018/#0311-mon","title":"03/11 Mon","text":""},{"location":"lego/log/log-03-2018/#debug-victim-cache","title":"Debug victim cache","text":"<p>Morning. Today I will continue debugging victim and clflush, running with MT phoenix+2GB, seq+4GB. Sounds good.</p> <p>Digging into yesterday\u2019s 21th run log. The warning comes from <code>victim_alloc_slowpath</code>. The allocation abort after 10 seconds timeout. And interestingly, a lot threads abort. (The case is, <code>pset</code> is full, so <code>pcache_alloc</code> will try to evict one to victim cache. But victim cache is full as well. So it needs to evict one victim cache line too. Somehow this does not proceed as planned.) I guess somewhere deadlock happens. <pre><code>[ 1682.040428] WARNING: CPU: 7 PID: 34 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1682.161063] WARNING: CPU: 19 PID: 46 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1686.602779] WARNING: CPU: 10 PID: 37 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1687.384837] WARNING: CPU: 3 PID: 53 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1687.505474] WARNING: CPU: 21 PID: 48 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1687.737386] WARNING: CPU: 16 PID: 43 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1687.859063] WARNING: CPU: 4 PID: 54 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1688.034819] WARNING: CPU: 6 PID: 56 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1688.210574] WARNING: CPU: 14 PID: 41 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1688.488246] WARNING: CPU: 5 PID: 55 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1689.598935] WARNING: CPU: 22 PID: 49 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1689.953565] WARNING: CPU: 0 PID: 51 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1691.740234] WARNING: CPU: 13 PID: 40 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1691.861911] WARNING: CPU: 1 PID: 52 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n[ 1791.554552] WARNING: CPU: 11 PID: 38 at managers/processor/pcache/victim.c:447 victim_prepare_insert+0x322/0x4b0\n</code></pre></p> <p>1<sup>st</sup> run. MT+2GB. Victim allocation as predicted. Somehow I already forgot how the code is designed. I need to take a detailed reread.</p> <p>Along the testing, fixed a bug in eviction code: handle failed evict_line properly. If eviction mechanism failed, we need to clear what the algorithm part has done. This is also related to yesterday\u2019s big idea: always do proper cleanup. Many thanks go to pcache free checking, help me to find this bug.</p> <p>Less is more. I printed too much useless info when pcache_alloc or victim_alloc fail. I removed all the dump_pset from the failing path. It can give me a much more clean message to debug.</p> <p>Hmm, it is really weird. I dump all victims once alloc timeout. You can see that all victim are not Flushed, that means none of them can be evicted. Take a look at the stat. Hmm, I probabaly should not do this per-cpu counter?? <pre><code>...\n[ 4751.460819]   --   Start Dump Victim Cache     --\n[ 4751.518022]   --   CPU19 [word_count-pthr][pid=46, tgid=32] --\n[ 4751.587706] victim:ffff88207ff71000 index:0 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800440\n[ 4751.747872]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff20011000\n[ 4751.827955]     pset:ffff88207f800440 set_idx: 17 nr_lru:8\n[ 4751.893478]\n[ 4751.911159] victim:ffff88207ff71048 index:1 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f8003c0\n[ 4752.071326]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff2000f000\n[ 4752.428060]     pset:ffff88207f8003c0 set_idx: 15 nr_lru:8\n[ 4752.630868]\n[ 4752.931441] victim:ffff88207ff71090 index:2 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800540\n[ 4753.370339]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff20015000\n[ 4753.450422]     pset:ffff88207f800540 set_idx: 21 nr_lru:8\n[ 4753.515945]\n[ 4753.533627] victim:ffff88207ff710d8 index:3 refcount:3 nr_fill:1 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207fbdff40\n[ 4753.693792]     hit[0] owner: [word_count-pthr][32] addr: 0x7fffbf7fd000\n[ 4753.773875]     pset:ffff88207fbdff40 set_idx: 63485 nr_lru:7\n[ 4753.842518]\n[ 4753.860199] victim:ffff88207ff71120 index:4 refcount:3 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800500\n[ 4754.020367]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff20014000\n[ 4754.100449]     pset:ffff88207f800500 set_idx: 20 nr_lru:8\n[ 4754.165971]\n[ 4754.183653] victim:ffff88207ff71168 index:5 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800480\n[ 4754.343819]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff30012000\n[ 4754.423902]     pset:ffff88207f800480 set_idx: 18 nr_lru:8\n[ 4754.489426]\n[ 4754.507106] victim:ffff88207ff711b0 index:6 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f8004c0\n[ 4754.808718]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff30013000\n[ 4754.888802]     pset:ffff88207f8004c0 set_idx: 19 nr_lru:8\n[ 4754.954325]\n[ 4754.972006] victim:ffff88207ff711f8 index:7 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800400\n[ 4755.132172]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff20010000\n[ 4755.212255]     pset:ffff88207f800400 set_idx: 16 nr_lru:8\n[ 4755.277778]\n[ 4755.295458]   --   End Dump Victim Cache       --\n\n...\n\n[ 4757.948641] nr_pgfault: 313898\n[ 4757.983067] nr_clflush: 488\n[ 4758.016347] nr_pgfault_wp: 0\n[ 4758.050669] nr_pgfault_wp_cow: 0\n[ 4758.089151] nr_pgfault_wp_reuse: 0\n[ 4758.129713] nr_pgfault_due_to_concurrent_eviction: 0\n[ 4758.188995] nr_pcache_fill_from_memory: 313833\n[ 4758.242038] nr_pcache_fill_from_victim: 54\n[ 4758.290919] nr_pcache_eviction_triggered: 243280263\n[ 4758.349161] nr_pcache_eviction_eagain: 243279763\n[ 4758.404283] nr_pcache_eviction_succeed: 488\n[ 4758.454207] nr_victim_eviction: 426\n[ 4758.495807] nr_victim_prepare_insert: 500\n[ 4758.543649] nr_victim_finish_insert: 488\n[ 4758.590451] nr_victim_flush_submitted: 488\n[ 4758.639333] nr_victim_flush_finished: 488\n</code></pre></p> <p>I counted it wrong. Below is the log. Since <code>nr_victim_flushd_run * 8 = nr_victim_flush_finished</code>, it basically means for every run, victim_flushd needs to flush all 8 victims, which implies eviction rate is much higher than the flushd running rate. <code>nr_pcache_fill_from_victim: 21</code>, which means there are some succeed refills, but I don\u2019t know how it can improve performance.</p> <pre><code>[  475.468489] CPU4 PID:54 Abort victim alloc (10010ms) nr_usable_victims: 8 req from pset:ffff88207f800000, pset_idx:0, nr_lru:7\n[  475.602752] CPU3 PID:53 Abort victim alloc (10010ms) nr_usable_victims: 8 req from pset:ffff88207f900a00, pset_idx:16424, nr_lru:7\n[  476.029145] CPU5 PID:55 Abort victim alloc (10010ms) nr_usable_victims: 8 req from pset:ffff88207fbdff40, pset_idx:63485, nr_lru:7\n[  476.169542] CPU9 PID:36 Abort victim alloc (10010ms) nr_usable_victims: 8 req from pset:ffff88207f900000, pset_idx:16384, nr_lru:7\n[  477.360322] CPU1 PID:52 Abort victim alloc (10010ms) nr_usable_victims: 8 req from pset:ffff88207fbfff80, pset_idx:65534, nr_lru:7\n[  479.206291] CPU18 PID:45 Abort victim alloc (10010ms) nr_usable_victims: 8 req from pset:ffff88207fb00000, pset_idx:49152, nr_lru:7\n\n[  475.743150]   --   Start Dump Victim Cache     --\n[  475.800350]   --   CPU4 [word_count-pthr][pid=54, tgid=32] --\n[  475.868989] victim:ffff88207ff71000 index:0 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800a80\n[  476.309940]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff3002a000\n[  476.390020]     pset:ffff88207f800a80 set_idx: 42 nr_lru:8\n[  476.455538]\n[  476.473218] victim:ffff88207ff71048 index:1 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800bc0\n[  476.633376]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff4002f000\n[  476.713453]     pset:ffff88207f800bc0 set_idx: 47 nr_lru:8\n[  476.778972]\n[  476.796652] victim:ffff88207ff71090 index:2 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800b80\n[  476.956809]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff3002e000\n[  477.036889]     pset:ffff88207f800b80 set_idx: 46 nr_lru:8\n[  477.102406]\n[  477.120086] victim:ffff88207ff710d8 index:3 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800a00\n[  477.280245]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff30028000\n[  477.500721]     pset:ffff88207f800a00 set_idx: 40 nr_lru:8\n[  477.566239]\n[  477.583918] victim:ffff88207ff71120 index:4 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800b40\n[  477.744077]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff3002d000\n[  477.824155]     pset:ffff88207f800b40 set_idx: 45 nr_lru:8\n[  477.889673]\n[  477.907353] victim:ffff88207ff71168 index:5 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800b00\n[  478.067511]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff3002c000\n[  478.147590]     pset:ffff88207f800b00 set_idx: 44 nr_lru:8\n[  478.213109]\n[  478.230788] victim:ffff88207ff711b0 index:6 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800a40\n[  478.390946]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff30029000\n[  478.471024]     pset:ffff88207f800a40 set_idx: 41 nr_lru:8\n[  478.536542]\n[  478.554222] victim:ffff88207ff711f8 index:7 refcount:2 nr_fill:0 locked:0 flags:(allocated|usable|hasdata) pcm:          (null) pset:ffff88207f800ac0\n[  478.714380]     hit[0] owner: [word_count-pthr][32] addr: 0x7fff3002b000\n[  478.794458]     pset:ffff88207f800ac0 set_idx: 43 nr_lru:8\n[  478.859977]\n[  478.877657]   --   End Dump Victim Cache       --\n\n[  480.324070] nr_pgfault: 372353\n[  480.358494] nr_clflush: 336\n[  480.391774] nr_pgfault_wp: 0\n[  480.426093] nr_pgfault_wp_cow: 0\n[  480.464573] nr_pgfault_wp_reuse: 0\n[  480.505132] nr_pgfault_due_to_concurrent_eviction: 0\n[  480.564410] nr_pcache_fill_from_memory: 372326\n[  480.617450] nr_pcache_fill_from_victim: 21\n[  480.666330] nr_pcache_eviction_triggered: 178320088\n[  480.724569] nr_pcache_eviction_eagain: 178319746\n[  480.779687] nr_pcache_eviction_succeed: 336\n[  480.829606] nr_victim_eviction_triggered: 20589049\n[  480.886805] nr_victim_eviction_eagain: 20588741\n[  480.940885] nr_victim_eviction_succeed: 308\n[  480.990804] nr_victim_prepare_insert: 342\n[  481.038643] nr_victim_finish_insert: 336\n[  481.085442] nr_victim_flush_submitted: 336\n[  481.134321] nr_victim_flush_finished: 336\n[  481.182161] nr_victim_flushd_run: 42\n</code></pre>"},{"location":"lego/log/log-03-2018/#0310-sun","title":"03/10 Sun","text":""},{"location":"lego/log/log-03-2018/#fix-bug-from-__unhash_procees","title":"Fix bug from <code>__unhash_procees()</code>","text":"<p>[Summary]: a bug cause by laziness. When fork happens, the new thread is added into parent\u2019s thread_group list. However, we forgot to remove it when the new thread exit. Thus, the field in parent\u2019s thread_group will point to a freed page. To make it worse, the freed page got allocated again. In our case, the page was used by pgtable. So, when the parent tries to use that field, it simply corrupts pgtable. This bug is fixed by this commit: 64d43fc.</p> <p>Got something going on. Huh.</p> <p>Anyway, pick up what left last night.</p> <p>8<sup>th</sup> run, <pre><code>[  426.595911] SYSC_mmap(cpu5): ret_addr:0x7ffefbeac000\n\npte page got allocated\n[  426.653216]     pmd is none index 0x1e3 line 567 from_addr 0x7ffefc6acd90\n[  426.734334] __pte_alloc(): for addr: 0x7ffefc6acd90 pte_index: ac\n[  426.807132]     pte is none index 0x38 line 574 from_addr 0x7ffefc6acd90\n[  427.304148]     pte is none index 0x38 line 576 from_addr 0x7ffefc6acd90\n\nthis addr seems fine\n[  427.382251]     pte is none index 0x38 line 567 from_addr 0x7ffefc6abe78\n[  427.462329]     pte is none index 0x38 line 574 from_addr 0x7ffefc6abe78\n[  427.644439]     pte is none index 0x38 line 576 from_addr 0x7ffefc6abe78\n\nSomething happen in between corrupted pgtable\n[  427.722547] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000)\n[  427.858779] line: 567 from_addr: 0x6fc6d8 pte.cont: 0xffff88207e8c31c0\n\n[  427.938858] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000)\n[  428.075095] line: 574 from_addr: 0x6fc6d8 pte.cont: 0xffff88207e8c31c0\n</code></pre></p> <p>9<sup>th</sup> run, found actually it created another thread. And it exit. And it corrupted aftet the pid33 exit. Bang, it should be something wrong in exit(). <pre><code>wuklab13 0311-4\n[  813.127325] CPU6 pid:33     pmd is none index 0x1e3 line 586 from_addr 0x4b0db0\n[  813.214683] CPU5 pid:32     pmd is none index 0x1e3 line 593 from_addr 0x6f4768\n[  813.302042] CPU6 pid:33     pmd is none index 0x1e3 line 593 from_addr 0x4b0db0\n[  813.397836] CPU5 pid:32     pmd is none index 0x1e3 line 595 from_addr 0x6f4768\n[  813.593364] CPU6 pid:33     pmd is none index 0x1e3 line 595 from_addr 0x4b0db0\n\n[  813.678751] do_exit() pid:33,tgid:32 code:0x0\n\n[  814.474321] CPU5 pid:32     pmd is none index 0x1e3 line 567 from_addr 0x7ffefc6acd90\n[  814.567918] CPU5 pid:32     pmd is none index 0x1e3 line 575 from_addr 0x7ffefc6acd90\n[  814.661516] CPU5 pid:32     pmd is none index 0x1e3 line 583 from_addr 0x7ffefc6acd90\n[  814.755115] CPU5 pid:32     pmd is none index 0x1e3 line 586 from_addr 0x7ffefc6acd90\n[  814.848714] __pte_alloc(): for addr: 0x7ffefc6acd90 pte_index: ac\n[  814.921511] CPU5 pid:32     pte is none index 0x38 line 593 from_addr 0x7ffefc6acd90\n[  815.125249] CPU5 pid:32     pte is none index 0x38 line 595 from_addr 0x7ffefc6acd90\n[  815.215833] After pcache_handle_fault\n[  815.259511] CPU5 pid:32     pte is none index 0x38 line 726 from_addr 0x7ffefc6acd90\n\n[  815.352071] CPU5 pid:32     pte is none index 0x38 line 567 from_addr 0x7ffefc6abe78\n[  815.444627] CPU5 pid:32     pte is none index 0x38 line 575 from_addr 0x7ffefc6abe78\n[  815.537186] CPU5 pid:32     pte is none index 0x38 line 583 from_addr 0x7ffefc6abe78\n[  815.629744] CPU5 pid:32     pte is none index 0x38 line 586 from_addr 0x7ffefc6abe78\n[  815.722303] CPU5 pid:32     pte is none index 0x38 line 593 from_addr 0x7ffefc6abe78\n[  815.916890] CPU5 pid:32     pte is none index 0x38 line 595 from_addr 0x7ffefc6abe78\n[  816.007471] After pcache_handle_fault\n[  816.051151] CPU5 pid:32     pte is none index 0x38 line 726 from_addr 0x7ffefc6abe78\n\n[  816.143715] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000)\n[  816.279946] do_exit() pid:34,tgid:32 code:0x0\n[  816.331945] CPU5 pid:32 line: 567 from_addr: 0x6fc6d8 pte.cont: 0xffff88207e8c31c0\n</code></pre></p> <p>10<sup>th</sup> run, actually 2 threads are created. When pid 33 exit, everything stays okay. But after fork of pid 34. It went wrong: <pre><code>wuklab13 0311-8\n[  609.490893] do_exit() pid:33,tgid:32 code:0x0\n\n[  609.542894] CPU6 pid:33 caller: do_exit    pmd is none index 0x1e3 line 401 from_addr 0x0\n[  609.640661] CPU6 pid:33 caller: do_exit    pmd is none index 0x1e3 line 443 from_addr 0x0\n[  609.738429] CPU6 pid:33 caller: do_exit    pmd is none index 0x1e3 line 465 from_addr 0x0\n[  609.836197] exit_mm:378 mm-&gt;users 2 mm-&gt;count 1\n[  609.891320] exit_mm:380 mm-&gt;users 1 mm-&gt;count 1\n[  609.946445] CPU6 pid:33 caller: do_exit    pmd is none index 0x1e3 line 468 from_addr 0x0\n[  610.044212] CPU6 pid:33 caller: do_exit    pmd is none index 0x1e3 line 471 from_addr 0x0\n[  610.141979] CPU6 pid:33 caller: do_exit    pmd is none index 0x1e3 line 474 from_addr 0x0\n\n[  610.239747] SYSC_mmap(cpu5): ret_addr:0x7ffefbeac000\n[  610.299031] CPU6 pid:33 caller: do_exit    pmd is none index 0x1e3 line 482 from_addr 0x0\n[  610.396798] CPU5 pid:32 caller: pcache_handle_fault    pmd is none index 0x1e3 line 568 from_addr 0x7ffefc6acd90\n[  610.518489] CPU5 pid:32 caller: pcache_handle_fault    pmd is none index 0x1e3 line 576 from_addr 0x7ffefc6acd90\n[  610.640178] CPU5 pid:32 caller: pcache_handle_fault    pmd is none index 0x1e3 line 584 from_addr 0x7ffefc6acd90\n[  610.761866] CPU5 pid:32 caller: pcache_handle_fault    pmd is none index 0x1e3 line 587 from_addr 0x7ffefc6acd90\n[  610.883557] __pte_alloc(): for addr: 0x7ffefc6acd90 pte_index: ac\n[  610.956362] CPU5 pid:32 caller: pcache_handle_fault    pte is none index 0x38 line 594 from_addr 0x7ffefc6acd90\n[  611.179051] CPU5 pid:32 caller: pcache_handle_fault    pte is none index 0x38 line 596 from_addr 0x7ffefc6acd90\n[  611.297723] After pcache_handle_fault\n[  611.341406] CPU5 pid:32 caller: do_page_fault    pte is none index 0x38 line 726 from_addr 0x7ffefc6acd90\n[  611.455816] CPU5 pid:32 caller: pcache_handle_fault    pte is none index 0x38 line 568 from_addr 0x7ffefc6abe78\n[  611.576464] CPU5 pid:32 caller: pcache_handle_fault    pte is none index 0x38 line 576 from_addr 0x7ffefc6abe78\n[  611.697113] CPU5 pid:32 caller: pcache_handle_fault    pte is none index 0x38 line 584 from_addr 0x7ffefc6abe78\n[  611.817762] CPU5 pid:32 caller: pcache_handle_fault    pte is none index 0x38 line 587 from_addr 0x7ffefc6abe78\n[  611.938412] CPU5 pid:32 caller: pcache_handle_fault    pte is none index 0x38 line 594 from_addr 0x7ffefc6abe78\n[  612.161103] CPU5 pid:32 caller: pcache_handle_fault    pte is none index 0x38 line 596 from_addr 0x7ffefc6abe78\n[  612.279778] After pcache_handle_fault\n[  612.323461] CPU5 pid:32 caller: do_page_fault    pte is none index 0x38 line 726 from_addr 0x7ffefc6abe78\n\n[  612.437875] do_fork: current: 32 new: 34\n\n[  612.484676] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000)\n[  612.620924] do_exit() pid:34,tgid:32 code:0x0\n[  612.672928] CPU5 pid:32 caller: pcache_handle_faultline: 568 from_addr: 0x6fc6d8 pte.cont: 0xffff88207e8c31c0\n\n[  612.793577] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000)\n[  612.929828] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000)\n[  613.066078] CPU7 pid:34 caller: do_exitline: 401 from_addr: 0x0 pte.cont: 0xffff88207e8c31c0\n</code></pre></p> <p>11<sup>th</sup> run, found it orignate from <code>copy_process()</code>. Good. <pre><code>[  869.591729] CPU5 pid:32 caller: do_fork    pte is none index 0x38 line 886 from_addr 0x0\n\n[  869.688449] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000)\n[  869.824681] CPU5 pid:32 caller: do_fork line: 894 from_addr: 0x0 pte.cont: 0xffff88207e8c31c0\n</code></pre></p> <p>12<sup>th</sup> run, found the opeation that corrupt pgtable: <pre><code>[ 1099.974106] CPU5 pid:32 caller: copy_process    pte is none index 0x38 line 897 from_addr 0x0\n[ 1100.076032] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000)\n[ 1100.212282] CPU5 pid:32 caller: copy_process line: 902 from_addr: 0x0 pte.cont: 0xffff88207e8c31c0\n\n896         if (current-&gt;tgid == 32)\n897                 jasmine(0, __LINE__, __func__);\n898\n899                         list_add_tail(&amp;p-&gt;thread_group,\n900                                           &amp;p-&gt;group_leader-&gt;thread_group);\n901         if (current-&gt;tgid == 32)\n902                 jasmine(0, __LINE__, __func__);\n</code></pre></p> <p>13<sup>th</sup> run, interesting, the list_add_tail write to the pgtable. <code>pte.cont = 0xffff88207e8c31c0, p-&gt;thread_group: 0xffff88207e8c31c0</code>. <pre><code>[  916.269942] CPU5 pid:32 caller: copy_process    pte is none index 0x38 line 898 from_addr 0x0\n\n[  916.371863] p: ffff88207e8c3000 p-&gt;group_leader: ffff88107e190000(32) p-&gt;thread_group: ffff88207e8c31c0 leader-&gt;thread_grou: ffff88107e1901c0\n\n[  916.523705] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000)\n[  916.659947] CPU5 pid:32 caller: copy_process line: 906 from_addr: 0x0 pte.cont: 0xffff88207e8c31c0\n\n[  916.769148] p: ffff88207e8c3000 p-&gt;group_leader: ffff88107e190000(32) p-&gt;thread_group: ffff88207e8c31c0 leader-&gt;thread_grou: ffff88107e1901c0\n</code></pre></p> <p>14<sup>th</sup> run, got an log like this. Clearly, the pte is written the value  of p-&gt;thread_group. But the leader\u2019s pointer is correct. Weird, going to dig deeper. <pre><code>                p: ffff88207e8c3000 p-&gt;group_leader: ffff88107e189000(32)\n\n                p-&gt;thread_group:        ffff88207e8c31c0\n                leader-&gt;thread_group:   ffff88107e1891c0\n\n                pte page:               ffff88207e8b5000\n                pte:                    ffff88207e8b51c0\n\n                pte.cont:               ffff88207e8c31c0\n</code></pre></p> <p>15<sup>th</sup> run, found the bug. <pre><code>wuklab13 0311-15\n[ 1474.477687] dup_task_struct(): current: 32 new: ffff88207e8b5000\n..\nwhile pid 33 exit\nso the ffff88207e8b5000 is freed\n\nbut allocated again by pte_alloc\n[ 1481.420200] __pte_alloc():CPU5 for addr: 0x7ffefc6acd90 pte_index: ac new pte page: ffff88207e8b5000\n\nHowever, we forgot to remove it from group_leader's thread_group\n\n[ 1485.895938]\n                p: ffff88207e8c3000\n                p-&gt;group_leader: ffff88107e19b000(32)\n\n                p-&gt;thread_group:        ffff88207e8c31c0\n                leader-&gt;thread_group:   ffff88107e19b1c0\n\n[ 1486.047784]\n                tg-&gt;next:               ffff88207e8c31c8\n                tg-&gt;prev:               ffff88207e8c31c0\n                leader-&gt;tg-&gt;next        ffff88107e19b1c8\n                leader-&gt;tg-&gt;prev        ffff88107e19b1c0\n\n[ 1486.191311]  next                    ffff88107e19b1c0\n                prev                    ffff88207e8b51c0\n                next                    ffff88107e19b1c0\n\n[ 1486.276594] CPU5 pid:32 caller: __list_add    pte is none index 0x38 line 61 from_addr 0x0 page: 0xffff88207e8b5000\n[ 1486.401399] CPU5 pid:32 caller: __list_add    pte is none index 0x38 line 65 from_addr 0x0 page: 0xffff88207e8b5000\n[ 1486.526203] CPU5 pid:32 caller: __list_add    pte is none index 0x38 line 69 from_addr 0x0 page: 0xffff88207e8b5000\n[ 1486.651010] CPU5 pid:32 caller: __list_add    pte is none index 0x38 line 73 from_addr 0x0 page: 0xffff88207e8b5000\n\n[ 1486.775814] pte:ffff88207e8b51c0 pfn:0x8207e8c3 flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000)\n[ 1486.912060] CPU5 pid:32 caller: __list_add line: 77 from_addr: 0x0 pte.cont: 0xffff88207e8c31c0\n</code></pre></p> <p>16<sup>th</sup> run, damn, after patching <code>__unhash_process()</code>, it finally works. Going to workout, see you tonight.</p>"},{"location":"lego/log/log-03-2018/#victim-report-error","title":"victim report error","text":"<p>17<sup>th</sup> run. The phoenix program has bug itself, it is not able to run with 4GB dataset. So try it with 2GB dataset. Uuh, the log is too long. <code>__put_vicim</code> report a victim that has wrong flags. Going to disable the evict log and try again.</p> <p>18<sup>th</sup> run. Happen to run seq with 100MB\u2026 It actually half finished. But the printf of phoenix has funny chars. I guess memory is corrupted. The log shows it is ib_mad_completion. <pre><code>[ 2244.018806] Processor: Processor manager is running.\n[ 2246.394568] STDOUT: ---[\nenvp[0] HOME=/\n\n]---\n[ 2246.447719] STDOUT: ---[\nenvp[1] TERM=linux\n\n]---\n[ 2246.507003] STDOUT: ---[\nargv[0] /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-seq\n\n]---\n[ 2246.618289] STDOUT: ---[\nargv[1] /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_100MB.txt\n\n]---\n[ 2258.805633] STDOUT: ---[\nWord-Count-Seq: Computation Completed 12.46633 sec\n\n]---\n[ 2258.923180] SYSC_close(): [4] -&gt; [/proc/meminfo]\n[ 2258.995743] STDOUT: ---[\nUse len is 123748\n[ 2263.484774] STDOUT: ---[\nTHE: 1115050\n]---\n[ 2263.666785] STDOUT: ---[\nOF: 615296\n]---\n[ 2266.103660] STDOUT: ---[\nAND: 545303 (a lot funny chars, deleted.)\n]---\n[ 2267.016837] Code: [ 2267.038680] STDOUT: ---[\nTO: 475179\n+&gt;\u00d5\u00fe\u00da\u00e9\u00d8^G\u00a7&lt;87&gt;k&lt;80&gt;z^T&lt;86&gt;ruJ\u00b7\u00bf\u00bb&lt;9e&gt;\u00e9\u00de\u00ed\u00d1r\u00dc\u00d5^W\u00e5^W*^_{(\u00ca?R\u00f9a\u00e9\u00f6\u00f78\u00ed&lt;91&gt;\u00dc\u00e8&lt;8f&gt;\u00f2\u00bfi^?\u00e84&lt;94&gt;\u00d7\u00b2\u00c9\u00b5^V\u00bf\u00ab\u00ebP]\u00ed\u00efh^G\u00ca\u00eb&lt;98&gt;^T\u00d7Qp\u00b9O\u00ae\u00ef^\\\u00da^?^A\u00ed&lt;91&gt;\u00d9v\u00ddBy^_\u00e9iwP^r&lt;97&gt;\u00eb\u00f9\u00ef\u00df]\u00a3\u00df\u00ad&lt;98&gt;&lt;81&gt;\u00f8&lt;85&gt;\u00ceEy^Y\u00e5^?V\u00f9\u00ba^Y\u00de\u00f5\u00cb]r5\u00c9\u00f0^^'&lt;92&gt;\u00c9]^]P^\u00c7i\u00bbz:\u00d4^S\n\u00aee&lt;8a&gt;+\\\u00e9&lt;8a&gt;\u00ae\u00b1\u00e0E\u00d5\u00ce,\u00f0\u00d2\u00e23\u00c1_^P_^H^[|\u00b8\u00ae\u00e1s\u00edF\u00bfm&lt;95&gt;&lt;9d&gt;?&lt;82&gt;\u00f2:\u00be\u00de\u00f53\u00ca\u00d7T\u00fc\u00ae\n]---\n[ 2263.339165] BUG: unable to handle kernel paging request at ffffffffffff8100\n[ 2263.422369] IP: [&lt;ffffffffffff8100&gt;] 0xffffffffffff8100\n[ 2263.570058] PGD 1140067 PUD 1142067 PMD 0\n[ 2263.618942] Oops: 0010 [#1] SMP PROCESSOR\n[ 2264.705811] CPU: 0 PID: 27 Comm: ib_mad_completi 4.0.0-lego-ys+ #408\n[ 2264.781736] RIP: 0010:[&lt;ffffffffffff8100&gt;]  [&lt;ffffffffffff8100&gt;] 0xffffffffffff8100\n[ 2264.873262] RSP: 0000:ffff88107efabc90  EFLAGS: 00010046\n[ 2264.936705] RAX: 5636000000000098 RBX: db5affffffffffff RCX: 0000000000000001\n[ 2265.021990] RDX: ffff88107efabd38 RSI: 0000000000000000 RDI: 4460ffffffff8114\n[ 2265.107277] RBP: ffff88107efabce0 R08: 000000000000001f R09: ffff88107efa43c0\n[ 2265.192561] R10: ffff88107efabe68 R11: 0000000000000001 R12: ac02000004ecbdbd\n[ 2265.277847] R13: 0000000000000000 R14: ffff88107efa4228 R15: ffff88107e1ab000\n[ 2265.363133] FS:  0000000000000000(0000) GS:ffff88107fc00000(0000) knlGS:0000000000000000\n[ 2265.459858] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 2265.528503] CR2: ffffffffffff8100 CR3: 000000000113d000 CR4: 00000000000406b0\n[ 2265.613789] Stack:\n[ 2265.637710] ffffffff810151a7 0000000000000082 ffff88107fc04980 0000000000000000\n[ 2265.725075] ffff88107efabcc8 ffff88107fc04980 0000000000000000 0000000000000000\n[ 2265.812441] ffff88107efa4228 ffff88107e1ab000 ffff88107efabcf8 ffffffff81016e17\n[ 2265.899806] 000000007efabe20 ffff88107efabd20 ffffffff810066f4 ffffffff81072f20\n[ 2265.987172] ffff88107fc05e00 ffff88107efa4000 ffff88107efabe08 ffffffff8100e4aa\n[ 2266.074538] Call Trace:\n[ 2266.206626] &lt;TSK&gt;\n[ 2266.229507] [&lt;ffffffff810151a7&gt;] ? update_wall_time+0x47/0x6b0\n[ 2266.299192] [&lt;ffffffff81016e17&gt;] tick_handle_periodic+0x67/0x70\n[ 2266.369916] [&lt;ffffffff810066f4&gt;] apic_timer_interrupt+0x54/0x90\n[ 2266.440641] [&lt;ffffffff8100e4aa&gt;] smp__apic_timer_interrupt+0x6a/0x70\n[ 2266.516565] [&lt;ffffffff810663b8&gt;] ? __schedule+0xf8/0x1e0\n[ 2266.580010] [&lt;ffffffff810664b3&gt;] schedule+0x13/0x30\n[ 2266.638254] [&lt;ffffffff81058c97&gt;] ib_mad_completion_handler+0x2b7/0x860\n[ 2266.716258] [&lt;ffffffff810589e0&gt;] ? ib_mad_send_done_handler.isra.22+0x1d0/0x1d0\n[ 2266.803624] [&lt;ffffffff81020376&gt;] kthread+0xf6/0x110\n[ 2266.861867] [&lt;ffffffff81020280&gt;] ? __kthread_parkme+0x70/0x70\n[ 2266.930512] [&lt;ffffffff8100e732&gt;] ret_from_fork+0x22/0x30\n[ 2266.993955] &lt;EOT&gt;\n</code></pre></p> <p>19<sup>th</sup>, try seq+100MB again. Well succeed. I guess I start S too later. So that thread has issues. We run 12.3 sec, while linux run 9.7 sec.</p> <p>20<sup>th</sup>, try seq+4GB data. Linux runs <code>314.4 sec</code>. Lego runs <code>403 sec</code>. But Lego has some clflush error messages. I don\u2019t know why actually. <pre><code>[  794.604628] Processor: Processor manager is running.\n[  796.884884] STDOUT: ---[\nenvp[0] HOME=/\n\n]---\n[  796.938032] STDOUT: ---[\nenvp[1] TERM=linux\n\n]---\n[  796.997312] STDOUT: ---[\nargv[0] /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-seq\n\n]---\n[  797.108596] STDOUT: ---[\nargv[1] /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_4GB.txt\n\n]---\n[  980.640200] __clflush_one(): EFAULT:bad address\n[  980.692315] __clflush_one(): EFAULT:bad address\n[  980.746397] __clflush_one(): EFAULT:bad address\n[  980.800478] __clflush_one(): EFAULT:bad address\n[  980.854559] __clflush_one(): EFAULT:bad address\n[  980.908642] __clflush_one(): EFAULT:bad address\n[  980.962723] __clflush_one(): EFAULT:bad address\n[  981.016804] __clflush_one(): EFAULT:bad address\n[  981.070886] __clflush_one(): EFAULT:bad address\n[  981.124968] __clflush_one(): EFAULT:bad address\n[  981.179048] __clflush_one(): EFAULT:bad address\n[  981.233129] __clflush_one(): EFAULT:bad address\n[  981.287211] __clflush_one(): EFAULT:bad address\n[  981.341293] __clflush_one(): EFAULT:bad address\n[  981.395375] __clflush_one(): EFAULT:bad address\n[  981.449456] __clflush_one(): EFAULT:bad address\n[  981.503538] __clflush_one(): EFAULT:bad address\n[  981.557619] __clflush_one(): EFAULT:bad address\n[  981.611702] __clflush_one(): EFAULT:bad address\n[  981.665782] __clflush_one(): EFAULT:bad address\n[  981.719863] __clflush_one(): EFAULT:bad address\n[  981.773945] __clflush_one(): EFAULT:bad address\n[  981.828026] __clflush_one(): EFAULT:bad address\n[  981.882108] __clflush_one(): EFAULT:bad address\n[  981.936188] __clflush_one(): EFAULT:bad address\n[  981.990271] __clflush_one(): EFAULT:bad address\n[  982.044352] __clflush_one(): EFAULT:bad address\n[  982.098434] __clflush_one(): EFAULT:bad address\n[  982.152515] __clflush_one(): EFAULT:bad address\n[  982.206596] __clflush_one(): EFAULT:bad address\n[ 1200.759741] STDOUT: ---[\nWord-Count-Seq: Computation Completed 403.519401 sec\n\n]---\n...\n[ 1200.989480] STDOUT: ---[\nTHE: 44602000\n...\n[ 1201.755779] do_group_exit() pid:32,tgid:32 exit_code:0x0\n[ 1201.819136] do_exit() pid:32,tgid:32 code:0x0\n[ 1201.872451] nr_pgfault: 1049525\n[ 1201.908579] nr_pgfault_wp: 0\n[ 1201.942899] nr_pgfault_wp_cow: 0\n[ 1201.981380] nr_pgfault_wp_reuse: 0\n[ 1202.021941] nr_pgfault_due_to_concurrent_eviction: 0\n[ 1202.081223] nr_pcache_fill_from_memory: 1045393\n[ 1202.135304] nr_pcache_fill_from_victim: 4132\n[ 1202.186265] nr_pcache_eviction: 525230\n[ 1202.230987] nr_victim_eviction: 521090\n</code></pre></p> <p>21th run. Do not have time and energy to debug the clflush issue. I just want to run MT+2GB again. Well victim has issues! Some warning are triggered. Log is <code>wuklab13:~/ys/0311-22</code>. Continue tomorrow! Good night world. (Such a lonly phd.)</p>"},{"location":"lego/log/log-03-2018/#0310-sat","title":"03/10 Sat","text":"<p>Running python hello world. Tried to make kmalloc use buddy directly.</p>"},{"location":"lego/log/log-03-2018/#put_pcache-in-pcache_zap_pte","title":"put_pcache in pcache_zap_pte","text":"<p>So this time, python keep running for a long time. But P crashed when the first time eviction was triggered.</p> <p>Below is log from S side, those libraries do not exist, so these log are fine: <pre><code>S:\n[Mar10 10:39] handle_access_request /etc/ld.so.preload 4, -2\n[Mar10 10:44] local_file_open : Cannot open required file [/usr/lib64/python2.7/site.so].\n[  +0.352839] local_file_open : Cannot open required file [/usr/lib64/python2.7/sitemodule.so].\n[ +22.254465] local_file_open : Cannot open required file [/usr/lib64/python2.7/os.so].\n[  +0.350759] local_file_open : Cannot open required file [/usr/lib64/python2.7/osmodule.so].\n[Mar10 10:45] local_file_open : Cannot open required file [/usr/lib64/python2.7/posixpath.so].\n[  +0.358045] local_file_open : Cannot open required file [/usr/lib64/python2.7/posixpathmodule.so].\n[ +13.421033] local_file_open : Cannot open required file [/usr/lib64/python2.7/stat.so].\n[  +0.352838] local_file_open : Cannot open required file [/usr/lib64/python2.7/statmodule.so].\n[Mar10 10:46] local_file_open : Cannot open required file [/usr/lib64/python2.7/genericpath.so].\n[  +0.360126] local_file_open : Cannot open required file [/usr/lib64/python2.7/genericpathmodule.so].\n[ +11.582165] local_file_open : Cannot open required file [/usr/lib64/python2.7/warnings.so].\n[  +0.357003] local_file_open : Cannot open required file [/usr/lib64/python2.7/warningsmodule.so].\n[ +11.989828] local_file_open : Cannot open required file [/usr/lib64/python2.7/linecache.so].\n[  +0.358043] local_file_open : Cannot open required file [/usr/lib64/python2.7/linecachemodule.so].\n[Mar10 10:47] local_file_open : Cannot open required file [/usr/lib64/python2.7/types.so].\n[  +0.353879] local_file_open : Cannot open required file [/usr/lib64/python2.7/typesmodule.so].\n</code></pre></p> <p>Weird P\u2019s bug, seems like the pcm returned by evict_find_line has issue. Well, I\u2019m trying to debug what is going with this set. <pre><code>wuklab13 0310-2\n[ 1046.880649] SYSC_read() cpu(5) tsk(32/32/python) user-ip:0x7ffff6e117e0\n[ 1046.959692]     fd: 8, buf: 00007ffff7ffb000, count: 4096\n[ 1048.726624] pcache_evict_line(): pset: ffff88207f9ffec0, for uva: 0x7ffff7ffb000\n[ 1048.813053] ------------[ cut here ]------------\n[ 1048.868174] BUG: failure at ./include/processor/pcache.h:284/pcache_meta_to_pcache_set()!\n[ 1048.965937] Kernel Panic - not syncing: BUG!\n[ 1049.016898] CPU: 5 PID: 32 Comm: python 4.0.0-lego-ys+ #347\n[ 1049.083460] Stack:\n[ 1049.107380] ffff88107e18fca8 ffffffff81026f1c 0000000000000008 ffff88107e18fcb8\n[ 1049.194743] ffff88107e18fc70 0000000021475542 0000000000000000 0000000000000000\n[ 1049.282107] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[ 1049.369468] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[ 1049.456832] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[ 1049.544193] Call Trace:\n[ 1049.573315] &lt;TSK&gt;\n[ 1049.596195] [&lt;ffffffff81026f28&gt;] panic+0xc2/0xeb\n[ 1049.651318] [&lt;ffffffff8101c3fc&gt;] ? task_tick_rt+0x2c/0xd0\n[ 1049.715799] [&lt;ffffffff81019a65&gt;] ? scheduler_tick+0x55/0x60\n[ 1049.782360] [&lt;ffffffff81017035&gt;] ? tick_handle_periodic+0x45/0x70\n[ 1049.855163] [&lt;ffffffff81006764&gt;] ? apic_timer_interrupt+0x54/0x90\n[ 1049.927966] [&lt;ffffffff8101c3fc&gt;] ? task_tick_rt+0x2c/0xd0\n[ 1049.992447] [&lt;ffffffff81019a65&gt;] ? scheduler_tick+0x55/0x60\n[ 1050.059009] [&lt;ffffffff81017035&gt;] ? tick_handle_periodic+0x45/0x70\n[ 1050.131812] [&lt;ffffffff8103c41a&gt;] ? put_dec+0x1a/0x80\n[ 1050.191093] [&lt;ffffffff81006764&gt;] ? apic_timer_interrupt+0x54/0x90\n[ 1050.263895] [&lt;ffffffff8100e56a&gt;] ? smp__apic_timer_interrupt+0x6a/0x70\n[ 1050.341897] [&lt;ffffffff81012ded&gt;] ? printk+0x11d/0x1b0\n[ 1050.402219] [&lt;ffffffff810340c5&gt;] dump_pcache_meta+0xc5/0xd0\n[ 1050.468782] [&lt;ffffffff81034588&gt;] pcache_evict_line+0x158/0x220\n[ 1050.538463] [&lt;ffffffff81030f5e&gt;] pcache_alloc+0x22e/0x2f0\n[ 1050.602945] [&lt;ffffffff8103015a&gt;] common_do_fill_page+0x2a/0x430\n[ 1050.673668] [&lt;ffffffff8102fb20&gt;] ? pcache_meta_to_kva+0x30/0x30\n[ 1050.744389] [&lt;ffffffff81030702&gt;] pcache_handle_fault+0x1a2/0x6c0\n[ 1050.816152] [&lt;ffffffff810103d2&gt;] do_page_fault+0xa2/0x1a0\n[ 1050.880634] [&lt;ffffffff8100db9f&gt;] page_fault+0x1f/0x30\n[ 1050.940955] [&lt;ffffffff8103bb82&gt;] ? copy_user_enhanced_fast_string+0x2/0x10\n[ 1051.023118] [&lt;ffffffff81038423&gt;] ? normal_p2m_read+0x233/0x330\n[ 1051.092800] [&lt;ffffffff810363ce&gt;] sys_read+0x9e/0x160\n[ 1051.152081] [&lt;ffffffff810268d0&gt;] ? strace_enter_default+0x30/0x40\n[ 1051.224884] [&lt;ffffffff8100e935&gt;] do_syscall_64+0x45/0xd0\n[ 1051.288326] [&lt;ffffffff8100d82c&gt;] entry_SYSCALL64_slow_path+0x25/0x25\n</code></pre></p> <p>Interesting, added several debug messages. The bug is I forgot to put_pcache when a rmap was zapped. One rmap counts one refcount (effectively one process), thus when a rmap was zapped, we should decrease the refcount. I found I\u2019ve already done so for <code>pcache_remove_rmap</code>, and <code>pcache_move_pte</code>. But damn, forgot this one. I remember this code was written before fork+pcache. So.. I don\u2019t have a big picture at that time. Multithreaded system plus background reclaim really a very rigours design usage of refcount and lock. <pre><code>[ 1418.038411] CPU5 PID32 sys_read+0x0/0xa0\n[ 1418.085227] pcache_evict_line(): pset: ffff88207f9ffec0, for uva: 0x7ffff7ffb000\n[ 1418.173617] pset:ffff88207f9ffec0 set_idx: 32763 nr_lru:8\n[ 1418.238105] pcache:ffff8801801ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880107ffb000\n[ 1418.351476] pcache:ffff8801805ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880117ffb000\n[ 1418.464847] pcache:ffff8801809ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880127ffb000\n[ 1418.578220] pcache:ffff880180dffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880137ffb000\n[ 1418.691591] pcache:ffff8801811ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880147ffb000\n[ 1418.804963] pcache:ffff8801815ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880157ffb000\n[ 1418.918334] pcache:ffff8801819ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880167ffb000\n[ 1419.031706] pcache:ffff880181dffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880177ffb000\n[ 1419.145077] After dump pset\n[ 1419.176280] pcache:ffff8801801ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880107ffb000\n[ 1419.289652] pcache dumped because: evict_find_line_lru\n[ 1419.351018] pcache:ffff8801805ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880117ffb000\n[ 1419.464389] pcache dumped because: evict_find_line_lru\n[ 1419.525757] pcache:ffff8801809ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880127ffb000\n[ 1419.639127] pcache dumped because: evict_find_line_lru\n[ 1419.700494] pcache:ffff880180dffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880137ffb000\n[ 1419.813865] pcache dumped because: evict_find_line_lru\n[ 1419.875231] pcache:ffff8801811ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880147ffb000\n[ 1419.988604] pcache dumped because: evict_find_line_lru\n[ 1420.049969] pcache:ffff8801815ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880157ffb000\n[ 1420.163341] pcache dumped because: evict_find_line_lru\n[ 1420.224708] pcache:ffff8801819ffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880167ffb000\n[ 1420.338079] pcache dumped because: evict_find_line_lru\n[ 1420.399445] pcache:ffff880181dffec0 mapcount:0 refcount:1 flags:(allocated|usable) kva: ffff880177ffb000\n[ 1420.512817] pcache dumped because: evict_find_line_lru\n[ 1420.574183] evict_find_line_lru(): pcm: ffff88207f9ffea8\n[ 1420.637631] ------------[ cut here ]------------\n[ 1420.692756] BUG: failure at ./include/processor/pcache.h:340/pcache_meta_to_kva()!\n[ 1420.783245] Kernel Panic - not syncing: BUG!\n[ 1420.834210] CPU: 5 PID: 32 Comm: python 4.0.0-lego-ys+ #349\n[ 1420.900777] Stack:\n</code></pre></p>"},{"location":"lego/log/log-03-2018/#python-hello-world-run-to-end","title":"python hello world run to end","text":"<p>Glad to say, python hello world finished, even with some missed syscalls. Especially the stdin stuff, so the string is actually not printed out. Log is wuklab13:~/ys/0310-4 <pre><code>[ 3149.540308] CPU5 PID32 sys_ioctl+0x0/0x10\n[ 3149.588144] CPU5 PID32 sys_ioctl+0x0/0x10\n[ 3149.635982] CPU5 PID32 sys_write+0x0/0xa0\n[ 3149.683818] STDOUT: ---[\n&gt;&gt;&gt;\n]---\n[ 3149.726456] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff6d9aeb0 flags:0x150\n[ 3149.926247] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff6d9aeb0 flags:0x150 ret:0(OKAY)\n[ 3150.033464] CPU5 PID32 sys_newfstat+0x0/0x10\n[ 3150.084420] CPU5 PID32 sys_ioctl+0x0/0x10\n[ 3150.132256] strace__mmap cpu5 addr=0x0, len=0x1000, prot(0x3)=PROT_READ|PROT_WRITE, flags(0x22)=MAP_PRIVATE|MAP_ANONYMOUS, fd=18446744073709551615( ), off=0x0\n[ 3150.301772] CPU5 PID32 sys_read+0x0/0xa0\n[ 3150.348562] ------------[ cut here ]------------\n[ 3150.403679] WARNING: CPU: 5 PID: 32 at managers/processor/fs/stdio.c:24 stdio_file_read+0x30/0x50\n[ 3150.509751] Process wants STDIN!\n[ 3150.546149] CPU: 5 PID: 32 Comm: python 4.0.0-lego-ys+ #352\n[ 3150.612705] Stack:\n[ 3150.636624] ffff88107e18fe90 ffffffff81012b15 ffffffff811464e0 00007ffff7ffb000\n[ 3150.723977] 0000000000000400 00007ffff70e5640 ffff88107e18fef0 ffffffff81012bd2\n[ 3150.811331] ffffffff81079d6b ffff881000000018 ffff88107e18ff00 ffff88107e18fec0\n[ 3150.898687] 0000000000000020 ffffffff810346b0 0000000000000022 ffffffff811464f0\n[ 3150.986040] 00007ffff7fdf740 0000000000000000 ffff88107e18ff00 ffffffff81035ac0\n[ 3151.073394] Call Trace:\n[ 3151.102514] &lt;TSK&gt;\n[ 3151.125392] [&lt;ffffffff81012b21&gt;] __warn.constprop.0+0x91/0xd0\n[ 3151.194028] [&lt;ffffffff81012bd2&gt;] warn_slowpath_fmt+0x42/0x50\n[ 3151.261623] [&lt;ffffffff810346b0&gt;] ? sweep_pset_lru+0x220/0x220\n[ 3151.330259] [&lt;ffffffff81035ac0&gt;] stdio_file_read+0x30/0x50\n[ 3151.395775] [&lt;ffffffff810346e3&gt;] sys_read+0x33/0xa0\n[ 3151.454010] [&lt;ffffffff8100e875&gt;] do_syscall_64+0x45/0xd0\n[ 3151.517446] [&lt;ffffffff8100d76c&gt;] entry_SYSCALL64_slow_path+0x25/0x25\n[ 3151.593362] &lt;EOT&gt;\n[ 3151.616240] ---[ end trace 0000000000000000 ]---\n[ 3151.671360] CPU5 PID32 sys_write+0x0/0xa0\n[ 3151.719194] STDOUT: ---[\n\n\n]---\n[ 3151.759756] CPU5 PID32 sys_close+0x0/0x140\n[ 3151.808628] SYSC_close(): [3] -&gt; [/root/ys/py_hello.py]\n[ 3151.871028] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff7a79380 flags:0x150\n[ 3152.070817] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff7a79380 flags:0x150 ret:0(OKAY)\n[ 3152.178033] CPU5 PID32 sys_rt_sigaction+0x0/0xb0\n[ 3152.234151] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff7a77f60 flags:0x150\n[ 3152.432941] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff7a77f60 flags:0x150 ret:0(OKAY)\n[ 3152.540242] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff73ee794 flags:0x150\n[ 3152.739952] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff73ee794 flags:0x150 ret:0(OKAY)\n[ 3152.847171] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff715b278 flags:0x150\n[ 3153.046958] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff715b278 flags:0x150 ret:0(OKAY)\n[ 3153.154179] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff6de74f0 flags:0x150\n[ 3153.353965] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff6de74f0 flags:0x150 ret:0(OKAY)\n[ 3153.461180] CPU5 PID32 sys_exit_group+0x0/0x10\n</code></pre></p>"},{"location":"lego/log/log-03-2018/#trying-phoenix-pthread-again","title":"Trying phoenix pthread again","text":"<p>4GB pcache, 1GB dataset.</p> <p>1<sup>th</sup> run with CONFIG_STRACE on, 1GB dataset finished, result is correct.</p> <p>2<sup>th</sup> run without CONFIG_STRACE, 1GB dataset stuck. Two weird things:</p> <ul> <li>open/close dev/cpu/online file too many times than a normal linux run</li> <li>IB stucked So next I\u2019m going to try add a lock to ibapi, see if it is ib internal deadlock issue.</li> </ul> <pre><code>wuklab13 0310-7\n[  702.895936] Processor: Processor manager is running.\n[  722.400159] STDOUT: ---[\nenvp[0] HOME=/\n\n]---\n[  722.453307] STDOUT: ---[\nenvp[1] TERM=linux\n\n]---\n[  722.512589] STDOUT: ---[\nargv[0] /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n\n]---\n[  722.628036] STDOUT: ---[\nargv[1] /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_1GB.txt\n\n]---\n[  722.759101] STDOUT: ---[\nWordcount: Running...\n]---\n[  722.819406] STDOUT: ---[\n\n\n]---\n[  722.860139] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  722.940653] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.011483] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.084287] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.157090] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.229894] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.302698] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.375502] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.448306] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.521111] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.593914] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.666718] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.739522] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.812326] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  723.885130] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  766.701260] ibapi_send_reply() polling timeout (30010 ms), caller: net_send_reply_timeout+0x11b/0x1ee\n[  766.809538]  net_send_reply_timeout() caller: __pcache_do_fill_page+0x82/0x140\n[  766.895863] word_count-pthr[65]: segfault at 0x7fffb5eba000 ip 000000000040249d sp 00007fffb5e9ad80 error 6\n[  767.012348] CPU: 15 PID: 65 Comm: word_count-pthr 4.0.0-lego-ys+ #359\n[  767.089312] RIP: 0033:[&lt;000000000040249d&gt;]  [&lt;000000000040249d&gt;] 0x40249d\n[  767.170436] RSP: 002b:00007fffb5e9ad80  EFLAGS: 00010216\n[  767.233879] RAX: 00007fffb5eba000 RBX: 0000000000001388 RCX: 000000000000004f\n[  767.319164] RDX: 00007fffe4ea92a4 RSI: 00007fffe626fac9 RDI: 00007fffe4ea92a4\n[  767.404449] RBP: 00000000007540e0 R08: 0000000000000000 R09: 0000000000014fa0\n[  767.489733] R10: 0000000000427fb0 R11: 0000000000000202 R12: 0000000000012b12\n[  767.575018] R13: 00007fff496ab890 R14: 00007fff48704fb0 R15: 0000000000001388\n[  767.660303] FS:  00007fffb5e9b700(0000) GS:ffff88207fce0000(0000) knlGS:0000000000000000\n[  767.757028] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[  767.825671] CR2: 00007fffb5eba000 CR3: 000000207fe3a000 CR4: 00000000000406a0\n[  767.910958] get_signal(): dequeue_signr: 11, handler:          (null)\n[  767.987928] get_signal(): dequeue_signr: 9, handler:          (null)\n</code></pre> <p>3<sup>th</sup> run, without STRACE, with locked ibapi, it finished, result is correct. Runtime: <code>18.692936 sec</code>. <pre><code>[  555.423623] nr_pgfault: 288100\n[  555.458042] nr_pgfault_wp: 0\n[  555.492360] nr_pgfault_wp_cow: 0\n[  555.530838] nr_pgfault_wp_reuse: 0\n[  555.571396] nr_pgfault_due_to_concurrent_eviction: 0\n[  555.630673] nr_pcache_fill_from_memory: 288081\n[  555.683710] nr_pcache_fill_from_victim: 12\n[  555.732588] nr_pcache_eviction: 494\n[  555.774187] nr_victim_eviction: 474\n</code></pre></p> <p>4<sup>th</sup> run, same setting with the 3<sup>th</sup> run, same result. But the nr_pgfault differs, I guess it is due to runtime things. Runtime: <code>19.12861 sec</code>. <pre><code>[  469.891700] nr_pgfault: 288119\n[  469.926123] nr_pgfault_wp: 0\n[  469.960444] nr_pgfault_wp_cow: 0\n[  469.998924] nr_pgfault_wp_reuse: 0\n[  470.039484] nr_pgfault_due_to_concurrent_eviction: 0\n[  470.098764] nr_pcache_fill_from_memory: 288093\n[  470.151805] nr_pcache_fill_from_victim: 12\n[  470.200684] nr_pcache_eviction: 513\n[  470.242285] nr_victim_eviction: 493\n</code></pre></p> <p>5<sup>th</sup> run, same with 4<sup>th</sup>, succeed, Runtime: <code>18.653879 sec</code>. <pre><code>[  313.202348] nr_pgfault: 288070\n[  313.236772] nr_pgfault_wp: 0\n[  313.271093] nr_pgfault_wp_cow: 0\n[  313.309575] nr_pgfault_wp_reuse: 0\n[  313.350139] nr_pgfault_due_to_concurrent_eviction: 0\n[  313.409421] nr_pcache_fill_from_memory: 288052\n[  313.462465] nr_pcache_fill_from_victim: 6\n[  313.510307] nr_pcache_eviction: 446\n[  313.551909] nr_victim_eviction: 432\n</code></pre></p> <p>6<sup>th</sup>, setting is the same, but with 4GB dataset, crashed: <pre><code>[  512.028141] Processor: Processor manager is running.\n[  529.375605] STDOUT: ---[\nWordcount: Running...\n]---\n[  529.435906] STDOUT: ---[\n\n\n]---\n[  529.476660] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[  529.555983] ------------[ cut here ]------------\n[  529.609128] BUG: failure at managers/processor/pcache/rmap.c:735/pcache_zap_pte()!\n[  529.699613] Kernel Panic - not syncing: BUG!\n[  529.750576] CPU: 5 PID: 32 Comm: word_count-pthr 4.0.0-lego-ys+ #361\n[  529.826500] Stack:\n[  529.850422] ffff88107e1a3dd8 ffffffff810259b4 0000000000000008 ffff88107e1a3de8\n[  529.937787] ffff88107e1a3da0 0000000021475542 0000000000000000 0000000000000000\n[  530.025152] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[  530.112517] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[  530.199882] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[  530.287247] Call Trace:\n[  530.316370] &lt;TSK&gt;\n[  530.339251] [&lt;ffffffff810259c0&gt;] panic+0xc2/0xeb\n[  530.394374] [&lt;ffffffff8106190a&gt;] ? client_internal_poll_sendcq+0x2a/0x80\n[  530.474458] [&lt;ffffffff8101bfcc&gt;] ? task_tick_rt+0x2c/0xd0\n[  530.538943] [&lt;ffffffff81019725&gt;] ? scheduler_tick+0x55/0x60\n[  530.605506] [&lt;ffffffff81016df5&gt;] ? tick_handle_periodic+0x45/0x70\n[  530.678311] [&lt;ffffffff8103768a&gt;] ? put_dec+0x1a/0x80\n[  530.737595] [&lt;ffffffff810066f4&gt;] ? apic_timer_interrupt+0x54/0x90\n[  530.810398] [&lt;ffffffff8100e4aa&gt;] ? smp__apic_timer_interrupt+0x6a/0x70\n[  530.888403] [&lt;ffffffff81012ccd&gt;] ? printk+0x11d/0x1b0\n[  530.948726] [&lt;ffffffff81030429&gt;] pcache_zap_pte+0xf9/0x160\n[  531.014250] [&lt;ffffffff8102f090&gt;] ? __pcache_move_pte_fastpath+0x50/0x50\n[  531.093295] [&lt;ffffffff8102c8dc&gt;] unmap_page_range+0x32c/0x3b0\n[  531.161940] [&lt;ffffffff8102c97e&gt;] release_pgtable+0x1e/0x40\n[  531.227463] [&lt;ffffffff8102bfb3&gt;] sys_munmap+0xc3/0x120\n[  531.288827] [&lt;ffffffff8100e86d&gt;] do_syscall_64+0x3d/0xc0\n[  531.352270] [&lt;ffffffff8100d76c&gt;] entry_SYSCALL64_slow_path+0x25/0x25\n</code></pre></p> <p>7<sup>th</sup> run, add debug info, does not seem that useful: <pre><code>]---\n[15755.579501] SYSC_close(): [4] -&gt; [/sys/devices/system/cpu/online]\n[15755.672760] pte:ffff88107e1a3dd8 pfn:0x8207e80b flags:(dirty|large|global|softw4|pkey0|pkey1|pkey2|pkey3|nx|0x3ff800000000000)\n[15755.807015] pte dumped because: Invalid pte\n[15755.856932] address: 0x7ffefc638000\n[15755.899569] ------------[ cut here ]------------\n[15755.954684] BUG: failure at managers/processor/pcache/rmap.c:747/pcache_zap_pte()!\n[15756.045159] Kernel Panic - not syncing: BUG!\n[15756.096114] CPU: 5 PID: 32 Comm: word_count-pt\n</code></pre></p> <p>Tried several times, even with mmap/munmap debug option on, it crashed at the same point. Key is address <code>0x7ffefc638000</code>, and the mmap() related to it.</p> <p>Close to find the bug. Latest log in 0310-18.</p>"},{"location":"lego/log/log-03-2018/#0309-fri","title":"03/09 Fri","text":""},{"location":"lego/log/log-03-2018/#find-bug-in-kmalloc","title":"Find bug in kmalloc","text":"<p>Tried to print pud in every syscall and catch the criminal: <pre><code>wuklab13 0309-1\n[  320.088684] CPU5 PID32 sys_close+0x0/0x1f0\n[  320.137567] do_syscall_64(): enter pgd ffff88207fccf000, pgd.cont_va ffff88207fc6f000, pud_index=0x0 pud: ffff88207fc6f000\n[  320.269657] SYSC_close() cpu(5) tsk(32/32/python) user-ip:0x7ffff7df3c37\n[  320.349742]     3\n[  320.372624] SYSC_close(): [3] -&gt; [/lib64/libpython2.7.so.1.0]\n[  320.441268] SYSC_close() cpu(5) tsk(32/32/python) ret: 0x0 (0)\n[  320.510954] do_syscall_64(): leave pgd ffff88207fccf000, pgd.cont_va ffff88207fc6f000, pud_index=0x0 pud: ffff88207fc6f000\n\n[  320.643043]     addr: 0x7ffff7a101f0, pgd: ffff88207fccf7f8\n[  320.709607]     addr: 0x7ffff7a101f0, pgd: ffff88207fccf7f8 pud ffff88207fcaeff8\n[  320.798014] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff7a101f0 flags:0x50\n[  320.995755] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff7a101f0 flags:0x50 ret:0(OKAY)\n\n[  321.101944]     addr: 0x7ffff7a21749, pgd: ffff88207fccf7f8\n[  321.168509]     addr: 0x7ffff7a21749, pgd: ffff88207fccf7f8 pud ffff88207fcaeff8\n[  321.256914] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff7a21749 flags:0x50\n[  321.454651] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff7a21749 flags:0x50 ret:0(OKAY)\n\n[  321.560845]     addr: 0x7ffff7ff2fda, pgd: ffff88207fccf7f8\n[  321.627409]     addr: 0x7ffff7ff2fda, pgd: ffff88207fccf7f8 pud ffff88207fcaeff8\n[  321.715815] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff7ff2fda flags:0x50\n[  321.913553] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff7ff2fda flags:0x50 ret:0(OKAY)\n\n[  322.019745] CPU5 PID32 sys_open+0x0/0x10\n[  322.066548] do_syscall_64(): enter pgd ffff88207fccf000, pgd.cont_va ffff9001801ff000, pud_index=0x0 pud: ffff9001801ff000\n[  322.198638] SYSC_open() cpu(5) tsk(32/32/python) user-ip:0x7ffff7df3b27\n[  322.277683]     f_name: /lib64/libpthread.so.0, flags: 80000, mode: e150\n[  322.357780] SYSC_open() cpu(5) tsk(32/32/python) ret: 0x3 (3)\n[  322.426414] do_syscall_64(): leave pgd ffff88207fccf000, pgd.cont_va ffff9001801ff000, pud_index=0x0 pud: ffff9001801ff000\n</code></pre></p> <p>After printing more in pcache_handle_fault, I found who corrupted pgtable: <pre><code>wuklab13 0309-5\n[  661.308584] CPU5 PID32 sys_close+0x0/0x1f0\n[  661.357466] do_syscall_64(): enter pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[  661.489557] SYSC_close() cpu(5) tsk(32/32/python) user-ip:0x7ffff7df3c37\n[  661.569642]     3    \n[  661.592525] SYSC_close(): [3] -&gt; [/lib64/libpython2.7.so.1.0]\n[  661.661170] SYSC_close() cpu(5) tsk(32/32/python) ret: 0x0 (0)\n[  661.730854] do_syscall_64(): leave pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[  661.862944] pcache_handle_fault(): enter pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[  662.001275]     addr: 0x7ffff7a101f0, pgd: ffff88207fccf7f8\n[  662.067840]     addr: 0x7ffff7a101f0, pgd: ffff88207fccf7f8 pud ffff88207fcafff8\n[  662.156247] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff7a101f0 flags:0x50\n[  662.353985] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff7a101f0 flags:0x50 ret:0(OKAY)\n[  662.460176] pcache_handle_fault(): leave pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n\n[  662.600586] pcache_handle_fault(): enter pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[  662.738916]     addr: 0x7ffff7a21749, pgd: ffff88207fccf7f8\n[  662.805481]     addr: 0x7ffff7a21749, pgd: ffff88207fccf7f8 pud ffff88207fcafff8\n[  662.893888] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff7a21749 flags:0x50\n[  663.091636] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff7a21749 flags:0x50 ret:0(OKAY)\n[  663.197831] pcache_handle_fault(): leave pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n\n[  663.338242] pcache_handle_fault(): enter pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[  663.476572]     addr: 0x7ffff7ff2fda, pgd: ffff88207fccf7f8\n[  663.543135]     addr: 0x7ffff7ff2fda, pgd: ffff88207fccf7f8 pud ffff88207fcafff8\n[  663.631543] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff7ff2fda flags:0x50\n[  663.829279] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff7ff2fda flags:0x50 ret:0(OKAY)\n[  663.935472] pcache_handle_fault(): leave pgd ffff88207fccf000, pgd.cont_va ffff9001801ff000, pud_index=0x0 pud: ffff9001801ff000\n\n[  664.075884] CPU5 PID32 sys_open+0x0/0x10\n[  664.122686] do_syscall_64(): enter pgd ffff88207fccf000, pgd.cont_va ffff9001801ff000, pud_index=0x0 pud: ffff9001801ff000\n[  664.254776] SYSC_open() cpu(5) tsk(32/32/python) user-ip:0x7ffff7df3b27\n[  664.333821]     f_name: /lib64/libpthread.so.0, flags: 80000, mode: e150\n[  664.413918] SYSC_open() cpu(5) tsk(32/32/python) ret: 0x3 (3)\n[  664.482552] do_syscall_64(): leave pgd ffff88207fccf000, pgd.cont_va ffff9001801ff000, pud_index=0x0 pud: ffff9001801ff000\n</code></pre></p> <p>Then, try catching bug with address <code>0x7ffff7ff2fda</code> fault. Printing still being the most effective way to debug. :-)</p> <p>Dig further, I found pgtable corrupted after <code>pcache_add_rmap()</code>, namely after <code>alloc_pcache_rmap()</code>: <pre><code>[ 5024.482570] pcache_add_rmap() 343 pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[ 5024.613601] alloc_pcache_rmap(): size: 56, rmap: ffff88207fccefd0\n[ 5024.686396] pcache_add_rmap() 358 pgd ffff88207fccf000, pgd.cont_va ffff90207fcce000, pud_index=0x0 pud: ffff90207fcce000\n</code></pre></p> <p>Well, <code>rmap: ffff88207fccefd0</code> &amp; <code>ffff90207fcce000</code>, clearly <pre><code>[  843.916517] pcache_add_rmap() 372 pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[  844.047557] alloc_pcache_rmap() 60 pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[  844.179638] alloc_pcache_rmap(): size: 56, rmap: ffff88207fccefd0\n[  844.252438] alloc_pcache_rmap() 71 pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[  844.384517] alloc_pcache_rmap(): size: 56, rmap: ffff88207fccefd0\n[  844.457317] alloc_pcache_rmap() 85 pgd ffff88207fccf000, pgd.cont_va ffff90207fcce000, pud_index=0x0 pud: ffff90207fcce000\n[  844.589398] pcache_add_rmap() 387 pgd ffff88207fccf000, pgd.cont_va ffff90207fcce000, pud_index=0x0 pud: ffff90207fcce000\n\n46 static struct pcache_rmap *alloc_pcache_rmap(void)\n47 {\n48         struct pcache_rmap *rmap;\n49\n50         pgd_t *pgd;\n51         pud_t *pud;\n52         unsigned long addr;\n53         struct mm_struct *mm = current-&gt;mm;\n54\n55         if (pall) {\n56                 addr = 0x601008;\n57                 pgd = pgd_offset(mm, addr);\n58                 pud = pud_alloc(mm, pgd, addr);\n59                 pr_info(\"%s() %d pgd %p, pgd.cont_va %lx, pud_index=%#lx pud: %p\\n\",\n60                         __func__, __LINE__, pgd, pgd_page_vaddr(*pgd), pud_index(addr), (void *)pud);\n61         }\n62\n63         rmap = kmalloc(sizeof(*rmap), GFP_KERNEL);\n64\n65         if (pall) {\n66                 addr = 0x601008;\n67                 pgd = pgd_offset(mm, addr);\n68                 pud = pud_alloc(mm, pgd, addr);\n69                 pr_info(\"%s(): size: %zu, rmap: %p\\n\", __func__, sizeof(*rmap), rmap);\n70                 pr_info(\"%s() %d pgd %p, pgd.cont_va %lx, pud_index=%#lx pud: %p\\n\",\n71                         __func__, __LINE__, pgd, pgd_page_vaddr(*pgd), pud_index(addr), (void *)pud);\n72         }\n73\n74         if (rmap) {\n75                 INIT_LIST_HEAD(&amp;rmap-&gt;next);\n76                 rmap-&gt;flags = 0;\n77         }\n78\n79         if (pall) {\n80                 addr = 0x601008;\n81                 pgd = pgd_offset(mm, addr);\n82                 pud = pud_alloc(mm, pgd, addr);\n83                 pr_info(\"%s(): size: %zu, rmap: %p\\n\", __func__, sizeof(*rmap), rmap);\n84                 pr_info(\"%s() %d pgd %p, pgd.cont_va %lx, pud_index=%#lx pud: %p\\n\",\n85                         __func__, __LINE__, pgd, pgd_page_vaddr(*pgd), pud_index(addr), (void *)pud);\n86         }\n87\n88         return rmap;\n89 }\n</code></pre></p> <p>Narrow it down to <code>INIT_LIST_HEAD</code>: <pre><code>[ 1334.548682] alloc_pcache_rmap(): size: 56, rmap: ffff88207fccefd0\n[ 1334.621487] alloc_pcache_rmap() 71 pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[ 1334.753576] alloc_pcache_rmap() 76 &amp;rmap-&gt;next ffff88207fcceff8 &amp;flags ffff88207fccefd8\n[ 1334.922067] alloc_pcache_rmap() 86 pgd ffff88207fccf000, pgd.cont_va ffff90207fcce000, pud_index=0x0 pud: ffff90207fcce000\n[ 1335.126962] alloc_pcache_rmap() 98 pgd ffff88207fccf000, pgd.cont_va ffff90207fcce000, pud_index=0x0 pud: ffff90207fcce000\n\n74         if (rmap) {\n75         pr_info(\"%s() %d &amp;rmap-&gt;next %p &amp;flags %p\\n\",\n76                 __func__, __LINE__, &amp;rmap-&gt;next, &amp;rmap-&gt;flags);\n77\n78                 INIT_LIST_HEAD(&amp;rmap-&gt;next);\n79\n80         if (pall) {\n81                 addr = 0x601008;\n82                 pgd = pgd_offset(mm, addr);\n83                 pud = pud_alloc(mm, pgd, addr);\n84                 pr_info(\"%s(): size: %zu, rmap: %p\\n\", __func__, sizeof(*rmap), rmap);\n85                 pr_info(\"%s() %d pgd %p, pgd.cont_va %lx, pud_index=%#lx pud: %p\\n\",\n86                         __func__, __LINE__, pgd, pgd_page_vaddr(*pgd), pud_index(addr), (void *)pud);\n87         }\n88\n89                 rmap-&gt;flags = 0;\n90         }\n</code></pre></p> <p>Seriously, if this is running on user-level on VM, I would be able to find the bug maybe in 30min. But I spent several hours to find it out with physical machine. Damn you physical machine.</p> <p>Hmm, this func is used A LOT. How can it fail at this point? Possible reasons:</p> <ul> <li>kmalloced area happen to intersect with pgtable?</li> <li>one physical page is mapped twice? one to pgtable, one by this rmap.</li> <li>tty/serial code has bug? Really ancient code.</li> </ul> <p>After add a few printk, IB seems stuck. And this happens just with few more lines of code! Why? code size matters? <pre><code>[  722.381469] pcache_handle_fault(): enter pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[  722.519778]     addr: 0x7ffff7feffcc, pgd: ffff88207fccf7f8\n[  722.586334]     addr: 0x7ffff7feffcc, pgd: ffff88207fccf7f8 pud ffff88207fcafff8\n[  722.674727] Before fill address=0x7ffff7feffcc set_idx:0x7fef\n[  722.743362] pcache:ffff8801801ffbc0 mapcount:0 refcount:1 flags:(allocated|usable) set_idx=0x7fef kva: ffff880107fef000\n[  722.872312] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff7feffcc flags:0x50\n[  722.967985] __pcache_do_fill_page(): before net pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\nlast line\n</code></pre></p> <p>Well, the following finding finally find the bug line. And it kind of explains the above bug. Probably kmalloc\u2019ed area has issues, so IB is touching wrong data. The following bug is related to kmalloc, the rmap is 56 bytes, and it should be within 1 single page, but it is not: <pre><code>[ 1862.307427] pcache_add_rmap() 413 pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[ 1862.438477] alloc_pcache_rmap() 86 pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[ 1862.570568] sp-&gt;units: 50 SLOB_UNITS: 32\n[ 1862.617372] alloc_pcache_rmap(): size: 56, rmap: ffff88207fccefd0\n[ 1862.690178] alloc_pcache_rmap() 97 pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[ 1862.822268] alloc_pcache_rmap() 104 &amp;rmap-&gt;next ffff88207fcceff8 &amp;flags ffff88207fccefd8\n[ 1862.918995] __INIT_LIST_HEAD(): next ffff88207fcceff8 prev ffff88207fccf000\n[ 1863.002202] __INIT_LIST_HEAD() 63 pgd ffff88207fccf000, pgd.cont_va ffff88207fcae000, pud_index=0x0 pud: ffff88207fcae000\n[ 1863.133253] __INIT_LIST_HEAD(): next ffff88207fcceff8 prev ffff88207fccf000\n[ 1863.216459] alloc_pcache_rmap(): size: 56, rmap: ffff88207fccefd0\n[ 1863.289265] alloc_pcache_rmap() 114 pgd ffff88207fccf000, pgd.cont_va ffff90207fcce000, pud_index=0x0 pud: ffff90207fcce000\n</code></pre></p> <p>Analysis: The @prev field in line 7 has address <code>ffff88207fccf000</code>, which happen to the pgd page (<code>pgd ffff88207fccf000</code>). Thus when we do <code>list-&gt;prev = list</code>, it writes to the first 8 bytes of pgd page, corrupts the original pgd entry. That is why we see a corrupted pgd entry (<code>ffff90207fcce000</code>).</p> <p>This roots from kmalloc, which should not allocate such an object that cross two pages.</p>"},{"location":"lego/log/log-03-2018/#0308-thur","title":"03/08 Thur","text":"<p>Took several days off. This morning finished the porting of <code>wait4</code> and <code>waitid</code>, which actually has a lot code change. The concept and mechanism is fairly simple, but the legacy UNIX tradition make the implementation quite complex.</p> <p>Now, look back to finish debugging the pcache issue. It must be fixed this week.</p>"},{"location":"lego/log/log-03-2018/#python","title":"python","text":"<p>Tried <code>python hello_world.py</code>, the program runs for a while and crashes at a deterministic point: <pre><code>wuklab13 and wuklab15, ~/ttyS1\n[419097.929969] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff7a4b008 flags:0x50 ret:0(OKAY)\n[419098.039145] __pcache_do_fill_page(): I pid:32 tgid:32 address:0x7ffff7a4c010 flags:0x50\n[419098.306537] __pcache_do_fill_page(): O pid:32 tgid:32 address:0x7ffff7a4c010 flags:0x50 ret:0(OKAY)\n[419098.413756] CPU5 PID32 sys_mprotect+0x0/0x90\n[419098.465753] SYSC_mprotect() cpu(5) tsk(32/32/python) user-ip:0x7ffff7df3d27\n[419098.549990]     start:0x7ffff7d8c000,len:0x2000,prot:0x1\n[419098.614469] BUG: unable to handle kernel paging request at ffff9001801ff000\n[419098.698703] IP: [&lt;ffffffff8102f7a9&gt;] pcache_handle_fault+0x69/0x6c0\n[419098.774621] PGD 0\n[419098.799579] Oops: 0000 [#1] SMP PROCESSOR\n[419098.848457] CPU: 5 PID: 32 Comm: python 4.0.0-lego-ys+ #312\n[419098.916054] RIP: 0010:[&lt;ffffffff8102f7a9&gt;]  [&lt;ffffffff8102f7a9&gt;] pcache_handle_fault+0x69/0x6c0\n[419099.021089] RSP: 0000:ffff88107e857ed8  EFLAGS: 00010286\n[419099.085567] RAX: ffff9001801ff000 RBX: ffff9001801ff000 RCX: 00003ffffffff000\n[419099.171884] RDX: 00000801801ff000 RSI: 0000000000601008 RDI: ffff88107e83d648\n[419099.258199] RBP: ffff88107e857f18 R08: 00007ffff7fe3000 R09: 00007ffff7fe3000\n[419099.344516] R10: 0000000000000000 R11: 0000000000000206 R12: 0000000000601008\n[419099.430832] R13: ffff88107e83d648 R14: 0000000000000050 R15: 00007ffff7ffe150\n[419099.517149] FS:  00007ffff7fdf740(0000) GS:ffff88207fc40000(0000) knlGS:0000000000000000\n[419099.614905] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[419099.684582] CR2: ffff9001801ff000 CR3: 000000207fccf000 CR4: 00000000000406a0\n[419099.770899] Stack:\n[419099.795858] 00007ffff7d8c000 0000000000002000 0000000000000001 0000000000000004\n[419099.884254] 0000000000601008 ffff88107e857f58 0000000000000000 00007ffff7ffe150\n[419099.972650] ffff88107e857f48 ffffffff81010082 0000000000000000 0000000000000001\n[419100.061047] 000392c29c720ba2 0000000000000000 00007fffffffdc40 ffffffff8100d91f\n[419100.149442] 00007ffff7ffe150 0000000000000000 000392c29c720ba2 0000000000000001\n[419100.237839] Call Trace:\n[419100.267998] &lt;TSK&gt;\n[419100.291917] [&lt;ffffffff81010082&gt;] do_page_fault+0xa2/0x1a0\n[419100.357434] [&lt;ffffffff8100d91f&gt;] page_fault+0x1f/0x30\n[419100.418792] &lt;EOT&gt;\n\n\nM:\n...\n[419142.163396] handle_p2m_pcache_miss() cpu 4 I nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7a4c010\n[419142.268460] handle_p2m_pcache_miss() cpu 4 O nid:0 pid:32 tgid:32 flags:50 vaddr:0x7ffff7a4c010\n(Last Message)\n</code></pre></p> <p>Dig deeper: <pre><code>int pcache_handle_fault(struct mm_struct *mm,\n                        unsigned long address, unsigned long flags)\n{\n        ..\n        pgd = pgd_offset(mm, address);\n        pr_info(\"    addr: %#lx, pgd: %p\\n\", address, pgd);\n        pud = pud_alloc(mm, pgd, address);\n        pr_info(\"    addr: %#lx, pgd: %p pud %p\\n\", address, pgd, pud);\n        if (!pud)\n                return VM_FAULT_OOM;\n        pmd = pmd_alloc(mm, pud, address);\n        if (!pmd)\n..\n}\n\n[21130.503314] strace__mprotect cpu5 start=0x7ffff7d8c000, len=0x2000, prot(0x1)=PROT_READ\n[21130.598994] SYSC_mprotect() cpu(5) tsk(32/32/python) user-ip:0x7ffff7df3d27\n[21130.682193]     start:0x7ffff7d8c000,len:0x2000,prot:0x1\n[21130.745635]     addr: 0x601008, pgd: ffff88207fccf000\n[21130.805954]     addr: 0x601008, pgd: ffff88207fccf000 pud ffff9001801ff000\n[21130.888116] BUG: unable to handle kernel paging request at ffff9001801ff000\n[21130.971314] IP: [&lt;ffffffff8102fa11&gt;] pcache_handle_fault+0x91/0x6f0\n</code></pre></p> <p>Print pgd and pud info, these three messages are related and the last one leads to panic: <pre><code>wuklab13 ~/ys/0308-6\n[  479.375498] addr: 0x400040, pgd: ffff88207fccf000\n[  479.435819] pud_alloc_one(): addr: 0x400040, pud: ffff88207fc6f000\n[  479.511739] pud_alloc(): addr: 0x400040 pgd ffff88207fccf000, pgd.cont_va ffff88207fc6f000, pud_index=0x0 pud: ffff88207fc6f000\n[  479.649021] addr: 0x400040, pgd: ffff88207fccf000 pud ffff88207fc6f000\n\n[  480.016381] addr: 0x600dd8, pgd: ffff88207fccf000\n[  480.076701] pud_alloc(): addr: 0x600dd8 pgd ffff88207fccf000, pgd.cont_va ffff88207fc6f000, pud_index=0x0 pud: ffff88207fc6f000\n[  480.213982] addr: 0x600dd8, pgd: ffff88207fccf000 pud ffff88207fc6f000\n\n[  680.072819] addr: 0x601008, pgd: ffff88207fccf000\n[  680.133138] pud_alloc(): addr: 0x601008 pgd ffff88207fccf000, pgd.cont_va ffff90107e834000, pud_index=0x0 pud: ffff90107e834000\n[  680.270422] addr: 0x601008, pgd: ffff88207fccf000 pud ffff90107e834000\n\n[  680.352583] BUG: unable to handle kernel paging request at ffff90107e834000\n[  680.435783] IP: [&lt;ffffffff8102fc43&gt;] pcache_handle_fault+0xb3/0x770\n[  680.510664] PGD 0\n</code></pre></p> <p>I need to check what happens between 480s to 680s. Something in between corrupted pgtable. I doubt it can be:</p> <ul> <li>copy_to_user related syscalls</li> <li>pcache establish mapping, mempcy</li> <li>all other memcpy strcpy etc stuff</li> </ul>"},{"location":"lego/log/log-03-2018/#0302-fri","title":"03/02 Fri","text":"<p>TODO:</p> <ul> <li>-add vsyscall-</li> <li>-pcache_exit_process: free rmap, free cacheline, etc. When rmap is NULL, we clearly should free this pcache.-</li> <li>pcache_exit_thread? I don\u2019t think we need this. All pcache related activities should relate to mm, or thread group leader, not one particular thread.</li> <li>check python bug</li> <li>use omnigraffle to draw the whole workflow of pcache.</li> </ul> <p>Phoenix, word_count-seq, 4G dataset, 4GB pcache: <pre><code>[  273.268853] Processor: Processor manager is running.\n[  573.272479] page:ffffea0071bb9660 count:0 mapcount:-128\n[  573.332903] flags: 0x200000000000300(slab|slob_free)\n[  573.392182] page dumped because: VM_BUG_ON_PAGE(page_ref_count(page) == 0)\n[  573.474340] ------------[ cut here ]------------\n[  573.529459] BUG: failure at ./include/lego/mm.h:251/put_page_testzero()!\n[  573.609537] Kernel Panic - not syncing: BUG!\n[  573.660496] CPU: 4 PID: 13 Comm: kvictim_flushd 4.0.0-lego+ #18\n[  573.731212] Stack:\n[  573.755132] ffff88207e4bfe10 ffffffff81023644 0000000000000008 ffff88207e4bfe20\n[  573.842490] ffff88207e4bfdd8 0000000021475542 0000000000000000 0000000000000000\n[  573.929848] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[  574.017205] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[  574.104563] 0000000000000000 0000000000000000 0000000000000000 0000000000000000\n[  574.191921] Call Trace:\n[  574.221039] &lt;TSK&gt;\n[  574.243919] [&lt;ffffffff81023650&gt;] panic+0xc2/0xeb\n[  574.299038] [&lt;ffffffff8105a35a&gt;] ? client_internal_poll_sendcq+0x2a/0x80\n[  574.379115] [&lt;ffffffff8105a4fd&gt;] ? client_send_message_with_rdma_write_with_imm_request+0x14d/0x360\n[  574.487273] [&lt;ffffffff8101ac3c&gt;] ? task_tick_rt+0x2c/0xd0\n[  574.551751] [&lt;ffffffff81018395&gt;] ? scheduler_tick+0x55/0x60\n[  574.618308] [&lt;ffffffff81015a45&gt;] ? tick_handle_periodic+0x45/0x70\n[  574.691107] [&lt;ffffffff810064c4&gt;] ? apic_timer_interrupt+0x54/0x90\n[  574.763905] [&lt;ffffffff8100dbaa&gt;] ? smp__apic_timer_interrupt+0x6a/0x70\n[  574.841903] [&lt;ffffffff8101198d&gt;] ? printk+0x11d/0x1b0\n[  574.902222] [&lt;ffffffff81025c00&gt;] __free_pages+0x2e0/0x3c0\n[  574.966699] [&lt;ffffffff81028472&gt;] kfree+0x62/0x480\n[  575.022858] [&lt;ffffffff8102e6be&gt;] victim_flush_func+0x15e/0x1e0\n[  575.092536] [&lt;ffffffff8102e560&gt;] ? victim_try_fill_pcache+0x390/0x390\n[  575.169494] [&lt;ffffffff8101e446&gt;] kthread+0xf6/0x120\n[  575.227733] [&lt;ffffffff8101e350&gt;] ? __kthread_parkme+0x70/0x70\n[  575.296371] [&lt;ffffffff8100de32&gt;] ret_from_fork+0x22/0x30\n[  575.359810] &lt;EOT&gt;\n</code></pre></p>"},{"location":"lego/log/log-03-2018/#0301-thur","title":"03/01 Thur","text":"<p>Weird. <pre><code>[43181.388400] p2m_fork(cpu5): I cur:24-word_count-seq new:25\n[43181.435341] p2m_fork(cpu5): O succeed cur:24-word_count-seq new:25\n[43181.436013] __pcache_do_fill_page(): I pid:24 tgid:24 address:0x4158d0 flags:0x150\n[43181.439246] __pcache_do_fill_page(): O pid:24 tgid:24 address:0x4158d0 flags:0x150 ret:0(OKAY) csum:0x9e8f028e\n\n[43181.510534] __pcache_do_fill_page(): I pid:25 tgid:25 address:0x415000 flags:0x150\n[43181.517729] __pcache_do_fill_page(): O pid:25 tgid:25 address:0x415000 flags:0x150 ret:0(OKAY) csum:0xffff88029e8f028e\n</code></pre></p> <p>After all, it is TLB issue. I forgot to flush tlb after making the original pte read-only during fork. So the parent will be also to continue RW some pages, which should be process-private.</p> <p>Lego\u2019s current TLB flush is very native, we do tlbflush after each pte changes. This will have worse performance compared to linux\u2019s batch flush.</p> <p>Today\u2019s case is flush tlb after making pte read-only. And this really has to be performed one by one</p>"},{"location":"lego/log/log-04-2018/","title":"April 2018","text":""},{"location":"lego/log/log-04-2018/#0504-fri","title":"05/04 Fri","text":"<p>We made it. We\u2019ve done our part, now, it depends on reviewers. Please, be mercy, our hardworking deserves something good.</p>"},{"location":"lego/log/log-04-2018/#0429-sun","title":"04/29 Sun","text":"<p>Rolling.</p>"},{"location":"lego/log/log-04-2018/#0426-thus","title":"04/26 Thus","text":"<p>Fix the victim pte_same issue in SMP race cases. SMP is really pain in the ass, how many times? But\u2026 another victim ref count bug show up in SMP. First log in 0426-w15-\u00bd</p> <pre><code>0426-w15-1/3\n\n[  206.381646] CPU12 PID28  victim:ffff88207ff69120 index:4 refcount:0 nr_fill:0 locked:0 flags:(0x2e)(allocated|usable|hasdata|waitflush) pcm:          (null) pset:ffff88207ff72000\n[  206.416658] CPU12 PID28     hit[0] owner:21 m_nid:1 rep_nid:1 addr: 0x7fffd0000000\n[  206.433431] CPU12 PID28  victim:ffff88207ff69120 index:4 refcount:0 nr_fill:0 locked:0 flags:(0x4e)(allocated|usable|hasdata|flushed) pcm:          (null) pset:ffff88207ff72000\n[  206.468429] CPU12 PID28     rmap to pset:ffff88207ff72000 set_idx: 0 nr_lru:63\n[  206.484425] CPU12 PID28     victim dumped because: PCACHE_BUG_ON_VICTIM(!VictimAllocated(v) || !VictimUsable(v) || !VictimFlushed(v) || VictimWriteback(v) || VictimLocked(v))\n[  206.543952] CPU: 12 PID: 28 Comm: python 4.0.0-lego+ #274\n[  206.521849] WARNING: CPU: 12 PID: 28 at managers/processor/pcache/victim.c:196 __put_victim_nolist+0xa5/0xd0\n[  206.722631] [&lt;ffffffff8103b555&gt;] __put_victim_nolist+0xa5/0xd0\n[  206.729127] [&lt;ffffffff8103c419&gt;] victim_try_fill_pcache+0x2d9/0x460\n[  206.736107] [&lt;ffffffff8103b740&gt;] ? victim_insert_hit_entry+0x170/0x170\n[  206.743378] [&lt;ffffffff810371ea&gt;] pcache_handle_fault+0x18a/0x750\n\n[  206.399206] CPU8 PID19  victim:ffff88207ff69120 index:4 refcount:0 nr_fill:0 locked:0 flags:(0x4e)(allocated|usable|hasdata|flushed) pcm:          (null) pset:ffff88207ff72000\n[  206.425092] CPU8 PID19     hit[0] owner:21 m_nid:1 rep_nid:1 addr: 0x7fffd0000000\n[  206.450977] CPU8 PID19  victim:ffff88207ff69120 index:4 refcount:0 nr_fill:0 locked:0 flags:(0x4e)(allocated|usable|hasdata|flushed) pcm:          (null) pset:ffff88207ff72000\n[  206.476475] CPU8 PID19     rmap to pset:ffff88207ff72000 set_idx: 0 nr_lru:63\n[  206.501779] CPU8 PID19     victim dumped because: PCACHE_BUG_ON_VICTIM(victim_ref_count(v) == 0)\n[  206.549963] CPU: 8 PID: 19 Comm: kvictim_flushd 4.0.0-lego+ #274\n[  206.532803] WARNING: CPU: 8 PID: 19 at ./include/processor/pcache_victim.h:119 __victim_flush_func+0x1e4/0x1f0\n</code></pre>"},{"location":"lego/log/log-04-2018/#0425","title":"04/25","text":"<p>Stay humble. Be real.</p>"},{"location":"lego/log/log-04-2018/#0422-sun","title":"04/22 Sun","text":"<p>Testing. Hardworking!</p>"},{"location":"lego/log/log-04-2018/#0421-sat","title":"04/21 Sat","text":"<p>Another major bug report in 0421-w15-19. Rmapped corrupted. lock issue?</p> <p>Fixed. It is handle_m2m_fork bug. <pre><code>pcache_miss_error+0x20\n</code></pre></p> <p>Keep it going.</p> <p>I can not remember how many times I have seen this bug issue. And I have no idea. <pre><code>[  714.144354] IP: [&lt;ffffffffffff8100&gt;] 0xffffffffffff8100\n[  714.150171] PGD 115c067 PUD 115e067 PMD 0\n[  714.154729] Oops: 0010 [#1] SMP PROCESSOR\n[  714.159189] CPU: 0 PID: 15 Comm: ib_mad_completi 4.0.0-lego+ #245\n[  714.165976] BUG: unable to handle kernel paging request at ffffffffffff8100\n[  714.173732] IP: [&lt;ffffffffffff8100&gt;] 0xffffffffffff8100\n[  714.179549] PGD 115c067 PUD 115e067 PMD 0\n[  714.184106] RIP: 0010:[&lt;ffffffffffff8100&gt;]  [&lt;ffffffffffff8100&gt;] 0xffffffffffff8100\n[  714.192638] RSP: 0000:ffff88103e88fc80  EFLAGS: 00010046\n[  714.198552] RAX: 6e82000000000098 RBX: 7b0bffffffffffff RCX: 0000000000000001\n[  714.206503] RDX: ffff88103e88fd28 RSI: 0000000000000000 RDI: 44c0ffffffff8116\n[  714.214453] RBP: ffff88103e88fcd0 R08: 000000000000001f R09: ffff88103e8643c0\n[  714.222403] R10: ffff88103e88fe68 R11: 0000000000000001 R12: a9670000018d71ba\n[  714.230354] R13: 0000000000000000 R14: ffff88103e85d0f8 R15: ffff88103dd58000\n[  714.238304] Oops: 0010 [#2] SMP PROCESSOR\n[  714.242763] FS:  0000000000000000(0000) GS:ffff88107fc00000(0000) knlGS:0000000000000000\n[  714.251781] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[  714.258180] CR2: ffffffffffff8100 CR3: 0000000001159000 CR4: 00000000000406b0\n[  714.266130] CPU: 10 PID: 20 Comm: python 4.0.0-lego+ #245\n[  714.272141] RIP: 0010:[&lt;ffffffffffff8100&gt;]  [&lt;ffffffffffff8100&gt;] 0xffffffffffff8100\n[  714.280673] RSP: 0018:ffff88103dd8fe10  EFLAGS: 00010202\n[  714.286588] RAX: ffff88101fa54270 RBX: 00000000000c92a6 RCX: 0000000000000002\n[  714.294538] RDX: 00000000ffffffff RSI: 0000000000000000 RDI: 44c0ffffffff8116\n[  714.302488] RBP: ffff88103dd8fe20 R08: ffff88101fa6f000 R09: ffff88101fa54400\n[  714.310439] R10: ffff880000000000 R11: 00000000407e9c00 R12: ffff88101fa54000\n[  714.318389] R13: ffff88103dd68000 R14: ffff88101fa60000 R15: ffff88101fa54000\n[  714.326339] Stack:\n[  714.328569] FS:  00007ffff7fdf740(0000) GS:ffff88107fca0000(0000) knlGS:0000000000000000\n[  714.337585] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[  714.343984] CR2: ffffffffffff8100 CR3: 000000103dd9a000 CR4: 00000000000406a0\n[  714.351936] Stack:\n[  714.354165] ffffffff810157f9 00000000003d0f00 ffff88103dd8fec0 ffffffff8101dde5\n[  714.362309] ffff88103dd8fe68 ffffffff81036788 0000000000000038 0000000000000038\n[  714.370453] 00007fffd89a79c0 ffff88101fa541c0 ffff88101fa54188 0000000000000000\n[  714.378598] 000000101fa60000 00007fffd89a79d0 00007fffd89a7700 0000000000000000\n[  714.386742] 00007fffd89a6fb0 ffff88103dd8ff58 0000000000000038 00000000003d0f00\n[  714.394886] Call Trace:\n[  714.397600] ffffffff81014f37 0000000000000086 ffff88107fc05d80 ffff88103e864000\n[  714.405745] 0000000000000000 ffff88107fc04980 0000000000000000 0000000000000000\n[  714.413889] ffff88103e85d0f8 ffff88103dd58000 ffff88103e88fce8 ffffffff81016bb7\n[  714.422034] 000000007fc05d80 ffff88103e88fd10 ffffffff81006754 ffffffffffff0000\n[  714.430177] ffff88107fc05d80 ffff88103e864000 ffff88103e88fe00 ffffffff8100e4ea\n[  714.438321] Call Trace:\n[  714.441037] &lt;TSK&gt;\n[  714.443169] [&lt;ffffffff810157f9&gt;] ? ktime_get+0x19/0x60\n[  714.448890] [&lt;ffffffff8101dde5&gt;] copy_process+0x2c5/0x1170\n[  714.454998] [&lt;ffffffff81036788&gt;] ? strace_printflags+0x88/0xc0\n[  714.461495] &lt;TSK&gt;\n[  714.463627] [&lt;ffffffff81014f37&gt;] ? update_wall_time+0x47/0x6b0\n[  714.470123] [&lt;ffffffff81016bb7&gt;] tick_handle_periodic+0x67/0x70\n[  714.476716] [&lt;ffffffff81006754&gt;] apic_timer_interrupt+0x55/0x90\n[  714.483309] [&lt;ffffffff8101ecb6&gt;] do_fork+0x26/0x160\n[  714.488738] [&lt;ffffffff8101eea9&gt;] sys_clone+0x29/0x30\n[  714.494265] [&lt;ffffffff8100e8ad&gt;] do_syscall_64+0x3d/0xd0\n[  714.500180] [&lt;ffffffff8100d7ac&gt;] entry_SYSCALL64_slow_path+0x25/0x25\n[  714.507257] [&lt;ffffffff8100e4ea&gt;] smp__apic_timer_interrupt+0x6a/0x70\n[  714.514335] &lt;EOT&gt;\n</code></pre></p>"},{"location":"lego/log/log-04-2018/#0420-fri","title":"04/20 Fri","text":"<p>Glad TF finally working now!</p> <p>Keep seeing this message from kernel. It have been many many times. Very deterministic. <pre><code>BUG: unable to handle kernel paging request at ffffffffffff8100\n</code></pre></p>"},{"location":"lego/log/log-04-2018/#0419-thur","title":"04/19 Thur","text":"<ul> <li>Patched clflush to use tgid, n_nid directly without task_struct.</li> <li> </li> </ul>"},{"location":"lego/log/log-04-2018/#in-a-256m-excache-today-0419-w15-4-a-timeout-happen-first-which-will-be-handled-as-segfault-to-kill-all-threads-in-an-eviction-victim_prepare_hits-the-get_memory_nodes-encounter-the-null-again-looks-like-the-thread_group-mm-got-cleared-before","title":"In a 256M excache today (0419-w15-4), a timeout happen first, which will be handled as segfault to kill all threads. In an eviction-&gt;victim_prepare_hits, the get_memory_nodes() encounter the NULL again. Looks like the thread_group-&gt;mm got cleared before.","text":""},{"location":"lego/log/log-04-2018/#0418-wed","title":"04/18 Wed","text":"<ul> <li>Try best to fix the pipe bug. (I found it by using my old way of debugging. By writing a function that test if PTE is corrupted or not. I put that function around the sycall enter/exit. So it help to find which syscall corrupt memory. I have used this stupid technique to find so many hard-to-find memory corruption bugs.....)<ul> <li>do_close_on_exec</li> <li>dup2</li> </ul> </li> <li> <p>Re-read Yutong\u2019s patch again. It touches a lot handler code. This has to be verified before using any nowait reply.</p> </li> <li> <p>pipe\u2019s wakeup may have issue?</p> </li> <li> <p>0418-w15-41. 39sec</p> </li> </ul>"},{"location":"lego/log/log-04-2018/#0417-tue","title":"04/17 Tue","text":"<p>Checking list:</p> <ol> <li>-pcache: ibapi use va or pa, does it matter?-<ul> <li>No, I change it to use the VA. Then we don\u2019t have the need to use PA reply any more.</li> </ul> </li> <li>=ib_mad, does it really corrupt Memory=<ul> <li>Still not sure. Should be something come from the <code>ib_poll_cq</code>.</li> </ul> </li> <li>M side per PTE lock, check if the lock is really the same lock!</li> <li>-Mail I20. Check CPT.-</li> <li>Dist-VMA<ul> <li>First make sure, TF+no-dist-vma work on my own setting. Though sometimes random bug happen (I doubt it is IB).</li> <li>Then turn on dist-vma<ul> <li>w/wo zerofill</li> <li>w/wo kfree</li> <li>w/wo all-zero Debug.</li> <li>w/wo M side per PTE lock</li> </ul> </li> </ul> </li> <li>Change most handlers to use TX buffer. Reduce the random mismatched reply case.</li> <li>P side watchdog patch: what to print</li> <li> <p>-It looks like it is more easier to have bug when I turn on those debug counter printing. I probably should check those buffer mgmt. All next test have zerofill:-</p> <ul> <li>w  print<ul> <li>F 0417-w15-2(rmap_walk list_for_each_entrry #GP)</li> <li>F 0417-w15-3(pcache_copy_page_range corrupted PTE)</li> <li>F 0417-w15-4(fit_poll_cq+0x39 ib_poll_cq() \u2026)</li> <li>F 0417-w15-5(pcache_copy_page_range corrupted PTE)</li> </ul> </li> <li>wo strace exit:<ul> <li>S 0417-w15-6(each 100 step take ~39s/ Linux is ~34s)</li> <li>S 0417-w15-7(filling shuffle data, that works)</li> <li>F 0417-w15-8(pcache_copy_page_range+0x5d1)</li> <li>F 0417-w15-9(rmap_walk+0x47 #GP)</li> </ul> </li> <li>disable strace:<ul> <li>F 0417-w15-10(pcache_copy_page_range+0x5d1)</li> </ul> </li> <li>Conclusion<ul> <li>it has nothing to do with the strace thing.</li> <li>most of them fail around <code>nr_reqs=19103</code></li> </ul> </li> </ul> </li> <li> <p>Why the pcache_copy_page_range always happen, after some fork, execve.</p> <ul> <li>w strace (fork, vfork, clone, execve)<ul> <li>F 0417-w15-11 (pcache_cp_pg_range). Understand its flow. Back to make sure P side per PTE lock is correct. If it is pcache_cp fault, it always fail at <code>nr_reqs=19103</code>. And it is: 1) python fork, 2) execve sh.</li> <li>S 0417-w15-12. With global PTE lock. Passed the failed stage above.</li> <li>F 0417-W15-13. With global PTE lock. Failed at pcache_cp. Same place. (Since global PTE lock also fail, so it is not the lock issue. Still someone write to wrong memory.)</li> <li>F 0417-w15-14. With global PTE lock. Same place. Found that I printed a misleading debug info. Modified a little bit to print the actual pte content. Hope can get some valid info next round.</li> <li>F 0417-w15-15. Same place. <code>copy: addr: 0x7fffdca07000, ptecont: 0x8800000000000</code>. <code>zap: ptent: 0x340 address: 0x7fffdca08000</code>.</li> <li>F 0417-w15-16. Well. BUG in ib_mad_send handler. I add the same checking in ib_mad_receive. This is really just used to catch it. Not fixing it.</li> <li>F 0417-w15-17. Again, <code>addr: 0x7fffdc207000, ptecont: 0x8800000000000</code></li> <li>F 0417-w15-18. <code>addr: 0x7fffdca07000, ptecont: 0x8800000000000</code></li> </ul> </li> <li>Conclusion<ul> <li>Only these two addresses</li> <li>addr: 0x7fffdca07000, ptecont: 0x8800000000000</li> <li>pte:ffff88103ea87038 (0x8800000000000) pfn:0x0 flags:(0x8800000000000)</li> <li>addr: 0x7fffdc207000, ptecont: 0x8800000000000</li> <li>pte:ffff88103ea97038 (0x8800000000000) pfn:0x0 flags:(0x8800000000000)</li> </ul> </li> </ul> </li> <li> <p>Bug found. In pipe_read/write. It somehow corrupted memory. Damn.</p> </li> <li> <p>-Another first thing, check this weird log.. : Hmm, this log should be fine. mad_post is after recv_done_handler. So even if we detect corrupted memory in handler, it has nothing to do with mad_post. The root cause should come from ib_poll_cq, that is where we pass wc to, and where the wc.wr_id was filled in.- <pre><code>[ 3850.911144] ib_mad_recv_done_handler(): c1: 2060 c2: 12 wc-&gt;wr_id: 0xffff88103eea1398\n[ 3850.921881] ib_mad_post_receive_mads(): c1: 2060 c2: 13 recv_wr.wr_id: 0xffff88103eea1008 recv_queue: ffff88103ee42520\n[ 3850.933620] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 13\n[ 3850.942346] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 14\n[ 3850.951266] ib_mad_recv_done_handler(): c1: 2061 c2: 13 wc-&gt;wr_id: 0xffff88103eea1560\n[ 3850.961999] ib_mad_post_receive_mads(): c1: 2061 c2: 14 recv_wr.wr_id: 0xffff88103eea11d0 recv_queue: ffff88103ee42520\n[ 3850.973737] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 14\n[ 3851.257563] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 15\n[ 3851.266295] ib_mad_recv_done_handler(): c1: 2062 c2: 14 wc-&gt;wr_id: 0xffff88103eea1728\n[ 3851.277029] ib_mad_post_receive_mads(): c1: 2062 c2: 15 recv_wr.wr_id: 0xffff88103eea1398 recv_queue: ffff88103ee42520\n[ 3851.288767] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 15\n[ 3851.297493] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 16\n[ 3851.306413] ib_mad_recv_done_handler(): c1: 2063 c2: 15 wc-&gt;wr_id: 0xffff88103eea18f0\n[ 3851.317147] ib_mad_post_receive_mads(): c1: 2063 c2: 16 recv_wr.wr_id: 0xffff88103eea1560 recv_queue: ffff88103ee42520\n[ 3851.328886] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 16\n[ 3851.903180] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 17\n[ 3851.911913] ib_mad_recv_done_handler(): c1: 2064 c2: 16 wc-&gt;wr_id: 0xffff88103eea1ab8\n[ 3851.922646] ib_mad_post_receive_mads(): c1: 2064 c2: 17 recv_wr.wr_id: 0xffff88103eea1728 recv_queue: ffff88103ee42520\n[ 3851.934384] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 17\n[ 3851.943110] ib_mad_completion_handler 2383 got successful recv cq op 128 mad_got_one 18\n[ 3851.952030] ib_mad_recv_done_handler(): c1: 2065 c2: 17 wc-&gt;wr_id: 0xffff88103eea1c80\n[ 3851.962764] ib_mad_post_receive_mads(): c1: 2065 c2: 18 recv_wr.wr_id: 0xffff88103eea18f0 recv_queue: ffff88103ee42520\n[ 3851.974502] ib_mad_completion_handler 2377 got successful send cq op 0 mad_got_one 18\n[ 3864.723128] ***  FIT layer ready to go!\n[ 3864.727206] ***\n[ 3867.339488] Processor LLC Configurations:\n[ 3867.343760]     PhysStart:         0x100000000\n[ 3867.348705]     VirtStart:         0xffff880100000000\n[ 3867.354329]     Registered Size:   0x400000000\n[ 3867.359274]     Actual Used Size:  0x208000000\n[ 3867.364219]     NR cachelines:     2097152\n[ 3867.368776]     Associativity:     8\n[ 3867.372751]     NR Sets:           262144\n[ 3867.377210]     Cacheline size:    4096 B\n[ 3867.381672]     Metadata size:     64 B\n[ 3867.385937]     NR cacheline bits: 12 [ 0 - 11] 0x0000000000000fff\n[ 3867.392821]     NR set-index bits: 18 [12 - 29] 0x000000003ffff000\n[ 3867.399705]     NR tag bits:       34 [30 - 63] 0xffffffffc0000000\n[ 3867.406588]     NR pages for data: 2097152\n[ 3867.411147]     NR pages for meta: 32768\n[ 3867.415509]     Cacheline (pa) range:   [       0x100000000 -        0x2ffffffff]\n[ 3867.423848]     Metadata (pa) range:    [       0x300000000 -        0x307ffffff]\n[ 3867.432186]     Cacheline (va) range:   [0xffff880100000000 - 0xffff8802ffffffff]\n[ 3867.440524]     Metadata (va) range:    [  ffff880300000000 - 0xffff880307ffffff]\n[ 3867.448862]     pcache_set_map(064B):   [  ffff88207ec00000 - 0xffff88207fbfffff]\n[ 3867.457201]     Way cache stride:  0x40000000\n[ 3867.462048]     Memmap $ semantic:       memblock reserved\n[ 3867.468156]     NR victim $ entries:     8\n[ 3867.472725] newpid: 1 home:1 replica: 1\n[ 3867.476980] p2m_fork(cpu0): I cur:1-kernel_init new:20\n[ 3867.482718] p2m_fork(cpu0): O succeed cur:1-kernel_init new:20\n[ 3867.489197] Processor: Processor manager is running.\n[ 3867.494724] Online CPU: 0,2,4,6,8,10,12,14,16,18,20,22\n[ 3867.500444] Active CPU: 0,2,6,10,12,14,16,18,20,22\n[ 3867.505777]   [0] Thread[kvictim_flushd:19] pinned at CPU 8\n[ 3867.511982]   [1] Thread[recvpollcq:17] pinned at CPU 4\n[ 3867.539217] do_close_on_exec(): TODO, not implemented.\n[ 3867.549209] STDOUT: ---[\nBefore execv^V\n]---\n[ 3867.553870] STDOUT: ---[\n\ne\n---\n[ 3867.557880] newpid: 20 home:1 replica: 1\n[ 3867.562248] p2m_fork(cpu10): I cur:20-exe.o new:21\n[ 3867.567560] p2m_fork(cpu10): O succeed cur:20-exe.o new:21\n[ 3867.573670] CPU12 PID21 sys_execve\n[ 3867.578681] do_close_on_exec(): TODO, not implemented.\n[ 3867.584215] CPU12 PID21 sys_execve = 0, 0x0\n[ 3867.599867] BUG: unable to handle kernel paging request at 0000000408446080\n[ 3867.607436] IP: [&lt;ffffffff8101bbbf&gt;] task_tick_rt+0x1f/0xd0\n</code></pre></p> </li> </ol>"},{"location":"lego/log/log-04-2018/#0416-mon","title":"04/16 Mon","text":"<p>Make dist-vma work with TF first. Tough work.</p> <p><code>0416-w14-7</code>: 1) do_wp_page triggered, 2) dealock on per pte lock. This really should not happen. It is single worker. Basically means the page-&gt;lock is not intialized. Probabaly our per PTE lock implementation is wrong. <pre><code>[ 5220.250552] hb: worker[0] CPU 4 stucked\n[ 5220.254819] hb:  common_header [op=0x20000000 src_nid:0]\n[ 5220.260734] hb:  msg [pid=21,tgid=21,flags=0x51,vaddr=0x7fff7b7fdfb8]\n[ 5220.267911] CPU: 4 PID: 31 Comm: thpool-worker0 4.0.0-lego-ys+ #237\n[ 5220.274890] RIP: 0010:[&lt;ffffffff81031aa3&gt;]  [&lt;ffffffff81031aa3&gt;] handle_lego_mm_fault+0x373/0x4f0\n\nhandle_lego_mm_fault+0x373/0x4ee:                                                                                                                                                                                   \narch_spin_lock at arch/x86/include/asm/spinlock.h:21                                                                                                                                                                \n (inlined by) spin_lock at include/lego/spinlock.h:72                                                                                                                                                               \n (inlined by) do_anonymous_page at managers/memory/vm/fault.c:115                                                                                                                                                   \n (inlined by) handle_pte_fault at managers/memory/vm/fault.c:142                                                                                                                                                    \n (inlined by) handle_lego_mm_fault at managers/memory/vm/fault.c:225\n</code></pre></p> <p>A IB bug during normal run (P M S TF), this is REALLY weird: <pre><code>[  395.259560] CPU12 PID21 sys_execve\n[  395.263345] BUG: unable to handle kernel NULL pointer dereference at 00000000000001a0\n[  395.272068] IP: [&lt;ffffffff81064c09&gt;] fit_poll_cq+0x39/0x530\n\nfit_poll_cq+0x39/0x523:git:(test_vma)] $ ./scripts/faddr2line vmImage  fit_poll_cq+0x39\nib_poll_cq at include/rdma/ib_verbs.h:1614\n (inlined by) fit_poll_cq at net/lego/fit_internal.c:1671\n</code></pre></p> <p>Catch the ib_mad bug once.. and mlx4_error follows. I added more checking to where the mad_queue was assigned. <pre><code>[  787.471385] ib_mad_completion_handler 2365 got successful recv cq op 128 mad_got_one 15\n[  787.480124] BUG! mad_list: ffff88103eea1728 mad_queue:           (null)\n[  787.487491] ------------[ cut here ]------------\n[  787.492630] WARNING: CPU: 0 PID: 15 at drivers/infiniband/core/mad.c:1909 ib_mad_completion_handler+0xa56/0xab0\n</code></pre></p>"},{"location":"lego/log/log-04-2018/#0415-sun","title":"04/15 Sun","text":"<p>Trying TF myself.</p> <p>Had a bug report on 0415-w15-5, on fork, execve etc. <pre><code>[  317.436811] newpid: 22 home:1 replica: 1\n[  317.477701] pte:ffff88103e94a038 pfn:0x0 flags:()\n[  317.482752] pte dumped because: corrupted\n[  317.487213] ------------[ cut here ]------------\n[  317.492352] WARNING: CPU: 14 PID: 22 at managers/processor/pgtable.c:365 pcache_copy_page_range+0x5d1/0x6c0\n[  317.503213] CPU: 14 PID: 22 Comm: python 4.0.0-lego+ #93\n[  317.552082] Call Trace:\n[  317.554799] &lt;TSK&gt;\n[  317.556930] [&lt;ffffffff810123a1&gt;] __warn.constprop.0+0x91/0xd0\n[  317.563330] [&lt;ffffffff8101246f&gt;] warn_slowpath_null+0xf/0x20\n[  317.569634] [&lt;ffffffff8102d401&gt;] pcache_copy_page_range+0x5d1/0x6c0\n[  317.576615] [&lt;ffffffff81037ed7&gt;] fork_dup_pcache+0x27/0x30\n[  317.582723] [&lt;ffffffff8101e514&gt;] copy_process+0xcf4/0x1140\n[  317.588833] [&lt;ffffffff8101e986&gt;] do_fork+0x26/0x160\n[  317.594264] [&lt;ffffffff8101eb89&gt;] sys_clone+0x29/0x30\n[  317.599789] [&lt;ffffffff8100e66d&gt;] do_syscall_64+0x3d/0xd0\n[  317.605705] [&lt;ffffffff8100d56c&gt;] entry_SYSCALL64_slow_path+0x25/0x25\n[  317.612782] &lt;EOT&gt;\n[  317.614917] ---[ end trace 0000000000000000 ]---\n[  317.625561] p2m_fork(cpu14): I cur:22-python new:36\n[  330.209312] p2m_fork(cpu14): O succeed cur:22-python new:36\n\n\n[  330.310909] ------------[ cut here ]------------\n[  330.315864] BUG: failure at managers/processor/pcache/rmap.c:804/pcache_zap_pte()!\n[  330.324302] Kernel Panic - not syncing: BUG!\n[  330.329050] CPU: 0 PID: 36 Comm: python 4.0.0-lego+ #93\n[  330.377824] Call Trace:\n[  330.380540] &lt;TSK&gt;\n[  330.382672] [&lt;ffffffff81026493&gt;] panic+0xc2/0x105\n[  330.387908] [&lt;ffffffff8101bbcc&gt;] ? task_tick_rt+0x2c/0xd0\n[  330.393920] [&lt;ffffffff81019245&gt;] ? scheduler_tick+0x55/0x60\n[  330.400126] [&lt;ffffffff810168f5&gt;] ? tick_handle_periodic+0x45/0x70\n[  330.406913] [&lt;ffffffff81006684&gt;] ? apic_timer_interrupt+0x54/0x90\n[  330.413700] [&lt;ffffffff8100e2aa&gt;] ? smp__apic_timer_interrupt+0x6a/0x70\n[  330.420973] [&lt;ffffffff810125ad&gt;] ? printk+0x11d/0x1b0\n[  330.426597] [&lt;ffffffff810375bc&gt;] pcache_zap_pte+0x14c/0x190\n[  330.432802] [&lt;ffffffff81035db0&gt;] ? __pcache_remove_rmap_one+0x70/0x70\n[  330.439978] [&lt;ffffffff8102cd25&gt;] unmap_page_range+0x325/0x3f0\n[  330.446379] [&lt;ffffffff8102ce0e&gt;] release_pgtable+0x1e/0x40\n[  330.452487] [&lt;ffffffff81037ef8&gt;] pcache_process_exit+0x18/0x20\n[  330.458984] [&lt;ffffffff8101d3c4&gt;] mmput+0x34/0xb0\n[  330.464123] [&lt;ffffffff8102c38d&gt;] do_execve+0x42d/0x760\n[  330.469845] [&lt;ffffffff8102c6c9&gt;] sys_execve+0x9/0x10\n[  330.475371] [&lt;ffffffff8100e66d&gt;] do_syscall_64+0x3d/0xd0\n[  330.481286] [&lt;ffffffff8100d56c&gt;] entry_SYSCALL64_slow_path+0x25/0x25\n[  330.488364] &lt;EOT&gt;\n[  330.490501] ---[ end Kernel panic - not syncing: BUG!\n</code></pre> one more <pre><code>[  369.223161] newpid: 22 home:1 replica: 1\n[  369.264307] pte:ffff88103ea41038 (0x0) pfn:0x0 flags:()\n[  369.269938] pte dumped because: corrupted\n[  369.274399] ------------[ cut here ]------------\n[  369.279538] WARNING: CPU: 14 PID: 22 at managers/processor/pgtable.c:365 pcache_copy_page_range+0x5d1/0x6c0\n[  369.290398] CPU: 14 PID: 22 Comm: python 4.0.0-lego+ #94\n[  369.296310] Stack:\n[  369.341976] &lt;TSK&gt;\n[  369.344107] [&lt;ffffffff810123a1&gt;] __warn.constprop.0+0x91/0xd0\n[  369.350508] [&lt;ffffffff8101246f&gt;] warn_slowpath_null+0xf/0x20\n[  369.356809] [&lt;ffffffff8102d401&gt;] pcache_copy_page_range+0x5d1/0x6c0\n[  369.363790] [&lt;ffffffff81037f07&gt;] fork_dup_pcache+0x27/0x30\n[  369.369897] [&lt;ffffffff8101e514&gt;] copy_process+0xcf4/0x1140\n[  369.376006] [&lt;ffffffff8101e986&gt;] do_fork+0x26/0x160\n[  369.381435] [&lt;ffffffff8101eb89&gt;] sys_clone+0x29/0x30\n[  369.386960] [&lt;ffffffff8100e66d&gt;] do_syscall_64+0x3d/0xd0\n[  369.392875] [&lt;ffffffff8100d56c&gt;] entry_SYSCALL64_slow_path+0x25/0x25\n[  369.399952] &lt;EOT&gt;\n[  369.402086] ---[ end trace 0000000000000000 ]---\n\n[  369.412750] p2m_fork(cpu14): I cur:22-python new:36\n[  369.418215] p2m_fork(cpu14): O succeed cur:22-python new:36\n[  369.500829] ptent: 0x340 address: 0x7fffe2408000\n[  369.505783] pte:ffff88103dbe5040 (0x340) pfn:0x0 flags:(dirty|global|softw1)\n[  369.513637] pte dumped because: corrupted\n[  369.518095] ------------[ cut here ]------------\n[  369.523236] BUG: failure at managers/processor/pcache/rmap.c:808/pcache_zap_pte()!\n[  369.531672] Kernel Panic - not syncing: BUG!\n</code></pre></p>"},{"location":"lego/log/log-04-2018/#0414-sat","title":"04/14 Sat","text":"<ol> <li>Check if page table pages, page themselves are freed in munmap, at both P and M. Need to confirm. Will they do harm</li> <li>Implement replication</li> <li>Add IB counter</li> </ol>"},{"location":"lego/log/log-04-2018/#0413-fri","title":"04/13 Fri","text":"<p>Patched M side pgtable to use per PTE/PMD lock. So thpool in M will not be bottlnecked by the page_table_lock.</p>"},{"location":"lego/log/log-04-2018/#ib_mad_recv_done_handler-may-corrupt-memory-again","title":"ib_mad_recv_done_handler may corrupt memory, again.","text":"<p>Somehow, during testing of this patch. Running with MT-Phoenix 1GB, the P side has reported bad pgd entries. I\u2019m using fork+execve way. The child(phoenix) already exit. This msg is printed when parent exit_mm. The pgd table should either be 0, or valid pud va. Memory corruption happened\u2026 <pre><code>[ 2551.687806] Kernel strace\n[ 2551.690715] Task: 21:21 nr_accumulated_threads: 1\n[ 2551.696327] % time        seconds  usecs/call     calls    errors syscall\n[ 2551.703704] ------ -------------- ----------- --------- --------- ----------------\n[ 2551.712141]  98.63   66.942660568    66942661         1         0 sys_wait4\n[ 2551.719898]   0.45    0.457060789      457061         1         0 sys_clone\n[ 2551.727654]   0.20    0.204320071       51081         4         0 sys_brk\n[ 2551.735216]   0.40    0.040378189       40379         1         0 sys_mmap\n[ 2551.742876]   0.13    0.013682424        4561         3         0 sys_write\n[ 2551.750633]   0.10    0.000001039           2         1         0 sys_newfstat\n[ 2551.758681]   0.88    0.000000888           1         2         0 sys_rt_sigaction\n[ 2551.767114]   0.79    0.000000792           1         2         0 sys_futex\n[ 2551.774871]   0.77    0.000000770           1         1         0 sys_rt_sigprocmask\n[ 2551.783501]   0.54    0.000000548           1         1         0 sys_arch_prctl\n[ 2551.791742]   0.49    0.000000499           1         1         0 sys_newuname\n[ 2551.799789]   0.46    0.000000469           1         1         0 sys_getrlimit\n[ 2551.807933]   0.19    0.000000195           1         1         0 sys_set_tid_address\n[ 2551.816659]   0.19    0.000000190           1         1         0 sys_set_robust_list\n[ 2551.825386]   0.18    0.000000181           1         1         0 sys_ioctl\n[ 2551.833143] ------ -------------- ----------- --------- --------- ----------------\n[ 2551.841577] 100.00   67.658107612                    22         0 total\n[ 2551.848945]\n[ 2551.850591]\n[ 2551.852240] Kernel Profile Points\n[ 2551.855924]  status                  name             total                nr            avg.ns\n[ 2551.865621] -------  --------------------  ----------------  ----------------  ----------------\n[ 2551.875317]     off      flush_tlb_others       0.000204992                58              3535\n[ 2551.885014]     off     __do_kmalloc_node       0.300783843            281501              1069\n[ 2551.894709]     off     __pcache_zerofill       0.009844770             16558               595\n[ 2551.904404]     off           pcache_miss      54.414457906            257869            211016\n[ 2551.914100]     off          pcache_flush       0.000000000                 0                 0\n[ 2551.923795] -------  --------------------  ----------------  ----------------  ----------------\n[ 2551.933490]\n[ 2552.074985] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956028(ffffffff81146ca0)\n[ 2552.084206] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956030(ffff88103e956030)\n[ 2552.093611] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956038(ffff88103e956030)\n[ 2552.103016] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956048(ffff88103cc48740)\n[ 2552.112421] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956050(00000000000001c0)\n[ 2552.121825] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956058(ffff88103eea2008)\n[ 2552.131230] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956060(ffff88103eea17d8)\n[ 2552.140635] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956068(ffff88103ee42520)\n[ 2552.150040] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e9560e8(000000103e9560f0)\n[ 2552.159444] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956118(0102008081018101)\n[ 2552.168849] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956120(3c010b0012000000)\n[ 2552.178254] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956128(0000000000001100)\n[ 2552.187659] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956138(00000000ffffffff)\n[ 2552.197064] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956158(03078a2402010101)\n[ 2552.206467] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956160(03078a2453946600)\n[ 2552.215872] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956168(03078a2450946600)\n[ 2552.225277] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956170(0310800051946600)\n[ 2552.234682] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956178(c902000100000000)\n[ 2552.244088] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956198(bfd0cc054a122000)\n[ 2552.253492] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e9561a0(000000000098b9c8)\n[ 2552.262897] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e9561a8(bfe0fe0610914e01)\n[ 2552.272302] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e9561b0(000000000050f2c7)\n[ 2552.281706] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e9561b8(bfd9a30000ec5100)\n[ 2552.291111] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e9561c0(bffc91d40f20f2c7)\n[ 2552.300516] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e9561c8(0f20cd054a20f2c7)\n[ 2552.309920] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e9561d0(1094edcf0f60edcf)\n[ 2552.319325] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e9561d8(0000000000000100)\n[ 2552.328730] ./arch/x86/include/asm/pgtable.h:579: bad pgd ffff88103e956218(0000000000005aa5)\n[ 2552.338151] nr_pgfault: 26\n</code></pre></p> <p>Second run, saw this invalid pointer deference again! Combined with the above log, I think ib_mad is definitely corrupting memory! I have to take a look. <pre><code>qp_info = mad_list-&gt;mad_queue-&gt;qp_info;\n</code></pre></p>"},{"location":"lego/log/log-04-2018/#patching-the-handlers-to-use-tx-buffer","title":"Patching the handlers to use tx buffer.","text":"<p>Patched.</p> <p>Once race condition: pcache_handle_miss use the page itself as the reply buffer. Assume later on, it changes to use nowait reply. When the reply is buffered in the queue and has not been sent. Another munmap comes in and invalidate this area, then the page will be freed. The data is invalidate.</p> <p>But this case seems abnormal. The application will not do so I guess.</p>"},{"location":"lego/log/log-04-2018/#check-if-page-table-pages-page-themselves-are-freed-in-munmap-at-both-p-and-m-need-to-confirm","title":"Check if page table pages, page themselves are freed in munmap, at both P and M. Need to confirm.","text":""},{"location":"lego/log/log-04-2018/#tonight-task-think-about-how-to-do-the-vma-replication-how-to-combine-with-the-line-replicaiton","title":"Tonight task. Think about how to do the VMA replication, how to combine with the $ line replicaiton.","text":""},{"location":"lego/log/log-04-2018/#0412-thur","title":"04/12 Thur","text":"<p>Patched zerofill. All done.</p> <p>Testing new driver fix with Phoenix - 1<sup>st</sup> run, the mismatch reply is still there. mmap() replied address is different from the one printed. So segfault follows. (0412-w15-4) - 2st run, 3st run, succeed.</p> <p>0412-w15-9 0412-w14-9  First time testing phoenix with zerofill (no net). Somehow, P has pcache timeout, but M\u2019s watchdog show there is no pending requests. This happen once before I remember\u2026</p> <p>0412-w15-10. Have not seen this ib mad thing for a long time. Indeed somewhere is wrong. <pre><code>[  297.794969] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 15\n[  297.803706] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020\n[  297.812431] IP: [&lt;ffffffff81058937&gt;] ib_mad_completion_handler+0xc7/0x810\n</code></pre> 2</p>"},{"location":"lego/log/log-04-2018/#0411-wed","title":"04/11 Wed","text":"<p>Adding anon first touch opt.</p> <p>0411-p/m-9: this log indicate M does not have any unhandled requests, but P side has 1 <code>__pcache_fill</code> timeout. It seems the message is lost somewhere.</p> <p>0411-p/m-11: catch one with the debug msg Yiying added. She says the M side send queue has 2 reqs. But poll does not return any error. Weird.</p> <p>Help debugging IB issue.</p>"},{"location":"lego/log/log-04-2018/#0410-tue","title":"04/10 Tue","text":"<p>Found. IB stuck. Damn. <pre><code>[ 2240.294960] RIP: 0010:[&lt;ffffffff8104a6d8&gt;]  [&lt;ffffffff8104a6d8&gt;] mlx4_ib_poll_cq+0x378/0x6a0\n[ 2242.694733] RIP: 0010:[&lt;ffffffff8104a6d8&gt;]  [&lt;ffffffff8104a6d8&gt;] mlx4_ib_poll_cq+0x378/0x6a0\n[ 2245.094524] RIP: 0010:[&lt;ffffffff8104a6e3&gt;]  [&lt;ffffffff8104a6e3&gt;] mlx4_ib_poll_cq+0x383/0x6a0\n[ 2247.494306] RIP: 0010:[&lt;ffffffff8104a6d8&gt;]  [&lt;ffffffff8104a6d8&gt;] mlx4_ib_poll_cq+0x378/0x6a0\n[ 2249.894088] RIP: 0010:[&lt;ffffffff8104a6d8&gt;]  [&lt;ffffffff8104a6d8&gt;] mlx4_ib_poll_cq+0x378/0x6a0\n[ 2252.293870] RIP: 0010:[&lt;ffffffff8104a6d8&gt;]  [&lt;ffffffff8104a6d8&gt;] mlx4_ib_poll_cq+0x378/0x6a0\n[ 2254.693651] RIP: 0010:[&lt;ffffffff8104a6d8&gt;]  [&lt;ffffffff8104a6d8&gt;] mlx4_ib_poll_cq+0x378/0x6a0\n[ 2257.093431] RIP: 0010:[&lt;ffffffff8104a6e3&gt;]  [&lt;ffffffff8104a6e3&gt;] mlx4_ib_poll_cq+0x383/0x6a0\n</code></pre></p>"},{"location":"lego/log/log-04-2018/#0409-mon","title":"04/09 Mon","text":"<p>thpool testing. 4 workers. MT-phoenix:</p> <pre><code>[root@wuklab05 ys]# cat 0409-p | grep __munmap\n[  227.054974] CPU14 PID22 strace__munmap([0x7fffb0ba9000 - 0x7fffb4000000], 54882304) = 0, 0x0\n[  227.093466] CPU16 PID23 strace__munmap([0x7fffab7ff000 - 0x7fffac000000], 8392704) = 0, 0x0\n[  227.102773] CPU14 PID22 strace__munmap([0x7fffb8000000 - 0x7fffb8ba9000], 12226560) = 0, 0x0\n[  227.141265] CPU18 PID24 strace__munmap([0x7fffa8000000 - 0x7fffac000000], 67108864) = 0, 0x0\n[  227.150669] CPU16 PID23 strace__munmap([0x7fffb0000000 - 0x7fffb37ff000], 58716160) = 0, 0x0\n[  227.218248] CPU22 PID26 strace__munmap([0x7fffa0000000 - 0x7fffa4000000], 67108864) = 0, 0x0\n[  227.285826] CPU2 PID28 strace__munmap([0x7fff98000000 - 0x7fff9c000000], 67108864) = 0, 0x0\n[  227.440567] CPU14 PID31 strace__munmap([0x7fff8a7fd000 - 0x7fff8c000000], 25178112) = 0, 0x0\n[  227.449972] CPU12 PID30 strace__munmap([0x7fff88000000 - 0x7fff8c000000], 67108864) = 0, 0x0\n[  227.459376] CPU14 PID31 strace__munmap([0x7fff90000000 - 0x7fff927fd000], 41930752) = 0, 0x0\n[  227.490109] CPU18 PID33 strace__munmap([0x7fff80000000 - 0x7fff84000000], 67108864) = 0, 0x0\n[  227.723140] word_count-pthr[29]: segfault at 0x4e842010 ip 0000000000420354 sp 00007fffb17f9bc0 error 6\n0x4e842010\n</code></pre> <ul> <li>Print mmap on M, if segfault. Printed, the <code>0x4e842010</code> is never a valid address. thpool makes Memory side SMP. Probably bring some issues.</li> </ul> <p>Found: <pre><code>P\nCPU22 PID26 strace__mmap(addr=0x0, len=0xfb000, prot(0x3)=PROT_READ|PROT_WRITE, flags(0x22)=MAP_PRIVATE|MAP_ANONYMOUS, fd=18446744073709551615( ), off=0x0) = 1317351432, 0x4e853008\nword_count-pthr[26]: segfault at 0x4e853010 ip 0000000000420354 sp 00007fff972a8bc0 error 6\n\nM\n[  583.120615]   00400000-004d9000 r-xp 00000000 /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  583.131578]   006d9000-006dc000 rw-p 000d9000 /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count-pthread\n[  583.142729]   006dc000-00755000 rw-p 00000000 [heap]\n[  583.148254]   7fff529c9000-7fffb93aa000 rw-p 00000000\n[  583.153974]   7fffb93aa000-7ffff7fff000 rw-p 00000000 /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_1GB.txt\n[  583.167355]   7ffffffde000-7ffffffff000 rw-p 00000000 [stack]\n[  583.173753] ------------[ cut here ]------------\n[  583.178892] WARNING: CPU: 4 PID: 31 at managers/memory/handle_pcache/fault.c:55 handle_p2m_pcache_miss+0x18e/0x1d0\n[  583.190430] src_nid:0,pid:21,vaddr:0x4e853010\n[  583.195279] CPU: 4 PID: 31 Comm: thpool-worker0 4.0.0-lego-ys+ #90\n</code></pre></p> <p>Confirmed. I printed added a number to mmap requests. And the compare the results of both P and M. The data is wrong. Btw, I\u2019m only running 1 worker thread at M, which makes it single thread handling. So, I\u2019m going to, 1) first use kmalloc to get the reply buffer, and 2) revert back the IB MAX_OUT config, remove the #ifdef COMP_MEMORY. See if it is this patch\u2019s issue. <pre><code>P:\nCPU18 PID24 strace__mmap(30 ..) = -1325940736, 0x7fffb0f7c000\nCPU22 PID26 strace__mmap(31 ..) = 2144269992, 0x7fcef6a8\n\nM:\n...\nhandle_p2m_mmap(): 30 7fffb0f7c000\nhandle_p2m_mmap(): 31 7fffb0efe000\n...\n</code></pre></p> <p>Anyway, this is temporary fixed by using kmalloced reply buffer.</p> <p>Spent whole afternoon and whole night. Finally figure out why timeout happen in P. It is because somewhere in the middle, M has 1 or more requests stucked/unhandled. Deadlock happen in the middle.</p> <p>Like this one. 5 requests queued waiting, 1 is being handled. And that 1 handler stuck. And it is handle_pcache_miss. Now, I need to find out where it stuck! <pre><code>thpool-worker0 nr_queued: 5 1\n</code></pre></p> <p>Oh, I really hope we can have some soft/hw lockdep, watchdog stuff. This should make out life much much much much much easier!</p>"},{"location":"lego/log/log-04-2018/#0408-sun","title":"04/08 Sun","text":"<p>Trying the fit_nowait patch.</p> <ul> <li>First try fit_nowait patch, without any chanegs to other code. See if this patch can work.</li> <li>Second, modify pcache to use reply_message_nowait. See if this can work. and improve performance.</li> <li>Third, if 2) can improve, perf. Move on to modify thpool patch.</li> </ul> <p>1<sup>st</sup>, P fail at ib_mad, during boot: <pre><code>[  349.239220] Online CPU: 0,2,4,6,8,10,12,14,16,18,20,22\n[  349.244940] Active CPU: 0,2,6,10,12,14,16,18,20,22\n[  349.250272]   [0] Thread[kvictim_flushd:19] pinned at CPU 8\n[  349.256478]   [1] Thread[recvpollcq:17] pinned at CPU 4\n[  356.188819] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 13\n[  356.197545] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020\n[  356.206270] IP: [&lt;ffffffff81058287&gt;] ib_mad_completion_handler+0xc7/0x810\n</code></pre></p> <p>2st run, P side, config MAX_OUT to 1. Then single-thread pheonix with 1GB data finished. But forgot to turn on the profile point. Run one more time.</p> <p>3st run. Same with 2st run setting. But with profile on. Bug shows. Ugh. I still think it is because of ib_mad_handler. It must write to wrong memory locations, and corrupt things randomly. <pre><code>[  456.237913] do_close_on_exec(): TODO, not implemented.\n...\n[  456.263274] BUG: unable to handle kernel paging request at 00000002f4bfbf58\n[  456.270843] IP: [&lt;ffffffff8101bbff&gt;] task_tick_rt+0x1f/0xd0\n[  456.277048] PGD 0\n[  456.279279] Thread overran stack, or stack corrupted\n[  456.284804] Oops: 0000 [#1] SMP PROCESSOR\n[  456.289265] CPU: 10 PID: 20 Comm: kevict_sweepd 4.0.0-lego+ #40\n[  456.295858] RIP: 0010:[&lt;ffffffff8101bbff&gt;]  [&lt;ffffffff8101bbff&gt;] task_tick_rt+0x1f/0xd0\n</code></pre></p> <p>4st run, succeed. But it looks like the perf is very bad. Oh. but 99% of the pcache miss are file-backed, which will go to storage. So the number is actually doubled. <pre><code>With fit_nowait patch:\n[  308.660051] Kernel Profile Points\n[  308.663734]  status                  name             total                nr            avg.ns\n[  308.673431] -------  --------------------  ----------------  ----------------  ----------------\n[  308.683128]     off      flush_tlb_others       0.000130715                53              2467\n[  308.692824]     off     __do_kmalloc_node       0.097344056            265647               367\n[  308.702521]     off           pcache_miss       4.504660891            258211             17446\n[  308.712218]     off          pcache_flush       0.000000000                 0                 0\n[  308.721914] -------  --------------------  ----------------  ----------------  ----------------\n</code></pre></p> <p>5st run. Just run large malloc test. Looks better than yesterday\u2019s result. But I\u2019m using 15 as P today, instead of 13. So, let me try one more time to see if it is the machine. <pre><code>With fit_nowait patch:\n[  674.382592] Kernel Profile Points\n[  674.386277]  status                  name             total                nr            avg.ns\n[  674.395974] -------  --------------------  ----------------  ----------------  ----------------\n[  674.405670]     off      flush_tlb_others       0.000130838                53              2469\n[  674.415366]     off     __do_kmalloc_node       1.604700641           1584917              1013\n[  674.425062]     off           pcache_miss       6.467938547            786571              8223\n[  674.434758]     off          pcache_flush       3.342783614            262225             12748\n[  674.444455] -------  --------------------  ----------------  ----------------  ----------------\n[  674.554497] nr_pgfault: 786513\n[  674.557706] nr_clflush: 262225\n[  674.561099] nr_pgfault_wp: 0\n[  674.564299] nr_pgfault_wp_cow: 0\n[  674.567887] nr_pgfault_wp_reuse: 0\n[  674.571668] nr_pgfault_due_to_concurrent_eviction: 0\n[  674.577195] nr_pcache_fill_from_memory: 786511\n[  674.582139] nr_pcache_fill_from_victim: 2\n</code></pre></p> <p>6st run. Looks like the above fit_nowait can have 400ns improvement. But how come? I did not even change the pcache handling to use ibapi_nowait!!! Maybe random variation. Let me run more. <pre><code>Without fit_nowait patches\n[  428.546738] Kernel Profile Points\n[  428.550424]  status                  name             total                nr            avg.ns\n[  428.560119] -------  --------------------  ----------------  ----------------  ----------------\n[  428.569815]     off      flush_tlb_others       0.000131140                53              2475\n[  428.579510]     off     __do_kmalloc_node       1.758704197           1331927              1321\n[  428.589205]     off           pcache_miss       6.807601189            786575              8655\n[  428.598899]     off          pcache_flush       3.699044847            262227             14107\n[  428.608594] -------  --------------------  ----------------  ----------------  ----------------\n[  428.618289]\n[  428.718670] nr_pgfault: 786515\n[  428.721878] nr_clflush: 262227\n[  428.725272] nr_pgfault_wp: 0\n[  428.728470] nr_pgfault_wp_cow: 0\n[  428.732058] nr_pgfault_wp_reuse: 0\n[  428.735840] nr_pgfault_due_to_concurrent_eviction: 0\n[  428.741365] nr_pcache_fill_from_memory: 786515\n[  428.746310] nr_pcache_fill_from_victim: 0\n</code></pre></p> <p>7<sup>th</sup> run. without fit_nowait. <pre><code>without fit_nowait.\n[  901.223090] Kernel Profile Points\n[  901.226775]  status                  name             total                nr            avg.ns\n[  901.236472] -------  --------------------  ----------------  ----------------  ----------------\n[  901.246168]     off      flush_tlb_others       0.000130802                53              2468\n[  901.255865]     off     __do_kmalloc_node       1.862575608           1331923              1399\n[  901.265560]     off           pcache_miss       6.814540477            786572              8664\n[  901.275257]     off          pcache_flush       3.699187003            262224             14107\n[  901.284953] -------  --------------------  ----------------  ----------------  ----------------\n</code></pre></p> <p>8<sup>th</sup> run. without fit_nowait. <pre><code>[  321.514564] Kernel Profile Points\n[  321.518250]  status                  name             total                nr            avg.ns\n[  321.527945] -------  --------------------  ----------------  ----------------  ----------------\n[  321.537639]     off      flush_tlb_others       0.000130934                53              2471\n[  321.547335]     off     __do_kmalloc_node       2.216772665           1331939              1665\n[  321.557031]     off           pcache_miss       6.806060415            786573              8653\n[  321.566726]     off          pcache_flush       3.725455841            262231             14207\n[  321.576421] -------  --------------------  ----------------  ----------------  ----------------\n</code></pre></p> <p>9<sup>th</sup> run. with fit_nowait <pre><code>[  374.847912] Kernel Profile Points\n[  374.851597]  status                  name             total                nr            avg.ns\n[  374.861293] -------  --------------------  ----------------  ----------------  ----------------\n[  374.870989]     off      flush_tlb_others       0.000130858                53              2470\n[  374.880684]     off     __do_kmalloc_node       1.485304454           1331934              1116\n[  374.890381]     off           pcache_miss       6.615317677            786582              8411\n[  374.900076]     off          pcache_flush       3.508328900            262234             13379\n[  374.909772] -------  --------------------  ----------------  ----------------  ----------------\n</code></pre></p> <p>10<sup>th</sup> run, with fit_nowait <pre><code>[  225.211058] Kernel Profile Points\n[  225.214743]  status                  name             total                nr            avg.ns\n[  225.224440] -------  --------------------  ----------------  ----------------  ----------------\n[  225.234137]     off      flush_tlb_others       0.000131029                53              2473\n[  225.243833]     off     __do_kmalloc_node       1.211421872           1331984               910  \n[  225.253529]     off           pcache_miss       6.583096125            786574              8370\n[  225.263226]     off          pcache_flush       3.464430818            262227             13212\n[  225.272922] -------  --------------------  ----------------  ----------------  ----------------\n</code></pre></p> <p>Sum: <pre><code>with fit_nowait:\n\n[  225.253529]     off           pcache_miss       6.583096125            786574              8370\n[  225.263226]     off          pcache_flush       3.464430818            262227             13212\n\n[  374.890381]     off           pcache_miss       6.615317677            786582              8411\n[  374.900076]     off          pcache_flush       3.508328900            262234             13379\n\n[  674.425062]     off           pcache_miss       6.467938547            786571              8223\n[  674.434758]     off          pcache_flush       3.342783614            262225             12748\n\nWithout fit_nowait:\n[  428.589205]     off           pcache_miss       6.807601189            786575              8655\n[  428.598899]     off          pcache_flush       3.699044847            262227             14107\n\n[  901.265560]     off           pcache_miss       6.814540477            786572              8664\n[  901.275257]     off          pcache_flush       3.699187003            262224             14107\n\n[  321.557031]     off           pcache_miss       6.806060415            786573              8653\n[  321.566726]     off          pcache_flush       3.725455841            262231             14207\n</code></pre></p>"},{"location":"lego/log/log-04-2018/#0407-sat","title":"04/07 Sat","text":"<p>Well, now we finished all the profiling stuff. Continue on other work.</p> <p>Now I like listening Jazz while coding. Amazing Jazz, really good.</p> <p>Once again, ib_mad_completion_handler bug will happen. During application run, or even after application exit. <pre><code>[  465.835447] nr_mremap_pset_diff: 0\n[  477.086886] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 21\n[  477.095620] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020\n[  477.104345] IP: [&lt;ffffffff81058277&gt;] ib_mad_completion_handler+0xc7/0x810\n\nib_mad_completion_handler+0xc7/0x808:\nib_mad_recv_done_handler at drivers/infiniband/core/mad.c:1899\n (inlined by) ib_mad_completion_handler at drivers/infiniband/core/mad.c:2345\n</code></pre></p> <p>After remove net from pcache miss: <pre><code>[  465.572131] Kernel Profile Points\n[  465.575815]  status                  name             total                nr            avg.ns\n[  465.585510] -------  --------------------  ----------------  ----------------  ----------------\n[  465.595206]     off      flush_tlb_others       0.000000000                 0                 0\n[  465.604901]     off     __do_kmalloc_node       0.656371295           1762220               373\n[  465.614597]     off           pcache_miss       7.172572671            786596              9119\n[  465.624291]     off          pcache_flush       3.698294960            262251             14103\n[  465.633987] -------  --------------------  ----------------  ----------------  ----------------\n</code></pre></p> <p>After remove net from pcache flush: <pre><code>[  684.984000] Kernel Profile Points\n[  684.987683]  status                  name             total                nr            avg.ns\n[  684.997379] -------  --------------------  ----------------  ----------------  ----------------\n[  685.007074]     off      flush_tlb_others       0.000000000                 0                 0\n[  685.016770]     off     __do_kmalloc_node       0.627372836           1500543               419\n[  685.026464]     off           pcache_miss       7.128702028            786596              9063\n[  685.036159]     off          pcache_flush       3.660772506            262251             13960\n[  685.045855] -------  --------------------  ----------------  ----------------  ----------------\n</code></pre></p> <p>malloc, miss, flush are too slow. Especially the flush, how can it take 13.9us?</p> <p>It must be our handlers! lego_copy_to_user stuff.</p>"},{"location":"lego/log/log-04-2018/#0406-fri","title":"04/06 Fri","text":"<p>Well. Now we have in-kernel strace, in-kernel readprofile. Yummy.</p>"},{"location":"lego/log/log-04-2018/#0405-thur","title":"04/05 Thur","text":"<p>Discussion with Yilun. 1. munmap+nr_pgfault figure: count number of pgfaults between munmap, it should be an interesting figure. 2. track number of pgfault at: since there is no eviction, so any mmaped area at M should only have exactly one pcache fetch. 3. I probably want to use per-cpu counter.</p> <p>Anyway, continue strace work first. Finished.</p>"},{"location":"lego/log/log-04-2018/#0404-wed","title":"04/04 Wed","text":""},{"location":"lego/log/log-04-2018/#strace-performance","title":"STRACE Performance","text":"<p>TF has very bad performance. It is either due to the syscall or pcache. Now I\u2019m adding facilities to track syscall activities, including average latency, total time.</p> <p>Basic utilities of strace are done. But I somehow need to change the design of multithread strace. Previously, I naively make the thread group keep some info, and let all other threads use that info to do bookkeeping.</p> <p>But this is really hard and not accurate. We first need to make sure we are running on a non-preemptable kernel, so the per-cpu time tracking will be accurate. Besides, we also need to make sure threads do not migrate because of syscalls such as sched_setaffinity.</p> <p>Oh, well, so I though I have to use per-thread strace_info. The first design I thought is: accumulating the counter of one thread to its thread group leader, when it exit. But this is slightly complex, and will affect the thread group leader runtime.</p> <p>So the second solution I came up is let all threads within a process, chain their straec_info together. And normal thread does not need to accumulate the counter. It can just exit. While the thread group leader exit, it walk through the chain to accumulate the counters. This is simpler. Besides, the strace_info of dead thread is safe. No one will touch it.</p> <p>Yeh! Let us do this tomorrow. We will have a robust kernel version strace.</p>"},{"location":"lego/log/log-04-2018/#sm-heartbeat","title":"SM Heartbeat","text":"<p>Continue run some experiments on yesterday\u2019s case.</p> <p>One we sure is SM will keep sending requests to HCA. And it looks like it does not send in a very deterministic interval: <pre><code>[ 1224.034898] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 15\n[ 1224.130616] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 15\n[ 1224.222189] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 16\n[ 1224.417181] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 16\n\n[ 1393.159845] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 17\n[ 1393.255546] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 17\n[ 1393.347132] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 18\n[ 1393.538972] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 18\n\n[ 1449.437542] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 19\n[ 1449.533248] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 19\n[ 1449.624833] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 20\n[ 1449.722512] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 20\n\n[ 4322.423624] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 21\n[ 4322.519328] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 21\n[ 4322.610914] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 22\n[ 4322.708594] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 22\n[ 4350.750574] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 23\n[ 4350.846278] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 23\n[ 4350.937863] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 24\n[ 4351.035543] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 24\n\n[ 4519.690559] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 25\n[ 4519.786262] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 25\n[ 4519.877848] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 26\n[ 4519.975527] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 26\n\n[ 4576.396279] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 27\n[ 4576.491979] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 27\n[ 4576.583565] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 28\n[ 4576.681245] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 28\n\n[ 4942.886820] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 29\n[ 4942.982523] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 29\n[ 4943.074108] ib_mad_completion_handler 2344 got successful recv cq op 128 mad_got_one 30\n[ 4943.171789] ib_mad_completion_handler 2338 got successful send cq op 0 mad_got_one 30\n</code></pre></p>"},{"location":"lego/log/log-04-2018/#0403-tue","title":"04/03 Tue","text":""},{"location":"lego/log/log-04-2018/#bug-bug-bug","title":"BUG BUG BUG","text":"<p>Finished basic replication mechanism last night.</p> <p>Today merged several patches. And both Yilun and I think there is something wrong with <code>ib_mad_completion_handler</code>. It seems it will break things behind our back.</p> <p>This is one bug catched today:</p>"},{"location":"lego/log/log-04-2018/#ib_mad_completion_handler","title":"ib_mad_completion_handler","text":"<pre><code>At very early stage:\n\n[ 1174.406177] newpid: 20 home:1 replica: 1\n[ 1174.452983] p2m_fork(cpu10): I cur:20-exe.o new:21\n[ 1177.462795] ib_mad_completion_handler 2324 got successful recv cq op 128 mad_got_one 22\n[ 1177.556502] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020\n[ 1177.650101] IP: [&lt;ffffffff81059104&gt;] ib_mad_completion_handler+0xb4/0x8a0\n\n./scripts/faddr2line vmImage  ib_mad_completion_handler+0xb4\nib_mad_completion_handler+0xb4/0x899:\nib_mad_recv_done_handler at drivers/infiniband/core/mad.c:1899\n (inlined by) ib_mad_completion_handler at drivers/infiniband/core/mad.c:2325\n\nib_mad_recv_done_handler():\n1899: qp_info = mad_list-&gt;mad_queue-&gt;qp_info;\n</code></pre> <p>A more scared one after I changed ib_mad_completion_handler. Note that recvcq is the only thread running on cpu4: <pre><code>[  863.887705] p2m_fork(cpu10): I cur:20-exe.o new:21\n[  868.478424] p2m_fork(cpu10): O succeed cur:20-exe.o new:21\n[  868.541991] BUG: unable to handle kernel NULL pointer dereference at 0000000000000008\n[  868.635569] IP: [&lt;ffffffff810656d4&gt;] __schedule+0x94/0x1e0\n[  868.701090] PGD 0\n[  868.725010] general protection fault: 0000 [#1] SMP PROCESSOR\n[  868.793651] CPU: 4 PID: 17 Comm: recvpollcq 4.0.0-lego-ys+ #737\n\nSource:\nclear_tsk_need_resched(prev);\n</code></pre></p> <p>Even this one for Phoenix: <pre><code>[  763.442043] BUG: unable to handle kernel NULL pointer dereference at 0000000000000010\n[  763.535636] IP: [&lt;ffffffff81018d6f&gt;] task_curr+0xf/0x30\n[  763.598035] PGD 103e956067 PUD 103e964067 PMD 0\n[  763.653154] Oops: 0000 [#1] SMP PROCESSOR\n[  763.700992] CPU: 12 PID: 21 Comm: word_count-pthr 4.0.0-lego-ys+ #740\n[  763.777950] RIP: 0010:[&lt;ffffffff81018d6f&gt;]  [&lt;ffffffff81018d6f&gt;] task_curr+0xf/0x30\n</code></pre></p> <p>This NEVER happen before. And this part of code should be correct. We\u2019ve ran a lot things.. I doubt if recent IB merge corrupt things.</p>"},{"location":"lego/log/log-04-2018/#fit_poll_cq","title":"fit_poll_cq","text":"<p>Another one: <pre><code>[  690.401626] stat: /root/ys/phoenix/phoenix-2.0/tests/word_count/word_count_datafiles/word_1GB.txt\n[  690.507742] SYSC_close() CPU12 PID:21 [fd: 4] -&gt; [/sys/devices/system/cpu/online]\n[  713.899884] ib_mad_completion_handler 2337 got successful recv cq op 128 mad_got_one 21\n[  713.995606] ib_mad_completion_handler 2331 got successful send cq op 0 mad_got_one 21\n[  714.087185] ib_mad_completion_handler 2337 got successful recv cq op 128 mad_got_one 22\n[  714.184871] ib_mad_completion_handler 2331 got successful send cq op 0 mad_got_one 22\n[  742.078102] ib_mad_completion_handler 2337 got successful recv cq op 128 mad_got_one 23\n[  742.173810] ib_mad_completion_handler 2331 got successful send cq op 0 mad_got_one 23\n[  742.265399] ib_mad_completion_handler 2337 got successful recv cq op 128 mad_got_one 24\n[  742.363085] ib_mad_completion_handler 2331 got successful send cq op 0 mad_got_one 24\n[  847.063372] mlx4_ib_handle_error_cqe syndrome 21\n[  847.116511] mlx4_ib_handle_error_cqe syndrome 5\n[  847.170590] send request failed at connection 7 as 12\n[  847.230909] mlx4_ib_handle_error_cqe syndrome 5\n[  847.284988] mlx4_ib_handle_error_cqe syndrome 5\n[  847.339067] mlx4_ib_handle_error_cqe syndrome 5\n[  847.393146] fit_poll_cq: failed status (5) for wr_id 1832\n[  847.457624] fit_poll_cq: failed status (5) for wr_id 1833\n[  847.522103] fit_poll_cq: connection 7 Recv weird event as -1\n[  847.589701] fit_poll_cq: failed status (5) for wr_id 1834\n[  847.654179] fit_poll_cq: connection 7 Recv weird event as -30704\n[  847.725938] fit_poll_cq: failed status (5) for wr_id 1835\n[  847.790416] fit_poll_cq: connection 7 Recv weird event as -30704\n[  847.862174] mlx4_ib_handle_error_cqe syndrome 5\n[  847.916252] mlx4_ib_handle_error_cqe syndrome 5\n[  847.970331] mlx4_ib_handle_error_cqe syndrome 5\n[  848.024410] mlx4_ib_handle_error_cqe syndrome 5\n[  848.078490] fit_poll_cq: failed status (5) for wr_id 1836\n[  848.142967] fit_poll_cq: failed status (5) for wr_id 1837\n[  848.207446] fit_poll_cq: connection 7 Recv weird event as -1\n[  848.275044] fit_poll_cq: failed status (5) for wr_id 1838\n[  848.339523] fit_poll_cq: connection 7 Recv weird event as -30704\n[  848.411281] fit_poll_cq: failed status (5) for wr_id 1839\n[  848.475760] fit_poll_cq: connection 7 Recv weird event as -30704\n[  848.547517] mlx4_ib_handle_error_cqe syndrome 5\n[  848.601596] mlx4_ib_handle_error_cqe syndrome 5\n[  848.655675] mlx4_ib_handle_error_cqe syndrome 5\n[  848.709753] mlx4_ib_handle_error_cqe syndrome 5\n[  848.763832] fit_poll_cq: failed status (5) for wr_id 1840\n\n[  848.828313] BUG: unable to handle kernel NULL pointer dereference at           (null)\n[  848.921908] IP: [&lt;ffffffff8106346d&gt;] fit_poll_cq+0x4ad/0x510\n[  848.989507] PGD 0\n[  849.013426] Oops: 0002 [#1] SMP PROCESSOR\n[  849.061265] CPU: 4 PID: 17 Comm: recvpollcq 4.0.0-lego-ys+ #744\n[  849.131983] RIP: 0010:[&lt;ffffffff8106346d&gt;]  [&lt;ffffffff8106346d&gt;] fit_poll_cq+0x4ad/0x510\n[  849.228700] RSP: 0000:ffff88103e813d88  EFLAGS: 00010246\n[  849.292139] RAX: 0000000000001008 RBX: ffff88103effbad0 RCX: 0000000000000000\n[  849.377418] RDX: 0000000000000000 RSI: ffffffff811d46e0 RDI: ffffffff811dbc08\n[  849.462695] RBP: ffff88103e813ea8 R08: 0000000000000000 R09: 0000000000000000\n[  849.547973] R10: 0000000000000002 R11: 0000000000000004 R12: 0000000000000000\n[  849.633251] R13: ffff88103e801008 R14: 0000000000000004 R15: ffff88103e813da0\n[  849.718529] FS:  0000000000000000(0000) GS:ffff88107fc40000(0000) knlGS:0000000000000000\n[  849.815246] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[  849.883884] CR2: 0000000000000000 CR3: 000000000113d000 CR4: 00000000000406a0\n[  849.969163] Stack:\n[  849.993082] ffffffff81003299 000001b03e813da0 0000000000000004 0000000000000730\n[  850.080440] 0000008100000005 00001008000000f9 ffff88103eff8c50 002c222040000000\n[  850.167798] 0010004000000002 ffff88107fc20000 0000000000000731 ffffffff00000005\n[  850.255156] ffff8810000000f9 ffff88103eff8c50 0000000000000000 ffff88103e813e38\n[  850.342513] ffffffff81019854 0000000000000732 ffff881000000005 ffff8810000000f9\n[  850.429871] Call Trace:\n[  850.458992] &lt;TSK&gt;\n[  850.481870] [&lt;ffffffff81003299&gt;] ? native_smp_send_reschedule+0x39/0x50\n[  850.560909] [&lt;ffffffff81019854&gt;] ? try_to_wake_up+0xe4/0x1f0\n[  850.628506] [&lt;ffffffff81065708&gt;] ? __schedule+0xf8/0x1e0\n[  850.691945] [&lt;ffffffff810634d0&gt;] ? fit_poll_cq+0x510/0x510\n[  850.757464] [&lt;ffffffff810634e4&gt;] fit_poll_cq_pass+0x14/0x30\n[  850.824021] [&lt;ffffffff81020636&gt;] kthread+0xf6/0x120\n[  850.882260] [&lt;ffffffff81020540&gt;] ? __kthread_parkme+0x70/0x70\n[  850.950898] [&lt;ffffffff8100e572&gt;] ret_from_fork+0x22/0x30\n\n/* handle normal reply */\n...\nmemcpy((void *)ctx-&gt;reply_ready_indicators[reply_indicator_index], &amp;length, sizeof(int));\n...\n(This is a bad memcpy: reply_indicator_index, ctx, etc should be checked.)\n</code></pre></p>"},{"location":"lego/log/log-04-2018/#ib-spec-qp-cqe-wqe-send","title":"IB Spec: QP, CQE, WQE, SEND","text":"<p>The channel adapter detects the WQE posting and accesses the WQE. The channel adapter interprets the command, validates the WQE\u2019s virtual 12 addresses, translates it to physical addresses, and accesses the data. The outgoing message buffer is split into one or more packets. To each packet the channel adapter adds a transport header (sequence numbers, opcode, etc.). If the destination resides on a remote subnet the channel adapter adds a network header (source &amp; destination GIDs). The channel adapter then adds the local route header and calculates both the variant and invariant checksums.</p> <p>For a Send operation, the QP retrieves the address of the receive buffer from the next WQE on its receive queue, translates it to physical addresses, and accesses memory writing the data. If this is not the last packet of the message, the QP saves the current write location in 38 its context and waits for the next packet at which time it continues writing the receive buffer until it receives a packet that indicates it is the last packet of the operation. It then updates the receive WQE, retires it, and sends an acknowledge message to the originator.</p> <p>When the originator receives an acknowledgment, it creates a CQE on the 5 CQ and retires the WQE from the send queue.</p> <p>A QP can have multiple outstanding messages at any one time but the 8 target always acknowledges in the order sent, thus WQEs are retired in the order that they are posted.</p>"},{"location":"lego/log/log-04-2018/#0402-mon","title":"04/02 Mon","text":"<p>Patching storage replica handler, able to finish today.</p>"},{"location":"lego/log/log-04-2018/#0401-sun","title":"04/01 Sun","text":"<p>Anyway. Summary of the day: replication at M almost done. Only flush part left. Storage also need a handler. But we still need code to recover.</p> <p>I\u2019m tired. :-( A month to go.</p> <p>Record a IB error. Using wuklab12 (P) and wuklab14(M+RAMFS), running usr/pcache_conflic.o: <pre><code>P\n[30801.296160] ibapi_send_reply() CPU:8 PID:19 timeout (30010 ms), caller: clflush_one+0x1c9/0x370\n[30938.564843] mlx4_ib_handle_error_cqe syndrome 21\n[30938.617988] mlx4_ib_handle_error_cqe syndrome 5\n[30938.672068] send request failed at connection 6 as 12\n[30938.732389] mlx4_ib_handle_error_cqe syndrome 5\n[30938.786470] mlx4_ib_handle_error_cqe syndrome 5\n[30938.840551] mlx4_ib_handle_error_cqe syndrome 5\n[30938.894632] fit_poll_cq: failed status (5) for wr_id 1584\n[30938.959112] fit_poll_cq: failed status (5) for wr_id 1585\n[30939.023593] fit_poll_cq: connection 6 Recv weird event as -1\n[30939.091194] fit_poll_cq: failed status (5) for wr_id 1586\n[30939.155676] fit_poll_cq: connection 6 Recv weird event as -30704\n[30939.227436] fit_poll_cq: failed status (5) for wr_id 1587\n[30939.291917] fit_poll_cq: connection 6 Recv weird event as -30704\n[30939.363678] mlx4_ib_handle_error_cqe syndrome 5\n[30939.417759] mlx4_ib_handle_error_cqe syndrome 5\n[30939.471839] mlx4_ib_handle_error_cqe syndrome 5\n[30939.525921] mlx4_ib_handle_error_cqe syndrome 5\n[30939.580002] fit_poll_cq: failed status (5) for wr_id 1588\n[30939.644483] BUG: unable to handle kernel NULL pointer dereference at           (null)\n[30939.738083] IP: [&lt;ffffffff81062fcd&gt;] fit_poll_cq+0x4ad/0x510\n[30939.805684] PGD 0\n[30939.829604] Oops: 0002 [#1] SMP PROCESSOR\n[30939.877445] CPU: 4 PID: 17 Comm: recvpollcq 4.0.0-lego-ys+ #715\n[30939.948166] RIP: 0010:[&lt;ffffffff81062fcd&gt;]  [&lt;ffffffff81062fcd&gt;] fit_poll_cq+0x4ad/0x510\n\nfit_poll_cq at net/lego/fit_internal.c:1734\nmemcpy((void *)ctx-&gt;reply_ready_indicators[reply_indicator_index], &amp;length, sizeof(int));\n\nM\n[30913.642698] mlx4_ib_handle_error_cqe syndrome 21\n[30913.695839] mlx4_ib_handle_error_cqe syndrome 5\n[30913.749919] send request failed at connection 1 as 12\n[30913.810236] mlx4_ib_handle_error_cqe syndrome 5\n[30913.864315] mlx4_ib_handle_error_cqe syndrome 5\n[30913.918395] mlx4_ib_handle_error_cqe syndrome 5\n[30913.972474] fit_poll_cq: failed status (5) for wr_id 305\n[30914.035912] fit_poll_cq: failed status (5) for wr_id 306\n</code></pre></p>"},{"location":"lego/log/log-08-2018/","title":"Aug 2018","text":""},{"location":"lego/log/log-08-2018/#aug-31","title":"Aug 31","text":""},{"location":"lego/log/log-08-2018/#one-major-todo","title":"One major TODO","text":"<p>Check <code>do_handle_p2m_pcache_miss()</code>. We MUST remove that mempcy, maybe by using another flag in thpool. This is just no acceptable.</p>"},{"location":"lego/log/log-08-2018/#ugh","title":"Ugh","text":"<p>Fuck. Without debug_mm, there is still memory corruption.</p>"},{"location":"lego/log/log-08-2018/#try-max_send_wr-and-number-of-qps","title":"Try max_send_wr and number of QPs","text":"<p>without lock_ib, with debug_mm. Change max_send_wr at all P M S.</p> <ul> <li>QP=4, max_send_wr = 1: always fail</li> <li>QP=4, max_send_wr = 256: always fail</li> <li>QP=24, max_send_wr = 1: succeed (0831-w14-18 0831-w14-20)</li> <li>QP=24, max_send_wr = 256: succeed (0831-w14-16 0831-w14-17)</li> </ul> <p>Pay attention to the <code>0831-w14-15</code>\uff1a something wrong with our timekeeping code? QP=24, max_send_wr = 1 case.</p>"},{"location":"lego/log/log-08-2018/#after-victim-bug-fix","title":"After Victim bug fix","text":"<p>MNIST 4 threads</p> <ul> <li>With lock_ib, debug_mm etc: 3 successful runs</li> <li>Only with debug_mm: Well fit failed. Lost CQE.</li> </ul> <p>Now the debug scope is limited. Let me try the micro test suite, to stress ibapi_send_reply itself.</p> <p>Potential: read/write buffer.</p>"},{"location":"lego/log/log-08-2018/#aug-30","title":"Aug 30","text":"<p>Be humble.</p>"},{"location":"lego/log/log-08-2018/#identified-victim-bug","title":"Identified victim bug.","text":"<p>Finally. I thought it through, and with the help of this <code>0830-w14-12</code>. The bug is in <code>victim_try_fill_pcache()</code>, when there are multiple hits to the same victim. Since we released the <code>usable_victim_lock</code> after a hit. There might a be race case where: 1) CPU0 reached <code>dec_and_test_filling</code>, and passed to free the line. 2) CPU1 just got to the <code>victim_check_hit</code>, and increment the fill counter to 1 again. When CPU1 finished filling, and do <code>dec_and_test_filling</code>, it will do the free again!!! What a double free.</p> <p>Tomorrow, let me do the fix. Thought: adding more sync in victim_check_hit part. Basically we want to ensure only one CPU can do the final free.</p>"},{"location":"lego/log/log-08-2018/#after-adding-pi_lock","title":"After adding pi_lock","text":"<p>Okay. the pi_lock is added. Although it is mostly used by futex-pi and rt-mutex, we lego does not have these two guys. Therefore, it is only used by sched/core.c, exit.c, and kthread.c. 99% is in core.c</p> <p>The purpose of having this back is to have the <code>spin_lock_irqsave(&amp;p-&gt;pi_lock)</code> back. Most scheduling code is not recursive, we have to disable interrupt. Of course we can use <code>spin_lock_irqsave(&amp;rq-&gt;lock)</code> instead of <code>spin_lock(&amp;rq-&gt;lock)</code>. But this is too dangerous at this stage. Porting based on Linux now is the fastest and safest way.</p> <p>The importance of disabling interrupt in some kernel path!!</p> <p>Good. Now I\u2019m seeing now debuggable victim issue.</p> <p>Classical deadlock catched. Now, only two victims.</p> <pre><code>[ 2819.068997] CPU14 PID29 Abort victim alloc (20010ms) nr_usable_victims: 2. From pset_idx:532 nr_lru:63 fault_uva: 0x7fff98614000\n[ 2819.094409] CPU14 PID29   --   Start Dump Victim Cache [0] total: 2\n[ 2819.114188] CPU14 PID29  victim[0]:ffffffff810c2880 refcount:2 nr_fill:1 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm:          (null) pset:ffff88207ff5a000\n[ 2819.133289] CPU14 PID29     hit[0] owner:21 m_nid:1 rep_nid:1 addr: 0x7fffcc000000\n[ 2819.141723] CPU14 PID29     rmap to pset:ffff88207ff5a000 set_idx: 0 nr_lru:63\n[ 2819.149770] CPU14 PID29  victim[1]:ffffffff810c2900 refcount:2 nr_fill:1 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm:          (null) pset:ffff88207ff5a000\n[ 2819.168870] CPU14 PID29     hit[0] owner:21 m_nid:1 rep_nid:1 addr: 0x7fffb0000000\n[ 2819.177306] CPU14 PID29     rmap to pset:ffff88207ff5a000 set_idx: 0 nr_lru:63\n[ 2819.185352] CPU14 PID29   --   End Dump Victim Cache [0]\n\n[ 2819.081708] CPU16 PID30 Abort victim alloc (20010ms) nr_usable_victims: 2. From pset_idx:0 nr_lru:63 fault_uva: 0x7fffcc000024\n[ 2819.209008] CPU16 PID30   --   Start Dump Victim Cache [1] total: 2\n[ 2819.223358] CPU16 PID30  victim[0]:ffffffff810c2880 refcount:2 nr_fill:1 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm:          (null) pset:ffff88207ff5a000\n[ 2819.252443] CPU16 PID30     hit[0] owner:21 m_nid:1 rep_nid:1 addr: 0x7fffcc000000\n[ 2819.260879] CPU16 PID30     rmap to pset:ffff88207ff5a000 set_idx: 0 nr_lru:63\n[ 2819.268926] CPU16 PID30  victim[1]:ffffffff810c2900 refcount:2 nr_fill:1 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm:          (null) pset:ffff88207ff5a000\n[ 2819.288026] CPU16 PID30     hit[0] owner:21 m_nid:1 rep_nid:1 addr: 0x7fffb0000000\n[ 2819.296461] CPU16 PID30     rmap to pset:ffff88207ff5a000 set_idx: 0 nr_lru:63\n[ 2819.304508] CPU16 PID30   --   End Dump Victim Cache [1]\n\n[ 2819.101391] CPU18 PID31 Abort victim alloc (20010ms) nr_usable_victims: 2. From pset_idx:15 nr_lru:63 fault_uva: 0x7fff98c0f000\n[ 2819.328165] CPU18 PID31   --   Start Dump Victim Cache [2] total: 2\n[ 2819.335146] CPU18 PID31  victim[0]:ffffffff810c2880 refcount:1 nr_fill:0 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm:          (null) pset:ffff88207ff5a000\n[ 2819.354246] CPU18 PID31     hit[0] owner:21 m_nid:1 rep_nid:1 addr: 0x7fffcc000000\n[ 2819.362680] CPU18 PID31     rmap to pset:ffff88207ff5a000 set_idx: 0 nr_lru:63\n[ 2819.370728] CPU18 PID31  victim[1]:ffffffff810c2900 refcount:2 nr_fill:1 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm:          (null) pset:ffff88207ff5a000\n[ 2819.389828] CPU18 PID31     hit[0] owner:21 m_nid:1 rep_nid:1 addr: 0x7fffb0000000\n[ 2819.398262] CPU18 PID31     rmap to pset:ffff88207ff5a000 set_idx: 0 nr_lru:63\n[ 2819.406310] CPU18 PID31   --   End Dump Victim Cache [2]\n\n#\n# This guy grabbed the fill counter right before the first timout\n# That's why the above three timeout happen. And this one is 20s later\n# which equals to the timeout second.\n#\n[ 2839.327457] CPU12 PID28 Abort victim alloc (20010ms) nr_usable_victims: 2. From pset_idx:0 nr_lru:63 fault_uva: 0x7fffb0000f00\n[ 2839.339964] CPU12 PID28   --   Start Dump Victim Cache [3] total: 2\n[ 2839.346945] CPU12 PID28  victim[0]:ffffffff810c2880 refcount:1 nr_fill:0 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm:          (null) pset:ffff88207ff5a000\n[ 2839.366046] CPU12 PID28     hit[0] owner:21 m_nid:1 rep_nid:1 addr: 0x7fffcc000000\n[ 2839.374480] CPU12 PID28     rmap to pset:ffff88207ff5a000 set_idx: 0 nr_lru:63\n[ 2839.382527] CPU12 PID28  victim[1]:ffffffff810c2900 refcount:2 nr_fill:1 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm:          (null) pset:ffff88207ff5a000\n[ 2839.401628] CPU12 PID28     hit[0] owner:21 m_nid:1 rep_nid:1 addr: 0x7fffb0000000\n[ 2839.410062] CPU12 PID28     rmap to pset:ffff88207ff5a000 set_idx: 0 nr_lru:63\n[ 2839.418109] CPU12 PID28   --   End Dump Victim Cache [3]\n</code></pre>"},{"location":"lego/log/log-08-2018/#rq-lock-deadlock","title":"rq-&gt;lock deadlock","text":"<p>Alright. We had rq-&gt;lock deadlock issue. Basically, we missed the part of disabling interrupt. A timer interrupt will try to acquire the lock again. Then, bang we have a deadlock. Digging into the code, you will be able to find the cause easily. The root cause we removed all the pi_lock stuff, which actually have a lot irqsave usages\u2026 Oh man, maybe it\u2019s time to add it back.</p> <pre><code>[ 3367.835389] ------------------- cut here -------------------\n[ 3367.841504] Possible deadlock happend locker_cpu: 0\n[ 3367.846934] Current call stack:\n[ 3367.850425] CPU: 0 PID: 1 Comm: kernel_init 4.0.0-lego+ #437\n[ 3367.856726] Stack:\n[ 3367.858957] ffff88107ff0fa58 ffffffff8101f4b6 ffff88107fc05e00 00000004a817c800\n[ 3367.867101] ffff88107ff0fa80 ffffffff8101f52e ffff88107fc05e00 ffff88107ffb4000\n[ 3367.875246] 0000000000000000 ffff88107ff0faa0 ffffffff8101b1ae ffff88107fc04980\n[ 3367.883390] 0000000000000000 ffff88107ff0fab8 ffffffff810174f5 0000000000000286\n[ 3367.891535] ffff88107ff0fae0 ffffffff81006774 ffff88107ffb9000 ffff88107fc05e00\n[ 3367.899680] Call Trace:\n[ 3367.902396] &lt;TSK&gt;\n[ 3367.904528] [&lt;ffffffff8101f4c2&gt;] report_deadlock+0x62/0x80\n[ 3367.910637] [&lt;ffffffff8101f52e&gt;] debug_spin_lock+0x4e/0x60\n[ 3367.916745] [&lt;ffffffff8101b1ae&gt;] scheduler_tick+0x2e/0x60\n[ 3367.922756] [&lt;ffffffff810174f5&gt;] tick_handle_periodic+0x45/0x70\n[ 3367.929350] [&lt;ffffffff81006774&gt;] apic_timer_interrupt+0x54/0x90\n[ 3367.935943] [&lt;ffffffff8100e8aa&gt;] smp__apic_timer_interrupt+0x6a/0x70\n[ 3367.943021] [&lt;ffffffff8101db99&gt;] ? enqueue_task_rt+0x149/0x250\n[ 3367.949518] [&lt;ffffffff8105908a&gt;] ? __mlx4_write_mtt+0xea/0x140\n[ 3367.956014] [&lt;ffffffff8101ad34&gt;] activate_task+0x44/0x50\n[ 3367.961929] [&lt;ffffffff8101b667&gt;] ttwu_do_activate+0x27/0x50\n[ 3367.968134] [&lt;ffffffff8101b89c&gt;] try_to_wake_up+0xdc/0x1f0\n[ 3367.974243] [&lt;ffffffff8106cc20&gt;] ? ib_mad_send_done_handler.isra.22+0x4d0/0x4d0\n[ 3367.982388] [&lt;ffffffff8101ba80&gt;] wake_up_process+0x10/0x20\n[ 3367.988497] [&lt;ffffffff81023116&gt;] __kthread_create_on_node+0x146/0x230\n[ 3367.995671] [&lt;ffffffff8102329f&gt;] kthread_create_on_node+0x2f/0x40\n[ 3368.002459] [&lt;ffffffff81066873&gt;] ? ib_create_cq+0x23/0x60\n[ 3368.008470] [&lt;ffffffff810695e1&gt;] ib_mad_init_device+0x1f1/0x7b0\n[ 3368.015064] [&lt;ffffffff81067246&gt;] ib_register_device+0x5d6/0x690\n[ 3368.021657] [&lt;ffffffff8105e9d3&gt;] mlx4_ib_add+0x653/0x780\n[ 3368.027571] [&lt;ffffffff8105147d&gt;] mlx4_add_device+0x8d/0x130\n[ 3368.033777] [&lt;ffffffff8105158c&gt;] mlx4_register_interface+0x6c/0xa0\n[ 3368.040661] [&lt;ffffffff811dc660&gt;] mlx4_ib_init+0x10/0x20\n[ 3368.046478] [&lt;ffffffff811dc619&gt;] mlx4_init+0x19/0x50\n[ 3368.052005] [&lt;ffffffff811dc68d&gt;] ib_core_init+0x1d/0x30\n[ 3368.057823] [&lt;ffffffff811db7f9&gt;] device_init+0x9/0x10\n[ 3368.063447] [&lt;ffffffff8100030b&gt;] kernel_init+0x4b/0xc0\n[ 3368.069168] [&lt;ffffffff8101b0ea&gt;] ? schedule_tail+0xa/0x40\n[ 3368.075178] [&lt;ffffffff810002c0&gt;] ? 0xffffffff810002c0\n[ 3368.080803] [&lt;ffffffff8100eb32&gt;] ret_from_fork+0x22/0x30\n[ 3368.086718] &lt;EOT&gt;\n</code></pre> <p>0830-w14-1: I really don\u2019t know how this happen. The refcounter and fill counter should be enough to serialize.. <pre><code>[37722.177024] CPU20 PID31  victim:ffffffff810c2880 index:0 refcount:0 nr_fill:0 max_fill:4 locked:0 flags:(0x12e)(allocated|usable|hasdata|waitflush|fillfree) pcm:          (null) pset:ffff88207ff5b980\n[37722.196623] CPU20 PID31     hit[0] owner:22 m_nid:1 rep_nid:1 addr: 0x2c33000\n[37722.204572] CPU20 PID31  victim:ffffffff810c2880 index:0 refcount:0 nr_fill:0 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm:          (null) pset:ffff88207ff5b980\n[37722.224154] CPU20 PID31     rmap to pset:ffff88207ff5b980 set_idx: 51 nr_lru:63\n[37722.232299] CPU20 PID31     victim dumped because: PCACHE_BUG_ON_VICTIM(!VictimAllocated(v) || !VictimUsable(v) || !VictimFlushed(v) || VictimWriteback(v) || VictimLocked(v))\n[37722.254790] WARNING: CPU: 20 PID: 31 at managers/processor/pcache/victim.c:196 __put_victim_nolist+0xb8/0x140\n ffffffff8103e170[37722.453632] [&lt;ffffffff8103c9c8&gt;] __put_victim_nolist+0xb8/0x140\n 0000000000000000[37722.461873] [&lt;ffffffff8103db18&gt;] victim_try_fill_pcache+0x2f8/0x440\n\n[37722.265842] CPU10 PID20  victim:ffffffff810c2880 index:0 refcount:0 nr_fill:0 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm:          (null) pset:ffff88207ff5b980\n[37722.291438] CPU10 PID20     hit[0] owner:22 m_nid:1 rep_nid:1 addr: 0x2c33000\n[37722.301616] CPU10 PID20  victim:ffffffff810c2880 index:0 refcount:0 nr_fill:0 max_fill:4 locked:0 flags:(0x14e)(allocated|usable|hasdata|flushed|fillfree) pcm:          (null) pset:ffff88207ff5b980\n[37722.324206] CPU10 PID20     rmap to pset:ffff88207ff5b980 set_idx: 51 nr_lru:63\n[37722.332349] CPU10 PID20     victim dumped because: PCACHE_BUG_ON_VICTIM(victim_ref_count(v) == 0)\n[37722.350673] WARNING: CPU: 10 PID: 20 at ./include/processor/pcache_victim.h:127 __victim_flush_func+0x232/0x250\n[37722.363568] CPU: 10 PID: 20 Comm: kvictim_flushd 4.0.0-lego+ #435\n[37722.534003] [&lt;ffffffff8103e152&gt;] __victim_flush_func+0x232/0x250\n[37722.547577] [&lt;ffffffff8103e1d9&gt;] victim_flush_async+0x69/0xb0\n[37722.553975] [&lt;ffffffff81022ec1&gt;] kthread+0x111/0x130\n[37722.565900] [&lt;ffffffff8100eb32&gt;] ret_from_fork+0x22/0x30\n</code></pre></p>"},{"location":"lego/log/log-08-2018/#aug-29","title":"Aug 29","text":"<p>The only thing left about core_IB is: ib_sa_query, which will be invoked when there is a mlx4 interrupts.</p> <p>Not sure if this is important.</p> <p>Anyway. Testing TF 4 threads MNIST again.</p> <p>When I enable SEQ_IBAPI\uff1a</p> <ul> <li>0829-w14-11 (0829-w09-11) succeed</li> <li>0829-w14-12: P side seems have deadlock. Let me enable DEBUG_SPINLOCK.</li> <li> <p>0829-w14-13: SEQ_IBAPI, DEBUG_SPINLOCK, this is a very useful log: <pre><code>[  531.495545] STDOUT: ---[\nINFO:tensorflow:loss = 0.5256375, step = 101 (25.166 sec)\n\n]---\n[  531.624474] BUG: unable to handle kernel NULL pointer dereference at 0000000000000064\n[  531.633016] IP: [&lt;ffffffff8103b60e&gt;] __put_victim_nolist+0xe/0xa0\n[  531.639803] PGD 0\n[  531.642032] Oops: 0002 [#1] SMP PROCESSOR\n[  531.646493] CPU: 10 PID: 20 Comm: kvictim_flushd 4.0.0-lego+ #426\n[  531.653279] RIP: 0010:[&lt;ffffffff8103b60e&gt;]  [&lt;ffffffff8103b60e&gt;] __put_victim_nolist+0xe/0xa0\n[  531.662781] RSP: 0000:ffff880fe392fde0  EFLAGS: 00010006\n[  531.668696] RAX: 0000000000000000 RBX: ffffffff810c2b00 RCX: ffffffff810c2b70\n[  531.676646] RDX: ffffffff810c2b70 RSI: 0000007aea3f42fa RDI: ffffffff810c2b00\n[  531.684597] RBP: ffff880fe392fdf0 R08: 000000000000001f R09: 0000000000000002\n[  531.692548] R10: 0000000080000000 R11: 00000000000664c3 R12: ffff88207ff57000\n[  531.700498] R13: ffffffff810c2b60 R14: ffff880a72555000 R15: ffffffff810c2b48\n[  531.708449] FS:  0000000000000000(0000) GS:ffff88107fca0000(0000) knlGS:0000000000000000\n[  531.717466] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[  531.723865] CR2: 0000000000000064 CR3: 00000000011b9000 CR4: 00000000000406a0\n[  531.731816] Stack:\n[  531.734046] ffffffff810c2b00 ffff88207ff57000 ffff880fe392fe08 ffffffff8103bbea\n[  531.742190] ffffffff810c2b00 ffff880fe392fe48 ffffffff8103c729 000000008103d7c2\n[  531.750335] ffff880a72555060 ffff88107ff0fdc8 0000000000000000 ffffffff8103c780\n[  531.758479] 0000000000000000 ffff880fe392fe60 ffffffff8103c7e6 ffff880fe391c000\n[  531.766623] ffff880fe392ff48 ffffffff81022e81 0000000000000000 0000000000000000\n[  531.774768] Call Trace:\n[  531.777483] &lt;TSK&gt;\n[  531.779617] [&lt;ffffffff8103bbea&gt;] __put_victim+0x4a/0x50\n[  531.785433] [&lt;ffffffff8103c729&gt;] __victim_flush_func+0xb9/0x110\n[  531.792027] [&lt;ffffffff8103c780&gt;] ? __victim_flush_func+0x110/0x110\n[  531.798911] [&lt;ffffffff8103c7e6&gt;] victim_flush_async+0x66/0x90\n[  531.805310] [&lt;ffffffff81022e81&gt;] kthread+0x111/0x130\n[  531.810836] [&lt;ffffffff81022d70&gt;] ? __kthread_parkme+0x70/0x70\n[  531.817236] [&lt;ffffffff8100eb32&gt;] ret_from_fork+0x22/0x30\n[  531.823151] &lt;EOT&gt;\n</code></pre></p> </li> <li> <p>0829-w14-14: this looks like a double free, or concurrent eviction. But if you look into the evict code, we will check the Flushed flag. It means another eviction routine should have skipped this line, and will not pick this line to do eviction. Some other possibilities?</p> </li> <li> <p>check until 0829-w14-18 <pre><code>[ 1671.661424] ------------[ cut here ]------------\n[ 1671.666378] BUG: failure at managers/processor/pcache/victim.c:610/victim_finish_insert()!\n[ 1671.675591] Kernel Panic - not syncing: BUG!\n[ 1671.680339] CPU: 20 PID: 31 Comm: python 4.0.0-lego+ #426\n[ 1671.686351] Stack:\n[ 1671.688581] ffff880fbe76fda0 ffffffff810289b7 ffffffff00000008 ffff880fbe76fdb0\n[ 1671.696725] ffff880fbe76fd68 ffffff0021475542 ffff88107fd45e00 ffff880fbe753000\n[ 1671.704870] 0000000000000000 0000000000000001 ffff880fbe76f9b0 ffffffff8101b1b7\n[ 1671.713015] ffff88107fd44980 ffff880fbe76f9d8 ffffffff8101405f 0000000000000000\n[ 1671.721160] 0000000000000001 ffff880ff992a000 0000000000000001 ffff880fbe76f9f0\n[ 1671.729304] Call Trace:\n[ 1671.732019] &lt;TSK&gt;\n[ 1671.734153] [&lt;ffffffff810289c3&gt;] panic+0xc2/0x10a\n[ 1671.739388] [&lt;ffffffff8101b1b7&gt;] ? scheduler_tick+0x57/0x60\n[ 1671.745593] [&lt;ffffffff8101405f&gt;] ? generic_smp_call_function_single_interrupt+0x8f/0x160\n[ 1671.754611] [&lt;ffffffff8100339e&gt;] ? call_function_interrupt+0x2e/0x40\n[ 1671.761688] [&lt;ffffffff8100e9fa&gt;] ? smp__call_function_interrupt+0x6a/0x70\n[ 1671.769251] [&lt;ffffffff8101f4bb&gt;] ? debug_spin_lock+0x1b/0x50\n[ 1671.775555] [&lt;ffffffff81075efc&gt;] ? fit_internal_poll_sendcq+0x6c/0x140\n[ 1671.782826] [&lt;ffffffff81042039&gt;] ? find_next_bit+0x19/0x20\n[ 1671.788934] [&lt;ffffffff8101f4bb&gt;] ? debug_spin_lock+0x1b/0x50\n[ 1671.795236] [&lt;ffffffff8101dcac&gt;] ? task_tick_rt+0x2c/0xd0\n[ 1671.801248] [&lt;ffffffff8101b1b7&gt;] ? scheduler_tick+0x57/0x60\n[ 1671.807453] [&lt;ffffffff810174d5&gt;] ? tick_handle_periodic+0x45/0x70\n[ 1671.814240] [&lt;ffffffff81006774&gt;] ? apic_timer_interrupt+0x54/0x90\n[ 1671.821029] [&lt;ffffffff8100e8aa&gt;] ? smp__apic_timer_interrupt+0x6a/0x70\n[ 1671.828300] [&lt;ffffffff81012bc8&gt;] ? printk+0x118/0x1b0\n[ 1671.833924] [&lt;ffffffff8103c161&gt;] victim_finish_insert+0x171/0x180\n[ 1671.840711] [&lt;ffffffff8103b2a2&gt;] pcache_evict_line+0xf2/0x2e0\n[ 1671.847110] [&lt;ffffffff81038d7c&gt;] pcache_alloc+0x1ac/0x380\n[ 1671.853122] [&lt;ffffffff8103a10c&gt;] ? pcache_add_rmap+0x7c/0x260\n[ 1671.859521] [&lt;ffffffff810382bb&gt;] common_do_fill_page+0x2b/0x1e0\n[ 1671.866114] [&lt;ffffffff81038631&gt;] pcache_handle_fault+0x1c1/0x620\n[ 1671.872804] [&lt;ffffffff81037fc0&gt;] ? pcache_meta_to_kva+0x30/0x30\n[ 1671.879398] [&lt;ffffffff8101006f&gt;] do_page_fault+0xaf/0x1c0\n[ 1671.885410] [&lt;ffffffff8100dedf&gt;] page_fault+0x1f/0x30\n</code></pre></p> </li> <li> <p>0829-w14-16: we got this by having debug_spinlock, and seq_ibapi. This is interesting and serious. I think our general C code is fine.. Should I go check the assembly part? This is the rq-&gt;lock? come on\u2026 <pre><code>[  683.748135] ------------------- cut here -------------------\n[  683.754252] Possible deadlock happend\n[  683.758323] Current call stack:\n[  683.761815] CPU: 4 PID: 39 Comm: python 4.0.0-lego+ #428\n[  683.767728] Stack:\n[  683.769959] ffff880fc1c1fc38 ffffffff8101f48c ffff88107fc45e00 ffff880fc1c1fc60\n[  683.778103] ffffffff8101f4e4 ffff88107fc45e00 ffff880fc23fb000 0000000000000000\n[  683.786247] ffff880fc1c1fc80 ffffffff8101b18e ffff88107fc44980 0000000000000004\n[  683.794391] ffff880fc1c1fc98 ffffffff810174d5 ffffffff8101dddb ffff880fc1c1fcc0\n[  683.802537] ffffffff81006774 ffff88107fc45e00 00000004a817c800 0000009a8a78c5e7\n[  683.810680] Call Trace:\n[  683.813396] &lt;TSK&gt;\n[  683.815528] [&lt;ffffffff8101f498&gt;] report_deadlock+0x58/0x60\n[  683.821637] [&lt;ffffffff8101f4e4&gt;] debug_spin_lock+0x44/0x50\n[  683.827745] [&lt;ffffffff8101b18e&gt;] scheduler_tick+0x2e/0x60\n[  683.833758] [&lt;ffffffff810174d5&gt;] tick_handle_periodic+0x45/0x70\n[  683.840351] [&lt;ffffffff8101dddb&gt;] ? dequeue_task_rt+0x1b/0x180\n[  683.846750] [&lt;ffffffff81006774&gt;] apic_timer_interrupt+0x54/0x90\n[  683.853343] [&lt;ffffffff8100e8aa&gt;] smp__apic_timer_interrupt+0x6a/0x70\n[  683.860421] [&lt;ffffffff8101f4d1&gt;] ? debug_spin_lock+0x31/0x50\n[  683.866723] [&lt;ffffffff8101b86e&gt;] try_to_wake_up+0xce/0x1f0\n[  683.872832] [&lt;ffffffff8101b9e4&gt;] wake_up_q+0x54/0xc0\n[  683.878358] [&lt;ffffffff81028487&gt;] do_futex+0x407/0x620\n[  683.883982] [&lt;ffffffff8103a941&gt;] ? pcache_add_rmap+0xb1/0x600\n[  683.890381] [&lt;ffffffff8102870c&gt;] sys_futex+0x6c/0x130\n[  683.896005] [&lt;ffffffff8100ec66&gt;] do_syscall_64+0x36/0xc0\n[  683.901919] [&lt;ffffffff8100db6c&gt;] entry_SYSCALL64_slow_path+0x25/0x25\n</code></pre></p> </li> </ul>"},{"location":"lego/log/log-08-2018/#aug-27","title":"Aug 27","text":"<p>There a lot lost CQE cases. This one is about P-&gt;M-&gt;S. And M lost the CQE for the WQE sent to S. <pre><code>0827-w9-5\n[  963.304865] watchdog: worker[0] CPU10 stucked\n[  963.309712] watchdog:  common_header [op=0x20000000 src_nid:0]\n[  963.316210] CPU: 10 PID: 20 Comm: thpool-worker0 4.0.0-lego+ #43\n[  963.322899] RIP: 0010:[&lt;ffffffff8106ad51&gt;]  [&lt;ffffffff8106ad51&gt;] fit_send_reply_with_rdma_write_with_imm+0x2a1/0x3a0\n[  963.334632] RSP: 0000:ffff88103ef3fc20  EFLAGS: 00000287\n[  963.340547] RAX: 00000000ffffb6d4 RBX: 000000000000000b RCX: 0000000000001770\n[  963.348498] RDX: 00000000ffffa70d RSI: fffffffffffff039 RDI: 0000000000000000\n[  963.356450] RBP: ffff88103ef3fcc0 R08: 000000000000001f R09: 0000000000000002\n[  963.364400] R10: 0000000080000000 R11: 000077ff80000000 R12: 0000000000000000\n[  963.372352] R13: ffff88103ef26738 R14: 00000000000b3d54 R15: ffff88103ef25008\n[  963.380303] FS:  0000000000000000(0000) GS:ffff88107fca0000(0000) knlGS:0000000000000000\n[  963.389320] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[  963.395720] CR2: 0000000000000000 CR3: 000000000116a000 CR4: 00000000000406a0\n[  963.403671] Stack:\n[  963.405901] 00007fff000b3d54 ffffffff800b3d54 ffff881000000004 ffff88103ef3fc78\n[  963.414045] 0000000900000000 ffff881000000000 0000100800000001 ffff88103d216000\n[  963.422191] ffff88103eebae48 800b3d540000011c ffffff9b00000246 ffffea0000000001\n[  963.430337] 000000103d216000 0000000000010c00 000000000000011c 0000000000001008\n[  963.438481] 000000000000011c 0000000000001008 ffff88103eebae48 ffff88103ef3fd70\n[  963.446626] Call Trace:\n[  963.449342] &lt;TSK&gt;\n[  963.451475] [&lt;ffffffff81067c80&gt;] ibapi_send_reply_imm+0x50/0xd0\n[  963.458068] [&lt;ffffffff8102e953&gt;] ? __storage_read+0xc3/0x120\n[  963.464371] [&lt;ffffffff8102e953&gt;] __storage_read+0xc3/0x120\n[  963.470480] [&lt;ffffffff8102e9bf&gt;] storage_read+0xf/0x50\n[  963.476201] [&lt;ffffffff8102eab7&gt;] storage_vma_fault+0xb7/0x130\n[  963.482600] [&lt;ffffffff8103262f&gt;] handle_lego_mm_fault+0x13f/0x4a0\n[  963.489389] [&lt;ffffffff8102ecf4&gt;] common_handle_p2m_miss.isra.1+0x54/0xc0\n[  963.496855] [&lt;ffffffff8102edc7&gt;] handle_p2m_pcache_miss+0x67/0x2d0\n[  963.503739] [&lt;ffffffff8102bf96&gt;] thpool_worker_func+0x296/0x3a0\n[  963.510332] [&lt;ffffffff8102bd00&gt;] ? handle_bad_request+0x40/0x40\n[  963.516926] [&lt;ffffffff81020ca6&gt;] kthread+0xf6/0x120\n[  963.522357] [&lt;ffffffff81020bb0&gt;] ? __kthread_parkme+0x70/0x70\n[  963.528756] [&lt;ffffffff8100e632&gt;] ret_from_fork+0x22/0x30\n</code></pre></p> <p>hmm, another on lost CQE happen at P. Today is weird, why we happen to have so many lost CQE today?</p> <p>Think about why CQE is not generated?</p> <pre><code>0827-w14-6\n[ 1185.835707]\n*****\n***** Fail to to get the CQE from send_cq after 20 seconds!\n***** This means the packet was lost and something went wrong\n***** with your NIC...\n***** connection_id: 7 dest node: 1\n*****\n[ 1185.856465] IB Stats:\n[ 1185.858985]     nr_ib_send_reply:            3452\n[ 1185.864221]     nr_bytes_tx:               506507\n[ 1185.869456]     nr_bytes_rx:              8981004\n[ 1185.874692] ------------[ cut here ]------------\n[ 1185.879829] WARNING: CPU: 14 PID: 22 at net/lego/fit_internal.c:1108 fit_internal_poll_sendcq+0xe5/0x140\n[ 1185.890399] CPU: 14 PID: 22 Comm: python 4.0.0-lego+ #356\n[ 1185.896410] Stack:\n[ 1185.898640] ffff88103c49fb30 ffffffff810126f5 ffff88103cb22000 00000004a817c800\n[ 1185.906784] 0000010f7139214f 0000000000000007 ffff88103c49fb40 ffffffff810127cf\n[ 1185.914927] ffff88103c49fbf0 ffffffff810724b5 000000023cb2c280 ffff88103cb2c1f8\n[ 1185.923072] 0000000000000286 ffff88103c49fc18 ffff88103cb06000 ffff88103cb2c150\n[ 1185.931217] 000000000000024b ffff88108101c7dc ffff88107fce5d80 ffff88103c46f000\n[ 1185.939360] Call Trace:\n[ 1185.942075] &lt;TSK&gt;\n[ 1185.944209] [&lt;ffffffff81012701&gt;] __warn.constprop.1+0x91/0xd0\n[ 1185.950607] [&lt;ffffffff810127cf&gt;] warn_slowpath_null+0xf/0x20\n[ 1185.956909] [&lt;ffffffff810724b5&gt;] fit_internal_poll_sendcq+0xe5/0x140\n[ 1185.963987] [&lt;ffffffff81019dd5&gt;] ? scheduler_tick+0x55/0x60\n[ 1185.970192] [&lt;ffffffff81072662&gt;] fit_send_message_with_rdma_write_with_imm_request+0x152/0x350\n[ 1185.979791] [&lt;ffffffff810741ff&gt;] fit_send_reply_with_rdma_write_with_imm+0x25f/0x3a0\n[ 1185.988420] [&lt;ffffffff810368c2&gt;] ? __pcache_do_fill_page+0xc2/0x1d0\n[ 1185.995401] [&lt;ffffffff810701e9&gt;] ibapi_send_reply_timeout+0x79/0x120\n[ 1186.002479] [&lt;ffffffff810368c2&gt;] ? __pcache_do_fill_page+0xc2/0x1d0\n[ 1186.009459] [&lt;ffffffff810368c2&gt;] __pcache_do_fill_page+0xc2/0x1d0\n[ 1186.016245] [&lt;ffffffff81036ac4&gt;] common_do_fill_page+0xf4/0x1f0\n[ 1186.022839] [&lt;ffffffff81036d80&gt;] pcache_handle_fault+0x1c0/0x610\n[ 1186.029528] [&lt;ffffffff81036800&gt;] ? __pcache_do_zerofill_page+0x100/0x100\n[ 1186.036995] [&lt;ffffffff8100fdff&gt;] do_page_fault+0xaf/0x1c0\n[ 1186.043005] [&lt;ffffffff8100dc1f&gt;] page_fault+0x1f/0x30\n</code></pre>"},{"location":"lego/log/log-08-2018/#aug-26","title":"Aug 26","text":"<p>Oh well. I saw the same damn lost packet issue again. The issue can be desribed as: P use lite rpc to send a request to M. M processed the handled, and called rpc reply to sent back to P. M need to poll send_cq to poll completion. But M fail to get the CQE for the should-be-sent-out WQE.</p> <p>This is tested with M\u2019s <code>CONFIG_FIT_NOWAIT</code> optimization, which is basically an optimization that M will not poll cq every time a reply was sent out, instead, do batch polling.</p> <p>The following stack dump was reported by M side watchdog. It is not necessary mlx4_poll_cq\u2019s issue, since there is a while (1) loop at fit code. Oh well. <pre><code>Log name: 0826-w9-1\n\n[187736.669027] watchdog: worker[0] CPU10 stucked\n[187736.673972] watchdog:  common_header [op=0x30000000 src_nid:0]\n[187736.680566] CPU: 10 PID: 20 Comm: thpool-worker0 4.0.0-lego+ #26\n[187736.687351] RIP: 0010:[&lt;ffffffff810522c3&gt;]  [&lt;ffffffff810522c3&gt;] mlx4_ib_poll_cq+0x1d3/0x850\n[187736.696854] RSP: 0000:ffff88103ef3f750  EFLAGS: 00000286\n[187736.702865] RAX: 00000000fffffff5 RBX: 0000000000000000 RCX: ffff88103ed6b050\n[187736.710913] RDX: 0000000080630000 RSI: 0000000000000001 RDI: ffff88103edb0bf0\n[187736.718961] RBP: ffff88103ef3f7b8 R08: 0000000000000020 R09: 0000000000000002\n[187736.727007] R10: 0000000ffc53fddc R11: 0000000040bf1040 R12: ffff88103ef3f7c8\n[187736.735055] R13: 0000000000000000 R14: 0000000000000000 R15: ffff88103edb0bf0\n[187736.743104] FS:  0000000000000000(0000) GS:ffff88107fca0000(0000) knlGS:0000000000000000\n[187736.752218] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[187736.758714] CR2: 0000000000000000 CR3: 000000000116a000 CR4: 00000000000406a0\n[187736.766762] Stack:\n[187736.769089] 0000000ffc53fddc 0000000000000002 0000000000000020 ffff88103edb0c98\n[187736.777331] 0000000000000286 0000000080630000 ffff88103ef3f7d0 0000638000000018\n[187736.785572] ffff88103edb0bf0 0000000000000001 ffff88103ef25008 0000000000000003\n[187736.793813] 000000000000000c ffff88103ef3fd30 ffffffff8106920c ffff88103ef3fd54\n[187736.802054] 0000000100000000 0000000100000000 ffff88103edb07b0 ffff88103e81b008\n[187736.810296] Call Trace:\n[187736.813108] &lt;TSK&gt;\n[187736.815338] [&lt;ffffffff8106920c&gt;] fit_internal_poll_sendcq+0x6c/0xe0\n[187736.822416] [&lt;ffffffff8106ab2f&gt;] ? fit_send_reply_with_rdma_write_with_imm+0x25f/0x3a0\n[187736.831336] [&lt;ffffffff81033ff0&gt;] ? _lego_copy_to_user+0x110/0x250\n[187736.838220] [&lt;ffffffff81028d65&gt;] ? __free_pages+0x25/0x30\n[187736.844329] [&lt;ffffffff8102e981&gt;] ? __storage_read+0xf1/0x120\n[187736.850728] [&lt;ffffffff81019865&gt;] ? scheduler_tick+0x55/0x60\n[187736.857031] [&lt;ffffffff810693d2&gt;] ? fit_send_message_with_rdma_write_with_imm_request+0x152/0x350\n[187736.866920] [&lt;ffffffff810693d2&gt;] ? fit_send_message_with_rdma_write_with_imm_request+0x152/0x350\n[187736.876810] [&lt;ffffffff8103043f&gt;] ? __vma_adjust+0x38f/0x550\n[187736.883113] [&lt;ffffffff81030944&gt;] ? vma_merge+0x1a4/0x280\n[187736.889123] [&lt;ffffffff81030f20&gt;] ? arch_get_unmapped_area_topdown+0xe0/0x220\n[187736.897075] [&lt;ffffffff810693d2&gt;] fit_send_message_with_rdma_write_with_imm_request+0x152/0x350\n[187736.906771] [&lt;ffffffff81069ab5&gt;] fit_ack_reply_callback+0x185/0x1e0\n[187736.913848] [&lt;ffffffff8102f129&gt;] ? handle_p2m_flush_one+0x69/0x160\n[187736.920830] [&lt;ffffffff8102bde0&gt;] thpool_worker_func+0xe0/0x3a0\n[187736.927424] [&lt;ffffffff8102bd00&gt;] ? handle_bad_request+0x40/0x40\n[187736.934113] [&lt;ffffffff81020ca6&gt;] kthread+0xf6/0x120\n[187736.939639] [&lt;ffffffff81020bb0&gt;] ? __kthread_parkme+0x70/0x70\n[187736.946137] [&lt;ffffffff8100e632&gt;] ret_from_fork+0x22/0x30\n</code></pre></p>"},{"location":"lego/log/log-08-2018/#aug-22","title":"Aug 22","text":"<p>Damn it!!! After so much effort verifying we had a solid IB stack, we still has memory corruption and deadlock issues. Fuck!</p> <p>One thing at a time, simple stuff first. Okay, tomorrow first add DEBUG_SPINLOCK to detect possible deadlocks. This, could help to identify some buggy code. After this, I will spend some time looking into the LITE, it\u2019s fucking HEAVY. I do found a lot issues during summer.</p> <p>Personally, I\u2019m not feeling good this days. I treat someone with love and respect, but there is not too much in return. Yeahyeahyeah, I know how this works. It\u2019s just sad that sometimes you just have a BAD timing. I\u2019ve went through too much things in 2018, good and bad. I care sooo much about the people I love, family and others. I feel this is good, of course. Anyway, it is supposed to be a Lego dump, that no one probably interested in.</p>"},{"location":"lego/log/log-09-2018/","title":"Sep 2018","text":""},{"location":"lego/log/log-09-2018/#sep-20","title":"Sep 20","text":"<pre><code>[   54.602054] nr_pcache_pee_free: 0\n[   54.602537] nr_pcache_pee_free_kmalloc: 0\n[ 1468.765410] mlx4_msi_x_interrupt(): IRQ: 27 CPU: 1\n[ 1468.766956] event PORT_MNG_CHG arrived\n[ 1468.768193] &lt;mlx4_ib&gt; handle_port_mgmt_change_event: rereg  \n[ 1468.813660] ib_cache: ib_cache_update(): Updated port 1 of dev 0000:00:08.0\n[ 1468.815097] ib_sa_event(): TODO\n[ 1479.178651] mlx4_msi_x_interrupt(): IRQ: 27 CPU: 1\n[ 1479.180201] event PORT_MNG_CHG arrived\n[ 1479.181430] &lt;mlx4_ib&gt; handle_port_mgmt_change_event: rereg\n[ 1479.190813] bad: scheduling from the idle thread!\n[ 1479.192158] CPU: 1 PID: 0 Comm: swapper/1 4.0.0-lego+ #146\n[ 1479.193622] Stack:\n[ 1479.194408] ffff88083fddf980 ffffffff8101eefc ffff88083fc45d80 ffff88083fc45d80\n[ 1479.196826] ffff88083fddf9a8 ffffffff8101ace4 00000001810067d4 ffff88083fe43000\n[ 1479.199226] ffffffffffff0000 ffff88083fddf9e0 ffffffff81078bf6 ffffffff8100e8ea\n[ 1479.203615] ffffffffffff0000 0000000000000000 ffff88083fe43000 ffff88083fe43000\n[ 1479.206532] ffff88083fddf9f8 ffffffff81078ca3 7fffffffffffffff ffff88083fddfa68\n[ 1479.208791] Call Trace:\n[ 1479.209606] &lt;TSK&gt;\n[ 1479.210322] [&lt;ffffffff8101ef08&gt;] dequeue_task_idle+0x48/0x60\n[ 1479.211726] [&lt;ffffffff8101ace4&gt;] deactivate_task+0x44/0x50\n[ 1479.213092] [&lt;ffffffff81078bf6&gt;] __schedule+0x146/0x1e0\n[ 1479.214410] [&lt;ffffffff8100e8ea&gt;] ? smp__apic_timer_interrupt+0x6a/0x70\n[ 1479.215960] [&lt;ffffffff81078ca3&gt;] schedule+0x13/0x30\n[ 1479.217211] [&lt;ffffffff810789da&gt;] schedule_timeout+0x12a/0x1a0\n[ 1479.218625] [&lt;ffffffff81079e54&gt;] __down_common+0xaa/0x103\n[ 1479.219904] [&lt;ffffffff81079ec5&gt;] __down+0x18/0x1a\n[ 1479.221046] [&lt;ffffffff8101f24c&gt;] down+0x3c/0x40\n[ 1479.222163] [&lt;ffffffff8104dba7&gt;] __mlx4_cmd+0x1d7/0x3c0\n[ 1479.223397] [&lt;ffffffff810619de&gt;] mlx4_MAD_IFC+0x22e/0x490\n[ 1479.224666] [&lt;ffffffff8105d321&gt;] __mlx4_ib_query_pkey+0x181/0x240\n[ 1479.226045] [&lt;ffffffff8105d3f3&gt;] mlx4_ib_query_pkey+0x13/0x20\n[ 1479.227365] [&lt;ffffffff81064cb4&gt;] ib_query_pkey+0x14/0x20\n[ 1479.228617] [&lt;ffffffff810651a7&gt;] ib_cache_update+0x237/0x480\n[ 1479.229862] [&lt;ffffffff810657f8&gt;] ib_cache_event+0x28/0x30\n[ 1479.231026] [&lt;ffffffff81064bf0&gt;] ib_dispatch_event+0x40/0x70\n[ 1479.232222] [&lt;ffffffff810627c8&gt;] handle_port_mgmt_change_event+0x158/0x1c0\n[ 1479.233602] [&lt;ffffffff8105b5ac&gt;] mlx4_ib_event+0x7c/0xa0\n[ 1479.234744] [&lt;ffffffff8104ee55&gt;] mlx4_dispatch_event+0x65/0x90\n[ 1479.235968] [&lt;ffffffff8104f2c3&gt;] mlx4_eq_int+0x273/0x4f0\n[ 1479.237113] [&lt;ffffffff8104f616&gt;] mlx4_msi_x_interrupt+0x36/0x40\n[ 1479.238352] [&lt;ffffffff81017894&gt;] handle_irq_event_percpu+0x24/0xa0\n[ 1479.239584] [&lt;ffffffff81017938&gt;] handle_irq_event+0x28/0x50\n[ 1479.240696] [&lt;ffffffff810180fe&gt;] handle_edge_irq+0x5e/0xc0\n[ 1479.241794] [&lt;ffffffff810054c3&gt;] do_IRQ+0x43/0xd0\n[ 1479.242779] [&lt;ffffffff810067d4&gt;] ? apic_timer_interrupt+0x54/0x90\n[ 1479.243971] [&lt;ffffffff8100e0aa&gt;] common_interrupt+0x6a/0x6a\n[ 1479.245084] [&lt;ffffffff8101c6b0&gt;] ? cpu_idle+0x10/0x30\n[ 1479.246123] [&lt;ffffffff81003425&gt;] start_secondary_cpu+0x55/0x60\n[ 1479.247278] &lt;EOT&gt;\n</code></pre>"},{"location":"lego/log/log-09-2018/#sep-17","title":"Sep 17","text":"<p>Can not believe I\u2019m wasting time on this crap X again.</p>"},{"location":"lego/log/log-09-2018/#sep-16","title":"Sep 16","text":"<p>Tests done today:</p> Setting Log nr_workers Tracing (strace/counter/profiling) Runtime (s) pcache_flush_net (us) TF-MNIST, Linux 13.2s TF4-MNIST, 128MB 0916-w14-1 1 ON avg 48.5s 9891 TF4-MNIST, 128MB 0916-w14-2 1 OFF (46.1+44.6+45.5+45.7+44)/5 = 45.2s N/A TF4-MNIST, 128MB 0916-w14-4 4 ON (43.4+44+43.9+42.6+42.1)/5=43.2 8351 TF4-MNIST, 128MB 0916-w14-3 4 OFF (40.1+42.1+42.0+41.7+42.1)/5 = 41.6 N/A TF4-Cifar, Linux 235.5s TF4-Cifar, 128MB 0916-w14-5 4 OFF (636.2+635.0+636.8+637.2+634.1)/5=635.8 N/A TF4-Cifar, 128MB 0916-w14-6 1 OFF (660.2+662.2+662.8+663.8+661+5)/5=663s N/A TF4-Cifar, 256MB 0916-w14-7 1 OFF 486s N/A"},{"location":"lego/log/log-09-2018/#sep-15","title":"Sep 15","text":"<p>DAMN.</p> <p>Let us summarize today. Okay. Fixed the double-post-cqe issue. Hehe. The post part is the only fucking left code that I did not look into at fit_poll_recv_cq. And, ironically, there is no error checking for ib_post_recv(), which won\u2019t generate any error/warning.</p> <p>error checking error checking\u2026</p> <p>Anyway fuck it.</p> <p>Today I created a new tag v0.0.9, hope we have a stable net. The RPC profile code is very stressing, and fit survived.</p> <p>The following wanring is fixed by post rx_depth/2. <pre><code>[ 1812.017204] fit: To align first QPN, we skipped: #72 #72 #73 #74 #75 #76 #77 #78 #79\n[ 1812.157570] fit: fit_post_receives_message()-628 CPU 2 Fail to post recv conn_id: 12\n[ 1812.166013] ------------[ cut here ]------------\n[ 1812.171152] WARNING: CPU: 2 PID: 16 at net/lego/fit_internal.c:629 fit_post_receives_message.isra.7+0xce/0x100\n[ 1812.182302] CPU: 2 PID: 16 Comm: ib-initd 4.0.0-lego+ #95\n[ 1812.188314] Stack:\n[ 1812.190544] ffff880ff98bfd50 ffffffff8101299b 0000000000000cff 0000000000000060\n[ 1812.198689] 0000000000000d00 0000000000000100 ffff880ff98dc030 ffff880ff98bfd60\n[ 1812.206834] ffffffff81012a8f ffff880ff98bfdc8 ffffffff810743de fffffff4fffffff4\n[ 1812.214978] ffff880ff98bfd80 0000000000000000 0000000000000cff 0000000000000000\n[ 1812.223124] 0000000000000000 ffff880ff98dc000 0000000000000000 000000000000000c\n[ 1812.231269] Call Trace:\n[ 1812.233984] &lt;TSK&gt;\n[ 1812.236116] [&lt;ffffffff810129a7&gt;] __warn.constprop.0+0xa7/0x100\n[ 1812.242613] [&lt;ffffffff81012a8f&gt;] warn_slowpath_null+0xf/0x20\n[ 1812.248915] [&lt;ffffffff810743de&gt;] fit_post_receives_message.isra.7+0xce/0x100\n[ 1812.256770] [&lt;ffffffff81076a1a&gt;] fit_add_newnode+0xca/0x170\n[ 1812.262974] [&lt;ffffffff81079d10&gt;] fit_establish_conn+0x7b0/0xaa0\n[ 1812.269568] [&lt;ffffffff81073ce8&gt;] ? ibv_add_one+0x98/0x120\n[ 1812.275580] [&lt;ffffffff810741f0&gt;] ? ibapi_get_node_id+0x20/0x20\n[ 1812.282076] [&lt;ffffffff81074258&gt;] lego_ib_init+0x68/0xf0\n[ 1812.287893] [&lt;ffffffff81023261&gt;] kthread+0x111/0x130\n[ 1812.293421] [&lt;ffffffff81023150&gt;] ? __kthread_parkme+0x70/0x70\n[ 1812.299820] [&lt;ffffffff8100eaf2&gt;] ret_from_fork+0x22/0x30\n[ 1812.305735] &lt;EOT&gt;\n[ 1812.307868] ---[ end trace 0000000000000000 ]---\n</code></pre></p>"},{"location":"lego/log/log-09-2018/#sep-11","title":"Sep 11","text":"<p>Got this log, 5 machine, p2s_open, S side has this issue. Damn.</p> <pre><code>[ 1672.962279]                                                                                                                                                                                                                                \n*****                                                                                                                                                                                                                                         \n***** Fail to to get the CQE from send_cq after 20 seconds!                                                                                                                                                                                   \n***** This means the packet was lost and something went wrong                                                                                                                                                                                 \n***** with your NIC...\n***** connection_id: 11 dest node: 0\n*****\n[ 1673.061668] ------------[ cut here ]------------\n[ 1673.074937] WARNING: CPU: 10 PID: 4624 at /root/ys/LegoOS_2M/linux-modules/fit/fit_internal.c:956 fit_internal_poll_sendcq+0xda/0x130 [fit]()\n[ 1673.101557] Modules linked in: storage(OF) fit(OF) xt_CHECKSUM iptable_mangle ipt_MASQUERADE iptable_nat nf_nat_ipv4 nf_nat nf_conntrack_ipv4 nf_defrag_ipv4 xt_conntrack nf_conntrack ipt_REJECT tun bridge stp llc ebtable_filter ebtable\ns ip6table_filter ip6_tables iptable_filter xprtrdma sunrpc ib_isert iscsi_target_mod ib_iser libiscsi scsi_transport_iscsi ib_srpt target_core_mod ib_srp scsi_transport_srp scsi_tgt ib_ipoib rdma_ucm ib_ucm ib_uverbs ib_umad rdma_cm ib_c\nm iw_cm ib_addr x86_pkg_temp_thermal coretemp kvm_intel kvm crc32_pclmul ghash_clmulni_intel aesni_intel lrw gf128mul glue_helper ipmi_devintf ablk_helper cryptd ipmi_si iTCO_wdt ipmi_msghandler iTCO_vendor_support dcdbas sg pcspkr shpchp\n acpi_power_meter lpc_ich mfd_core wmi mperf uinput binfmt_misc ip_tables ext4 mbcache jbd2 mlx4_ib\n[ 1673.182609]  ib_sa ib_mad ib_core mlx4_en sd_mod crc_t10dif mgag200 syscopyarea sysfillrect sysimgblt i2c_algo_bit drm_kms_helper ttm drm ahci crc32c_intel libahci mlx4_core libata tg3 nvme megaraid_sas ptp i2c_core pps_core dm_mirror\ndm_region_hash dm_log dm_mod\n[ 1673.222604] CPU: 10 PID: 4624 Comm: lego-storaged Tainted: GF       W  O 3.11.1-vanilla #1\n[ 1673.235825] Hardware name: Dell Inc. PowerEdge R730/0599V5, BIOS 1.5.4 10/002/2015\n[ 1673.248883]  0000000000000009 ffff88102186b9f8 ffffffff8159a5a4 0000000000000000\n[ 1673.261795]  ffff88102186ba30 ffffffff810641bd ffff882027180400 00000004a817c800\n[ 1673.274499]  00000180dc3abde5 0000000000000000 0000000000000000 ffff88102186ba40\n[ 1673.287034] Call Trace:\n[ 1673.299259]  [&lt;ffffffff8159a5a4&gt;] dump_stack+0x45/0x56\n[ 1673.311371]  [&lt;ffffffff810641bd&gt;] warn_slowpath_common+0x7d/0xa0\n[ 1673.323268]  [&lt;ffffffff8106429a&gt;] warn_slowpath_null+0x1a/0x20\n[ 1673.334892]  [&lt;ffffffffa063669a&gt;] fit_internal_poll_sendcq+0xda/0x130 [fit]\n[ 1673.346348]  [&lt;ffffffff81093e25&gt;] ? check_preempt_curr+0x85/0xa0\n[ 1673.357575]  [&lt;ffffffffa06367f7&gt;] fit_send_message_with_rdma_write_with_imm_request+0x107/0x3f0 [fit]\n[ 1673.368777]  [&lt;ffffffff8107bde4&gt;] ? wake_up_worker+0x24/0x30\n[ 1673.379741]  [&lt;ffffffffa0636ee9&gt;] fit_reply_message+0x89/0xa0 [fit]\n[ 1673.390497]  [&lt;ffffffffa063507b&gt;] ibapi_reply_message+0x1b/0x20 [fit]\n[ 1673.401039]  [&lt;ffffffffa0646785&gt;] handle_open_request+0xa5/0xe0 [storage]\n[ 1673.411367]  [&lt;ffffffffa0646106&gt;] storage_manager+0x106/0x300 [storage]\n[ 1673.421470]  [&lt;ffffffffa0646000&gt;] ? 0xffffffffa0645fff\n[ 1673.431297]  [&lt;ffffffffa0646000&gt;] ? 0xffffffffa0645fff\n[ 1673.440797]  [&lt;ffffffff81085ec0&gt;] kthread+0xc0/0xd0\n[ 1673.450034]  [&lt;ffffffff81085e00&gt;] ? insert_kthread_work+0x40/0x40\n[ 1673.459063]  [&lt;ffffffff815a94ac&gt;] ret_from_fork+0x7c/0xb0\n[ 1673.467837]  [&lt;ffffffff81085e00&gt;] ? insert_kthread_work+0x40/0x40\n[ 1673.476400] ---[ end trace f9b19a31d409f910 ]---\n[ 1695.867276] storage_self_monitor(): in_handler=1\n[ 1695.875906] handle_replica_flush: 0\n[ 1695.884613] handle_replica_vma: 0\n[ 1695.893265] handle_replica_read: 12740\n[ 1695.901920] handle_replica_write: 0\n[ 1713.012565] INFO: rcu_sched self-detected stall on CPU { 10}  (t=60001 jiffies g=7646 c=7645 q=0)\n[ 1713.013339] sending NMI to all CPUs:\n[ 1713.013573] INFO: rcu_sched detected stalls on CPUs/tasks: { 10} (detected by 15, t=60002 jiffies, g=7646, c=7645, q=0)\n[ 1713.014807] NMI backtrace for cpu 0\n[ 1713.015685] CPU: 0 PID: 4591 Comm: wq_handler Tainted: GF       W  O 3.11.1-vanilla #1\n[ 1713.016624] Hardware name: Dell Inc. PowerEdge R730/0599V5, BIOS 1.5.4 10/002/2015\n[ 1713.017575] task: ffff88201f193b40 ti: ffff88101a34a000 task.ti: ffff88101a34a000\n[ 1713.018530] RIP: 0010:[&lt;ffffffffa0636b55&gt;]  [&lt;ffffffffa0636b55&gt;] waiting_queue_handler+0x75/0x140 [fit]\n[ 1713.018530] RIP: 0010:[&lt;ffffffffa0636b55&gt;]  [&lt;ffffffffa0636b55&gt;] waiting_queue_handler+0x75/0x140 [fit]\n[ 1713.019512] RSP: 0018:ffff88101a34be78  EFLAGS: 00000296\n[ 1713.020444] RAX: 0000000000080080 RBX: ffff8820200253f0 RCX: ffff88201f193b40\n[ 1713.021364] RDX: 0000000000000001 RSI: ffff88103f414760 RDI: ffff88103f4146c0\n[ 1713.022260] RBP: ffff88101a34bec8 R08: 0000000000000000 R09: 0000000000000001\n[ 1713.023138] R10: 0000000000000001 R11: ffffffffa0636b55 R12: ffff8820200253c0\n[ 1713.024000] R13: ffff881022005000 R14: ffffffffa063b8e4 R15: ffffffffa063b8e4\n[ 1713.024839] FS:  0000000000000000(0000) GS:ffff88103f400000(0000) knlGS:0000000000000000\n[ 1713.025676] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 1713.026481] CR2: 00007fd77ef46000 CR3: 0000000001876000 CR4: 00000000001407f0\n[ 1713.027273] Stack:\n[ 1713.028035]  ffff881000000000 ffff881000300660 ffff882000000003 0000000000000000\n[ 1713.028818]  ffff881000000000 ffff881021eafc38 ffff881022005000 ffffffffa0636ae0\n[ 1713.029585]  0000000000000000 0000000000000000 ffff88101a34bf48 ffffffff81085ec0\n[ 1713.030350] Call Trace:\n[ 1713.031098]  [&lt;ffffffffa0636ae0&gt;] ? fit_send_message_with_rdma_write_with_imm_request+0x3f0/0x3f0 [fit]\n[ 1713.031875]  [&lt;ffffffff81085ec0&gt;] kthread+0xc0/0xd0\n[ 1713.032641]  [&lt;ffffffff81085e00&gt;] ? insert_kthread_work+0x40/0x40\n[ 1713.033407]  [&lt;ffffffff815a94ac&gt;] ret_from_fork+0x7c/0xb0\n[ 1713.034171]  [&lt;ffffffff81085e00&gt;] ? insert_kthread_work+0x40/0x40\n</code></pre>"},{"location":"lego/log/log-09-2018/#sep-08","title":"Sep 08","text":"<p>Check this log out: <pre><code>]---\n[  427.218569] STDOUT: ---[\nINFO:tensorflow:Graph was finalized.\n\n]---\n[  427.416043] BUG: unable to handle kernel NULL pointer dereference at           (null)\n[  427.424583] IP: [&lt;ffffffff810748fb&gt;] fit_poll_recv_cq+0x5cb/0x860\n[  427.431370] mlx4_msi_x_interrupt(): IRQ: 27 CPU: 0\n[  427.436702] PGD 0\n[  427.438932] CQ_ERROR CQ overrun on CQN 000082\n[  427.443780] Oops: 0002 [#1] SMP PROCESSOR\n[  427.448240] event qp_event arrived\n[  427.452022] CPU: 6 PID: 18 Comm: FIT_RecvCQ-0 4.0.0-lego+ #23\n[  427.458421] event qp_event arrived\n[  427.462203] RIP: 0010:[&lt;ffffffff810748fb&gt;]  [&lt;ffffffff810748fb&gt;] fit_poll_recv_cq+0x5cb/0x860\n[  427.471704] RSP: 0000:ffff881023e3fe60  EFLAGS: 00010287\n[  427.477618] RAX: 0000000000000000 RBX: 000000002aaaaaab RCX: 0000000000000004\n[  427.485570] RDX: 0000000000000000 RSI: 0000000000000053 RDI: 0000000000000000\n[  427.493520] RBP: ffff881023e3fec0 R08: 0000000000000001 R09: ffff881039900000\n[  427.501470] R10: 0000000000000000 R11: ffff881039918000 R12: ffff8810398f2000\n[  427.509421] R13: 0000000000000000 R14: 0000000000000001 R15: ffff881023e25008\n[  427.517371] event qp_event arrived\n[  427.521153] FS:  0000000000000000(0000) GS:ffff88107fc60000(0000) knlGS:0000000000000000\n[  427.530169] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[  427.536569] CR2: 0000000000000000 CR3: 000000000117a000 CR4: 00000000000406a0\n[  427.544519] event qp_event arrived\n</code></pre></p> <p>Trying to tune FIT\u2019s number polling threads. This could be the throughput/latency killer.</p> <p>128M</p> P num_polling M worker M num_polling Runtime (s) 1 1 1 46.8s 1 4 1"},{"location":"lego/log/log-09-2018/#sep-07","title":"Sep 07","text":"<p>Set up Infiniswap again. What a fucking crap code, and crash the kernel out of nowhere. crap crap crap.</p> <p>Hmm, Linux will tune the CPU freq during runtime, will be higher than 2.4GHz. So disable it, make it a fair comparison with Lego.</p> <p><code>intel_pstate=disable.</code></p>"},{"location":"lego/log/log-09-2018/#sep-06","title":"Sep 06","text":"<p>Did two optimizations on pcache, both are buffer management. Especially the pcache rmap case. In both opts, we kind of use static/pre-allocated array to serve dynamic allocation.</p> <p>This is a better solution than using kmem_cache, faster. kmem_cache will be a more general solution here.</p> <p>kmem_cache, FIFO queue (thpool buffer), static preallocated array (rmap, clflush)\u2026 Buffer management is really a very important thing in system building. I should be aware at the beginning next time.</p> <p>These changes are in commits: <pre><code>6e0cf6c5c64edbe445a27cf55f86ac51f8a897b3\n73377cafce95ffa0cfb155f77cac97456a5e4a71\n</code></pre></p>"},{"location":"lego/log/log-09-2018/#sep-05","title":"Sep 05","text":"<p>Alright. Besides some flaws/bugs in some kfree stuff, LegoOS now actually is very robust! Ran a quick git summary:</p> <pre><code> project  : LegoOS\n repo age : 1 year, 11 months\n active   : 358 days\n commits  : 1540\n files    : 1161\n authors  :\n  1317  Yizhou Shan                  85.5%\n   120  root                         7.8%\n    36  hythzz                       2.3%\n    27  yilun                        1.8%\n    16  Yutong Huang                 1.0%\n    10  Build Android                0.6%\n     8  Yiying Zhang                 0.5%\n     4  sumukh1991                   0.3%\n     1  Yizhou SHan                  0.1%\n     1  Sumukh Hallymysore Ravindra  0.1%\n</code></pre> <p>Of course, there are still PLENY room for improvement, and I know where. At this time, I really think we need something like kmem_cache, which is so fucking useful. It can probably further reduce much overhead.</p>"},{"location":"lego/log/log-09-2018/#sep-04","title":"Sep 04","text":"<p>Trying the perset eviction list mechanism, instead of victim cache. The benefit of using this is: we will no longer be bottelnecked by victim cache anymore. Each faulting thread will do eviction/flush within its own context.</p> <p>For 4 threads MNIST, I saw 3 seconds reduction.</p> <p>Removed the bitmap, use per pcache set counter for quick reference.</p>"},{"location":"lego/log/log-09-2018/#sep-03","title":"Sep 03","text":"<p>With DEBUG_MM, try enable HAVE_FREE directory by directory</p>"},{"location":"lego/log/log-09-2018/#-","title":"-","text":"<p>-</p> <p>update_wall_time+0x44 is where we call tsc_read. And this has been called many times (HZ per second). All of a sudden, the pointer got crashed. Who wrote to this code memory?? Remote RDMA? <pre><code>[ 1052.470714] general protection fault: 0000 [#1] SMP PROCESSOR\n[ 1052.477113] CPU: 0 PID: 15 Comm: ib_mad1 4.0.0-lego+ #509\n[ 1052.483125] RIP: 0010:[&lt;ffffffff81015764&gt;]  [&lt;ffffffff81015764&gt;] update_wall_time+0x44/0x6f0\n[ 1052.492530] RSP: 0000:ffff88103ad9fc88  EFLAGS: 00010046\n[ 1052.498445] RAX: 4510ffffffff8118 RBX: 0380ffffffffffff RCX: 0000000000000001\n[ 1052.506396] RDX: ffff88103ad9fd28 RSI: 0000000000000000 RDI: 4510ffffffff8118\n[ 1052.514346] RBP: ffff88103ad9fcd0 R08: 000000000000001f R09: 0000000000000000\n[ 1052.522298] R10: 0000000000000029 R11: ffff881013f8e130 R12: aaff0000024a2677\n[ 1052.530248] R13: 0000000000000000 R14: ffff88103ad85228 R15: ffff88103ae0c000\n[ 1052.538199] FS:  0000000000000000(0000) GS:ffff88107fc00000(0000) knlGS:0000000000000000\n[ 1052.547216] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 1052.553616] CR2: 0000000000000000 CR3: 000000000117b000 CR4: 00000000000406b0\n[ 1052.561567] Stack:\n[ 1052.563797] 0000000000000086 ffff88107fc05d80 ffff88103ad85000 0000000000000000\n[ 1052.571941] ffff88107fc04980 0000000000000000 0000000000000000 ffff88103ad85228\n[ 1052.580085] ffff88103ae0c000 ffff88103ad9fce8 ffffffff81017557 000000003ad9fe10\n[ 1052.588230] ffff88103ad9fd10 ffffffff810067a4 ffffffff81088040 ffff88107fc05d80\n[ 1052.596375] ffff88103ad85000 ffff88103ad9fdf8 ffffffff8100e8ea ffff88103ad9fd28\n[ 1052.604520] Call Trace:\n[ 1052.607236] &lt;TSK&gt;\n[ 1052.609368] [&lt;ffffffff81017557&gt;] tick_handle_periodic+0x67/0x70\n[ 1052.615961] [&lt;ffffffff810067a4&gt;] apic_timer_interrupt+0x54/0x90\n[ 1052.622555] [&lt;ffffffff8100e8ea&gt;] smp__apic_timer_interrupt+0x6a/0x70\n[ 1052.629633] [&lt;ffffffff8107b488&gt;] ? __schedule+0xf8/0x1e0\n[ 1052.635548] [&lt;ffffffff8107b583&gt;] schedule+0x13/0x30\n[ 1052.640978] [&lt;ffffffff8106c98e&gt;] ib_mad_completion_handler+0x5de/0xc20\n[ 1052.648250] [&lt;ffffffff8101de3b&gt;] ? dequeue_task_rt+0x1b/0x180\n[ 1052.654648] [&lt;ffffffff8106c3b0&gt;] ? ib_mad_send_done_handler.isra.22+0x4e0/0x4e0\n[ 1052.662793] [&lt;ffffffff81022af6&gt;] kthread+0xf6/0x110\n[ 1052.668223] [&lt;ffffffff81022a00&gt;] ? __kthread_parkme+0x70/0x70\n[ 1052.674622] [&lt;ffffffff8100eb72&gt;] ret_from_fork+0x22/0x30\n[ 1052.680538] &lt;EOT&gt;\n[ 1052.682670] Code: db e4 16 00 79 0d f3 90 80 3d d0 e4 16 00 00 7e f5 eb ea 48 8b 1d fd fa 1f 00 48 8b 05 e6 fa 1f 00 4c 8b 25 f7 fa 1f 00 48 89 c7 &lt;ff&gt; 50 28 49 89 c7 48 89 d8 4d 29 e7 48 d1 e8 49 21 df 48 f7 d0\n[ 1052.703711] RIP  [&lt;ffffffff81015764&gt;] update_wall_time+0x44/0x6f0\n[ 1052.710498]  RSP &lt;ffff88103ad9fc88&gt;\n</code></pre></p>"},{"location":"lego/log/misc/","title":"MISC","text":"<ul> <li> <p><code>/etc/ld.so.preload</code>: GLIBC uses <code>access()</code> to check if this file exist (normally it does not exist)<sup>1</sup>. This is something related to <code>LD_PRELOAD</code>: If both <code>LD_PRELOAD</code> and <code>/etc/ld.so.preload</code> are employed, the libraries specified by <code>LD_PRELOAD</code> are preloaded first. /<code>etc/ld.so.preload</code> has a system-wide effect, causing the specified libraries to be preloaded for all programs that are executed on the system<sup>2</sup>.</p> </li> <li> <p>I was reading a FAST18 paper (Fail-Slow Datacenter). I found it quite interesting and some suggestions are very useful for all system designers. Especially:</p> <ul> <li>Make implicit error-masking explicit. DO NOT FAIL SILENTLY. Since this is not a fail-stop (binary) issue, normally system designers will not raise exceptions. System designers should be aware of uncommon situations, raise explicit exceptions to convert a fail-slow (non-binary) case to a fail-stop (binary) case .Actually, this also reminds the email by Linus Torvards on BUG_ON usage<sup>3</sup>.</li> <li>Exposing performance statistic information for all-level (device, firmware, system software, application). However, based on my own experience, do not generate too much useless logs, it will just help to hide the root cause.</li> </ul> </li> <li> <p>Testing of applications is often done on a testing environment, smaller in size (perhaps only a single server) and less loaded than the \u201clive\u201d environment. The replication behavior of such an installation may differ from a live environment in ways that mean that replication lag is unlikely to be observed in testing - masking replication-sensitive bugs.</p> </li> <li> <p>mmap <code>PROT_NONE</code> is really used by applications, or library. They have their special usage.</p> </li> </ul> <ol> <li> <p>etc/ld.so.preload \u21a9</p> </li> <li> <p>ld.so.8.html \u21a9</p> </li> <li> <p>LKML:BUG_ON \u21a9</p> </li> </ol>"},{"location":"lego/log/test-note/","title":"Scripts","text":"<p>Scripts used to run OSDI\u201818 LegoOS experiments.</p>"},{"location":"lego/log/test-note/#cpu-freq","title":"CPU Freq","text":"<p>For fair comparision, we disable cpu freq tuning (because lego does not have it. shame!):</p> <p>Add this to boot kernel command parameter: <pre><code>intel_pstate=disable\n</code></pre></p>"},{"location":"lego/log/test-note/#swap-to-ssd","title":"swap-to-ssd","text":"<p>Please remember to clear the page cache! <pre><code>echo 3 &gt; /proc/sys/vm/drop_caches\nrm -rf /tmp/mnist_model/\nlxc-execute -n test -s lxc.cgroup.memory.limit_in_bytes=128M -- python mnist.py\n</code></pre></p>"},{"location":"lego/log/test-note/#swap-to-ramdisk","title":"swap-to-ramdisk","text":"<p>Please note we are using BLK_DEV_RAM, a block device based on RAM. We are NOT using tmpfs or ramfs. The difference is:. <pre><code>modprobe brd rd_size=16777216\ndd if=/dev/zero of=/dev/ram0 bs=4K\nmkswap /dev/ram0\nswapon /dev/ram0\nswapoff others\n</code></pre></p>"},{"location":"lego/log/test-note/#accelio-and-nbdx","title":"Accelio and nbdX","text":"<p>Follow this, and this.</p> <p>Tested with</p> <ul> <li><code>CentOS 7.2</code></li> <li><code>kernel 3.13.1</code></li> <li><code>wuklab14, wuklab18</code></li> </ul> <p>Side notes</p> <ul> <li>Server side, the block device created for client, can not be raw disk/SSD. I created a file from SSD</li> <li>Stick with 3.13 at both client and server. Client with 3.19 will crash</li> </ul> <p>Server: <pre><code>touch /mnt/ssd/swap\ntruncate -s +4G /mnt/ssd/swap\n\nraio_server -a 10.0.0.X -p 5555 -t rdma -f 0\n</code></pre></p> <p>Client: <pre><code>modprobe xio_rdma; modprobe xio_tcp\nmodprobe nbdx\n\nnbdxadm -o create_host -i 0 -p \"10.0.0.X:5555\"\nnbdxadm -o create_device -i 0 -d 0 -f \"/mnt/ssd/swap\"\n\nnbdxadm -o show_all_devices\n\nmkswap /dev/nbdx0\nswapon /dev/nbdx0\nswapoff others\n</code></pre></p>"},{"location":"lego/log/test-note/#infiniswap","title":"Infiniswap","text":"<p>Tested with</p> <ul> <li><code>CentOS 7.2</code></li> <li><code>MLNX_OFED_LINUX-3.3-1.0.4.0-rhel7.2-x86_64</code></li> <li><code>kernel 3.13.1</code></li> </ul> <p>Note</p> <p>1. At server side, use server ib0\u2019s IP address:</p> <pre><code># ifconfig\nib0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 2044\n        inet 10.0.0.67  netmask 255.255.255.0  broadcast 10.0.0.255\n\n./infiniswap-daemon 10.0.0.67 9400\n</code></pre> <p>At client side, use server ib0\u2019s IP in portal.list: <pre><code>1\n10.0.0.67:9400\n</code></pre></p> <p>2. At client side, change the <code>BACKUP_DISK</code> to an unused disk, and use a CORRECT one! Otherwise, wait for kernel panic, ugh. <pre><code>Use HDD such as /dev/sdb\nA SSD will kill Infiniswap.\n</code></pre></p> <p>3. Also, looks like we need to remove <code>memmap</code> from kernel parameter.</p>"},{"location":"lego/paper/genz/","title":"Interconnect Technology Comparison","text":"Interconnect Technology Products or Vendor Physical Domain Cache Coherent Access Semantic Maximum Bandwidth Medium Latency Gen-Z<sup>7</sup><sup>8</sup> N/A Cross components Memory 32 GBps ~ 400+ GBps  <code>Unidirectional</code> &lt;100ns OpenCAPI<sup>7</sup> IBM Power9 Motherboard Memory 50 GBps per lane  <code>Bidirectional</code> ? CCIX<sup>7</sup> N/A Motherboard Memory 32/40/50 GBps/lane  <code>Bidirectional</code> ? OmniPath<sup>9</sup><sup>10</sup> Intel KnightsLanding Cross networrk Network 25 GBps/port  <code>Bidirectional</code> ? PCIe 3.0 A Lot Motherboard PCIe ~1GBps/lane<sup>12</sup> 4B Read ~756ns<sup>11</sup> PCIe 4.0 Soon Motherboard PCIe ~2GBps/lane ? IB EDR Mellanox ConnectX4,X5 Cross network Network 100Gbps 0.5us IB HDR Mellanox ConnectX6 Cross network Network 200Gbps &lt;0.5us HyperTransport<sup>4</sup> AMD Motherboard Memory 51.2 GBps per link  <code>Bidirectional</code> ? NVLink<sup>2</sup> NVIDIA V100  IBM Power9 Motherboard Memory 50GBps per link  <code>Bidirectional</code> ? QPI<sup>5</sup><sup>6</sup> Intel Motherboard Memory ? ? Intel Main Memory Bus Intel Processor Memory E7-8894 v4 <code>85 GB/s</code>  E5-2620 v3 <code>59 GB/s</code> ? Ethernet<sup>3</sup> A Lot Motherboard Network Mellanox <code>200Gbps</code>  Cisco ASR <code>100 Gbps</code><sup>1</sup> ? <ul> <li>POWER9, NVLink 2.0, 300GB/s</li> </ul> <p>\u2013 Created: Feb 28, 2018 Last Updated: March 01, 2018</p> <ol> <li> <p>Ethernet Cisco ASR 9000 Series 4-Port 100-Gigabit Ethernet \u21a9</p> </li> <li> <p>Terabit Ethernet https://en.wikipedia.org/wiki/NVLink \u21a9</p> </li> <li> <p>NVLink \u21a9</p> </li> <li> <p>HyperTransport \u21a9</p> </li> <li> <p>https://en.wikipedia.org/wiki/Intel_QuickPath_Interconnect \u21a9</p> </li> <li> <p>https://communities.intel.com/thread/21872 \u21a9</p> </li> <li> <p>https://www.openfabrics.org/images/eventpresos/2017presentations/213_CCIXGen-Z_BBenton.pdf \u21a9\u21a9\u21a9</p> </li> <li> <p>Gen-Z Overview \u21a9</p> </li> <li> <p>http://www.hoti.org/hoti23/slides/rimmer.pdf \u21a9</p> </li> <li> <p>https://www.intel.com/content/www/us/en/products/network-io/high-performance-fabrics/omni-path-edge-switch-100-series.html \u21a9</p> </li> <li> <p>https://forum.stanford.edu/events/posterslides/LowLatencyNetworkInterfaces.pdf \u21a9</p> </li> <li> <p>https://www.xilinx.com/support/documentation/white_papers/wp350.pdf \u21a9</p> </li> </ol>"},{"location":"lego/paper/nmp/","title":"Near Memory Processing","text":"<ul> <li>NMP: Near Memory Processing</li> <li> <p>NDC: Near Data Computing</p> </li> <li> <p><code>PRIME: A Novel Processing-in-memory Architecture for Neural Network Computation in ReRAM-based Main Memory, ISCA'16</code></p> <ul> <li>High-performance acceleration of NN requires high memory bandwidth since the PUs are hungry for fetching the synaptic weights [17]. To address this challenge, recent special-purpose chip designs have adopted large on-chip memory to store the synaptic weights. For example, DaDianNao [18] employed a large on-chip eDRAM for both high bandwidth and data locality; TrueNorth utilized an SRAM crossbar memory for synapses in each core [19].</li> </ul> </li> <li>DianNao and DaDianNao<ul> <li>\u2026 memory bandwidth requirements of two important layer types: convolutional layers with private kernels (used in DNNs) and classifier layers used in both CNNs and DNNs. For these types of layers, the total number of required synapses can be massive, in the millions of parameters, or even tens or hundreds thereof.</li> <li>providing sufficient eDRAM capacity to hold all synapse on the combined eDRAM of all chips will save on <code>off-chip DRAM accesses</code>, which are particularly costly energy-wise</li> <li>Synapses. In a perceptron layer, all synapses are usually unique, and thus there is no reuse within the layer. On the other hand, the synapses are reused across network invocations, i.e., for each new input data (also called \u201cinput row\u201d) presented to the neural network. So a sufficiently large L2 could store all network synapses and take advantage of that locality. For DNNs with private kernels, this is not possible as the total number of synapses are in the tens or hundreds of millions (the largest network to date has a billion synapses [26]). However, for both CNNs and DNNs with shared kernels, the total number of synapses range in the millions, which is within the reach of an L2 cache. In Figure 6, see CLASS1 - Tiled+L2, we emulate the case where reuse across network invocations is possible by considering only the perceptron layer; as a result, the total bandwidth requirements are now drastically reduced.</li> <li>So, ML workloads do need large memory bandwidth, and need a lot memory. But how about temporary working set size? It\u2019s the best if it has a reasonable working set size that can fit the cache.</li> </ul> </li> <li>TPU<ul> <li>Each model needs between 5M and 100M weights (9<sup>th</sup> column of Table 1), which can take a lot of time and energy to access. To amortize the access costs, the same weights are reused across a batch of independent examples during inference or training, which improves performance.</li> <li>The weights for the matrix unit are staged through an onchip Weight FIFO that reads from an off-chip 8 GiB DRAM called Weight Memory (for inference, weights are read-only; 8 GiB supports many simultaneously active models). The weight FIFO is four tiles deep. The intermediate results are held in the 24 MiB on-chip Unified Buffer, which can serve as inputs to the Matrix Unit.</li> <li>In virtual cache model, we actually can assign those weights to some designated sets, thus avoid conflicting with other data, which means we can sustain those weights in cache!</li> </ul> </li> </ul> <p>To conclude: <code>a)</code> ML needs to use weight/synapses during computation, and those data will be reused repeatly across different stages. Besides, output from last stage serves the input of next stage, so buffering the <code>intermediate data</code> is important. Most ML accelerators use some kind of <code>on-chip memory</code> (Weighted FIFO, Unified Cache in TPU) to buffer those data. This fits the <code>HBM+Disaggregated Memory</code> model: HBM is the on-chip memory, while disaggregated memory is the off-chip memory. <code>b)</code> Combined with virtual cache, we could assign special virtual addresses to weight data, so they stay in some designated cache sets. Kernel can avoid allocating conflict virtual addresses later. Thus we can retain these weight data in virtual cache easily.</p>"},{"location":"lego/paper/os/","title":"Operating System","text":"<ul> <li>Multics</li> <li>Hydra (operating system), CMU 70\u2019s</li> <li>Firefly DEC, 80\u2019s</li> <li>HIVE</li> <li>Disco</li> <li>IBM K42</li> <li>Tessellation, UCB</li> <li> <p>Akaros, UCB</p> </li> <li> <p>Amoeba</p> <ul> <li>The Amoeba distributed operating system</li> <li>Amoeba A Distributed Operating System for the 1990s</li> </ul> </li> <li> <p>Corey</p> <ul> <li>Corey: An Operating System for Many Cores</li> </ul> </li> <li> <p>Barrelfish</p> <ul> <li>Decoupling Cores, Kernels, and Operating Systems</li> <li>The Multikernel: A new OS architecture for scalable multicore systems</li> </ul> </li> <li> <p>Drawbridge</p> </li> <li>Graphene</li> <li> <p>L4</p> </li> <li> <p>FOS</p> <ul> <li>An Operating System for Multicore and Clouds: Mechanisms and Implementation</li> </ul> </li> </ul>"},{"location":"lego/paper/processor_oom/","title":"Process/Memory Kernel Memory","text":"<p>This document is based on discussion with Yiying, about how to deal with processor or memory component\u2019s out-of-kernel-memory situation. It mainly bothers processor component, which has a small kernel memory while needs to support all running user threads.</p> <p>Process\u2019s local kernel memory is limited by design. There are several major users:</p> <ul> <li>1) pcache\u2019s rmap, which is propotional to pcache size.</li> <li>2) IB, which depends on concurrent outgoing messages.</li> <li>3) running threads. For each thread at processor, Lego needs to allocate some kernel memory for it, e.g, <code>kernel stack</code>, <code>task_strcut</code>, and so on.</li> </ul> <p>Both 1) and 2) are fine, they can be easily controlled. However we can not limit how many threads user can create, thus 3) becomes the critical criminal of oom.</p> <p>When processor is running out of kernel memory, Lego needs to deal with it. Currently, we propose three different solutions:</p> <ul> <li>s1) <code>Swap</code> kernel memory to remote memory component</li> <li>s2) <code>Kill</code> some threads to have some usable memory (OOM killer)</li> <li>s3) <code>Migrate</code>, or <code>checkpoint</code>, threads to processors that have usable kernel memory</li> </ul> <p>For solution 3), there is a case where <code>all</code> processors are running out of memory. Then we have to use solution 1) or 2).</p> <p>\u2013 Yizhou Shan Feb 17, 2018</p>"},{"location":"lego/paper/related/","title":"Related","text":""},{"location":"lego/paper/related/#dredbox","title":"dRedBox","text":"<ul> <li>news</li> <li>IBM Advancing cloud with memory disaggregation</li> <li>[Slides: Open Source Cloud Ecosystem for Next-Gen Disaggregated Datacenters] (https://schd.ws/hosted_files/osseu17/60/dReDBox.CloudOpen2017.talk.pdf)</li> <li>Slides: Demo</li> </ul>"},{"location":"lego/paper/replication/","title":"Replication, Checkpoint, Logging, and Recovery","text":""},{"location":"lego/paper/replication/#discussion","title":"Discussion","text":"<ul> <li> <p>03/25/18:</p> <ul> <li>Revisit RAMCloud, which has a very similar goal with Lego. It keeps a full copy of data in DRAM, use disk to ensure crash consistency. The key assumption of RAMCloud is the battery-backed DRAM or PM on its disk side.</li> <li>We don\u2019t need to provide a 100% recoverable model. Our goal here is to reduce the failure probabilities introduced by more components. Let us say Lego do the persist in a batching fashion, instead of per-page. We are not able to recover if and only if failure happen while we do the batch persist. But we are safe if failure happen between batched persist.</li> <li>That actually also means we need to checkpoint process state in Processor side. We have to save all the process context along with the persisted memory log! Otherwise, the memory content is useless, we don\u2019t know the exact IP and other things.</li> <li>I\u2019m wrong. :-)</li> </ul> </li> <li> <p>03/20/18: when memory is enough, use pessimistic replication, when demand is high, use optimistic to save memory components.</p> </li> </ul>"},{"location":"lego/paper/replication/#replication","title":"Replication","text":"<p>Before started, I spent some time recap, and found Wiki pages<sup>1</sup><sup>2</sup><sup>3</sup> are actually very good.</p> <p>Two main approaches:</p> <ul> <li>Optimistic (Lazy, Passive) Replication <sup>4</sup>, in which replicas are allowed to diverge<ul> <li>Eventual consistency<sup>5</sup><sup>6</sup><sup>7</sup>, meaning that replicas are guaranteed to converge only when the system has been quiesced for a period of time</li> </ul> </li> <li>Pessimistic (Active, Multi-master<sup>8</sup>) Replication, tries to guarantee from the beginning that all of the replicas are identical to each other, as if there was only a single copy of the data all along.</li> </ul> <p>Lego is more towards memory replication, not storage replication. We may want to conduct some ideas from DSM replication (MRSW, MRMW), or in-memory DB such as RAMCloud, VoltDB?</p>"},{"location":"lego/paper/replication/#checkpointing","title":"Checkpointing","text":"<p>Some nice reading<sup>9</sup>.</p> <p>Application types:</p> <ul> <li>Long-running v.s. Short-lived</li> <li>Built-in checkpoint/journaling v.s. no built-in checkpoint/journaling</li> </ul> <p>Two main approaches:</p> <ul> <li>Coordinated<ul> <li>2PC</li> </ul> </li> <li>Un-coordinated<ul> <li>Domino effect</li> </ul> </li> </ul> <p>We should favor [Long-running &amp;&amp; no built-in checkpoint/journaling] applications. Normally they are not distributed systems, right? Even it is, it might be running as a single-node version. Based on this, I think we should favor coordinated checkpointing.</p> <p>HPC community<sup>10</sup><sup>11</sup><sup>12</sup> has a lot publications on checkpoint/recovery (e.g., Lawrence National Laboratory).</p>"},{"location":"lego/paper/replication/#misc","title":"MISC","text":"<p>Some other interesting topics:</p> <ul> <li>Erasure Coding<ul> <li>Less space overhead</li> <li>Parity Calculation is CPU-intensive</li> <li>Increased latency</li> </ul> </li> </ul> <p>\u2013 Yizhou Shan Created: Mar 19, 2018 Last Updated: Mar 19, 2018</p> <ol> <li> <p>Wiki: Replication \u21a9</p> </li> <li> <p>Wiki: High-availability_cluster \u21a9</p> </li> <li> <p>Wiki: Virtual synchrony \u21a9</p> </li> <li> <p>Wiki: Optimistic Replication \u21a9</p> </li> <li> <p>Wiki: Quiesce \u21a9</p> </li> <li> <p>Wiki: Eventual Consistency \u21a9</p> </li> <li> <p>Wiki: CAP Theorem \u21a9</p> </li> <li> <p>Wiki: Multi-master replication \u21a9</p> </li> <li> <p>Wiki: Application Checkpointing \u21a9</p> </li> <li> <p>Paper: A Survey of Checkpoint/Restart Implementations  \u21a9</p> </li> <li> <p>Paper: The Design and Implementation of Berkeley Lab\u2019s Linux Checkpoint/Restart \u21a9</p> </li> <li> <p>Berkeley Lab Checkpoint/Restart (BLCR) for LINUX \u21a9</p> </li> </ol>"},{"location":"lego/pcache/config/","title":"Pcache Configuration","text":"<p>This doc explains what configuration options pcache has, and how to config them properly. Pcache is only enabled in Lego\u2019s processor manager and currently it uses DRAM to emulate the last-level cache (or, L4).</p>"},{"location":"lego/pcache/config/#kconfig","title":"Kconfig","text":""},{"location":"lego/pcache/config/#config_memmap_memblock_reserved","title":"CONFIG_MEMMAP_MEMBLOCK_RESERVED","text":"<p>DEFAULT: Y</p> <p>By default, boot command line option <code>memmap $</code> will reserve a range of physical memory. This reserved memory will be marked reserved in e820 table, which means this range will not be registered into <code>memblock</code>. Only memory that has been registered into <code>memblock</code> will be assigned <code>struct page</code> with it (both <code>memblock.memory</code> and <code>memblock.reserve</code> will have). And do note that this part of reserved memory can be mapped as 1GB page at boot time.</p> <p>In other words, by default (the linux semantic), users need to <code>ioremap</code> the <code>memmap $</code> reserved physical memory, and use the returned kernel virtual address afterwards. And do note that the <code>ioremap()</code> only support 4KB mapping.</p> <p>In Lego, if this option is enabled, the memory marked by <code>memmap $</code> will NOT be marked reserved into e820 table, instead, it will be pushed into <code>memblock</code>, which means it is mapped into kernel direct mapping and has <code>struct page</code>.</p> <p>For those who have done DAX, or NVM related stuff, you must have struggled with <code>memmap $</code>, and complained why it does not have <code>struct page</code>, I guess? So here is the simple code to do so: <pre><code>if (*p == '@') {\n        start_at = memparse(p+1, &amp;p);\n        e820_add_region(start_at, mem_size, E820_RAM);\n} else if (*p == '#') {\n        start_at = memparse(p+1, &amp;p);\n        e820_add_region(start_at, mem_size, E820_ACPI);\n} else if (*p == '$') {\n        start_at = memparse(p+1, &amp;p);\n\n#ifdef CONFIG_MEMMAP_MEMBLOCK_RESERVED\n        memblock_reserve(start_at, mem_size);\n#else\n        e820_add_region(start_at, mem_size, E820_RESERVED);\n#endif\n</code></pre></p> <p>But why we are having this? Because I think the <code>direct 1GB mapping</code> may have better performance: huge page mapping can truly save us a lot TLB misses. However, the real performance number is unknown.</p> <p>If unsure, say <code>Y</code>.</p> <p>\u2013 Yizhou Shan  Created: Feb 01, 2018 Last Updated: Feb 01, 2018</p>"},{"location":"lego/pcache/evict_and_ref/","title":"Mumble pcache eviction and refcount","text":"<p>This is about how Lego is doing eviction against live references of pcache. Unlike the <code>garbage collection</code> where it only reclaims object that has no references, pcache eviction may try to evict a pcache that is currently being used by another thread. Both parties need to be very careful. A tricky business.</p> <p>To describe the issue in a high-level, let us consider this case: the system now has two threads running on two different cores. The first thread try to evict a pcache line, and it truly find a candidate and prepare to evict. Meanwhile, the other thread is currently using this pcache line to do some operations such as <code>zap_rmap()</code>. If the first thread evict the pcache line without synchronization with the second thread, oops, the second thread is playing with a wrong pcache.</p> <p>The textbook idea is adding refcount. However, this is not enough in C. Because:</p> <ul> <li>There is no way to prevent the second thread from getting the <code>pointer</code> to that pcm.</li> <li>A simple <code>inc_refcount()</code> from the second thread can happen anytime in the middle of first thread\u2019s eviction.</li> </ul> <p>Solutions:</p> <ul> <li>To actually prevent the second thread from getting the pointer, we should think about how it get the pointer? Luckily, in Lego, there is only one entry point, which is from <code>pte to pcm</code> (aka. pcache_meta). So to synchronize pte change becomes very important. Luckily, we are doing pte_lock before getting the pcm. So this simple pte lock ensures the second thread a safe, will-not-be-evicted pcm (of course, with some other checkings). This idea can also be generalized to any data structures that need pointer references: protect your pointer!</li> <li>Refcount checking is also necessary. In the eviction routine, we need to use  <code>atomic_xchg</code> to reset the refcount. If this fails, it means someone else is using it. Do note, this <code>atomic_xchg</code> is carried out with pcm locked. Thus the ordering of locking, get/put matters in the code.</li> </ul> <p>The code itself tells a much more complete story, I strongly recommend you read the code if you are interested. Here I will list the most interesting part. For the other users except eviction, they need to do this: <pre><code>pcm = pte_to_pcache_meta(ptent);\n/*   \n * We have a strict lock ordering everyone should obey:\n *      lock pcache\n *      lock pte\n * The caller already locked pte, thus we should avoid deadlock here\n * by droping pte lock first and then acquire both of them in order.\n */\nif (unlikely(!trylock_pcache(pcm))) {\n    /* in case it got evicted and @pcm becomes invalid */\n    get_pcache(pcm);\n\n    /*\n     * Once we release the pte lock, this pcm may be\n     * unmapped by another thread who is doing eviction.\n     * Since we have grabbed one extra ref above, so even\n     * it is unmapped, eviction thread will not fail to free it.\n     */\n    spin_unlock(ptl);\n\n    lock_pcache(pcm);\n    spin_lock(ptl);\n\n    /*   \n     * Since we dropped the lock, the pcache line might\n     * be got evicted in the middle.\n     */\n    if (!pte_same(*pte, ptent)) {\n        unlock_pcache(pcm);\n        /*   \n         * This put maybe decreases the ref to 0\n         * and eventually free the pcache line.\n         * This happens if the @pcm was selected\n         * to be evicted at the same time.\n         */\n        put_pcache(pcm);\n        return -EAGAIN;\n    }    \n    put_pcache(pcm);\n}\n</code></pre></p> <p>As for the eviction thread, it needs to make sure it is the last user using this pcm: <pre><code>/*  \n * Each rmap counts one refcount, plus the one grabbed\n * during evict_find_line(), we should have (nr_mapped + 1)\n * here if there are no any other users.\n *\n * Furthurmore, others can not go from munmap/mremap/wp to\n * put_pcache() within pcache_zap_pte(), pcache_move_pte()\n * or pcache_do_wp_page(). Thus the refcount must larger or\n * equal to (nr_mapped + 1).\n *\n * But if there truly other users (refcount &gt; nr_mapped + 1),\n * then we should manually sub the refcount. The other users\n * which are currently holding the ref, will free the pcache\n * once it call put_pcache.\n */\nPCACHE_BUG_ON_PCM(pcache_ref_count(pcm) &lt; nr_mapped + 1, pcm);\nif (unlikely(!pcache_ref_freeze(pcm, nr_mapped + 1))) {\n    if (unlikely(pcache_ref_sub_and_test(pcm, nr_mapped + 1))) {\n        pr_info(\"BUG: pcm refcount, nr_mapped: %d\\n\", nr_mapped);\n        dump_pcache_meta(pcm, \"ref error\");\n        BUG();\n    }   \n\n    ClearPcacheReclaim(pcm);\n    add_to_lru_list(pcm, pset);\n    unlock_pcache(pcm);\n\n    inc_pcache_event(PCACHE_EVICTION_EAGAIN_CONCURRENT);\n    return PCACHE_EVICT_EAGAIN_CONCURRENT;\n}\n</code></pre></p> <p>My personal thought: live eviction against live objects/references is very hard. You first need to use refcount to ensure a correct ordering. You also need to have a way to prevent others from using the going-to-be-evicted pointer, or have a way to detect a under-use pointer.  In this Lego pcache case, we use the combination of pte lock, pcache lock, and pcache refcount, to ensure everyone is safe. And all these is quite similar to Linux page operations. I learned a lot from its code. But I still not fully understand how it ensures the page is not used by others, it has way more parties than lego that can use the page at the same time of eviction. Magic kernel folks.</p> <p>\u2013 Yizhou Shan  Created: Mar 15, 2018 Last Updated: Mar 16, 2018</p>"},{"location":"lego/pcache/pgtable-lock/","title":"Fine-grain Page Table Lock","text":"<p>In old Linux or previous Lego, user page table operations, such as set, clear, are protected by <code>mm-&gt;page_table_lock</code>. This one single lock prohibits a lot parallelisms on big SMP machines. An ideal solution is to have finer-granularity locks, so that faults on different parts of the user address space can be handled with less contention.</p> <p>But finer-granularity locks means you need more memory for the locks. This is a simple trade-off. Lego currently mimic the Linux x86 default setting<sup>1</sup>, where each PMD and PTE page table pages has their own lock. The lock is a spinlock embedded in the <code>struct page</code>. As illustrated below:</p> <p></p> <p>Both Processor and Memory managers are using the same mechanism to increase parallelism. And it is something that can improve performance a lot.</p> <p>\u2013 Yizhou Shan Created: Mar 22, 2018 Last Updated: April 13, 2018</p> <ol> <li> <p>Split page table locks \u21a9</p> </li> </ol>"},{"location":"lego/pcache/replication/","title":"Memory Replication","text":"<ul> <li> <p>Keep a single copy of each page in DRAM, with redundant copies on secondary storage such as disk or flash. This makes replication nearly free in terms of cost, and energy usage. But we should consider the extra network cost.</p> </li> <li> <p>RAMCloud has two components running on a single machine: <code>master</code>, and <code>backup</code>. In lego, <code>master</code> is the handler running on <code>Memory</code>, <code>backup</code> is the handler running on <code>Storage</code>.</p> </li> <li> <p>Because of <code>dual-Memory solution</code>, we don\u2019t need a hash table from <code>&lt;pid, user_vaddr&gt;</code> to objects in log: M1 has its own <code>&lt;VA-PA&gt;</code> mapping table, and it will not be updated on replication. M2 does not need to look up.</p> </li> <li> <p>RAMCloud use 8MB segment. Logs are first appended within each segment. Each log has different size, depends on the objects being written. Lego is different. Replication is triggered by pcache/victim flush, which means the data is always the size of a pcache line (4KB now). This make things somehow simpler. But other general rules still apply.</p> </li> </ul> <p>\u2013 Yizhou Shan Created: Mar 31, 2018 Last Updated: Mar 31, 2018</p>"},{"location":"lego/pcache/rmap/","title":"Reverse Mapping of Pcache","text":"<p>This document explains Lego\u2019s reverse mapping design for pcache. We also present Lego internal functions that eventually manipulate rmap data structures. For readers who are not familiar with reverse mapping, I recommend you search what is rmap in Linux first.</p>"},{"location":"lego/pcache/rmap/#design","title":"Design","text":"<p>The reverse mapping, or rmap, of our pcache is implemented in a very basic and straightforward way: pointing back to all page table entries (ptes) directly. Shared pcache lines will have a list of ptes that point to this pcache line. We also did this way in Hotpot.</p> <p>rmap is used by 1) a bunch of syscalls, such as <code>fork()</code>, <code>execv()</code>, <code>mmap()</code>, <code>munmap()</code>, <code>mremap()</code>, <code>brk()</code>. 2) page reclaim, which needs to unmap all ptes for a given swapped page. Other than <code>fork()</code> and <code>execv()</code>, other vm related syscalls are invoked very frequently for a typical datacenter application. Moreover, page reclaim and swap also run concurrently to gain exclusive access to rmap.</p> <p>So, rmap operations have to be fast. Directly pointing to pte seems the best solution here. However, this fine-granularity design will consume a lot memory for the per-pte list. Furthermore, vma creation, deletion, split and merge happen frequently, the overhead to manage rmap is quite high. No wonder Linux choses another object-based way to do so, which leverages vma itself to take a longer path towards pte.</p> <p>The important question is: does this naive solution fit current Lego?</p> <p>Yes, it fits, for several reasons. 1) Current Lego run static-linked ELF binary only, thus there will not be any shared hot library pages, which implies rmap list maintenance is simplified. 2) Our targeted applications mostly are single process. Even for multiple process ones, the number of processes stay stable and <code>fork()</code> happen at early init time. 3) major users of rmap such as <code>mremap()</code> and <code>munmap()</code>  perform rmap operation explicitly, <code>mmap()</code> perform rmap implicitly via pgfault (or pcache miss), <code>pcache reclaim</code> perform sweep async. All of them, combined with 1) and 2), most of the time will perform rmap operation on a single pte.</p>"},{"location":"lego/pcache/rmap/#internal","title":"Internal","text":"<p>The following table describes different contexts that manipulate rmap data structures. Currently, rmap only has four possible operations. The context field describes the large context that trigger such rmap operation. The related functions and pcache callback field lists functions that actually did the dirty work.</p> rmap operation Context Related functions and pcache callback Add <code>fork()</code> <code>pgfault</code> <code>copy_pte_range()</code> -&gt; <code>pcache_copy_pte()</code> <code>pcache_add_rmap()</code> Remove <code>munmap()</code> <code>exit_mmap()</code> <code>write_protected</code> <code>zap_pte_range()</code> -&gt; <code>pcache_zap_pte()</code> <code>pcache_do_wp</code> -&gt; <code>pcache_remove_rmap</code> Update <code>mremap()</code> <code>move_ptes()</code> -&gt; <code>pcache_move_pte()</code> Lookup pcache eviction sweep, etc. <code>pcache_referenced()</code>, <code>pcache_wrprotect()</code> <code>pcache_try_to_unmap()</code> <p>Each rmap holds one refcount of pcache. The refcount is increased after <code>pcache_add_rmap</code>, and must be decreased after removing pcache rmap, can from <code>pcache_remove_rmap</code>, <code>pcache_zap_pte</code> or <code>pcache_move_pte_slowpath</code>.</p>"},{"location":"lego/pcache/rmap/#thought","title":"Thought","text":"<p>One function I personally love the most is <code>rmap_walk()</code>, whose name pretty much tells the story. To use <code>rmap_walk()</code>, caller passes a <code>struct rmap_walk_control</code>, which including caller specific callback for each rmap. This function also isolates the specific data structures used by rmap from various callers. In Lego, a lot pcache functions are built upon <code>rmap_walk()</code>.</p> <p><code>struct rmap_walk_control</code>, or <code>struct scan_control</code>, or <code>struct something_control</code> are used a lot by Linux kernel. Personally I do love this way of doing data structure walk, or reuse functions. However, even this way can greatly reduce duplicated code size, it will make the code unnecessary complex. As a system developer, no more expects to see a function longer than 100 lines. People love saying: Do one thing and do it better, while it not always works that perfectly. Coding is nothing different life, it is all about trade-off.</p> <p>\u2013 Yizhou Shan  Created: Feb 02, 2018 Last Updated: Mar 10, 2018</p>"},{"location":"lego/pcache/smp_design/","title":"SMP Design Thought","text":"<p>Coding pcache is nothing different from coding mm code. It is the same with your familiar mixed pgfault, LRU, page cache and writeback code. Each pcache line can be involved with multiple activities at the same time. We have to use different states to synchronize among them. If you have ever read linux mm code, you will know that sometimes, comment is literally more than code. SMP pain in ass.</p> <p>I don\u2019t think this document is well written. It is just some random thoughts I wrote down while coding. Some of them might be wrong. But it is still worth looking back.</p>"},{"location":"lego/pcache/smp_design/#pcache-and-victim-cache-organization","title":"Pcache and Victim Cache Organization","text":"<p>Our pcache and victim cache are allocated and arranged as a big array. As for pcache we look at it in a cache set view, which means consecutive pcache lines are not relevant in natual. As for victim cache, we simply treat it as a big array and walk through it one by one.</p>"},{"location":"lego/pcache/smp_design/#allocationeviction-smp-consideration","title":"Allocation/Eviction SMP Consideration","text":"<p>The alloc/free of both pcache and victim cache are simple: each pcache line or victim cache line has a <code>Allocated</code> bit to indicate if this line is free or not. The <code>Allocated</code> bit is manipulated by atomic bit operations, thus SMP safe. This further implies that we do not need another spinlock to guard allocation.</p> <p>However, other activities such as explict eviction, background sweep may walk through the cache lines at the same time of cache allocation, a single <code>Allocated</code> bit is not enough. Because an allocated cache line will need some initial setup, such as reset refcount, clear flags (prep_new_pcache), thus there is a small time gap between Allocated bit being set and the cache line being truly safe to use. Other activities must wait the cache line to be usable, and then they can do further operations on this cache line.</p> <p>To solve this race condition, there two possible solutions: 1) Add another bit: <code>Usable</code>, which is set once initial setup is done.    In this case, functions excluding alloction code should always check if the <code>Usable</code>    bit is set or not. a) If it is set, this means the cache line is safe for further operations    b) If not, and <code>Allocated</code> bit is set, this means the cache line is under setup in another core,    We should skip it.    c) If not, and <code>Allocated</code> bit is not set, this means this cache line is simply free.    We should skip it.</p> <p>2) Add allocated cache lines to a list (such as LRU list), and functions excluding allocation    code will only look into cache lines within this list. In other words, others will only    look into surely usable cache lines.</p> <p>Both solutions try to avoid others looking into un-mature cache lines in SMP envorinment. The rule is simple: function should NOT look into data that is not supposed to be seen. The cache line that has Allocated bit set but under setup is a typical case.</p> <p>As an example, the physical page allocator, page reclaim, page cache in Linux are implemented with the second solution. Pages freshly allocated will be added a LRU list or page cache own list. And page reclaim code will only look into pages within the LRU list, it will not go through all physical pages to do so. The reason for Linux to do so is simple: kernel can not scan the whole physical pages to find out pages to operate.</p> <p><code>Pcache:</code> When it comes to pcache, we use both. In our envision, pcache will have high-associativity such as 64 or 128. It will have very bad performance if our eviction algorithm or sweep thread need to go through every cache lines within a set to find out candidates, while there might be only 1 or 2 allocated lines. However, additional <code>Usable</code> bit is added for debug purpose.</p> <p><code>Victim Cache:</code> When it comes to victim cache, the first solution seems a better choice. Because victim cache only a few cache lines, e.g., 8 or 16. This means a whole victim cache line walk is fast. While the list deletion and addition seem may introduce some unnecessary overhead. It is all about trade-off.</p> <p>These choices affect the usage of pcache and victim cache, mostly the eviction code.</p>"},{"location":"lego/pcache/smp_design/#more-on-above-two-solutions","title":"More on above two solutions","text":"<p>The first solution is used if evict_random is configured. The second solution is used when evict_lru is configured.</p> <p>I do not have any doubt about second solution, it works, though with a lot SMP pain in ass. But I do have more to say about the first solution, which is adding another usable bit. The <code>Usable</code> bit only ensures other threads will not use unmature pcache, but it can not prevent other threads seeing a going-to-be-freed pcache.</p> <p>What is this going-to-be-freed asshole? Let us consider this case: CPU0 is doing eviction and checked the <code>Usable</code> bit, which is set. Then CPU0 thought this cache line is all set, ready to be torqued. Before doing all the dirty work, CPU0 will <code>get_pcache_unless_zero()</code> first to make sure the pcache will not go away in the middle. However, meanwhile, CPU1 did a <code>put_pcache()</code> and a consecutive <code>pcache_alloc()</code> right before CPU0 did called <code>get_pcache_unless_zero()</code>. Bang! CPU0 may use an mature pcache line, cause CPU1\u2019s <code>pcache_init_ref_count()</code> may come before CPU1\u2019s <code>get_pcache_unless_zero()</code>! How to solve this? CPU0 need to add additional checking after <code>get_pcache_unless_zero()</code>.</p> <p>For more details, please check the code in <code>pcache/evcit_random.c</code>, which has more pretty explanation.</p> <p>\u2013 Yizhou Shan Jan 31, 2018</p>"},{"location":"lego/pcache/sweep/","title":"Pcache Sweep","text":"<p>Some notes while coding pcache sweep thread. The sweep thread wants to detect the hotness of pages, and then adjust LRU list accordingly.</p>"},{"location":"lego/pcache/sweep/#data-worth-a-billion","title":"Data Worth a Billion","text":"<p>Pcache-reclaim, or any other object reclaim, need some data to algorithm about. So specific algorithm can select the <code>best</code> candidate to reclaim. In reality, algorithms are designed quite well, but how to get the data part becomes extremely hard. I think this applies to many different systems.</p> <p>For example, to select the hot pages in x86 is notorious hard because x86 hardware only provides a <code>Referenced</code> bit for system software to reason about. To make it worse, <code>Referenced</code> bit is cached in TLB, which means CPU will NOT  set the <code>Referenced</code> bit even you reset in PTE, because CPU think the bit is already set. In order to get an accurate hot pages tracking, you probably need a TLB flush after reset <code>Referenced</code> bit.\u00a0But, are you kidding me, a TLB flush after each reset? We have to say NO here. The Linux code explains it well: <pre><code>static inline int ptep_clear_flush_young(pte_t *ptep)\n{\n        /*\n         * On x86 CPUs, clearing the accessed bit without a TLB flush\n         * doesn't cause data corruption. [ It could cause incorrect\n         * page aging and the (mistaken) reclaim of hot pages, but the\n         * chance of that should be relatively low. ]\n         *\n         * So as a performance optimization don't flush the TLB when\n         * clearing the accessed bit, it will eventually be flushed by\n         * a context switch or a VM operation anyway. [ In the rare\n         * event of it not getting flushed for a long time the delay\n         * shouldn't really matter because there's no real memory\n         * pressure for swapout to react to. ]\n         */\n        return ptep_test_and_clear_young(ptep);\n}\n</code></pre></p>"},{"location":"lego/pcache/sweep/#aggressiveness","title":"Aggressiveness","text":"<p>An aggressive sweep algorithm will disturb the normal operations a lot. In Lego, there 4 main factors that define the aggressiveness:</p> <ul> <li>Time interval between each run</li> <li>Number of sets to look at during each run<ul> <li>Skip if it is not full</li> <li>Skip if it is under eviction</li> </ul> </li> <li>Number of lines to look at for each set<ul> <li>Smaller or equal to associativity</li> </ul> </li> <li>Number of lines to adjust for each set<ul> <li>Smaller or equal to lines to look at</li> </ul> </li> </ul> <p>\u2013 Yizhou Shan Created: Mar 18, 2018 Last Updated: Mar 18, 2018</p>"},{"location":"lego/pcache/tlb/","title":"TLB Coherence","text":"<p>x86 does not keep TLB coherent across cores, nor with in-memory page table. And that is why we need explicit TLB flush when some PTE modifications happen (e.g. downgrade RW to RO, clear PTE, etc.). Besides, TLB flush is very important and affect application correctness. I\u2019ve had some really awful debugging experience which was eventually introduced by missed TLB flush. Below is a list of operations that should have TLB flush followed:</p> <ul> <li><code>munmap</code> (optional, can be optimized by holding the old VA range)</li> <li><code>mremap</code> (required)</li> <li><code>fork (RW-&gt;RO)</code> (required)</li> <li><code>CoW (RO-&gt;RW)</code> (required)</li> <li><code>mprotect</code> (required)</li> <li><code>migration</code> (required)</li> </ul> <p>Unfortunately, TLB flush is costly, especially if we need to shootdown TLB entries on remote core. TLB shootdown<sup>1</sup><sup>2</sup><sup>3</sup> is performed by sending IPI to remote core, and remote core will flush local TLB entries within its handler. Linux optimize this by batching TLB flush until context switch happens. Lego currently does not have this nice feature, we flush TLB one by one for each PTE change (listed as TODO).</p> <p>\u2013 Yizhou Shan Created: Mar 19, 2018 Last Updated: Mar 19, 2018</p> <ol> <li> <p>Optimizing the TLB Shootdown Algorithm with Page Access Tracking, ATC\u201818 \u21a9</p> </li> <li> <p>LATR: Lazy Translation Coherence, ASPLOS\u201818 \u21a9</p> </li> <li> <p>Hardware Translation Coherence for Virtualized Systems, ISCA\u201817 \u21a9</p> </li> </ol>"},{"location":"lego/pcache/victim/","title":"Victim Cache","text":"<p>\u2013 Yizhou Shan Created: Mar 12, 2018 Last Updated: Mar 12, 2018</p>"},{"location":"lego/pcache/virtual_cache/","title":"Virtual Cache","text":"<ul> <li>Synonymous<ul> <li>impact Cache coherence</li> <li>impact TLB shootdown</li> <li>The good thing is, synonymous actually happen very rare in really workload. But when OS is invoked, it actually creates a lot synonymous. Because the physical page is mapped both low user virtual address and high kernel virtual address.</li> <li>What is this?</li> <li>What is bad about this?</li> <li>When does this happen? (All cases: kernel, shared vma mapping)</li> <li>How to solve this?<ul> <li>Software solution: OS level detection, global virtual address, identical virtual address etc.</li> <li>Hardware solution: detect and manage at runtime. Back pointer, Dynamic synonymous remapping, reverse mapping. Similar ideas.</li> <li>A nice summary can be found on <code>A new perspective for efficient virtual-cache coherence, ISCA'13</code>.</li> </ul> </li> </ul> </li> </ul> <p>Let me share my reading list. I think I\u2019ve collected most of the important virtual cache papers: </p> <ul> <li> <p>TLB and cache line lifetime:</p> <ul> <li><code>Enigma, ISC'10</code>: For each case where valid data exists in the cache hierarchy without a corresponding valid translation entry, systems with physically-tagged caches have to resolve the translation miss. Only after the page table has been \u201cwalked\u201d and a valid translation entry installed can the already cache-resident data be provided to the processing core. Especially in the faster levels of cache, the additional page table walk can add significant latency to what otherwise would have been a low-latency cache hit. </li> <li><code>GPU virtual cache, ASPLOS'18</code>: We notice that the per-CU TLB miss ratio is high; however, many TLB misses hit in the GPU caches. Only 34% of references that miss in the 32-entry per-CU L1 TLB are also L2 cache misses and access main memory (blue bars). An average of 31% of total per-CU TLB misses find the corresponding data in private L1 caches (black bars), and an additional 35% of the total misses hit in a shared L2 virtual cache (red bars). These hits occur because blocks in the cache hierarchy are likely to reside longer than the lifetime of the corresponding per-CU TLB entries </li> </ul> </li> <li> <p>Reading the <code>GPU virtual cache ASPLOS'18</code> paper today. I mostly interested in how they handle synonymous and mremap issue.</p> <ul> <li>Synonymous:</li> <li>Their solution for synonymous is quite simple (not sure if practical or effective): use a <code>leading</code> virtual address, which is the first VA that has the virtual cache miss. Subsequent misses that from <code>different</code> VA will not have the their cache lines filled, instead, they will make subsequent VA forever miss, and fetch the content from the leading VA cache line (they call it replay). In all, synonymous is solved by only having one cache line, and does not fill other VA cache lines.</li> <li>mremap:</li> <li>They did not mention mremap. But I guess they do not need to care this. When remap happens, the original PTE is invalidated first, and TLB shootdown follows, all they need to do is to invalidate the virtual cache line (need to be flushed back to memory if dirty). When the new VA mapping established and accessed, it will be a normal virtual cache miss</li> <li>OVC also does not need to care about this because they are doing a similar way (I guess).</li> <li>Lego need to handle mremap differently. Because we don\u2019t want to flush the dirty line back to memory, to save 1) one clflush, 2) another pcache miss. This means Lego wants to keep the content in Pcache. So the set_index of new VA and old VA matters in our case.</li> </ul> </li> </ul> <p>\u2013 Yizhou Shan Created: Mar 28, 2018 Last Updated: Mar 29, 2018  </p>"},{"location":"lego/syscall/compat/","title":"Compat SYSCALL in Lego","text":"<p>Lego does not support compatible syscalls, where one is able to run 32-bit image on 64-bit OS. However, the ugly FPU code and signal part in Linux is heavily hacked with the assumption that compat syscall is supported. We are no expert in this FPU thing, just to make sure we don\u2019t break this FPU evil, Lego adds the fake compat syscall support. Fake means whenever a 32-bit syscall is issued, Lego will just panic.</p>"},{"location":"lego/syscall/compat/#kconfig","title":"Kconfig","text":"<p>If one compiles a x86_64 Linux kernel, compat syscalls are supported by default. Everything related to compat syscalls are controlled by the following two Kconfig options. Lego may want to support compat syscalls in the future, thus we add these two Kconfigs to avoid future mess:</p> <ul> <li><code>CONFIG_COMPAT</code></li> <li><code>CONFIG_IA32_EMULATION</code></li> </ul>"},{"location":"lego/syscall/compat/#internal","title":"Internal","text":""},{"location":"lego/syscall/compat/#entry-points","title":"Entry Points","text":"<p>The assembly entry points are defined in <code>entry/entry_64_compat.S</code>: <pre><code>ENTRY(entry_SYSENTER_compat)\n        ...\n        call    do_fast_syscall_32\nGLOBAL(__end_entry_SYSENTER_compat)\nENDPROC(entry_SYSENTER_compat)\n\nENTRY(entry_SYSCALL_compat)\n        ...\n        call    do_fast_syscall_32\nEND(entry_SYSCALL_compat)\n\nENTRY(entry_INT80_compat)\n        ...\n        call    do_int80_syscall_32\nEND(entry_INT80_compat)\n</code></pre></p>"},{"location":"lego/syscall/compat/#entry-points-setup","title":"Entry Points Setup","text":"<p>The assembly entry points are filled to system registers and IDT table. So users can <code>actually</code> issue those calls, Lego is able to catch them: <pre><code>static void syscall_init(void)\n{\n        wrmsr(MSR_STAR, 0, (__USER32_CS &lt;&lt; 16) | __KERNEL_CS);\n        wrmsrl(MSR_LSTAR, (unsigned long)entry_SYSCALL_64);\n\n#ifdef CONFIG_IA32_EMULATION\n        wrmsrl(MSR_CSTAR, (unsigned long)entry_SYSCALL_compat);\n        /*  \n         * This only works on Intel CPUs.\n         * On AMD CPUs these MSRs are 32-bit, CPU truncates MSR_IA32_SYSENTER_EIP.\n         * This does not cause SYSENTER to jump to the wrong location, because\n         * AMD doesn't allow SYSENTER in long mode (either 32- or 64-bit).\n         */\n        wrmsrl_safe(MSR_IA32_SYSENTER_CS, (u64)__KERNEL_CS);\n        wrmsrl_safe(MSR_IA32_SYSENTER_ESP, 0ULL);\n        wrmsrl_safe(MSR_IA32_SYSENTER_EIP, (u64)entry_SYSENTER_compat);\n#else\n        wrmsrl(MSR_CSTAR, (unsigned long)ignore_sysret);\n        wrmsrl_safe(MSR_IA32_SYSENTER_CS, (u64)GDT_ENTRY_INVALID_SEG);\n        wrmsrl_safe(MSR_IA32_SYSENTER_ESP, 0ULL);\n        wrmsrl_safe(MSR_IA32_SYSENTER_EIP, 0ULL);\n#endif\n\n\n        /* Flags to clear on syscall */\n        wrmsrl(MSR_SYSCALL_MASK,\n               X86_EFLAGS_TF|X86_EFLAGS_DF|X86_EFLAGS_IF|\n               X86_EFLAGS_IOPL|X86_EFLAGS_AC|X86_EFLAGS_NT);\n}\narch/x86/kernel/cpu/common.c\n\nvoid __init trap_init(void)\n{\n        ...\n#ifdef CONFIG_IA32_EMULATION\n        set_system_intr_gate(IA32_SYSCALL_VECTOR, entry_INT80_compat);\n        set_bit(IA32_SYSCALL_VECTOR, used_vectors);\n#endif\n        ...\n}\narch/x86/kernel/traps.c\n</code></pre></p>"},{"location":"lego/syscall/compat/#c-code","title":"C code","text":"<p>The actual C code is in <code>entry/common.c</code>: <pre><code>#if defined(CONFIG_X86_32) || defined(CONFIG_IA32_EMULATION)\nstatic __always_inline void do_syscall_32_irqs_on(struct pt_regs *regs)\n{\n#ifdef CONFIG_IA32_EMULATION\n        current-&gt;thread.status |= TS_COMPAT;\n#endif\n\n        BUG();\n}\n\n/* Handles int $0x80 */\n__visible void do_int80_syscall_32(struct pt_regs *regs)\n{\n        BUG();\n}\n\n/* Returns 0 to return using IRET or 1 to return using SYSEXIT/SYSRETL. */\n__visible long do_fast_syscall_32(struct pt_regs *regs)\n{\n        BUG();\n}\n#endif\n</code></pre></p> <p>\u2013 Yizhou Shan Created: Feb 22, 2018 Last Updated: Feb 22, 2018</p>"},{"location":"lego/syscall/facts/","title":"Lego SYSCALL Facts","text":"<p>This document is about the general concepts of Lego syscall implementation. If you are developing syscall, please read this document first.</p>"},{"location":"lego/syscall/facts/#interrupts-enabled","title":"Interrupts Enabled","text":"<p>Each syscall is invoked with interrupts enabled. Also, it must return with interrupts enabled as well. Any buggy syscall implementation will be catched by <code>syscall_return_slowpath()</code>: <pre><code>void syscall_return_slowpath(struct pt_regs *regs)\n{\n        if (WARN(irqs_disabled(), \"syscall %ld left IRQs disabled\", regs-&gt;orig_ax))\n                local_irq_enable();\n\n        local_irq_disable();\n        prepare_exit_to_usermode(regs);\n}\n\nvoid do_syscall_64(struct pt_regs *regs)\n{\n        ..\n        local_irq_enable();\n\n        if (likely(nr &lt; NR_syscalls)) {\n                regs-&gt;ax = sys_call_table[nr](\n                        regs-&gt;di, regs-&gt;si, regs-&gt;dx,\n                        regs-&gt;r10, regs-&gt;r8, regs-&gt;r9);\n        }   \n\n        syscall_return_slowpath(regs);\n        ..\n}\n</code></pre></p>"},{"location":"lego/syscall/facts/#get-user-entry-pt_regs","title":"Get User Entry pt_regs","text":"<p>The macro <code>task_pt_regs()</code> always return the <code>pt_regs</code>, that saves the user context when it issued the syscall, no matter how many levels interrupts are nested when you call <code>task_pt_regs()</code>. This is based on the fact that kernel stack is empty at syscall entry, thus this user <code>pt_regs</code> was saved at the <code>top</code> of kernel stack: <pre><code>#define task_pt_regs(tsk)       ((struct pt_regs *)(tsk)-&gt;thread.sp0 - 1)\n</code></pre> <pre><code>ENTRY(entry_SYSCALL_64)\n        SWAPGS\n\n        /*\n         * SYSCALL does not change rsp for us!\n         * Save the previous rsp and load the top of kernel stack.\n         * It must be the top of kernel stack, since we came here\n         * from *userspace*.\n         */\n        movq    %rsp, PER_CPU_VAR(rsp_scratch)\n        movq    PER_CPU_VAR(cpu_current_top_of_stack), %rsp\n\n        /*\n         * Construct struct pt_regs on stack\n         *\n         * In any syscall handler, you can use\n         *      current_pt_regs()\n         * to get these registers.\n         */\n        pushq   $__USER_DS                      /* pt_regs-&gt;ss */\n        pushq   PER_CPU_VAR(rsp_scratch)        /* pt_regs-&gt;sp */\n        pushq   %r11                            /* pt_regs-&gt;flags */\n        pushq   $__USER_CS                      /* pt_regs-&gt;cs */\n        pushq   %rcx                            /* pt_regs-&gt;ip */\n        pushq   %rax                            /* pt_regs-&gt;orig_ax */\n        pushq   %rdi                            /* pt_regs-&gt;di */\n        pushq   %rsi                            /* pt_regs-&gt;si */\n        pushq   %rdx                            /* pt_regs-&gt;dx */\n        pushq   %rcx                            /* pt_regs-&gt;cx */\n        pushq   $-ENOSYS                        /* pt_regs-&gt;ax */\n        pushq   %r8                             /* pt_regs-&gt;r8 */\n        pushq   %r9                             /* pt_regs-&gt;r9 */\n        pushq   %r10                            /* pt_regs-&gt;r10 */\n        pushq   %r11                            /* pt_regs-&gt;r11 */\n        sub     $(6*8), %rsp                    /* pt_regs-&gt;bp, bx, r12-15 */\n        ....\n</code></pre></p> <p>\u2013 Yizhou Shan Created: Feb 22, 2018 Last Updated: Feb 22, 2018</p>"},{"location":"lego/syscall/fork/","title":"fork()","text":""},{"location":"lego/syscall/fork/#memory-manager","title":"Memory Manager","text":"<p>We need to duplicate the address space in the memory manager side. Follow the traditional <code>fork()</code> semantic, both the existing and newly created address space will be write-protected.</p> <p>Since we have the flexibility to implement any VM organization, we should be careful while duplicating the address space. Currently, we are using page-based VM, thus the duplicating is basically creating a new <code>pgd</code> and copy existing pgtables, and further downgrade permission to read-only. This is now performed by <code>lego_copy_page_range()</code>.</p> <p>The final write-protect is performed by <code>lego_copy_one_pte()</code>: <pre><code>static inline int lego_copy_one_pte(..)\n{\n    ..\n    /*\n     * If it's a COW mapping, write protect it both\n     * in the parent and the child\n     */\n    if (is_cow_mapping(vm_flags)) {\n        ptep_set_wrprotect(src_pte);   \n        pte = pte_wrprotect(pte);      \n    }\n    ...\n}\n</code></pre></p>"},{"location":"lego/syscall/fork/#duplicate-vm-free-pool","title":"Duplicate VM Free Pool","text":"<p>TODO Yutong</p>"},{"location":"lego/syscall/fork/#processor-manager","title":"Processor Manager","text":"<p>Boring implementation details in the processor manager side.</p>"},{"location":"lego/syscall/fork/#entry-points","title":"Entry Points","text":"<ul> <li><code>fork()</code></li> <li><code>vfork()</code></li> <li><code>clone()</code></li> <li><code>kernel_thread()</code></li> </ul> <p>All of them land on <code>do_fork()</code>, which is Lego\u2019s main fork function.</p>"},{"location":"lego/syscall/fork/#do_fork","title":"do_fork()","text":"<p>There are mainly three parts within <code>do_fork()</code>: <code>1)</code> <code>copy_process()</code>, which duplicates a new task based on <code>current</code>, including allocate new kernel stack, new task_struct, increase mm reference counter, etc. <code>2)</code> If we are creating a new process, then tell global monitor or memory manager to let them update bookkeeping and create corresponding data structures. <code>3)</code> <code>wake_up_new_task()</code>, which gives away the newly created task to local scheduler.</p>"},{"location":"lego/syscall/fork/#copy_process","title":"copy_process()","text":"<p>The routine is kind of boring. It do a lot dirty work to copy information from calling thread to new thread. The most important data structures of course are <code>task_struct</code>, <code>mm_sturct</code>, <code>sighand</code>, and so on. This section only talks about few of them, and leave others to readers who are interested.</p>"},{"location":"lego/syscall/fork/#sanity-checking","title":"Sanity Checking","text":"<p>Mainly check if <code>clone_flags</code> are passed properly. For example, if user is creating a new thread, that implies certain data structures are shared, cause new thread belongs to the same process with the calling thread. If <code>CLONE_THREAD</code> is passed, then <code>CLONE_SIGHAND</code>, <code>CLONE_VM</code>, and so on must be set as well. <pre><code>    /*\n     * Thread groups must share signals as well, and detached threads\n     * can only be started up within the thread group.\n     */\n    if ((clone_flags &amp; CLONE_THREAD) &amp;&amp; !(clone_flags &amp; CLONE_SIGHAND))\n        return ERR_PTR(-EINVAL);\n\n    /*\n     * Shared signal handlers imply shared VM. By way of the above,\n     * thread groups also imply shared VM. Blocking this case allows\n     * for various simplifications in other code.\n     */\n    if ((clone_flags &amp; CLONE_SIGHAND) &amp;&amp; !(clone_flags &amp; CLONE_VM))\n        return ERR_PTR(-EINVAL);\n</code></pre></p>"},{"location":"lego/syscall/fork/#dup_task_struct","title":"dup_task_struct()","text":"<p>Two main things: 1) duplicate a new <code>task_struct</code>, 2) duplicate a new kernel stack. x86 is just a weird architecture, the size of <code>task_struct</code> depends on the size of fpu. So the allocation and duplication need to callback to x86-specific code to duplicate the task_struct and fpu info. <pre><code>int arch_dup_task_struct(struct task_struct *dst, struct task_struct *src)\n{\n    memcpy(dst, src, arch_task_struct_size);\n\n    return fpu__copy(&amp;dst-&gt;thread.fpu, &amp;src-&gt;thread.fpu);\n}\n</code></pre> The stack duplication is fairly simple, just copy everything from the old stack to new stack. Of course, it needs to setup the <code>thread_info</code> to points to this new thread, so the <code>current</code> macro will work. <pre><code>static void setup_thread_stack(struct task_struct *p, struct task_struct *org)\n{\n        /* Duplicate whole stack! */\n        *task_thread_info(p) = *task_thread_info(org);\n\n        /* Make the `current' macro work */\n        task_thread_info(p)-&gt;task = p;\n}\n</code></pre></p>"},{"location":"lego/syscall/fork/#copy_mm","title":"copy_mm()","text":"<p>This is where threads within a process will share the virtual address space happens. If we are creating a new process, then this function will create a new <code>mm_struct</code>, and also a new <code>pgd</code>: <pre><code>/*\n * pgd_alloc() will duplicate the identity kernel mapping\n * but leaves other entries empty:\n */\nmm-&gt;pgd = pgd_alloc(mm);\nif (unlikely(!mm-&gt;pgd)) {\n        kfree(mm);\n        return NULL;\n}\n</code></pre></p>"},{"location":"lego/syscall/fork/#duplicate-pcache-data","title":"Duplicate pcache data","text":"<p>TODO</p> TODO: hook with pcache <p>We need to duplicate the pcache vm_range array, once Yutong finished the code.</p>"},{"location":"lego/syscall/fork/#setup_sched_fork","title":"setup_sched_fork()","text":"<p>Callback to scheduler to setup this new task. It may reset all scheduler related information. Here we also have a chance to change this task\u2019s scheduler class:</p> <pre><code>int setup_sched_fork(unsigned long clone_flags, struct task_struct *p)\n{\n        int cpu = get_cpu();\n\n        __sched_fork(clone_flags, p);\n\n        p-&gt;state = TASK_NEW;\n        ...\n        if (unlikely(p-&gt;sched_reset_on_fork)) {\n                if (task_has_rt_policy(p)) {\n                        p-&gt;policy = SCHED_NORMAL;\n                        p-&gt;static_prio = NICE_TO_PRIO(0);\n                        p-&gt;rt_priority = 0;\n                } else if (PRIO_TO_NICE(p-&gt;static_prio) &lt; 0)\n                        p-&gt;static_prio = NICE_TO_PRIO(0);\n\n                p-&gt;prio = p-&gt;normal_prio = __normal_prio(p);\n                set_load_weight(p);\n                ...\n        }    \n\n        if (rt_prio(p-&gt;prio))\n                p-&gt;sched_class = &amp;rt_sched_class;\n        else {\n                p-&gt;sched_class = &amp;fair_sched_class;\n                set_load_weight(p);\n        }    \n\n        __set_task_cpu(p, cpu);\n        if (p-&gt;sched_class-&gt;task_fork)\n                p-&gt;sched_class-&gt;task_fork(p);\n\n        ...\n}\n</code></pre>"},{"location":"lego/syscall/fork/#allocate-new-pid","title":"Allocate new pid","text":"<p>In both Lego and Linux, we don\u2019t allocate new pid for a new thread, if that thread is an <code>idle thread</code>. So callers of <code>do_fork</code> needs to pass something to let <code>do_fork</code> know. In Linux, they use <code>struct pid, init_struct_pid</code> to check. In Lego, we introduce an new clone_flag <code>CLONE_IDLE_THREAD</code>. If that flag is set, <code>do_fork()</code> will try to allocate a new pid for the new thread. Otherwise, it will be 0: <pre><code>/* clone idle thread, whose pid is 0 */\nif (!(clone_flags &amp; CLONE_IDLE_THREAD)) {\n        pid = alloc_pid(p);\n        if (!pid)\n                goto out_cleanup_thread;\n}\n</code></pre></p> <p>So, only the <code>init_idle()</code> function can pass this <code>CLONE_IDLE_THREAD</code> down. All other usages are wrong and should be reported.</p> <p>In order to avoid conflict with Linux clone_flag, we define it as: <pre><code>#define CLONE_IDLE_THREAD       0x100000000\n</code></pre></p>"},{"location":"lego/syscall/fork/#settidcleartid","title":"SETTID/CLEARTID","text":"<p>These are some futex related stuff. I will cover these stuff in futex document: <pre><code>p-&gt;set_child_tid = (clone_flags &amp; CLONE_CHILD_SETTID) ? child_tidptr : NULL;\n/*  \n * Clear TID on mm_release()?\n */\np-&gt;clear_child_tid = (clone_flags &amp; CLONE_CHILD_CLEARTID) ? child_tidptr : NULL;\n\n#ifdef CONFIG_FUTEX\np-&gt;robust_list = NULL;\n#endif\n</code></pre></p>"},{"location":"lego/syscall/fork/#copy_thread_tls","title":"copy_thread_tls()","text":"<p>This is the most interesting function. Cover later.</p>"},{"location":"lego/syscall/fork/#p2m_fork","title":"p2m_fork()","text":"<p>In order to track user activities, we need to know when user are going to create new process. Fork is the best time and the only time we kernel know. So, Lego adds this special hook to tell remote global monitor or memory manager that there is a new process going to be created. Upon receiving this message, remote monitor will update its bookkeeping for this specific user/vNode.</p> <pre><code>/* Tell remote memory component */\n#ifdef CONFIG_COMP_PROCESSOR\nif (clone_flags &amp; CLONE_GLOBAL_THREAD) {\n        ...\n        p2m_fork(p, clone_flags);\n        ...\n}   \n#endif\n</code></pre> <p>The <code>CLONE_GLOBAL_THREAD</code> should only be set, if the following cases happen:</p> <ul> <li>fork()</li> <li>vfork()</li> <li>clone(), without <code>CLONE_THREAD</code> being set</li> </ul> <p>In order to avoid conflict with Linux clone_flag, we define it as: <pre><code>#define CLONE_GLOBAL_THREAD     0x200000000\n</code></pre></p>"},{"location":"lego/syscall/fork/#wake_up_new_task","title":"wake_up_new_task()","text":"<p>The last step of <code>do_fork</code> is waking up the new thread or process, which is performed by <code>wake_up_new_task()</code> function. The first question this function will ask is: <code>which cpu to land?</code> The answer comes from <code>select_task_rq()</code>:</p> <pre><code>static inline\nint select_task_rq(struct task_struct *p, int cpu, int sd_flags, int wake_flags)\n{\n        if (p-&gt;nr_cpus_allowed &gt; 1)\n                cpu = p-&gt;sched_class-&gt;select_task_rq(p, cpu, sd_flags, wake_flags);\n        else\n                cpu = cpumask_any(&amp;p-&gt;cpus_allowed);\n        ...\n}\n</code></pre> <p>Clearly, this is determined by <code>cpus_allowed</code>, which is the same with its parent at this point. That being said, if the parent is only able to run on one specific CPU, then all its children will end up running on the same CPU when they wake up (they could change their affinity later). This is also the default on Linux: <code>A child created via fork(2) inherits its parent's CPU affinity mask. The affinity mask is preserved across an execve(2).</code></p> <p>After landing CPU is selected, following operation is simple: just enqueue this task into landing CPU\u2019s runqueue, and we are done:</p> <pre><code>void wake_up_new_task(struct task_struct *p)\n{\n        ...\n/* Select a CPU for new thread to run */\n#ifdef CONFIG_SMP\n        /*   \n         * Fork balancing, do it here and not earlier because:\n         *  - cpus_allowed can change in the fork path\n         *  - any previously selected cpu might disappear through hotplug\n         */\n        set_task_cpu(p, select_task_rq(p, task_cpu(p), SD_BALANCE_FORK, 0));\n#endif\n\n        rq = __task_rq_lock(p);\n        activate_task(rq, p, 0);\n        p-&gt;on_rq = TASK_ON_RQ_QUEUED;\n        ...\n}\n</code></pre> <p>\u2013 Yizhou Shan Created: Feb 11, 2018 Last Updated: Feb 27, 2018</p>"},{"location":"lego/syscall/getrusage/","title":"getrusage","text":"<p>The syscall <code>getrusage</code> is used to get user program resource usage. It is a nice syscall. But only nice if kernel has all the nice bookkeeping. It is a luxury for us to have all the counting.</p> <p>The syscall is added recently due to <code>wait</code> family syscalls, which use and bookkeep some of <code>rusage</code>.</p> <p>As on the last updated date (Mar 7), the syscall in Lego only reports number of context switches and a few others.</p> <p>\u2013 Yizhou Shan Created: Mar 7, 2018 Last Updated: Mar 7, 2018</p>"},{"location":"lego/syscall/mremap/","title":"mremap()","text":""},{"location":"lego/syscall/msync/","title":"msync()","text":"<p>The document is a summary I wrote after reading <code>Failure-atomic msync()</code> paper, which help me understand several questions related to <code>msync()</code>.</p> <ul> <li> <p><code>msync() is not atomic.</code> During msync(), pages are being written back to disk one by one (or batched): few pages have been flushed back, but few pages are still in the memory. This premature writeback is not atomic and will be affected by failure.\u000b\u000b</p> </li> <li> <p><code>msync() need concurrency control</code>. This actually is the issue I asked before. With a multi-threaded application, does msync() provide the synchronization semantic? The answer is no. Other threads within the same process are able to write to pages under msync(). This implies, application need to handle concurrency by themselves, e.g., rwlocks. \u000b\u000bAt the very beginning, I thought msync() provide this semantic. The only way to implement this should be: kernel make all pages\u2019 PTE read-only, and then perform flush back. If any other threads does a write during flush, they will have a page fault. And in the pgfault function, we hold the threads until the pages are written back.</p> </li> <li> <p>Probably some nice reading. <code>fsync, fdatasync</code><sup>1</sup>.</p> </li> </ul> <p>\u2013 Yizhou Shan Created: Feb 01, 2018 Last Updated: Mar 23, 2018</p> <ol> <li> <p>RFLUSH: Rethink the Flush \u21a9</p> </li> </ol>"},{"location":"lego/syscall/wait_and_exit/","title":"wait4(), waitid(), and exit()","text":"<p>Lego supports <code>wait4()</code> and <code>waitid()</code> syscalls, and they are compatible with Linux programs. These two syscalls rely on <code>exit_notify()</code> function when a thread <code>exit()</code>. Basically, when a thread exit, it will notify its parent, and reparent<sup>3</sup> its children if necessary.</p> <p>Facts in Lego:</p> <ul> <li>Lego does not have process group and session<sup>2</sup> concept. Each process is within its own process group and session.</li> <li>This implies Lego will not have Orphaned Process Group<sup>1</sup> when a process exit.</li> <li>Orphan process<sup>3</sup> is adopted by init process (pid 1) if its father is a single-thread process, otherwise it will be adopted by other thread within its father\u2019s process. This is performed by function <code>forget_original_parent()</code>.</li> <li>wait, signal, exec, fork are close related.</li> </ul> <p>\u2013 Yizhou Shan Created: Mar 8, 2018 Last Updated: Mar 10, 2018</p> <ol> <li> <p>Orphaned Process Groups \u21a9</p> </li> <li> <p>Process Group \u21a9</p> </li> <li> <p>Orphan Process \u21a9\u21a9</p> </li> </ol>"},{"location":"misc/cheatsheet/","title":"Cheatsheet","text":""},{"location":"misc/cheatsheet/#python","title":"Python","text":"<ul> <li><code>f'{0x0c180606:032b}'</code></li> </ul>"},{"location":"misc/cheatsheet/#vnc","title":"VNC","text":"<ul> <li> <p>Server side: Start server on certain port with certain geometry: <pre><code>vncserver :66 -geometry 1920x1080\n</code></pre></p> </li> <li> <p>Client side: for safety, use SSH tunnel.</p> <ul> <li><code>-p 22</code>: ssh port is 22</li> <li><code>-L 7777:localhost:5966</code>: Forward localhost\u2019s 7777 to server\u2019s 5966 <pre><code>Step 1)\nssh -p 22 -v -C -L 7777:localhost:5966 root@yourserver.com\n\nStep 2)\nUse VNC client to establish connection with localhost:7777\n</code></pre></li> </ul> </li> </ul>"},{"location":"misc/cheatsheet/#virsh","title":"virsh","text":"<ul> <li>Pass commands to QEMU in the virsh bash: <pre><code># qemu-monitor-command guest_os_id --hmp \"info cpus\"\n</code></pre></li> </ul>"},{"location":"misc/cheatsheet/#markdown","title":"Markdown","text":"<ul> <li>Emoji cheatsheet</li> </ul>"},{"location":"misc/cheatsheet/#tmux","title":"tmux","text":"<ul> <li>Install tmux-plugins, it makes your terminal bling bling.</li> </ul>"},{"location":"misc/cheatsheet/#bash","title":"bash","text":"<ul> <li> <p>Show current git branch in PS1: <pre><code>parse_git_branch() {\n     git branch 2&gt; /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/ git:(\\1)/'\n}\n\nPS1=\"\\[\\e[32m\\][\\u@\\h: \\W\\e[33m\\]\\$(parse_git_branch)\\[\\033[32m\\]]\\[\\e[00m\\] $ \"\n</code></pre></p> </li> <li> <p>Forward <code>man</code> pages to <code>vim</code>: <pre><code>vman() { man $* | col -b | vim -c 'set ft=man nomod nolist' -; }    \nalias man=\"vman\"\n</code></pre></p> </li> </ul>"},{"location":"misc/cheatsheet/#git","title":"Git","text":"<pre><code>git log --pretty=\"%C(Yellow)%h %C(auto)%d (%C(Green)%cr%C(reset))%x09 %C(Cyan)%an: %C(reset)%s\" --date=short --graph\n</code></pre>"},{"location":"misc/cheatsheet/#qemu","title":"QEMU","text":"<ul> <li>Run standalone kernel: <pre><code># Create a new directory to store the serial output from printk().\nOUTPUT_DIR=\"test-output\"\nif [ -e $OUTPUT_DIR ]; then\n        if [ -f $OUTPUT_DIR ]; then\n                echo \"ERROR: $OUTPUT_DIR is not a directly\"\n                exit 1\n        fi\nelse\n        mkdir -p $OUTPUT_DIR\nfi\n\nKERNEL=\"arch/x86_64/boot/bzImage\"\nKERNEL_PARAM=\"console=ttyS0 earlyprintk=serial,ttyS0,115200\"\nSERIAL=\"-serial file:$OUTPUT_DIR/ttyS0 -serial file:$OUTPUT_DIR/ttyS1\"\n\n# -cpu Haswell,+tsc,+sse,+xsave,+aes,+avx,+erms,+pdpe1gb,+pge \\\n# Above -cpu option may not work with some kernels.\nqemu-system-x86_64 -s  \\\n        -nographic \\\n        -kernel $KERNEL -append \"$KERNEL_PARAM\" \\\n        -no-reboot \\\n        -d int,cpu_reset -D $OUTPUT_DIR/qemu.log \\\n        $SERIAL \\\n        -m 16G \\\n        -monitor stdio \\\n        -smp cpus=24,cores=12,threads=2,sockets=2 \\\n        -numa node,cpus=0-11,mem=8G,nodeid=0 \\\n        -numa node,cpus=12-23,mem=8G,nodeid=1\n</code></pre></li> </ul>"},{"location":"misc/cheatsheet/#install-centos-on-dell-poweredge","title":"Install CentOS on Dell PowerEdge","text":"<ul> <li>Enable <code>SR-IOV</code> for future usage<ul> <li>Press <code>F11 Boot Manager</code> during boot</li> <li>Find <code>Integrated Devices</code></li> <li>Enable <code>SR-IOV Global Enable</code></li> </ul> </li> <li>Partition<ul> <li><code>/boot</code>: e.g, 50GB</li> <li><code>swap</code>: e.g, 4G</li> <li><code>/</code>: all left</li> </ul> </li> <li>Don\u2019t forget to enable Network during installation.</li> <li>Change SSH port<ul> <li>Disable <code>firewalld</code><ul> <li><code>systemctl stop firewalld</code></li> <li><code>systemctl disable firewalld</code></li> </ul> </li> <li>If SELinux is enabled<ul> <li><code>yum install policycoreutils-python</code></li> <li><code>semanage port -a -t ssh_port_t -p tcp #PORTNUMBER</code></li> </ul> </li> <li>Change <code>/etc/ssh/sshd_config</code></li> <li><code>systemctl restart sshd</code></li> </ul> </li> </ul>"},{"location":"misc/cheatsheet/#avoid-typing-ssh-password","title":"Avoid Typing SSH Password","text":"<ul> <li>Generate keys: <code>ssh-keygen -t rsa</code></li> <li>Copy to remote: <code>ssh-copy-id -i ~/.ssh/id_rsa.pub username@remotehost -p 22</code></li> </ul>"},{"location":"misc/cheatsheet/#grub2-on-ubuntu","title":"GRUB2 on Ubuntu","text":"<ul> <li>Nothing like grubby?! Shame on you.</li> <li>Step I: <code>cat /boot/grub/grub.cfg | grep menuentry</code> <pre><code>menuentry 'Ubuntu, with Linux 4.16.0' --class ubuntu  ...\nmenuentry 'Ubuntu, with Linux 4.9.92' --class ubuntu  ...\n</code></pre></li> <li>Step II: Open <code>/etc/default/grub</code>, change<ul> <li>GRUB_DEFAULT=\u201dAdvanced options for Ubuntu&gt;Ubuntu, with Linux 4.16.0\u201d</li> <li>GRUB_DEFAULT=\u201dAdvanced options for Ubuntu&gt;Ubuntu, with Linux 4.9.92\u201d</li> </ul> </li> <li>Step III: <code>sudo update-grub</code></li> </ul>"},{"location":"misc/cheatsheet/#migrate-to-ubuntu-from-macos","title":"Migrate to Ubuntu From MacOS","text":"<ul> <li>Disable [Super+p]. This is my tmux prefix somehow.</li> <li>xmodmap to switch Super and CTRL. 1</li> </ul>"},{"location":"misc/essential/","title":"System Developing Essentials","text":""},{"location":"misc/essential/#misc-advice","title":"Misc Advice","text":"<ul> <li>Elevator Pitches, John Wilkes</li> <li>Creating an effective poster, John Wilkes</li> <li>How to Get a Paper Accepted at OOPSLA</li> </ul>"},{"location":"misc/essential/#tools","title":"Tools","text":"<ul> <li>Stack and Register Dumper</li> <li>NMI and software Watchdog</li> <li>Tracepoint and Ring Buffer</li> <li>Profilers</li> <li>Counters</li> <li>Whiskey and Luck</li> </ul>"},{"location":"misc/essential/#keep-in-mind","title":"Keep in mind","text":"<ul> <li>Stress your system<ul> <li>Every single critical subsystem</li> <li>Confident with your base subsystem</li> <li>Fix bug/Improve perf at early stage</li> </ul> </li> <li>Plan ahead<ul> <li>Single thread, or thread pool?</li> <li>How to avoid using <code>lock</code>?</li> <li>What lock to use?</li> <li>How to reduce <code>lock contention</code>?</li> <li>Does this data structure need <code>reference counter</code>?</li> <li>Should I use per-cpu data structures?</li> <li>Should I pad this lock $-line aligned to avoid pingpong?</li> </ul> </li> <li> <p>Decent Cleanup</p> <ul> <li>I\u2019m fucking hate a crap kernel module just kill my machine, either stuck or bug.</li> <li>Free buffer/structure</li> <li>Remove the pointer from friends\u2019 list/tree. If you forgot to do so, mostly you will have some silent memory corruption. So be kind, cleanup what you have done during intilization.</li> <li>Report error. Do not be SILENT.</li> </ul> </li> <li> <p>Clever Buffer Management</p> <ul> <li>kmem_cache?</li> <li>static pre-allocated array?</li> <li>Ring buffer?</li> <li>Other than kmem_cache, I used other two solutions to optimize various dynamic allocation in LegoOS. The motivation is very simple: some data structures will be allocated/free very very frequently at runtime. So we want to speed it up!</li> </ul> </li> </ul>"},{"location":"misc/essential/#system-building-advice","title":"System Building Advice","text":"<ul> <li>John Ousterhout<ul> <li>If you don\u2019t know what the problem was, you haven\u2019t fixed it</li> <li>If it hasn\u2019t been used, it doesn\u2019t work</li> </ul> </li> </ul>"},{"location":"misc/jasmine/","title":"Jasmine","text":"<p>Cool and good-to-know stuff:</p> <ul> <li> <p>GigaIO</p> </li> <li> <p>RSS (Receiver Side Scaling)</p> </li> <li>Intel Flow Director</li> <li> <p>E2, ClickOS, NetVM, and Metron.</p> </li> <li> <p>AutoML</p> </li> <li> <p>What is \u2018Site Reliability Engineering\u2019?</p> </li> <li> <p>Deduplication: Content Based Page Sharing (CBPS) + COW</p> <ul> <li>Linux\u2019s Kernel Same-page Merging (KSM)</li> </ul> </li> <li> <p>Multi-Queue SSD, MQ-SSD <sup>2</sup></p> </li> <li> <p>Write Anywhere File Layout, WAFL. NetApp Paper<sup>1</sup>.</p> <ul> <li>Journaling</li> <li>Shadow Paging</li> <li>Soft Updates</li> </ul> </li> <li> <p>Shared-nothing architecture -&gt; no single point of contention</p> </li> <li> <p>ZeptoOS</p> </li> <li> <p>Tail-tolerant Distributed Systems</p> </li> <li> <p>S.M.A.R.T (Self-Monitoring, Analysis, and Reporting Technology)</p> </li> <li> <p>linux-mm. Actually, not that interesting.</p> </li> <li> <p>Serveless</p> <ul> <li>AWS Lambda</li> <li>Google Cloud Function</li> <li>Azure Functions</li> </ul> </li> <li> <p>SDS</p> <ul> <li>TidalScale</li> <li>ScaleMP</li> </ul> </li> <li> <p>Apache Crail</p> </li> <li> <p>Redis Lab</p> </li> <li> <p>Journaling of journal</p> </li> <li> <p>Concurrent Data Structures</p> <ul> <li>NUMA-aware data structures</li> <li>linearizability</li> <li>lock-free skip list</li> <li>blog</li> </ul> </li> </ul> <ol> <li> <p>WAFL Iron: Repairing Live Enterprise File Systems, FAST\u201818\u00a0\u21a9</p> </li> <li> <p>Linux Block IO: Introducing Multi-queue SSD Access on Multi-core Systems, SYSTOR\u201813\u00a0\u21a9</p> </li> </ol>"},{"location":"misc/talk/","title":"Talk","text":"<p>DASH dynamic ad over HTTP (video) rate adaption algorithm: estimate net bw? Multipath TCP https://www.multipath-tcp.org/ cost/byte, perf/$</p>"},{"location":"notes/CXL/","title":"What is up with CXL?","text":"Version History Date Description Nov 15, 2022 Small fixes Jul 17, 2022 Initial"},{"location":"notes/CXL/#intro","title":"Intro","text":"<p>Is CXL just another NUMA?</p> <p>You probably have heared about CXL many times. And you\u2019ve probably wondered, what is it, exactly? And why folks are so excited about it? This (short) note explains CXL from my own pespective. In particular, what is it, how to use it,  what\u2019s the current status, and what\u2019s next.</p> <p>DISCLAIMER: I\u2019m no expert in the CXL protocol itself. I\u2019m just a systems researcher who may need to compare my systems against CXL-enabled ones. Hence my thoughts and views could be biased and wrong. If you are looking for serious CXL specification stuff, please check out the official CXL site.</p> <p>Without further ado, let\u2019s get started.</p>"},{"location":"notes/CXL/#what-is-cxl","title":"What is CXL?","text":"<p>CXL is short for Compute Express Link. It has 3 types. I will focus on CXL type 3 device, the one used for memory expansion. The CXL hereafter refers to type 3.</p> <p>Originally CXL was proposed to tame DRAM/PM heterogeneity and has a framework to maintain cache coherence among accelerators. CXL is now mainly used in the disaggregated memory scenario. But was CXL originally designed with the disaggregated memory setting in mind? I doubt that.</p> <p>Hence it is interesting to think why CXL has such a successful spin-off. My take: because CXL was designed for heterogeenous DRAM technologies, one of its core design principle is to work with different kinds of memory. Using memory usually requires extremely low latency. As such, CXL requires a low latency interconnection between a processing unit (e.g., CPU) and a CXL controller (the one right before memory chips). This pursuit eventually brings a CPU closer to a device (CXL controller) that is capable of accessing external resources. It calls for something better/faster than the long-standing PCIe. And this subsequently enables the disaggregated memory usage.</p>"},{"location":"notes/CXL/#how-to-use-cxl","title":"How to use CXL?","text":"<p>I think there are two ways to look at CXL, one from the traditional server angel, and the other from resource disaggregation. Either way, CXL enables disaggregated memory with extrmely low latency.</p> <p>From the traditional server angle: CXL allows the CPUs to access remote memory (i.e., memory resides outside the server box) at extremely low-latency, very much like accessing a NUMA node (could be ~100ns, see the MS arXiv paper). Since the remote memory is provisioned separately from the servers, you basically enjoys memory expansive \u201cfree\u201d. Of course not exactly free, but it is relatable to NUMA system tuning.</p> <p>From the disaggregated memory angle: CXL enables another design spectrum in disaggregated memory (DM) systems. Usually, DM systems access remote memory over RDMA with a few software tricks at the client side. The tricks include explicit APIs (AIFM, OSDI\u201820), runtime (Semeru, OSDI\u201820), kernel paging (InfiniSwap, NSDI\u201817). No matter what software is used, the overhead of accessing disaggregated memory is usually larger than 2-4 us. The overhead comes from software cost, DMA to RDMA NIC cost, RDMA NIC cost, etc. CXL brings something new to the table. At its core, CXL claims a PCIe bus address and allows CPUs to access remote memory using LD/ST, bypassing all the software and NIC overheads. The DirectCXL, ATC\u201822 paper has a nice breakdown.</p>"},{"location":"notes/CXL/#whats-the-status-of-cxl","title":"What\u2019s the status of CXL?","text":"<p>CXL is taking off.</p> <p>Cloud vendors are pushing it. Microsoft and Meta have released papers on their in-houst CXL platforms. Though no hardware is actually evaluated, they are building it. I remember Meta has CXL FPGAs long time ago.</p> <p>The whole industry is pushing it. There are numerous summits hosting CXL tutorials. The latest being OCP Global Summit 2022.</p>"},{"location":"notes/CXL/#whats-next-for-cxl","title":"What\u2019s next for CXL?","text":"<p>I think there are A LOT to explore. Research wise. Like concurrency.</p>"},{"location":"notes/CXL/#readings","title":"Readings","text":"<ul> <li>First-Gen CXL, arXiv\u201822.<ul> <li>Two contributions. Azure memory standing analysis, and a CXL prototype description.</li> <li>Works for opaque VM. The system is intergrated with cluster-side VM scheduler.</li> <li>No page migration, but VM migration.</li> <li>Has ML-based VM memory usage prediction</li> <li>And runtime QoS monitoring based on PMU countes</li> <li>The paper is accepted to ASPLOS\u201823 and renamed to Pond.</li> </ul> </li> <li>TPP, arXiv\u201822.<ul> <li>Two contribtions. Workloads analysis and an enhanced paging system.</li> <li>Works within a normal linux kernel (has user space parts), various improvements on LRU lists etc.</li> <li>Both the MS and TPP paper assume accessing to remote CXL memory is like accessing NUMA nodes, latency runs at around 100ns. Crazy numbers.</li> </ul> </li> <li>DirectCXL, ATC\u201822<ul> <li>First FPGA prototype.</li> <li>Since they don\u2019t have CXL-enabled x86, they use RISC-V.</li> <li>The latency is around 300ns?</li> </ul> </li> </ul>"},{"location":"notes/MLIR/","title":"MLIR","text":"Version History Date Description May 8, 2023 Add Mojo Jan 14, 2023 Add LingoDB and DAPHNE Jul 3, 2022 Add Pathways Apr 2, 2022 Ported from Craft. Recently, I switched to Craft for technical writing. I\u2019m very happy I made that transition. Craft is great at exporting things to Markdown format. <p>This document is organized as follows.</p> <ol> <li>MLIR at 10,000 feet - an overview.</li> <li>Why MLIR was created? - a study of the original MLIR paper.</li> <li>How MLIR is used in the wild? - case studies.</li> </ol> <p>Without further ado, let\u2019s get started.</p>"},{"location":"notes/MLIR/#mlir-at-10000-feet","title":"MLIR At 10,000 Feet","text":"<p>MLIR is short for Multi-Level Intermediate Representation. MLIR helps to build reusage compiler infrastructure and reduce duplicate codes.</p> <p>I draw the following figure to show MLIR\u2019s workflow at a very high level.</p> <p>In specific:</p> <ul> <li>MLIR\u2019s input: applications, compilers, C program, etc</li> <li>Within MLIR, we can implement multiple Dialects for distinct inputs. For instance, we could use a Dialect to deal with tensors. Further, we can deploy a shared optimization layer to unify things.</li> <li>Once we have an optimal IR, MLIR can now lower it onto the backends such as LLVM for CPUs, CIRCT for FPGAs. If you are targeting specialized hardware such as FPGA or TPU, you still need vendor-tools for final compilation (e.g., use Vivado to synthesis Verilog).</li> </ul> <p></p>"},{"location":"notes/MLIR/#resources","title":"Resources","text":"<p>I have found several excellent primer readings.</p> <ul> <li>LLVM Paper from Google, 2020. This paper describes the rationale behind MLIR. Chris L is one of the authors.</li> <li>LLVM MLIR Tutorial<ul> <li>I didn\u2019t understand this image when I first read it. But now it all makes sense. MLIR is something that lies across language AST and LLVM IR.</li> <li></li> </ul> </li> <li>ScaleHLS, HPCA\u201822 can compile HLS C/C++ or PyTorch model to optimized HLS C/C++ using MLIR.</li> </ul>"},{"location":"notes/MLIR/#motivation-from-the-google-mlir-paper","title":"Motivation from the Google MLIR Paper","text":"<p>This paper has a really nice Intro, pay close attention to how they lay out the storyline. If you are new to PL just like me, I strongly recommend going through the MLIR Toy Example (covered below ) for a better understanding, and then come back, read through this again. The following text are directly copied from this seminal paper.</p> <ol> <li>A common characteristic of popular ML systems is their \u201cone size \ufb01ts all\u201d approach\u2014a single abstraction level to interface with the system: the LLVM Intermediate Representation (IR) is roughly \u201cC with vectors\u201d, and JVM provides an \u201cobject-oriented type system with a garbage collector\u201d abstraction. This \u201cone size \ufb01ts all\u201d approach is incredibly valuable\u2014and in practice, the mapping to these domains from ubiquitous source languages (C/C++ and Java respectively) is straightforward.   (Praise the unified LLVM IR)</li> <li>At the same time, many problems are better modeled at a higher- or lower-level abstraction, e.g. source-level analysis of C++ code is very dif\ufb01cult on LLVM IR. We observe that many languages (including e.g. Swift, Rust, Julia, Fortran) develop their own IR in order to solve domain-speci\ufb01c problems, like language/library-speci\ufb01c optimizations, \ufb02ow-sensitive type checking. Similarly, machine learning systems typically use \u201cML graphs\u201d as a domain-speci\ufb01c abstraction in the same way. (Point out the issues about LLVM IR)</li> <li>While the development of domain speci\ufb01c IRs is a well studied art, their engineering and implementation cost remains high. \u2026 this can lead to lower quality compiler systems. (Point out that developing customized IR framework is challenging)</li> <li>The MLIR project aims to directly tackle these programming language design and implementation challenges\u2014by making it very cheap to de\ufb01ne and introduce new abstraction levels, and provide \u201cin the box\u201d infrastructure to solve common compiler engineering problems. MLIR does this by<ul> <li>standardizing the Static Single Assignment (SSA)-based IR data structures</li> <li>providing a declarative system for de\ufb01ning IR dialects (demonstrated below using the Toy example)</li> <li>providing a wide range of common infrastructure (including documentation, parsing and printing logic, location tracking, multithreaded compilation support, pass management, etc).</li> </ul> </li> </ol> <p>This image shows that most high-level languages have their own AST and associated infrastructure for transforming etc. Though language-specific, these are modules doing similar things. MLIR is a general framework to facilitate the development of such language-specific modules. It allows developers to use a unified codebase/framework to do their optimizations and develop some common, shared optimizations for multiple inputs.</p> <p>I recommend reading Toy Example Tutorial for a deep understanding.</p> <p></p> <p>This image is MLIR\u2019s original motivation. They found that ML graphs have a lot of different compilers. The compilation process is fragmented and some compilers are not following the best practices.</p> <p></p>"},{"location":"notes/MLIR/#case-studies","title":"Case Studies","text":""},{"location":"notes/MLIR/#example-1-mlir-toy-example","title":"Example 1: MLIR Toy Example","text":"<p>While reading through its documentation, I\u2019m starting to get a sense of what problem MLIR is trying to solve. The MLIR paper for sure describes the problem at a high level, but being able to read through the code example and its documentation helps a lot.</p> <p>The following quote is the same motivation described in the MLIR paper.</p> <p>Other compilers, like LLVM (see the Kaleidoscope tutorial), offer a fixed set of predefined types and (usually low-level / RISC-like) instructions.</p> <p>It is up to the frontend for a given language to perform any language-specific type-checking, analysis, or transformation before emitting LLVM IR. &lt;- also mentioned in the MLIR paper.</p> <p>For example, Clang will use its AST to perform not only static analysis but also transformations, such as C++ template instantiation through AST cloning and rewrite. Finally, languages with construction at a higher level than C/C++ may require non-trivial lowering from their AST to generate LLVM IR.</p> <p>Consequently, multiple frontends end up reimplementing significant pieces of infrastructure to support the need for these analyses and transformations. MLIR addresses this issue by being designed for extensibility. There are few pre-defined instructions (operations in MLIR terminology) or types.</p> <p>Like C, Swift, Rust, etc., each language has its own AST optimizers that do some language-specific transformations and analysis. This is quite tedious to do. So:</p> <p>MLIR is designed to allow all IR elements, such as attributes, operations, and types, to be customized. At the same time, IR elements can always be reduced to the above fundamental concepts. This allows MLIR to parse, represent, and round-trip** IR for any operation.**</p> <p>This is EXACTLY what I want to say for the APSys submission.</p> <p>Through dialects, MLIR allows for the representation of many different levels of abstraction; the Toy dialect that we have previously defined is one such example.</p> <p>Though these different dialects may represent different abstractions, there is often a set of common transformations and analyses that we would like to perform.</p> <p>The blog builds the Toy Example following these steps:</p> <ol> <li>It first defines the semantics of this toy language and some simple operations. It then defines an IR for the Toy language in an MLIR dialect. MLIR can transform the source code into its internal IR using the above dialect.</li> <li>It then performs \u201cHigh-level Language-Specific Analysis and Transformation\u201d and other optimizations on the generated IR within MLIR. The transformations are pretty straightforward, such as eliminating duplicated ops. These optimizations, however, would be difficult for LLVM to carry out.</li> <li>It then discussed an MLIR internal interface infrastructure that facilitates the above transformations. The rationale is that most transformations used by distinct languages are similar, hence a framework can reduce code duplication and also allow developers to design a set of shared common optimizations/passes.</li> <li>Then, the interesting part. It converts this Dialect into other MLIR built-in dialects (e.g., affine, arithmetic), thereby lowering the toy Dialect into more concrete memory accesses, and arithmetic ops, etc.</li> <li>Finally, it again lowers the above partially-lowered IR onto the LLVM IR. Once we are here, we can invoke LLVM to generate code (e.g., for x86 or ARM CPUs) or run with the LLVM JIT. Of course, instead of lowering it onto the LLVM IR, one can also lower it onto another IR, e.g., TPU IR (what TensorFlow does).</li> </ol> <p>My understanding</p> <ul> <li>MLIR is a generic framework that allows you to define your customized IR using MLIR\u2019s generic primitives (i.e., an indirection layer). From MLIR\u2019s perspective, your IR is just one of the many dialects it supports.</li> <li>More importantly, a dialect can fully or partially convert into other dialects. For instance, if you convert your IR into the LLVM IR, you can immediately take advantage of the LLVM\u2019s code-generation framework for CPUs. If you convert your IR into the TPU IR, you can then generate code running on TPUs.</li> </ul> <p>Say I want to build some P4 or FPGA stuff using MLIR, I would do:</p> <ol> <li>I would first define a language model together with a new IR using MLIR primitives.</li> <li>Then, within MLIR, I would do all sorts of language-specific optimizations, transformations, etc. I can also do some conversions among other dialects.</li> <li>After all that, say I\u2019ve got an optimized IR. What should I do next? I cannot fully lower it to the LLVM IR, because there is no P4/FPGA backend in the LLVM framework.</li> <li>If I target FPGA, I could generate FIRRTL, which is the input of CIRCIT or Chisel.</li> <li>If I target P4, I could generate the MLIR IR into something like a P4 IR/backend, which then will do vendor-specific compilation into deployable binaries.</li> <li>Is this P4 IR thing already part of the p4 compiler chain? If so, why should I go through all this trouble adding a new MLIR dialect, why not directly use the p4 compile chain? What benefits are we getting out of MLIR though?</li> <li>Answer: we will benefit from MLIR only if we are targeting multiple backends at the same time, thus we can share the same optimization infrastructure. In specific, one piece of code can run on top of a set of heterogeneous devices. All the optimizations are nicely done within the MLIR layer.</li> </ol>"},{"location":"notes/MLIR/#example-2-google-iree","title":"Example 2: Google IREE","text":"<p>IREE</p> <p>IREE (**I**ntermediate **R**epresentation **E**xecution **E**nvironment1) is an MLIR-based end-to-end compiler and runtime that lowers Machine Learning (ML) models to a unified IR</p> <p>I\u2019m not exactly sure what IREE is doing. Overall, it takes an ML program and tries to transform it into scheduling and computation modules run on various hardware components.</p> <ul> <li>The bottom right part is interesting. You can see that it can lower onto the LLVM IR, further generating codes for various CPUs; it can also lower onto SPIR-V IR, a special IR defined for GPUs. I\u2019m not sure what VMVX is.</li> </ul> <p></p>"},{"location":"notes/MLIR/#example-3-llvm-circt","title":"Example 3: LLVM CIRCT","text":"<p>CIRCT\u2019s inputs:</p> <ol> <li>Chisel\u2019s FIRRTL</li> <li>MLIR\u2019s output</li> </ol> <p>CIRCT\u2019s outputs:</p> <ol> <li>Verilog</li> <li>C++?</li> <li>TCL?</li> </ol> <p></p> <p>CIRCT Charter - CIRCT</p> <p>https://llvm.org/devmtg/2021-11/slides/2021-CIRCT-LiftingHardwareDevOutOfThe20thCentury.pdf</p> <ul> <li>CIRCT implements its own FIRRTL parser, so it can take an FIR file to generate RTL</li> <li>Other than that, CIRCT could also take MLIR outputs to generate RTL.</li> <li>Apparently, CIRCT also uses the Dialects concepts.</li> </ul> <p></p> <p></p>"},{"location":"notes/MLIR/#example-4-tensorflowpytorch-with-mlir","title":"Example 4: TensorFlow/PyTorch with MLIR","text":"<p>Torch-MLIR: https://github.com/llvm/torch-mlir</p> <ul> <li>It compiles some Torch operations into a newly defined torch-dialect in MLIR.</li> <li>Within MLIR, the torch-dialect is further lowered onto built-in dialects such as affine</li> <li>https://github.com/llvm/torch-mlir/blob/main/Torch-MLIR.png</li> </ul> <p></p>"},{"location":"notes/MLIR/#example-5-scalehls-hpca22","title":"Example 5: ScaleHLS, HPCA\u201922","text":"<p>https://github.com/hanchenye/scalehls</p> <p>https://raw.githubusercontent.com/hanchenye/scalehls/master/docs/ScaleHLS.svg  The whole system is implemented on top of MLIR. They introduced a new <code>HLSCPP</code> dialect. They take HLS C programs, or TORCH/ONNX graph-level programs, then produce highly-optimized HLS C/C++ programs.</p> <p>It is a very interesting read. The following image shows its workflow.</p> <p></p> <p>My thought: I think we will continue seeing more MLIR-based solutions to help DSA development. It\u2019ll be interesting to see some higher-level, or higher-order primitives constructed in MLIR to help, say, FPGA-based SQL develpoment (or rather, any types of FPGA-based computations). In general, MLIR helps to raise the abstrantion, hence we are able to raise the programmability futher.</p>"},{"location":"notes/MLIR/#example-6-equeue-hpca22","title":"Example 6: EQueue, HPCA\u201822","text":"<p>Compiler-Driven Simulation of Reconfigurable Hardware Accelerators, HPCA\u201822.</p> <ul> <li>The goal is to help simulation.</li> <li>Add a new dialect in MLIR to model different accelerators.</li> <li>There are two general approaches to do simulation: 1) use RTL-level, which is very precise and also very slow. 2) use high-level simulators, sth like gem5. Fast, but is far away from hardware.</li> <li>The goal of this paper is to use MLIR to build sth in the middle. It introduces a new dialect IR, which can describe various accelerator structure (e.g., how many processors, memory, DMA engines etc). Since MLIR can lower IR, their system can model the accelerator at different levels. On one extreme, they can do very high-level simulation (probably just use their new IR). On the other extreme, they can lower their IR to be close to actual hardware.</li> <li>Check their Fig3-Fig5 to understand how they can model different accelerators!</li> </ul>"},{"location":"notes/MLIR/#example-7-pathways-google","title":"Example 7: Pathways, Google","text":"<p>The paper is Pathways: Asynchronous Distributed Dataflow For ML, arXiv\u201822</p> <p>From the paper:</p> <p>\u201cSec 4.2: The client then constructs a device location-agnostic PATHWAYS intermediate representation (IR) for the program, expressed as a custom MLIR (Lattner et al., 2021) dialect. The IR is progressively \u201clowered\u201d via a series of standard compiler passes, which eventually output a low-level representation that includes the physical device locations. This low-level program takes into account the network connectivity between physical devices and includes operations to transfer outputs from a source computation shard to the locations of its destination shards, including scatter and gather operations when a data exchange is required.\u201d</p>"},{"location":"notes/MLIR/#example-8-daphne-cidr22","title":"Example 8: DAPHNE, CIDR22","text":"<p>DAPHNE is an extensive open framework that unites ML, HPC, and data management workloads. It uses MLIR to build operators and data representations (e.g., tensor, matrix).</p>"},{"location":"notes/MLIR/#example-9-lingodb-vldb22","title":"Example 9: LingoDB, VLDB22","text":"<p>LingoDB is quite interesting. I don\u2019t have enough knowledge to understand the paper well. But it appears to co-design database\u2019s query optimizer and underlying operators. The query optimizations are implemented as MLIR passes.</p>"},{"location":"notes/MLIR/#example-10-mojo","title":"Example 10: Mojo","text":"<p>The Modular.AI\u2019s first production releasing video is really exciting. Chris and the his team introduced another amazing programming language to the world. The doc says Mojo\u2019s low-level primitives are built on top of MLIR. I\u2019m still on waiting list to try Mojo out :)</p>"},{"location":"notes/MLIR/#misc","title":"Misc","text":"<p>Alpa, arXiv\u201821 proposes a set of methods to partition an ML training process to best utilize pipeline, data, model parallelism. This seems to be the first one doing all 3 at once.  There are, of course, similar papers in the past doing 2 out of 3 (a paper from the Stanford folks).</p> <p>TVM IP stuff is also highly related.</p>"},{"location":"notes/MLIR/#general-pl-related-readings","title":"General PL Related Readings","text":"<ol> <li>Saw this paper on twitter today (03/25/2022). It won the ICSE influential award. https://people.inf.ethz.ch/suz/publications/natural.pdf</li> </ol>"},{"location":"notes/arch/","title":"Architecture","text":"Version History Date Description Dec 30, 2020 Initial <p>This is my personal notes on architecture related topics.</p>"},{"location":"notes/arch/#cache-coherence","title":"Cache Coherence","text":"<p>See the Practical Cache Coherence blog.</p>"},{"location":"notes/arch/#reservation-station-and-rob","title":"Reservation Station and ROB","text":"<p>They serve different purposes. ROB can not replace reservation station. ROB records all instructions and their control information, their order.</p> <p>An instruction will alloc an ROB entry alive when it enters execution enegine and free the entry when it finally able to commit.</p> <p>An instruction will alloc an reservation station entry when it enters execution engine, just like ROB. But it will free the entry when the functional unit finished execution. Essentially, the ROB entry outlives the reservation station entry.</p> <p>This is why the number of ROB entries is larger than the number of reservation station entries. E.g., in Skylake, there are 224 ROB entries, and 97 reservation static entries.</p> <p>One thing I notice is that there is still a Comman Data Bus (CDB) connecting the output of execution engines to the reservation station and ROB. Image</p>"},{"location":"notes/arch/#physical-register-files-and-rob","title":"Physical Register Files and ROB","text":"<p>When we add speculation to traditional Tomasulo, we will add a ROB table. Each entry in ROB has an attached buffer. Like reservation station (RS), ROB can also store and forward results.</p> <p>Physical register file is a separate unit. With it, the ROB no longer needs to store/forward data. We only need a renaming table to manage the mapping.</p> <p>The benefit of using a separate physical register file over ROB-with-buffer is that we can greatly reduce data movement. The ROB no longer needs write back data to register file, it will be stored when the computing unit produces it.</p>"},{"location":"notes/arch/#distributed-vs-centralized-reservation-station","title":"Distributed v.s. Centralized Reservation Station","text":"<p>Textbook Tomasulo uses distributed reservation station, each functional unit has its own attached RS entries. Some old CPUs like PowerPC 604, Pentium 4 and newer generation CPUs like AMD Zen series, RISCV-BOOM are using the distributed reservation station design.</p> <p>Regarding AMD Zen, the architecture figure shows there are 6 small schedulers within the Integer execution pipeline, each with 14 entries, so in total 84 entries. It appears each scheduler is used exclusively by one execution port, but the <code>forwarding muxes</code> below confuses me. This mux maybe able to distribute work across different ports thereby overtime resource fragmentation issue of distributed reservation station approach? Not sure how exactly it is designed.</p> <p>On the contray, recent Intel CPUs are all using centralized reservation station design. There is one giant unified reservation station, or scheduler in Intel\u2019s wording, working for all functional units. E.g., in Skylake, this scheduler has 96 entries, meaning there can be 96 instructions currently being executed by functional units (The number of ROB entries is larger than this number, because ROB still cache info for already excuted but uncommitted instructions).</p> <p>I don\u2019t really know the actual practical trade-off among these two choices. My guess for centralized v.s. distributed reservation station trade-offs are:</p> <ol> <li>For centralized design, the RS is not statically partitioned like the distributed design. So the RS usage can adapt to workloads to avoid some blocking.</li> <li>Centralized design for sure has more complex control logic and more challenging to implement!</li> </ol> <p>Centralized Reservation Station (Intel Skylake): </p> <p>Distributed Reservation Station (AMD Zen): </p>"},{"location":"notes/arch/#further-reading","title":"Further Reading","text":"<ol> <li>Intel optimization manual</li> <li>Wikichips</li> <li>Agner Fog\u2019s optimization manuals (the microarchitecture one)</li> </ol>"},{"location":"notes/benchmark/","title":"Benchmarks","text":"Version History Date Description Apr 2, 2020 Update Aug 13, 2019 Update Aug 03, 2019 Initial draft"},{"location":"notes/benchmark/#areas","title":"Areas","text":""},{"location":"notes/benchmark/#synchronizationconcurrency-community","title":"Synchronization/Concurrency Community","text":"<ul> <li>Phoenix HPCA (heavy mmap/munmap, i.e., mm-sem usage)</li> <li>MOSBENCH/Metis (same as Phoenix)</li> <li>LevelDB (a popular workload)</li> <li>Linux locktorture</li> <li>Filesystems (fs)</li> <li>LiTL, ATC\u201816, https://github.com/multicore-locks/litl</li> <li>References<ul> <li>ShuffleLock, SOSP\u201819</li> <li>Compact NUMA-aware Locks, EuroSys\u201819</li> <li>fill me in</li> </ul> </li> </ul>"},{"location":"notes/benchmark/#os","title":"OS","text":"<ul> <li>will-it-scale</li> <li>lmbench</li> <li>sysbench</li> </ul>"},{"location":"notes/benchmark/#fpga","title":"FPGA","text":"<ul> <li>Rosetta: A Realistic High-Level Synthesis Benchmark Suite for Software Programmable FPGAs, FPGA\u201818</li> <li>AmophOS has a lot more.</li> </ul>"},{"location":"notes/benchmark/#misc-information","title":"Misc Information","text":"<ul> <li>Systems Benchmarking Crimes</li> </ul>"},{"location":"notes/cache_coherence/","title":"Practical Cache Coherence","text":"Version History Date Description Jul 2, 2021 add implication discussion Feb 24, 2020 Kobe and Gigi. Add Intel CCIP. Oct 3, 2019 Add FPGA related discussion Jun 28, 2019 Initial draft <ul> <li>Practical Cache Coherence</li> <li>Summary and Thoughs<ul> <li>Implication for Synchronization</li> <li>Implication for On-Chip Bandwidth and NUMA</li> </ul> </li> <li>Readings</li> <li>Case Study<ul> <li>Intel</li> <li>AMD</li> <li>ARM</li> <li>OpenCAPI and CCIX</li> <li>CXL</li> <li>OpenPiton</li> <li>FPGA</li> <li>Formal Verification</li> </ul> </li> </ul> <p>TL;DR. This is a note on how cache coherence protocols are implemented in real hardware. This note is NOT just about acadamic new ideas.</p> <p>I started this when I was having a hard time optimizing <code>lock delegation</code>, which relies on fine-tuning cache coherence to achieve extremely fast locks.</p>"},{"location":"notes/cache_coherence/#summary-and-thoughs","title":"Summary and Thoughs","text":"<p>The textbooks tough us the basic concept of MESI. And specific algorithms like snoop and directory. What usually missing is the implementation details when it comes to: 1) how to solve conflicts, 2) what if there is no single shared bus.</p> <p>Modern processors have Network-on-Chip (NoC). Within the die, cores, cache slices (large LLC is usually divided into slices), memory controllers and other components are connected via an on-chip network (e.g., a ring in old-generation Xeon, or a mesh in Xeon Scalable). This architecture is no different from connecting a set of distributed servers. The NoC has its own protocol (I guess ranging from L1 to L3, must be reliable data delivery). And all on-chip components communicate by sending/receiving packets. There is no central coordinator.</p> <p>What this means for cache coherence?</p> <p>Cache requests generated by MESI protocols should appear atomic to requesting cores. Given the distributed nature of all resources (via NoC), those cache requests are implemented like distributed transactions! This brings great complexity to a performant and correct cache coherence implementation. Hardware is much much faster than a set of distributed nodes. Besides, it cannot implement arbitrary logic, whatever protocol they design has a tight time budget.</p> <p>For example, Intel uses the MESIF cache coherence protocol. In their implementation, when a core made a read to an invalid line, the corresponding cache will perform a cache read transaction to get the data from either other caches or memory. This transaction consists of multiple steps, such as: send requests, collect responses, and finally send ACKs.</p> <p>Those transactions will conflict if multiple reads and writes happen at the same time. Someone has to resolve it. It can be resolved by different cache controllers, or by a single serialization point like home agent.</p> <p>Just like you can have many ways to implement transactions for distributed systems, there are also many ways to do cache coherence transactions. And there are many.</p> <p>Atomic Read-Modify-Write (RMW) instructions will make cache coherence implementations even more complex. Those instructions include <code>read-and-inc</code>, <code>test-and-set</code>, and <code>lock;</code>-prefixed. I think, there will some \u201clock the bus\u201d, or \u201clocked state\u201d at the home agent per cache line. Having atomic RMW instructions will add more complexity to the overall transaction design.</p> <p>While reading Intel related cache coherence diagrams/transactions, you might find many different descriptions. Don\u2019t panic. They are just different implementations proposed by Intel. Different implementations will have different trade-offs and performance, you can check Frank\u2019s post for more details.</p> <p>Directory-based cache coherence protocol and implementation will be the future for multicore machines. Because it incurs much less coherence traffic than snoop-based ones, thus more scalable. The trend is confirmed by recent Intel UPI directory-based approach.</p> <p>Related readings:</p> <ul> <li>[1]: Why On-Chip Cache Coherence Is Here to Stay</li> <li>[2]: QPI 1.1 Invovled</li> <li>[3]: Paper: Multicast Snooping: A New Coherence Method Using a Multicast Address Network, ISCA \u201899</li> <li>[4]: Paper: Using Destination-Set Prediction to Improve the Latency/Bandwidth Tradeoff in Shared-Memory Multiprocessors, ISCA\u201803</li> <li>[5]: The trade-off: </li> </ul> <p>Left questions: - Do cache coherence implementations ensure fairness among cores?</p>"},{"location":"notes/cache_coherence/#implication-for-synchronization","title":"Implication for Synchronization","text":"<p>Synchronization code (e.g., locking code) has deep relation with cache coherence and memory consistency. A lot optimizations are playing with certain cache coherence protocols. For example, a locking primitive may want to first read the lock then try to atomically change its value. By doing so, the first read will not trigger any cache invalidation to other cores, hence save latency and on-chip bandwidth.</p> <p>As for memory consistency, it affects how many barriers should be inserted and whether a release/acquire semantic should be used.</p> <p>Anyway, if you are implementing synchronization primitive, pay attention to cache coherence. Read the discussion posted by Dr. Bandwidth, especially this one on cache coherence flows on a procuder-consumer case. It is very useful if you are trying to implement high-performance spinlocks and concurrency data structures.</p>"},{"location":"notes/cache_coherence/#implication-for-on-chip-bandwidth-and-numa","title":"Implication for On-Chip Bandwidth and NUMA","text":"<p>Cache coherence consumes a LOT on-chip bandwidth. Think about all the messages it will send for a single transation. And this transaction can be easily triggered by normal read/write. So the cache coherent protocol end up using a lot on-chip bandwidth.</p> <p>This is problematic for two reasons: a) the NoC bus/ring is shared. It will affect other traffic hence performance. b) In a NUMA architecture, the interconnection between CPU dies is responsible for a lot things like data transfer, cache coherence traffic, and other misc traffic. If cache coherence uses a lot, there is little room for others.</p> <p>Many have complained this.</p> <p>So what\u2019s the mitigation? The first try is to move from Snoop to Directory so to avoid excessive traffic. Some sort of centralized coordinator could resolve conflicts therefore save tons of traffic. Intel\u2019s cache coherence protocol has involved for this direction as well. Other measures? I don\u2019t know.</p>"},{"location":"notes/cache_coherence/#readings","title":"Readings","text":"<ul> <li>The Architecture of the Nehalem Processor and Nehalem-EP SMP Platforms, chapter 5.2 Cache-Coherence Protocol for Multi-Processors.</li> <li>Intel: Performance Analysis Guide for Intel\u00ae Core\u2122 i7 Processor and Intel\u00ae Xeon\u2122 5500 processors</li> <li>Dr.Bandwidth on Core2Core cache coherence flows when running producer-consumer type of workload.. 100% recommended.</li> <li>Blog: NUMA Deep Dive Part 3: Cache Coherency<ul> <li>The BEST blog I\u2019ve seen on the topic of <code>Intel snoop models</code>.</li> <li>Intel is using MESIF cache coherence protocol, but it has multiple cache coherence implementations.   The first one is <code>Source Snoop</code> (or <code>Early Snoop</code>), which is more like a traditional snoop-based   cache coherence implementation. Upon miss, the caching agent will broadcast to other agents.   The second one is <code>Home Snoop</code>, which is more like a directory-based cache coherence implementation.   Upon miss, the caching agent will contact home agent, and then the home agent will send requests   to other caching agents who have the requested cache line.   There are other implementations like Cluster-on-Die.   Intel UPI gets rid of all this complexity, it is only using directory-based, in the hope to reduce   cache coherence traffic, which make sense.</li> <li>Related: Broadwell EP Snoop Models</li> <li>Related: Skylay UPI</li> </ul> </li> <li>Paper: MESIF: A Two-Hop Cache Coherency Protocol for Point-to-Point Interconnects (2009)__<ul> <li>A MUST read.</li> <li>This paper has the most extensive description of the MESIF protocol implementation.   It has many <code>timing diagrams</code> than describe how cache requests actually proceed.   Those diagrams can help us understand what is needed to finish a cache request.</li> <li>Their slides   has more timing diagrams.</li> <li>But do note: the implementation described by this paper is different from   what Intel QPI   has in products. The difference is discussed at chapter 4. MESIF and QPI, namely,   other caching agents will send responses to Home agent rather than to requesting agent.   QPI relies on Home agent to solve conflict.</li> <li>Also note: this is just one of the possible implementations to realize MESIF protocol.   There could be many other ways, e.g., QPI source snooping, QPI home snooping.   But all of them share the essential and general concepts and ideas.</li> </ul> </li> <li>Appendix I: Large-Scale Multiprocessors and Scientific Applications,   chapter 7 Implementing Cache Coherence.<ul> <li>This is probably some most insightful discussion about real implementation of cache coherence.   With the distributed nature and Network-on-Chip, implementing cache coherence in modern   processors is no different than implementing a distributed transaction protocol.</li> <li>Cache activities like read miss or write miss have multi-step operations, but they   need to appear as \u201catomic\u201d to users. Put in another way, misses are like transactions,   they have multiple steps but they must be atomic. They can be retried.</li> <li>Having directory for cache coherence will make implementation easier. Because   the place (e.g., L3) where directory resides can serve as the serialization point.   They can solve write races.</li> <li><code>Home directory controller</code> and <code>cache controller</code> will exchange messages like a set of distributed machines.   In fact, with NoC, they are actually distributed system.</li> </ul> </li> <li>Intel: An Introduction to the Intel\u00ae QuickPath Interconnect,   page 15 MESIF.<ul> <li>HotChips slide, has timing diagrams.</li> <li>It explains the <code>Home Snoop</code> and <code>Source Snoop</code> used by Intel.</li> <li>Based on their explanation, it seems both <code>Home Snoop</code> and <code>Source Snoop</code> are using a combination of     snoop and directory. The Processor#4 (pg 17 and 18) maintains the directory.</li> <li>And this is a perfect demonstration of the details described in Appendix I: Large-Scale Multiprocessors and Scientific Applications.</li> <li>Related patent: Extending a cache coherency snoop broadcast protocol with directory information</li> </ul> </li> <li>Paper: Multicast Snooping: A New Coherence Method Using a Multicast Address Network, ISCA \u201899<ul> <li>A hybrid snoop and directory cache coherence implementation. The insight is snoop   cause too much bandwidth, directory incurs longer latency.</li> <li>So this paper proposed <code>Multicast snoop</code>, where it multicasts coherence transactions   to selected processors, lowering the address bandwidth required for snooping.</li> </ul> </li> <li>Paper: Why On-Chip Cache Coherence Is Here to Stay, Communications of ACM\u201802<ul> <li>This paper discusses why cache coherence can scale. A nice read.</li> <li>R1: Coherence\u2019s interconnection network traffic per miss scales       when precisely tracking sharers. (Okay increased directory bits,   what about those storage cost? See R2).</li> <li>R2: Hierarchy combined with inclusion enables efficient scaling       of the storage cost for exact encoding of sharers.</li> <li>R3: private evictions should send explicit messages to shared cache       to enable precise tracking. Thus the recall (back invalidation) traffic can be   reduced when shared cache is evicting (assume inclusion cache).</li> <li>R4: Latencies of cache request can be amortized.</li> </ul> </li> <li>Book: Parallel Computer Organization and Design, Chapter 7.<ul> <li>Links coherence and consistency together. This chapter uses detailed graphs to show   how different cache coherence implementations affect consistency.</li> </ul> </li> <li>Book: A Primer on Memory Consistency and Cache Coherence<ul> <li>Best book for this topic.</li> </ul> </li> <li>Dr.Bandwidth on explaining core-to-core communication transactions!<ul> <li>Seriously, it\u2019s so good!</li> <li>Although, I just feel there are so many unpublished details about the exact coherence transactions.   Dr.Bandwidth himself used a lot \u201cmaybe\u201d, and listed possible actions.</li> </ul> </li> <li>Transactional Memory Coherence and Consistency, ISCA\u201804</li> <li>Programming with Transactional Coherence and Consistency (TCC)<ul> <li>Slide1</li> <li>Awarded the most influential paper at ISCA 2019. I took a read today (Jul 21, 2019).</li> <li>I feels like it\u2019s using the \u201cbatch\u201d optimization for all time. The TCC design,   kind of combines both cache coherence and memory consistency: how transactions   commit or orders, determins the coherence and consistency.</li> <li>It seems the load/store speculative execution used in their context is so similar   to what Dr.Bandwidth said about Intel\u2019s implementation. Basically, the processor   might read some data from L1/L2 and continue execution, but there is a chance,   that the data is modifed by others, and the L3 caching agent or home agent   could decide to revoke it. Once receiving such revoke message,   the processor must cancel all executions that use the speculatively read data. </li> <li>It mentions couple Thread-Level Speculation papers, I think they should on this topic.</li> </ul> </li> </ul>"},{"location":"notes/cache_coherence/#case-study","title":"Case Study","text":""},{"location":"notes/cache_coherence/#intel","title":"Intel","text":"<p>Misc Facts.</p> <ul> <li>Intel Caching Agent (Cbox) is per core (or per LLC slice). Intel Home Agent is per memory controller.<ul> <li>\u201cThe LLC coherence engine (CBo) manages the interface between the core and the last level cache (LLC). All core transactions that access the LLC are directed from the core to a CBo via the ring interconnect. The CBo is responsible for managing data delivery from the LLC to the requesting core. It is also responsible for maintaining coherence between the cores within the socket that share the LLC; generating snoops and collecting snoop responses from the local cores when the MESIF protocol requires it.\u201d</li> <li>\u201cEvery physical memory address in the system is uniquely associated with a single Cbox   instance via a proprietary hashing algorithm that is designed to keep the distribution of   traffic across the CBox instances relatively uniform for a wide range of possible address patterns.\u201d</li> <li>Read more here, chapter 2.3.</li> <li>Starting from Intel UPI, Caching Agent and Home Agent are combined as CHA.</li> </ul> </li> <li>A good discussion about why QPI gradually drop <code>Source Snoop</code> and solely use <code>Home Snoop</code>.<ul> <li>The motivation is scalability. It turns out the new UPI only supports directory-based protocol.</li> <li>This makes sense because 1) inter socket bandwidth is precious, 2) snoop will consume a lot bandwidth.</li> </ul> </li> <li>Intel UPI is using directory-based home snoop coherency protocol<ul> <li>Intel\u00ae Xeon\u00ae Processor Scalable Family Technical Overview</li> </ul> </li> <li>To provide sufficient bandwidth, shared caches are typically interleaved   by addresses with banks physically distributed across the chip.</li> </ul> <p>A Transaction Breakdown.</p> <p>Intel does not disclose too much details about their cache coherence implementations. The most valuable information is extracted from uncore PMU manuals, and discussions from Dr. Bandwidth. According to Dr. Bandwidth, the Intel CPU could dynamically adapt its coherence strategy during runtime according to workload. There won\u2019t be one fixed cache coherence implementation, there will be many. It depends on workload which one is used at runtime.</p> <p>What happens when a core tries to access a cache line? A detailed cache protocl breakdown derived from Dr.Bandwidth\u2019s comment.</p> <ul> <li>Physical addresses are uniquely hashed into L3 slices. That means each individual   physical address belongs to a L3 slice, and also belongs to a home agent.</li> <li>Upon L2 miss, it will send requests to corresponding L3 slice. If the L3 slice   is in the local socket, the request can be delievered within the same socket.   If the L3 slice belongs to another remote socket, the L2 miss request will   be sent over QPI/UPI. Also note that the L2 controller will not send snoop requests.   (This is answering the question of \u201cwhy using local memory is faster than remote\u201d    from the cache coherence perspective.)</li> <li>At L3, when received the request from a L2,<ul> <li>If it\u2019s in source snoop model, it will send <code>snoop messages</code> to other sockets.</li> <li>If it\u2019s in home snoop model, it will send <code>read message</code> to other sockets.   The another socket will generate snoop and collect responses. (R3QPI or home?)</li> <li>Quote Dr. Bandwidth: Maintaining consistency is easier if the data is sent   to the L3 first, and then to the requesting core, but it is also possible to   send to both at the same time (e.g., \u201cDirect2Core\u201d). In recent processors,   these return paths are chosen dynamically based on undocumented states and   settings of the processor.</li> <li>I\u2019m not sure who will ACK L2 at last. L3 or home agent? Both are possible.</li> </ul> </li> <li>I think both L3 and home agent have directory information. They know where   to send snoop/read messages. And both of them can serialize coherence transactions!   It\u2019s just undocumented who is doing what.</li> <li>In generall, we need to bear the fact that we cannot just figure out how Intel   cache coherence works underlying. We maybe just need to \u201cvaguely\u201d know the fact that:<ul> <li>Both directory and snoop will be used in combination.</li> <li>L3/home agent will serialize conflicting transactions</li> <li>L3/home agent will send data to requesting core</li> <li>L3/home agent will send final ACK to requesting L2</li> <li>A coherence transaction is a multi-step distributed transaction.   It involes sending requests, serialize conflicts, receiving responses/ACKs.</li> </ul> </li> </ul> <p>Read the discussion posted by Dr. Bandwidth, especially this one on detailed cache coherence flows on a procuder-consumer case, which is essential if you are trying to implement high-performance spinlocks and concurrency data structures.</p>"},{"location":"notes/cache_coherence/#amd","title":"AMD","text":"<ul> <li>AMD HyperTransport Assit for Cache Coherence<ul> <li>Slide</li> <li>Slide</li> </ul> </li> </ul>"},{"location":"notes/cache_coherence/#arm","title":"ARM","text":"<ul> <li>AMBA CHI Specifications<ul> <li>This is probabaly the most comprehensive document I\u2019ve ever seen about cache coherence.   Although terms used by ARM differs from the ones used by Intel, still, you can map them.   Chapter 5 Interconnect Protocol Flows has a lot timing diagrams regarding read/write/atomic   coherence transactions.</li> <li>It\u2019s a good reference to know, but it would be hard to actually understand the details.</li> </ul> </li> </ul>"},{"location":"notes/cache_coherence/#opencapi-and-ccix","title":"OpenCAPI and CCIX","text":"<ul> <li>CCIX White Paper</li> <li>OpenCAPI</li> </ul>"},{"location":"notes/cache_coherence/#cxl","title":"CXL","text":"<p>Like OpenCAPI and CCIX, it builds on top of PCIe. It is intra-server cache coherence protocol.</p> <p>Not very exciting to me. But it does receive some spotlight recently.</p>"},{"location":"notes/cache_coherence/#openpiton","title":"OpenPiton","text":"<ul> <li>OpenPiton Microarchitecture Specification<ul> <li>Directory-based MESI</li> <li>This spec has detailed coherence message packet format and type. Unfortunately,   it does not say anything about how they deal with coherence transaction conflicts.   E.g., some timeline diagrams like Figrue \u2154 in this paper.</li> </ul> </li> <li>BYOC: A \u201cBring Your Own Core\u201d Framework for Heterogeneous-ISA Research, ASPLOS\u201820</li> </ul>"},{"location":"notes/cache_coherence/#fpga","title":"FPGA","text":"<ul> <li>Analysis and Optimization of I/O Cache Coherency Strategies for SoC-FPGA Device, FPL\u201819</li> <li>LEAP Shared Memories: Automating the Construction of FPGA Coherent Memories, FCCM\u201814.<ul> <li>This work is built on their earlier work, which basically add the data caching   concept to FPGA: using BRAM as L1, on-board DRAM as L2, host or remote DRAM as L3.</li> <li>In their earlier work, each FPGA application (or bitstream) has a private L1 cache.</li> <li>In this work, the add MESI coherence to these private L1 caches, as in they can make   multiple L1 cache cache-coherent.</li> <li>The techniques and protocols from this paper are similar to the exisiting ones. For example,   1) they use a global serializing point to serialize transactions, 2) they designed a lot   messaging types such as INV, RESP and so on.</li> </ul> </li> <li>VMware Research Project PBerry<ul> <li>A very interesting and promising project.</li> <li>They have this follow up work \u201cRethinking software runtimes for disaggregated memory, ASPLOS\u201821\u201d.   But it is simulation using the HotOS paper idea. The real FPGA has not been built yet.   They need to know Intel\u2019s protocol to build it, which is.. impossible?   I think it is probably better to use RISC-V.</li> </ul> </li> <li>Intel FPGA PAC<ul> <li>Intel itself is building a FPGA-CPU cache coherent setting. They use the Intel UPI interconnect   to natually the spectrum. The FPGA shell has some modules to handle this.</li> </ul> </li> <li> <p>Intel FPGA CCIP</p> <ul> <li>Maybe the ASPLOS\u201820 Optimus paper is uing CCIP-related research platform?</li> </ul> </li> <li> <p>Also some pointer chasing related stuff</p> <ul> <li>A Study of Pointer-Chasing Performance on Shared-Memory Processor-FPGA Systems, FPGA\u201816</li> </ul> </li> </ul>"},{"location":"notes/cache_coherence/#formal-verification","title":"Formal Verification","text":"<p>I remember there are couple works from Princiton doing cache protocol verification.</p>"},{"location":"notes/cgroup-swap/","title":"How linux cgroup trigger kernel swap","text":"Version History Date Description Dec 3, 2018 Initial version <p>This is a note on how linux <code>cgroup-mm</code> triggers swap on the user-defined <code>limit_in_bytes</code>. This note assumes you have adequate knowledge on linux mm code. For more information about cgroup, please check the document from RedHat.</p> <p>This is NOT a complete walk through.</p> <p>There are several cgroup callbacks at <code>mm/memory.c</code>. Those functions are called to check if cgroup can honor this page allocation. All of these functions are located in <code>mm/memcontrol.c</code></p> <ul> <li><code>mem_cgroup_try_charge()</code></li> <li><code>mem_cgroup_commit_charge()</code></li> <li><code>mem_cgroup_cancel_charge()</code></li> </ul> <p>Some facts about the implementation (up to linux 5.2)</p> <ul> <li>Each memory cgroup has its own LRU list vector</li> <li>All memory cgroup\u2019s LRU lists and even the global LRU lists, they share a global LRU lock on a per-node basis. (Weird! Why?).</li> </ul> <p>Take a closer look of <code>mem_cgroup_try_charge()</code>, whose behavior is actually quite similar to the case of a real OOM: check if we still available memory (here means memory usage is smaller than <code>limit_in_bytes</code>), if unfortunately we run out of memory, it will then try to reclaim form the memory cgroup\u2019s LRU lists. If that did not work either, final step would be do OOM actions.</p> <ul> <li> <p><code>mem_cgroup_try_charge()</code></p> <ul> <li><code>try_charge()</code><ul> <li>page_counter_try_charge():<ul> <li>Check if we hit <code>limit_in_bytes</code> counter.</li> <li>Hierarchically charge pages, costly.</li> </ul> </li> <li>try_to_free_mem_cgroup_pages()<ul> <li>Callback to <code>mm/vmscan.c</code> to shrink the list (Bingo!)</li> </ul> </li> <li>Also, reclaimer will establish swap pte entries</li> <li>mem_cgroup_oom()</li> </ul> </li> </ul> </li> <li> <p><code>mem_cgroup_lruvec()</code></p> <ul> <li>Other than the global zone-wide LRU lists vector, each cgroup has its own LRU lists vector. Choose the vector that will be passed down to do <code>shrink_page_list()</code> etc.</li> </ul> </li> </ul>"},{"location":"notes/cgroup-swap/#lru-lists-maintainence","title":"LRU Lists Maintainence","text":"<p>Insertion to LRU lists is performed as follows: first, it will be inserted into a per-cpu array (<code>lru_add_pvec</code>). Once the array is full (default 15 entries), it will do a batch insertion into proper LRU lists (depends on <code>mem_cgroup_lruvec</code> we mentioned above).</p> <p>Why Linux is doing this way? To scale.</p>"},{"location":"notes/consistency/","title":"Consistency","text":"Version History Date Description Jun 30, 2021 Initial <p>zotero collection.</p>"},{"location":"notes/consistency/#introduction","title":"Introduction","text":""},{"location":"notes/consistency/#processors","title":"Processors","text":""},{"location":"notes/consistency/#distributed-systems","title":"Distributed Systems","text":""},{"location":"notes/cryptocurrency/","title":"Cryptocurrency","text":"Version History Date Description Jan 16, 2021 Planned <p>Definition: https://en.wikipedia.org/wiki/Cryptocurrency#Formal_definition</p>"},{"location":"notes/cryptocurrency/#bitcoin","title":"Bitcoin","text":"<p>Paper: https://bitcoin.org/bitcoin.pdf</p>"},{"location":"notes/cryptography/","title":"Cryptography","text":"Version History Date Description Oct 11, 2021 Add the github awesome link Jan 16, 2021 Updated Dec 27, 2020 Updated Dec 26, 2020 Created <p>So today (Dec 26, 2020) I\u2019m trying to write some crypto functions to encrypt/decrypt network packets. Then I realize my knowledge about network security is just too shallow. Although I know AES, SHA etc to some extent, I\u2019m not really sure how to build them.</p>"},{"location":"notes/cryptography/#learning","title":"Learning","text":"<p>Try this one: awesome-cryptograghy.</p> <p>Some basic concepts:</p> <ul> <li>cryptographic-standards-and-guidelines</li> <li>Cryptographic Hash Function<ul> <li>MD5</li> <li>SHA-1 SHA-2 SHA-3</li> <li>https://en.wikipedia.org/wiki/Avalanche_effect</li> </ul> </li> <li>Public Key Cryptography<ul> <li>https://en.wikipedia.org/wiki/PKCS_1</li> <li>AES</li> <li>Twofish, 128-bit block plaintext -&gt; ciphertext</li> </ul> </li> </ul> <p>Courses:</p> <ul> <li>UCSE CSE207 by Prof Mihir Bellare</li> </ul>"},{"location":"notes/cryptography/#tls-and-ssh","title":"TLS and SSH","text":"<p>SSH has a similar process as SSL/TLS. See Understanding the SSH Encryption and Connection Process.</p> <ul> <li>SSL/TLS<ul> <li>Cipher Suite</li> <li>OpenSSL, LibreSSL</li> </ul> </li> </ul> <p>So <code>TLS</code> (or <code>DTLS</code> for UDP) has an extra handshake protocol after a TCP or UDP port is open. This handshake process uses asymmetric-keys (public/private) keys to exchange info (e.g., choose TLS info, send pub key etc). They will reach a consensus on which TLS version to use, which cipher suite to use, which session key, or encryption key to use. Finally they will start sending traffic using symmetric encryption (e.g., AES). In addition, they will use secure hashing (e.g., SHA3) to ensure the integrity of the packets.</p>"},{"location":"notes/cryptography/#aes-related","title":"AES Related","text":"<p>As I know it, it two variables controlling its variations: 1) key size, 128-bit, 192-bit, 256-bit =&gt; AES128, AES192, AES256 2) mode of chaining, for data that is larger than standard AES 128-bit block size.    The modes can be CTR, CBC and so on. This is more advanced.</p> <p>AES is a <code>block cipher</code>. AES operates on 128-bit data block, and produces 128-bit encrypted data. Larger data (packets) needs to specify the mode of chaining.</p> <ul> <li>Block cipher</li> <li>Block cipher mode of operation</li> <li>Block size (cryptography)</li> </ul> <p>Details</p> <ul> <li> <p>S-Box</p> <ul> <li>https://en.wikipedia.org/wiki/S-box</li> <li>https://en.wikipedia.org/wiki/Rijndael_S-box</li> </ul> </li> <li> <p>Key Schedule, round constant</p> <ul> <li>https://en.wikipedia.org/wiki/AES_key_schedule</li> </ul> </li> </ul> <p>Quote</p> <p>mode of operation describes how to repeatedly apply a cipher\u2019s single-block operation to securely transform amounts of data larger than a block</p> <p>Quote</p> <p>Block ciphers operate on a fixed length string of bits. The length of this bit string is the block size. Both the input (plaintext) and output (ciphertext) are the same length; the output cannot be shorter than the input \u2013 this follows logically from the pigeonhole principle and the fact that the cipher must be reversible \u2013 and it is undesirable for the output to be longer than the input.</p>"},{"location":"notes/cryptography/#sha-related","title":"SHA Related","text":"<p>SHA-3 has several variations, depending the hash size, it can be <code>SHA3-224, SHA3-256, SHA3-384, and SHA3-512</code>.</p> <ul> <li>https://keccak.team/index.html</li> <li>https://csrc.nist.gov/projects/hash-functions</li> </ul>"},{"location":"notes/cryptography/#case-studies","title":"Case Studies","text":"<p>As usual, let us look at some real world use cases and codes.</p>"},{"location":"notes/cryptography/#software","title":"Software","text":"<p>Both of them have implemented a set of cryptographic functions, collectively called <code>libcrypto</code>. But.. these libraries have deep roots in their projects, thus using a lot project-specific macros etc, so I think they are not that easy to read. There are a lot simpler POC code out there.</p> <ul> <li>OpenSSL - libcrypto<ul> <li>their arch page is really good: https://www.openssl.org/docs/OpenSSLStrategicArchitecture.html</li> <li>OpenSSL 3.0.0 Design</li> </ul> </li> <li>OpenSSH - ssh/sshd/scp/etc</li> <li>Linux kernel crypto API</li> </ul>"},{"location":"notes/cryptography/#fpga","title":"FPGA","text":"<ol> <li>Opencore SHA-3</li> <li>Opencore AES</li> <li>SpninalCrypto<ul> <li>So I personally use this in my research project. It is clean.</li> </ul> </li> </ol>"},{"location":"notes/cryptography/#asic","title":"ASIC","text":"<ul> <li>CPU has extended instructions to accelerate AES and its friends: AES inst set</li> </ul>"},{"location":"notes/dcn/","title":"Notes on Modern Data Center Networking","text":"Version History Date Description Oct 2, 2021 Planning <p>This is my note on datacenter networking. This is work-in-progress. I will try to cover the following topics:</p> <ul> <li>Peering</li> <li>Cloud gateways</li> <li>Cloud internal routing</li> <li>Networking Topology</li> <li>Software Defined Networking (SDN) and OpenFlow</li> <li>Networking Load Balancers</li> <li>Networking Upgrade</li> <li>Switch Hardware and Software (e.g., p4 switch)</li> <li>Host-side NIC Design</li> <li>Host-side Network Virtualization (e.g., OpenVSwitch and VPC)</li> <li>Transport Design (Retransmission and Congestion Control)</li> <li>RDMA and RoCE</li> <li>Host-side Networking Stack Design</li> </ul>"},{"location":"notes/dcn/#overview","title":"Overview","text":"<p>I should draw a figure, including host side network stack/nic, switch, topologies, sdn controllers and so on. And list which parts demand attention.</p>"},{"location":"notes/dcn/#peering-gateway-and-routing","title":"Peering, Gateway, and Routing","text":""},{"location":"notes/dcn/#topology","title":"Topology","text":"<p>Clos, fat-tree, jupiter, vl2, fb\u2019s 40/100g topology.</p>"},{"location":"notes/dcn/#sdn-and-openflow","title":"SDN and OpenFlow","text":"<p>Orion, and its predecessor.</p>"},{"location":"notes/dcn/#upgrade","title":"Upgrade","text":"<p>NSDI papers, live update, cost.</p>"},{"location":"notes/dcn/#network-virtualization","title":"Network Virtualization","text":"<p>openvswitch, Andromeda.</p>"},{"location":"notes/dcn/#host-networking-stack","title":"Host Networking Stack","text":"<p>Snap.</p>"},{"location":"notes/dcn/#special-topics","title":"Special Topics","text":"<p>This section covers special topics.</p>"},{"location":"notes/dcn/#special-topcis-on-transport-design","title":"Special Topcis on Transport Design","text":"<p>and programmable transport</p>"},{"location":"notes/dcn/#congestion-control","title":"Congestion Control","text":"<p>Shallow switch buffer. DCTCP.</p>"},{"location":"notes/dcn/#special-topics-on-rdma-and-roce","title":"Special Topics on RDMA and RoCE","text":""},{"location":"notes/dcn/#speical-topics-on-programmable-switch-and-smartnic","title":"Speical Topics on Programmable Switch and SmartNIC","text":""},{"location":"notes/dcn/#special-topics-on-kernel-bypassing-netork-stacks","title":"Special Topics on Kernel-Bypassing Netork Stacks","text":"<p>RPC papers. ZygOS, Shenengo, Arrakis etc. whole stack design.</p>"},{"location":"notes/dcn/#special-topics-on-packet-scheduling","title":"Special Topics on Packet Scheduling","text":"<p>PIFO etc.</p>"},{"location":"notes/dcn/#special-topics-on-datacenter-traffic-study","title":"Special Topics on Datacenter Traffic Study","text":"<p>IMC\u201810 etc.</p>"},{"location":"notes/dcn/#special-topics-on-middlebox-and-network-function-virtualization-nfv","title":"Special Topics on Middlebox and Network Function Virtualization (NFV)","text":""},{"location":"notes/dcn/#special-topics-on-circuit-switches","title":"Special Topics on Circuit Switches","text":"<p>TBD</p>"},{"location":"notes/dcn/#special-topics-on-failure-reliability","title":"Special Topics on Failure, Reliability","text":"<p>Link error rate. Applied erasure coding on packets. Trace studies.</p>"},{"location":"notes/dcn/#cloud-case-studies","title":"Cloud Case Studies","text":"<p>In this section, we look at popular cloud vendors and briefly their networking stack status.</p>"},{"location":"notes/dcn/#gcp","title":"GCP","text":"<p>Their networking services https://github.com/priyankavergadia/google-cloud-4-words#networking.</p>"},{"location":"notes/dcn/#azure","title":"Azure","text":"<p>SmartNIC</p>"},{"location":"notes/dcn/#google-cloud","title":"Google Cloud","text":"<p>1RMA, Swifit, Snap, Orion</p>"},{"location":"notes/dcn/#alibaba","title":"Alibaba","text":"<p>p4 switch.</p>"},{"location":"notes/dist-xact/","title":"Distributed Transactions and Databases","text":"Version History Date Description Apr 5, 2022 Reorg Feb 25, 2022 Initial"},{"location":"notes/dist-xact/#why-i-started-this-note","title":"Why I started this note","text":"<p>This note was originally written in this google doc. This note was my attempt to revive the distributed transaction topic and to get a better understanding about database systems in general. The result was quite fruitful, I covered various concurrency control schemes, isolation levels, etc. The consensus protocols, query optimizations etc topics are not extensively discussed here.</p> <p>Today 02/16/2022, I\u2019m reading the  FORD, FAST\u201922  paper, they are designing distributed transactions for disaggregated persistent memory, they talked about OCC, 2PL, primary-backup etc schemes, and I decided to take another serious look at this topic. I still have the vivid memory of me reading some old Transaction-related surveys (after the ZooKeeper paper) in a small, smelly, broken Purdue ECE room when I first started my PhD. I also had a vivid memory of a meeting among myself, Yiying, Stanko, Marcus in a VMR office room. We were talking about OCC, MVCC, and the then upcoming OSDI\u201918 hybrid transaction paper. I was confused. Anyways, let\u2019s get started.</p>"},{"location":"notes/dist-xact/#quick-takeaways","title":"Quick Takeaways","text":"<p>(1) Concurrency control (CC) is categorized as two types: pessimistic CC using 2-phase locking (2PL) and optimistic CC using Timestamp-Ordering (T/O).. This categorization is derived from a classical paper (Concurrency Control in Distributed Database Systems, 1981). This image comes from An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914. Note, I think the MVCC actually should be MVTO. </p> <p>(2) Multi-versioning (MV) is the prevalent default implementation choice in the wild, for its better performance on various scenarios. Most people think MV is a CC mechanism, but it is not. MV must work with a CC mechanism (e.g., <code>2PL</code>, <code>T/O</code>) to become a full solution, resulting in combos such as <code>MVTO</code>, <code>MVOCC</code>, <code>MV2PL</code>. In my opinion, the commonly mentioned <code>MVCC</code> in various literatures actually refers to <code>MVTO</code>, i.e., multi-versioning with timestamp-ordering (see the MVCC section below for more details).</p> <p>This image shows the commercial/research use of MVCC DBMS. Credit: An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201817</p> <p></p> <p>(3) For better performance, DBMS usually adopt <code>Snapshot Isolation</code> or <code>Read Committed</code> as their default isolation level. The <code>Serializable</code> isolation level is usually not the default one in commercial DBMS. It is baffling to know the fact that many real world systems are actually operating under a weak consistency model and we (and the world) are okay with it! The RedBook offers an interesting take on this topic. The market follows Gresham\u2019s law: bad money drives out good money (See the Isolation section for more details).</p> <p>This image shows the default Isolation level used by various systems. Credit: Highly Available Transactions: Virtues and Limitations, VLDB\u201813 </p>"},{"location":"notes/dist-xact/#concepts","title":"Concepts","text":""},{"location":"notes/dist-xact/#concurrency-control","title":"Concurrency Control","text":"<p>Pessimistic Concurrency Control &amp; Optimistic Concurrency Control.</p> <p>Must Read</p> <ul> <li>Concurrency Control in Distributed Database Systems, 1981. This paper categorizes 2PL, MVCC, OCC etc into 2 big types.</li> <li>On Optimistic Methods for Concurrency Control, 1981. This is the first OCC paper.</li> <li>An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914. This CMU paper has follows the 1981 paper\u2019s categorization on CC methods.</li> <li>An Evaluation of Distributed Concurrency Control, VLDB\u201917 </li> <li>An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201917. This paper is a must read, it explains what is MVTO, MV2PL, MVOCC, etc.</li> <li>Optional Aurogon: Taming Aborts in All Phases for Distributed In-Memory Transactions, FAST\u201822</li> <li>Optional FORD, FAST\u201822</li> </ul> <p>Courses</p> <ul> <li>CMU  Database Systems (15-445/645) , thanks to  Andy Pavlo <ul> <li>Concurrency Control Theory </li> <li>Two-Phase Locking Concurrency Control </li> <li>Timestamp Ordering Concurrency Control </li> <li>Multi-Version Concurrency Control </li> </ul> </li> <li>CMU  Advanced Database Systems (15-721) , thanks to  Andy Pavlo <ul> <li>Multi-Version Concurrency Control (Design Decisions) </li> <li>Multi-Version Concurrency Control (Protocols) </li> <li>Multi-Version Concurrency Control (Garbage Collection) </li> </ul> </li> </ul> <p>As we mentioned earlier, database concurrency control is categorized as two types: pessimistic CC using 2-phase locking (2PL) and optimistic CC using Timestamp-Ordering (T/O). This categorization is derived from this classical paper Concurrency Control in Distributed Database Systems. The following table is from An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914.</p> <p></p> <p>Also from this  CMU 15-445 slide : </p> <p>Recap:</p> <ul> <li>Pessimistic CC: Two-phase Locking (2PL)</li> <li>Optimistic CC: Timestamp Ordering (T/O)<ul> <li>TO</li> <li>OCC</li> <li>MVCC-TO</li> </ul> </li> </ul> <p>The well-known <code>OCC</code>, <code>MVCC-TO</code> concepts fall into the T/O category.  However, don\u2019t confuse the MVCC with concurrency control. MVCC is not a concurrency control method. It must work with a CC method. The above table has MVCC under T/O because it is MVCC-T/O.</p> <p>(Old note: After reading the VLDB\u201917 paper, I think that MVCC can NOT be categorized as a standalone concurrency control method. Hence, we should not say MVCC, OCC, 2PL as if they are in the same league. MVCC states multiple versions of the same object/tuple, it needs to work with other concurrency control methods, so as to end up with MVTO, MVOCC, MV2PL. I think the most common one, or the one that people unconsciously talk about is MVTO. See the following MVCC section for more details!)</p> <p>Call back to Hotpot: I think its MRSW is 2PL+2PC, MRMW is OCC+2PC.</p>"},{"location":"notes/dist-xact/#pessimistic-cc-2pl","title":"Pessimistic CC: 2PL","text":"<p>Not too much to explain here. Maybe read the MV2PL paper for the MV + 2PL combo.</p>"},{"location":"notes/dist-xact/#optimistic-cc-to","title":"Optimistic CC: T/O","text":"<p>The essense of T/O, as its name suggested, is using timestamp to order operations and transactions. Image there exist a perfect logical clock available to all distributed nodes. Whenever a node wants to run a transaction, it will take a timestamp based on the global clock. The node further attaches this timestamp to all operations within the transaction it wishes to execute. This practice establishes a global order on all transactions. Conflicts therefore can be resolved using timestamps.</p> <p>The above reasoning is a super high-level gist on how a T/O based CC could work. There are many nuances and implementation choices to be made. First of all, there is no such perfect clock among distributed nodes. Even if there is a centralize time management system, the cost will be super high. Because it has high-concurrency issues. Second, a system can order things in the beginning of a transaction, or in the middle, or in the end (OCC). Third, there might a single version, or multiple versions of the same data. Combined, they lead to several popular subcategories listed below.</p> <ul> <li>Basic Timestamp-Ordering (Basic T/O)</li> <li>Optimistic Concurrency Control (OCC)</li> <li>Multi-version Concurrency Control (MVCC) with T/O</li> </ul> <p>Quote the VLDB\u201814 paper:</p> <p>Timestamp ordering (T/O) concurrency control schemes generate a serialization order of transactions a priori and then the DBMS enforces this order. A transaction is assigned a unique, monotonically increasing timestamp before it is executed; this timestamp is used by the DBMS to process con\ufb02icting operations in the proper order (e.g., read and write operations on the same element, or two separate write operations on the same element).</p> <p>As for their detailed implementation rationale, I recommend reading An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914, CMU 15-445 slide .</p>"},{"location":"notes/dist-xact/#multi-versioning","title":"Multi-Versioning","text":"<p>Papers</p> <ul> <li>https://15721.courses.cs.cmu.edu/spring2020/schedule.html. This course has links to various MVCC papers</li> <li>An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201917 </li> <li>Serializable Snapshot Isolation in PostgreSQL, VLDB\u201912 </li> <li>Scalable Garbage Collection for In-Memory MVCC Systems, VLDB\u201917 </li> </ul> <p>After a couple days of intensive reading, my understanding about MVCC has expanded quite a lot. It kind of went like this:</p> <ul> <li>In the first stage, I would list MVCC as the opposite approach to OCC. And appears this is most people\u2019s impression? Meaning, when we talk about a system, we will describe it either as OCC or MVCC, as if they are two different things that cannot co-exist.</li> <li>After reading Peloton, VLDB\u201917 paper and the Alibaba blog post, I realized that my understanding wasn\u2019t correct. They reminded me that OCC, at its core, is a concurrency control method, with a clear goal of reducing the amount of time that a transaction holds locks. Since the original and most OCC implementations are using a single-versioned database plus local copies, we naturally think OCC \u21d2 single version. However, if we recall the core of OCC, it does not preclude multi-versioning!. OCC can work with MVCC.</li> <li>My misconception also applies to MVCC, not just OCC. Like the alibaba blog post said, MVCC alone is not a concurrency control method, it merely says there will be multiple versions of the same object/tuple. As a result, MVCC has to work with a real concurrency control method to become a full solution.</li> </ul> <p>That\u2019s why we have MVCC+TO, MVCC+2PL, MVCC+OCC.</p> <p>MVCC is an optimization technique for read and write requests. It does not completely solve the concurrency problem of databases, so it must be used with concurrency control techniques for a complete concurrency control. E.g., multiversion two-phase locking (MV2PL), multiversion timestamp ordering (MVTO), multiversion optimistic concurrency control (MVOCC), and MV-SSI.  </p> <p>I highly recommend the An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201917 paper for a better understanding about MVTO, MVOCC, MV2PL, and how to implement them.</p> <p>This image is from this  Alibaba Blog . It is inline with what the above VLDB\u201917 paper said.  </p> <p>It is important to note that MVCC is the de-facto choice for modern DBMS for its better performance regarding read/write transactions. </p>"},{"location":"notes/dist-xact/#isolation-serializability-snapshot-isolation-linearliability","title":"Isolation: Serializability, Snapshot Isolation, Linearliability","text":"<p>Some official Isolation levels in DBMS systems:</p> <ul> <li>Serializable</li> <li>Repeatable reads</li> <li>Read committed</li> <li>Read uncommitted</li> </ul> <p>Readings:</p> <ul> <li>The RedBook Chapter 6 has great discussion on why weak consistency (e.g., non-serializable snapshot isolation)  is more popular than the serializability, and their guess on why the world is \u201cokay\u201d with that usage.</li> <li>A Critique of ANSI SQL Isolation Levels, 1995 </li> <li>Database Isolation Levels explained | by sudan </li> <li>Real Transactions are Serializable </li> <li>CockroachDB provides strong (\u201cSERIALIZABLE\u201d) isolation by default to ensure that your application always sees the data it expects.  </li> <li>When you use a non-SERIALIZABLE isolation level, you\u2019re giving the database permission to return an incorrect answer in the hope that it will be faster than producing the correct one.</li> <li>Oracle\u2019s implementation of the SERIALIZABLE isolation level is actually a weaker mode called \u201csnapshot isolation\u201d: It is stronger than READ COMMITTED but weaker than SERIALIZABLE. It is similar to REPEATABLE READ but not exactly equivalent</li> <li>PostgreSQL: Documentation: 14: 13.2. Transaction Isolation </li> <li>Highly Available Transactions: Virtues and Limitations, VLDB\u201917 <ul> <li>Discussed the default isolation models used by various systems. Quite telling</li> <li>Most systems DO NOT have Serializable as the default.</li> <li> </li> </ul> </li> </ul> <p>Takeaways</p> <ul> <li>Many real-world DBMS and NoSQL systems adopt a weak consistency model (e.g., non-serializable snapshot isolation) as the default isolation level. They prefer this over serializability because a weak consistency model offers better performance. </li> <li>Weak consistency could lead to anomalies that are super hard to reason about. So why is the real world okay using this model? The redbook\u2019s guess is that there is not enough concurrency in the real world workload so that corner cases rarely happen. I don\u2019t really buy this argument but I can\u2019t think of another good reason.</li> <li> <p>None of these weak isolation models guarantees serializability, but, as we see below, their bene\ufb01ts are often considered to outweigh costs of possible consistency anomalies that might arise from their use.</p> </li> </ul> <p>The reason I came across this is because I was trying to understand  Snapshot Isolation  while reading NAM-DB (it provides SI). And turns out it is a much deeper discussion.</p> <p>This wiki  Snapshot Isolation  has a great explanation on what SI exactly is, and how it compares to the strict serializability.  * The following note was written before I read the SI wiki: I have a very vague understanding about read-snapshots. My first thought is that it is probably only possible with MVCC, but not with OCC. Because intuitively, MVCC maintains multiple versions of the same object, hence able to provide a snapshot with respect to time. Spanner uses MVCC (2PL+2PC+Paxos) and has snapshots-related APIs. FaRMv1, DrTM uses OCC and has no snapshots. * After reading the SI wiki: I think my first impression is correct. MVCC is convenient to implement Snapshot Isolation, as MVCC already maintains a series of recent history. However, I\u2019m not 100% sure whether we can implement SI with OCC as well. We definitely need extra states on top of a normal OCC, and will that just result in sth like MVCC? * **Snapshot Isolation essentially allows****disjoint writes****from concurrent transactions, hence could result in a final state that is not possible in a Serialiable transaction.**Check the example case in the wiki, it is great and simple. * System wise, I came across these that provide SI     * Spanner - provide both serializable and (read-only) snapshot transactions     * NAM-DB, VLDB\u201917 - provides SI-only transactions</p> <p>Serializable Snapshot Isolation (SI) Serializable Snapshot Isolation (SSI)</p>"},{"location":"notes/dist-xact/#replication-protocols","title":"Replication Protocols","text":"<p>Paxos Vertical Paxos Raft Primary-Backup Virtual Synchrony</p> <p>TODO: come back and add more.</p>"},{"location":"notes/dist-xact/#integrate-distributed-transaction-and-replication","title":"Integrate Distributed Transaction and Replication","text":"<p> (image from TAPIR, SOSP\u201915)</p> <p>I think most traditional DBMS systems implement distributed transactions and replication *protocols as two different things. For example, the dist-xact could be sth like 2PL+2PC, OCC+2PC, MVOCC+2PC. Beneath, the replication protocol could be Primary-Backup replication, Paxos, or Raft.</p> <p>For Google Spanner, (1) I think their distributed transaction is multi-versioned 2-phase locking with distributed 2-phase commit (i.e., <code>MV2PL+2PC</code>). (2) Beneath, Spanner uses Paxos for data replication. The metadata is stored in GFS. In their design, a set of machines form a Paxos group. Each paxos group has a leader. During a transaction, this leader is the transaction manager for its Paxos group. If a distributed transaction spans multiple Paxos groups, all group leaders would run MV2PL+2PC among them; leaders themselves run Paxos protocol within their own Paxos group.</p> <p>This layering is good for modularization but at the cost of more data/messages exchanged. But Spanner is a geo-distributed database, such design might be okay. It is not like it is building on top of RDMA or something.</p> <p>The takeway message is that: The naive way of layering a distributed transaction protocol on top of a replication protocol results in <code>over-coordination</code>.</p> <p>It is only natural to co-design dist-xact and replication. For instance, FaRM, SOSP\u201915 &amp; FORD, FAST\u201822 both describe a co-designed four-phase protocol (lock, validation, commit-backup, commit-primary). </p> <p>Related work in this space</p> <ul> <li>**Hotpot, SoCC\u201917**co-designs distributed transaction and replication in its MRSW and MRMW protocols (which are 2PL+2PC, and OCC+2PC, respectively)</li> <li>FaRMv1, SOSP\u201915 &amp; NSDI\u201914 co-designs distributed transaction and replication in one 4-phase protocol, using RDMA</li> <li>FaRMv2, SIGMOD\u201919</li> <li>TAPIR, SOSP\u201915 </li> <li>FORD: Fast One-sided RDMA-based Distributed Transactions for Disaggregated Persistent Memory, FAST\u201822</li> <li>Papers from Mu Shuai</li> </ul>"},{"location":"notes/dist-xact/#2-phase-commit-vs-2pl","title":"2-Phase Commit v.s. 2PL","text":"<ul> <li>2-phase locking</li> <li>2-phase commit </li> <li>3-phase commit </li> </ul> <p>The two-phase commit (2PC) protocol should not be confused with the  two-phase locking  (2PL) protocol, a  concurrency control  protocol.  </p> <p>[NOTE: the description about OCC, MVCC, 2PL might be wrong. I had the wrong impression about them. But now I understand after reading the VLDB\u201917 paper. I believe the MVCC below can be thought of as MVCC-TO, or MVTO.]</p> <p>CC methods such as 2PL, T/O(OCC, MVCC-TO, T/O) are used to ensure that concurrent operations to shared data are serialized, hence ensuring serializability and data consistency. CC ensures operations such as read and write are ordered properly. CC can be used both within a single node or across nodes (e.g., the An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201904 paper evaluates several CC methods within a single node).</p> <p>However, a simple CC is not sufficient when it comes to a distributed setting with multiple nodes: it cannot ensure a transaction commit could commit at all participating nodes. For instance, some nodes may have committed, others may have not - and this creates an inconsistent state. Let me use <code>2PL</code> as an example: in 2PL, we first grab all locks across all involving nodes, we then run the execution/logic locally on a node, we then send all the new data (if any) to other nodes and release the locks. In the last step, there is no way for us to make sure that all participating nodes have received the message. If only some of them finalized/committed the transaction, then the whole database/system is in an inconsistent state.</p> <p>This is where Atomic Commit Protocol such as  2-phase commit comes to rescue. It ensures that all participants either all commit or none of them commits the transaction. It does so by using another 2-phase protocol: prepare + commit. It is not hard to understand. There are more complicated methods such as 3PC or Paxos Commit.</p> <p>I think my original confusion about 2PC and 2PL stems from my illusion that we can use 2PL to also implement what 2PC is designed to achieve. But after the above reasoning, I realized that is not possible. 2PC and 2PL have very clear distinctions. I also had a misconception that 2PC is needed because it can ensure durability. This is also false because 2PC is required simply to ensure atomic commit, for both scenarios w/ or w/o guarantees. If we want durability, then 2PC\u2019s participants would need to either do local logging or build on top of a replication mechanism such as Paxos.</p> <p>A short summary:</p> <ul> <li>Concurrency control protocols: 2PL, T/O (OCC, MVCC, etc)</li> <li>Atomic commit protocols 2PC, 2PC, paxos-commit</li> <li>Concurrency control methods can work in a single node or across node</li> <li>Once a CC goes distributed, it requires a atomic commit to ensure distributed consistency</li> <li>2PL + 2PC, OCC + 2PC, MVCC + 2PC etc are concurrency control + atomic commit</li> <li>Atomic commit can include or exclude durability guarantee</li> </ul>"},{"location":"notes/dist-xact/#classical-systems","title":"Classical Systems","text":"<p>These systems of course touch most of the above concepts.</p> <ul> <li>ZooKeeper. The key thing is its Atomic Broadcast network library.</li> <li>Google BigTable, need a revisit</li> <li>Google Spanner. I have vivid memory reading it. TruTime. Need a revisit as well. It touches a lot of things, appears it is MVCC? And uses Paxos.</li> </ul>"},{"location":"notes/dist-xact/#misc","title":"Misc","text":""},{"location":"notes/dist-xact/#scenarios-and-hardware","title":"Scenarios and Hardware","text":"<p>One key thing worth considering is the operating environment. Some systems like Spanner target geo-distributed data centers, which could go though low-latency WAN.</p>"},{"location":"notes/dist-xact/#bottlenecks","title":"Bottlenecks","text":"<p>Many papers and systems have mentioned that the global timestamp allocation is a major bottleneck in Timestamp Ordering concurrency control systems (including OCC and MVCC).  This is easy to understand: having some sort of global data structure that increases monotonically is hard in a distributed setting. I think that\u2019s why several systems (Spanner, FaRMv2) resort to proactively dealing with clock uncertainties. </p>"},{"location":"notes/dist-xact/#in-memory-vs-disk-base-dbms","title":"In-memory v.s. Disk-base DBMS","text":"<p>XXX</p>"},{"location":"notes/dist-xact/#self-driving-dbms","title":"Self-Driving DBMS","text":"<p>Essentially uses ML to make some decisions?</p> <p>Readings:</p> <ul> <li>Self-Driving Database Management Systems , CIDR\u201917 </li> <li>Automatic Database Management System Tuning Through Large-scale Machine Learning </li> </ul>"},{"location":"notes/dist-xact/#papers-and-readings","title":"Papers and Readings","text":"<p>Courses</p> <ul> <li>Schedule | CMU 15-445/645 :: Intro to Database Systems (Fall 2019). This is DBMS basics, good start. </li> <li>Schedule - CMU 15-721 :: Advanced Database Systems (Spring 2020). This is advanced paper reading.</li> </ul> <p>General Readings</p> <ul> <li>01 Papers - ALL   - a TAB is dedicated to this topic</li> <li>Zotero Paper Collection </li> <li>http://www.redbook.io/  The famous Red Book</li> <li>theanalyst/awesome-distributed-systems   - Github Awesome List</li> <li>Distributed Systems Reading List   - Reading List</li> </ul> <p>Good Readings</p> <ul> <li>Time, Clocks, and the Ordering of Events in a Distributed System, 1978  - classical</li> <li>On Optimistic Methods for Concurrency Control, 1981 <ul> <li>First paper proposing OCC, definitely a seminal paper.</li> </ul> </li> <li>Concurrency Control in Distributed Database Systems , 1981<ul> <li>This paper categorizes 2PL, MVCC, OCC etc into 2 big types.</li> <li>The CMU slides/papers use this categorization to this date.</li> </ul> </li> <li>Linearizability: a correctness condition for concurrent objects , 1990 </li> <li>An Evaluation of Concurrency Control with One Thousand Cores, VLDB\u201914 <ul> <li>A good read on comparing various concurrency control schemes.</li> <li>Note that the MVCC mentioned in this paper is MVTO.</li> </ul> </li> <li>An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, VLDB\u201917 <ul> <li>This is a really good read and should be read in great detail.</li> <li>Understand that OCC\u2019s core is to reduce the critical section time. And MVCC is not a concurrency control method on its own, it merely enables multiple versions of the same object/tuple. Hence MVCC could work with any concurrency control methods, resulting in combos like MVTO, MVOCC, MV2PL.</li> </ul> </li> <li>An Evaluation of Distributed Concurrency Control, VLDB\u201917 <ul> <li>This read reminds us the default Isolation level out in the wild is usually not serializability, but something weaker like Snapshot Isolation, or Read Committed.</li> </ul> </li> </ul>"},{"location":"notes/dist-xact/#misc_1","title":"Misc","text":"<p>The Marzullo\u2019s Algorithm, used by Google Spanner.  https://en.wikipedia.org/wiki/Marzullo%27s_algorithm </p> <p>Opacity, from FaRMv2</p> <p>What\u2019s Really New with NewSQL?  What\u2019s Really New with NewSQL? </p>"},{"location":"notes/dist-xact/#thoughts-on-future-work","title":"Thoughts on Future Work","text":"<p>Database is a long-standing area with tons of papers published every year. There is never lack of innovation in this area. The challenges usually stem from the use of new hardware, networking, and use cases.</p> <p>Based on the recent trends, I think the following directions interest me. Some of them have been explored already or being explored.</p> <ol> <li>Database with high speed network such as RDMA. The use of RDMA challenges the transaction design, the replication protocol design, and so on. It bascially calls for a system re-design. Systems such as FaRM, HERD, FORD, pDPM and so on have explored this area quite extensively. But I always feel there is more to explore here. For instance, explore the data structure designs.</li> <li>Database on disaggregation and progrmmable networking hardware. Qizhen has done some amazing work in this space. But hs work is limited to a certain design choices. Besides, we should bring in programmable networking hardware such as p4 switch, NIC, etc. Can we break down a database into small code pieces and then run them on top of a set of small devices.</li> </ol>"},{"location":"notes/dynamic_linking/","title":"Dynamic Linking","text":"Version History Date Description Mar 19, 2021 add sth about LD_PRELOAD Jan 01, 2021 Add kernel module loading part Dec 24, 2020 Adopted from my previous note <p>This blog looks at some part of the user-space dynamic linker, how kernel loads user program, and how kernel loads kernel modules.</p> <p>The related code: glibc, kernel execve loader, kernel module loader.</p>"},{"location":"notes/dynamic_linking/#c-start-up-csu","title":"C Start Up (csu)","text":"<p>For code pointers, see the glibc code here.</p> <p>In glibc:</p> <ul> <li><code>csu/libc-start.c</code></li> <li><code>__libc_start_main()</code> is the entry point.   Inside, it will call <code>__libc_csu_init()</code>.   Then it will call user\u2019s <code>main()</code>.</li> <li>Great reference: Linux x86 Program Start Up.   I saved a printed PDF copy in this repo.</li> </ul>"},{"location":"notes/dynamic_linking/#dynamic-linking-in-user-space","title":"Dynamic Linking in User Space","text":"<p>The dynamic linker/loader <code>ld.so</code> is part of glibc.</p> <p>I was particularly interested in how it resolves the dynamic symbols during runtime. I took a brief read of the source code and found some relevant ones.</p>"},{"location":"notes/dynamic_linking/#ldso","title":"ld.so","text":"<p>ld.so is the dynamic linker/loader: The programs ld.so find and load the shared objects (shared libraries) needed by a program, prepare the program to run, and then run it. You can run <code>man ld.so</code> to see more details.</p> <p>ld.so is a program, after all. It is part of glibc library.</p> <ul> <li>ELF\u2019s <code>.interp</code> section points to the dynamic linker. During execve(), kernel will jump to ld.so instead of user code entry point.</li> <li>Related code: <code>elf/rtld.c</code>, <code>sysdep/generic</code>, <code>sysdep/x86_64/</code>, and more</li> <li>Inside <code>dl_main()</code>, you can see how <code>LD_PRELOAD</code> is handled.</li> <li><code>GOT[1]</code> contains address of the <code>link_map</code> data structure.</li> <li><code>GOT[2]</code> points to <code>_dl_runtime_resolve()</code>! This is the runtime dynamic linker entry point.</li> </ul> <p>File <code>sysdep/generic/dl-machine.c</code> populates <code>GOT[1]</code> and <code>GOT[2]</code>. <pre><code>/* Set up the loaded object described by L so its unrelocated PLT\n   entries will jump to the on-demand fixup code in dl-runtime.c.  */\n\nstatic inline int\nelf_machine_runtime_setup (struct link_map *l, int lazy)\n{\n  extern void _dl_runtime_resolve (Elf32_Word);\n\n  if (lazy)\n    {\n      /* The GOT entries for functions in the PLT have not yet been filled\n         in.  Their initial contents will arrange when called to push an\n         offset into the .rel.plt section, push _GLOBAL_OFFSET_TABLE_[1],\n         and then jump to _GLOBAL_OFFSET_TABLE[2].  */\n      Elf32_Addr *got = (Elf32_Addr *) D_PTR (l, l_info[DT_PLTGOT]);\n      got[1] = (Elf32_Addr) l;  /* Identify this shared object.  */\n\n      /* This function will get called to fix up the GOT entry indicated by\n         the offset on the stack, and then jump to the resolved address.  */\n      got[2] = (Elf32_Addr) &amp;_dl_runtime_resolve;\n    }\n\n  return lazy;\n}\n</code></pre></p> <p><code>_dl_runtime_resolve()</code> is architecture specific and has a mix of assembly and C code. The flow is similar to the syscall handling: it first saves the registers, then calling the actual resolver, then restore all saved registers. For 64bit x86, the source code is in <code>sysdeps/x86_64/dl-trampoline.h</code>: <pre><code>    .globl _dl_runtime_resolve\n    .type _dl_runtime_resolve, @function\n_dl_runtime_resolve:\n    ...\n    ...\n\n    # Copy args pushed by PLT in register.\n    # %rdi: link_map, %rsi: reloc_index\n    mov (LOCAL_STORAGE_AREA + 8)(%BASE), %RSI_LP\n    mov LOCAL_STORAGE_AREA(%BASE), %RDI_LP\n    call _dl_fixup      # Call resolver.\n    mov %RAX_LP, %R11_LP    # Save return value\n\n    ...\n</code></pre></p> <p>Bingo, <code>_dl_fixup()</code> is the final piece of the runtime dynamic linker resolver. We could find it in <code>elf/dl-runtime.c</code>, which is a file for on-demand PLT fixup.: <pre><code>/* This function is called through a special trampoline from the PLT the\n   first time each PLT entry is called.  We must perform the relocation\n   specified in the PLT of the given shared object, and return the resolved\n   function address to the trampoline, which will restart the original call\n   to that address.  Future calls will bounce directly from the PLT to the\n   function.  */\n\nDL_FIXUP_VALUE_TYPE\nattribute_hidden __attribute ((noinline)) ARCH_FIXUP_ATTRIBUTE\n_dl_fixup (\n# ifdef ELF_MACHINE_RUNTIME_FIXUP_ARGS\n       ELF_MACHINE_RUNTIME_FIXUP_ARGS,\n# endif\n       struct link_map *l, ElfW(Word) reloc_arg)\n{\n    ...\n}\n</code></pre></p> <p>Understanding this piece of code requires some effort. Happy hacking!</p>"},{"location":"notes/dynamic_linking/#fun-fact-about-ld_preload","title":"Fun fact about LD_PRELOAD","text":"<p>If you use <code>LD_PRELOAD</code> to run a program, it will affect <code>popen()</code> since it will inherit environment variables. Hence, if you are doing some one time initilization within in your LD_PRELOAD library via, say <code>constructor</code> marked function, you should call <code>unsetenv(\"LD_PRELOAD\")</code> before <code>popen()</code> call.</p>"},{"location":"notes/dynamic_linking/#understanding","title":"Understanding","text":"<p>Most recent ELF produced by GCC is slightly different than the ones described by previous textbook or papers. The difference is small, though. You should use <code>man elf</code> to check latest.</p> <ul> <li>When a program imports a certain function or variable, the linker   will include a string with the function or variable\u2019s name in the   <code>.dynstr</code> section.</li> <li>A symbol (Elf Sym) that refers to the function or variable\u2019s name in the <code>.dynsym</code> section,   and a relocation (Elf Rel) pointing to that symbol in the <code>.rela.plt</code> section.</li> <li><code>.rela.dyn</code> and <code>.rela.plt</code> are for imported variables and functions, respectively.</li> <li><code>.plt</code> is the normal one, it has instructions.</li> <li><code>.got</code> and <code>.got.plt</code> maybe the first is for variable, and the latter is for function.   But essentially the same global offset table functionality.</li> </ul> <p>Relationship among <code>.dynstr</code>, <code>.dynsym</code>, <code>.rela.dyn</code> or <code>.rela.plt</code>. Credit: link: </p> <p>PIC Lazy Binding. Credit: link: </p> <p>Note</p> <p>GOT and PLT were invented for share libraries, so those libraries can be used by arbitrary processes without changing any of the library text.</p> <p>However, nowadays, even an non-PIC binary will always have GOT and PLT sections. In theory, it probably should use basic load-time relocation to resolve dynamic symbols (See CSAPP chapter 7 if you are not familiar with this).</p> <p>I think GOT/PLT are used over load-time relocation technique for the following 2 reasons: a) load-time relocation needs to modify code and this not good during time. Especially considering code section probably is not writable. b) GOT/PLT\u2019s lazy-binding has performance win at start-up time. However, keep in mind that GOT/PLT\u2019s lazy-bindling pay extra runtime cost!</p> <p>Reading:</p> <ul> <li>System V Application Binary Interface</li> <li>How the ELF Ruined Christmas</li> </ul>"},{"location":"notes/dynamic_linking/#how-kernel-loads-user-program","title":"How Kernel Loads User Program","text":"<p>Kernel loads user program via <code>exec()</code> or some variations. This post explained the flow in great details.</p> <p>Note that kernel can recognize dynamic linking via the <code>.interp</code> section and then invoke the dynamic linker <code>ld.so</code> instead of invoking user ELF binary directly.</p>"},{"location":"notes/dynamic_linking/#how-kernel-loads-kernel-module","title":"How Kernel Loads Kernel Module","text":"<p>Kernel can load modules during runtime. Those modules are ELF binaries. Let\u2019s first examine those binaries and see how kernel parses them.</p> <p>Suppose we have this simple C module code: <pre><code>int foo(void)\n{\n    printk(\"Hello World!\\n\");\n}\n\nstatic int hello_init(void)\n{\n    printk(\"Hello World!\\n\");\n    printk(\"Hello World!\\n\");\n    foo();\n    return 0;\n}\n</code></pre></p> <p>Once you compile it into a kernel module, we can examine the binary by using <code>objdump -dx hello.ko</code>. Those highlighted lines mark some of the dynamic linking slots. They will be patched by basic load-time relocation. <pre><code>Disassembly of section .text.unlikely:\n\n0000000000000000 &lt;foo&gt;:\n   0:   e8 00 00 00 00          callq  5 &lt;foo+0x5&gt;\n                        1: R_X86_64_PLT32       __fentry__-0x4\n   5:   55                      push   %rbp\n   6:   48 c7 c7 00 00 00 00    mov    $0x0,%rdi\n                        9: R_X86_64_32S .rodata.str1.1\n   d:   48 89 e5                mov    %rsp,%rbp\n  10:   e8 00 00 00 00          callq  15 &lt;foo+0x15&gt;\n                        11: R_X86_64_PLT32      printk-0x4\n  15:   5d                      pop    %rbp\n  16:   c3                      retq   \n\n0000000000000017 &lt;init_module&gt;:\n  17:   e8 00 00 00 00          callq  1c &lt;init_module+0x5&gt;\n                        18: R_X86_64_PLT32      __fentry__-0x4\n  1c:   55                      push   %rbp\n  1d:   48 c7 c7 00 00 00 00    mov    $0x0,%rdi\n                        20: R_X86_64_32S        .rodata.str1.1\n  24:   48 89 e5                mov    %rsp,%rbp\n  27:   e8 00 00 00 00          callq  2c &lt;init_module+0x15&gt;\n                        28: R_X86_64_PLT32      printk-0x4\n  2c:   48 c7 c7 00 00 00 00    mov    $0x0,%rdi\n                        2f: R_X86_64_32S        .rodata.str1.1\n  33:   e8 00 00 00 00          callq  38 &lt;init_module+0x21&gt;\n                        34: R_X86_64_PLT32      printk-0x4\n  38:   e8 00 00 00 00          callq  3d &lt;init_module+0x26&gt;\n                        39: R_X86_64_PLT32      foo-0x4\n  3d:   31 c0                   xor    %eax,%eax\n  3f:   5d                      pop    %rbp\n  40:   c3                      retq   \n</code></pre></p> <p>It is also worth checking out the <code>.symtab</code> section. If your module is using kernel functions or variables, the compiler does not know their precise addresses during compile time. The compiler will add several entries into the <code>.symtab</code> with properties marked as <code>GLOBAL, UND</code>. For example, you can run <code>readelf -s hello.ko</code> to check that. I will post part of the output: <pre><code>Symbol table '.symtab' contains 29 entries:\n   Num:    Value          Size Type    Bind   Vis      Ndx Name\n     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND \n     1: 0000000000000000     0 SECTION LOCAL  DEFAULT    1 \n    ....\n    13: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS haha.mod.c\n    ....\n    21: 0000000000000017    42 FUNC    LOCAL  DEFAULT    5 hello_init\n    22: 0000000000000000    11 FUNC    LOCAL  DEFAULT    3 hello_exit\n    23: 0000000000000000   896 OBJECT  GLOBAL DEFAULT   12 __this_module\n    24: 0000000000000000    11 FUNC    GLOBAL DEFAULT    3 cleanup_module\n    25: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND __fentry__\n    26: 0000000000000017    42 FUNC    GLOBAL DEFAULT    5 init_module\n    27: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND printk\n    28: 0000000000000000    23 FUNC    GLOBAL DEFAULT    5 foo\n</code></pre></p> <p>The <code>simplify_symbols()</code> below will find the kernel virtual addresses for UNDEF symbols in the <code>.symtab</code> section. Those will further be used to patch dynamic relocation entries.</p> <p>Now let us dive into kernel implementation.</p> <p>The kernel has several system calls for module. The loading part is using <code>SYSCALL_DEFINE3(init_module)</code>. Within that, it calls the big function <code>load_module()</code>.</p> <p>In the begining of <code>load_module()</code>, there are some usual tasks examining ELF headers, allocating memory etc. After that, kernel will try to find the addresses for UNDEF symbols:</p> <pre><code>kernel/module.c load_module()\n        /* Fix up syms, so that st_value is a pointer to location. */\n        err = simplify_symbols(mod, info);\n        if (err &lt; 0)\n                goto free_modinfo;\n\n        err = apply_relocations(mod, info);\n        if (err &lt; 0)\n                goto free_modinfo;\n\n==&gt;\n\nThis function will find the kernel virtual addresses\nfor UNDEF symbols in the `.symtab` section.\n\nsimplify_symbols()\n              case SHN_UNDEF:\n                        ksym = resolve_symbol_wait(mod, info, name);\n                        /* Ok if resolved.  */\n                        if (ksym &amp;&amp; !IS_ERR(ksym)) {\n                                sym[i].st_value = kernel_symbol_value(ksym);\n                                break;\n                        }\n</code></pre> <p>After resolving symbols to the real kernel virtual addresses, the next step is to patch the code to update all the relocation entries. If will do so for sections with these two types: <code>SHT_REL</code> and <code>SHT_RELA</code>. It looks like x86_64 is only using <code>apply_relocate_add()</code>, the one with explict addends. <pre><code>kernel/module.c apply_relocations()\n        ...\n                else if (info-&gt;sechdrs[i].sh_type == SHT_REL)\n                        err = apply_relocate(info-&gt;sechdrs, info-&gt;strtab,\n                                             info-&gt;index.sym, i, mod);\n                else if (info-&gt;sechdrs[i].sh_type == SHT_RELA)\n                        err = apply_relocate_add(info-&gt;sechdrs, info-&gt;strtab,\n                                                 info-&gt;index.sym, i, mod);\n</code></pre></p> <p>Zoom into <code>apply_relocate_add()</code>, very interesting function. It is similar to the userspace linker ld.so. It could be summarized as follows:</p> <ul> <li>Find the start of the relocation entry section in ELF.</li> <li>Walk through each relocation entry, for each entry, do:<ul> <li>Get the location where we need to patch the code (e.g., the assembly instructions dumped above)</li> <li>Find the symbol the entry is using. The symbol was alread resolved to kernel virtual address</li> <li>Update the location by applying certain computation on top of the resolved symbol address.   The computation is dictated by entry type (e.g., <code>R_X86_64_PLT32</code>)</li> </ul> </li> </ul> <p>See the full kernel code here.</p>"},{"location":"notes/dynamic_linking/#summary","title":"Summary","text":"<p>There you have it. We walk through how kernel loads user program, how kernel loads kernel module, and how dynamic linker resolves dynamic linking. The kernel and ld.so share a lot similarities in dealing with the linking process.</p> <p>We have not covered the static linking part in this post, but its process is similar to how the basic load-time relocation patches instructions.</p> <p>The essense of linking and loading is to do lazy information binding and pass information along the toolchain. The whole concetps involves many parties, ranging from compiler, linker, and kernel. Each takes its own part in the process.</p> <p>As always, hope you enjoyed this blog. Happy Hacking!</p>"},{"location":"notes/hardware_pl/","title":"Hardware Design Languages","text":"Version History Date Description Nov 13, 2020 Initial Version Sep 28, 2020 Initial Version"},{"location":"notes/hardware_pl/#introduction","title":"Introduction","text":"<p>There is an increasing interest from both industry and acadamic on designing high-level domain-specific languages for hardware development (both FPGA and ASIC). These advancements would benefit both software and hardware developers.</p> <p>This document reflects my effort on configuring/running these systems and my thoughts on their pros and cons (if any).</p> System Language Sponsor/Status Xilinx High-Level Synthesis C++ Industry. Mature Chisel Scala Industy and Acadamic. Mature SpinalHDL Scala Industry (solo effort). Mature Dahlia Scala Acadamic Google XLS Rust-like Industry. Pre-mature"},{"location":"notes/hardware_pl/#spinalhdl","title":"SpinalHDL","text":"<p>SpinalHDL is a scala-based meta HLD programming language. SpinalHDL will convert Scala into Verilog. The generated Verilog is very simple and matches what we write in Scala. Besides, you can use Scala Functional Programming to express hardware, really powerful!</p> <p>I found the following stuff very convenient: 1. Connection. I need to connect a lot of AxiStream interfaces very frequently. To connect an input port onto an output port, we can do something like the following snippets. <pre><code>io.in &gt;&gt; io.out.\n</code></pre> 2. Functional Programming. I can do something like this to get the sum of an array: <pre><code>array.foldLeft(0)(_+_)\n</code></pre></p>"},{"location":"notes/hardware_pl/#google-xls","title":"Google XLS","text":"<p>The XLS (Accelerated HW Synthesis) project is a Rust-like DSL for hardware development.</p>"},{"location":"notes/hardware_pl/#build","title":"Build","text":"<p>I used their <code>docker build .</code>, which is extremely lengthy. This is my first using Bazel. Once the build is done, use <code>docker images</code> to check the new docker image ID. To run, <code>docker run -i -t &lt;ID&gt; /bin/bash</code>. After that, follow their quick-guide.</p> <p>The whole project is pre-mature. There are not too many examples, the building process is too long, and even the basic <code>.x -&gt; .v</code> generation needs quite some manual typing.</p> <p>Following its <code>simple_adder</code> quick-start instructions, the following Verilog code is generated:</p> <pre><code>module __simple_add__add(\n  input wire clk,\n  input wire [31:0] x,\n  input wire [31:0] y,\n  output wire [31:0] out\n);\n  // ===== Pipe stage 0:\n\n  // Registers for pipe stage 0:\n  reg [31:0] p0_x;\n  reg [31:0] p0_y;\n  always_ff @ (posedge clk) begin\n    p0_x &lt;= x;\n    p0_y &lt;= y;\n  end\n\n  // ===== Pipe stage 1:\n  wire [31:0] p1_add_3_comb;\n  assign p1_add_3_comb = p0_x + p0_y;\n\n  // Registers for pipe stage 1:\n  reg [31:0] p1_add_3;\n  always_ff @ (posedge clk) begin\n    p1_add_3 &lt;= p1_add_3_comb;\n  end\n  assign out = p1_add_3;\nendmodule\n</code></pre>"},{"location":"notes/hardware_pl/#llvm-circt","title":"LLVM CIRCT","text":"<p>\u201cCIRCT\u201d stands for \u201cCircuit IR Compilers and Tools\u201d. This is also an early-stage LLVM project.</p>"},{"location":"notes/kvm-basic/","title":"Just some basics about KVM","text":"<p>Update: you can fine more info here https://gdoc.pub/doc/e/2PACX-1vSsskD0A2XgHoZhaYLAkS7lmCOrfxkGXk1WTovWEAyeoELVdBjrE-NzD8h-NvJfKhxMpUg2aXzaD-XG.</p>"},{"location":"notes/kvm-basic/#resources","title":"Resources","text":"<ul> <li>Intel Virtualisation: How VT-x, KVM and QEMU Work Together</li> </ul>"},{"location":"notes/kvm-basic/#hacking-notes","title":"Hacking Notes","text":"<p>If you are hacking some low-level stuff that is running as a VM, pay close attention if KVM is involved. I started this note because I spent sometime twisting <code>page_fault</code> IDT entry, but it turns out KVM uses <code>async_page_fault</code>. Oh, well.</p> <ul> <li>KVM page fault entry (<code>arch/x86/entry/entry_64.S</code>)<ul> <li>It is <code>idtentry async_page_fault       do_async_page_fault     has_error_code=1</code></li> <li>..not <code>idtentry page_fault             do_page_fault           has_error_code=1</code></li> </ul> </li> </ul>"},{"location":"notes/kvm-basic/#more-on-virturlization","title":"More on Virturlization","text":"<p>Well. I swear I want to learn more about Virturlization..</p> <ul> <li>Intel SDM, volume 3, Chapter 23 - Chapter 33.</li> </ul> <p>\u2013 Yizhou Shan Created: May 20, 2019 Last Updated: Sep 11, 2019</p>"},{"location":"notes/os/","title":"Operating Systems","text":"<p>Multics</p> <p>Plan 9</p> <p>Taos</p> <p>SPIN:</p> <p>V++:     - Cache kernel.</p> <p>Nemesis     - A more hybrid approach     - QoS Crosstalk</p> <p>Singularity, Helios</p>"},{"location":"notes/packet-sched/","title":"Switch Buffering Architecture and Packet Scheduling Algorithms","text":"Version History Date Description Jun 28, 2021 minor update Jan 15, 2021 add some FM10000 figs Jan 13, 2021 more Jan 12, 2021 Initial Version <p>I came across this topic for a research project I\u2019m doing.</p> <p><code>switch buffering architecture</code> and <code>packet scheduling</code> are two closely related topics. The buffering architecture could limit which scheduling algorithms can be used. Nonetheless, I think they are two different things and we should look at them separately. For example, consider a Combined Input Output Queued Switch (CIOQ), it is possible to use a Shared Memory Buffer to implement the output queues and use a separate <code>PIFO</code> blocks for packet scheduling.</p> <p>Facts about state-of-the-art switches:</p> <ol> <li>They use a large central packet buffer, can be as large as 64MB (i.e., Tofino2).</li> <li>They could have some input and output buffers independent from the central packet buffer, but these buffers would be small.</li> <li>They have something called <code>Traffic Manager</code> for packet scheduling.</li> <li>They usually have fixed packet scheduler, as in the algorithms cannot be changed after production. The typical ones are priority-based scheduling and so on. I\u2019m not quite sure whether they have the programmable packet scheduler concept pioneered by the PIFO paper.</li> </ol>"},{"location":"notes/packet-sched/#switch-buffering-architecture","title":"Switch Buffering Architecture","text":"<p>List of different switch buffering architectures:</p> <ul> <li>Input Queued (place buffer after each rx port)</li> <li>Virtual Output Queued (each rx port has per-tx queues)</li> <li>Output Queued (place buffer before each tx port)</li> <li>Combined Input and Output Queued (both rx and tx ports have buffers)</li> <li>Shared Memory (depends, it could be a central packet buffer for all tx ports while each tx port still has a small queue)</li> </ul> <p>The Output Queue (OQ) mode has the best performance (see ref-2). But if there is incast (multiple rx go to one tx), the buffer before each tx must be able to run N times faster. Since it is impossible to scale the memory bandwidth with respect to network bandwidth, the OQ is rarely used now.</p> <p>On the other hand, the memory in Input Queued (IQ) switch needs only run as fast as the line rate. This makes input queueing very appealing for switches with fast line rates, or with a large number of ports. For this reason, the highest performance switches and routers use input-queued crossbar switches (ref-2). And a lot recent FPGA-based switch papers are using the input-queued mode. BUTT, IQ mode suffers from HOL blocking. So naturally, people came up with the Virtual Output Queued (VOQ) mode, in which each tx port has a buffer at each rx port.</p> <p>However, all those IQ, OQ, VOQ, and CIOQ mode can not easily share the buffers among different ports, i.e., not able to dynamically partition the buffer usage. (I think) this issue calls for the shared memory based switch, in which the central packet buffer can be easily partitioned among tx ports, just a few counters will do. In fact, the switches I know (though only a few), all use shared memory mode. For example, the Inte Barefoot programmable p4 switch Tofino2 has a 64MB central packet buffer.</p>"},{"location":"notes/packet-sched/#packet-scheduling","title":"Packet Scheduling","text":"<p>There is nothing special about packet scheduling, it is just scheduling a bunch of packets :). This topic is concerned about in which order to transmit packets and when to tranmit them. Just like other scheduling work, there is Work-Conserving v.s. Non-Work-Conserving algorithms.</p> <p>The simplest algorithm is FIFO. But it could have a lot issues, e.g., HOL blocking. Since there might be multiple queues waiting to be transmitted, there could be RR, and weighted RR (WRR). And there are some advanced ones like Strict Priority, Shorted-Time-XXX.</p> <p>Normally, in our current machine, CPU will do the scheduling rather than the NIC itself. For example, kernel has Queuing Discipline layer that supports quite a lot algorithms.</p> <p>With the increasing bandwidth, packet scheduling is more important than before. It is buring CPU cycles, it may have bad perf, etc. So people have tried to offload that onto NIC or propose new CPU-friendly algorithms (i.e., Eiffel, NSDI\u201819 from Google).</p> <p>Packet scheduling is also a important piece for switches. Even for programmable switches, this part is not programmable. So there are work trying to solve that. The PIFO SIGCOMM\u201816 paper is for sure one of the seminal work in this space.</p> <p>To summarize, there are few aspects to consider: 1. where is it running? CPU, NIC, switch, or somewhere else. 2. is it programmable or fixed-function?</p>"},{"location":"notes/packet-sched/#case-study","title":"Case Study","text":"<p>Let us look at some real usages out there.</p>"},{"location":"notes/packet-sched/#linux-kernel","title":"Linux Kernel","text":"<p>Kernel has a subsystem called queuing discipline, or <code>qdisc</code>. It is a framework to schedule network packets. It is built in the classical way: a generic layer and a set of ops for callback, just like how VFS is built. You can find a lot resources about it online.</p> <p>Anyhow, you can find the code in <code>net/sched/sch_*.c</code>. You can probably look into <code>sch_api.c</code>, <code>sch_generic.c</code>, these seem to be general (e.g., <code>register_qdisc()</code>). The default qdisc is called <code>pfifo_xxx</code>, you can do a <code>git grep</code> to find it. It has quite a lot other algorithms like RED in <code>sch_red.c</code>.</p> <p>So all those are software-based packet scheduling implementations. If you are interested, you can also check out an NSDI\u201819 paper called <code>Eiffel</code> from Google, which also advocates for software-based packet scheduling.</p>"},{"location":"notes/packet-sched/#fpga-based-switching","title":"FPGA-based Switching","text":"<p>For packet scheduling: we need special data structure design.</p> <p>I\u2019m only aware of these two papers dealing with this:</p> <ul> <li>PIFO, SIGCOMM\u201816</li> <li>PIEO, SIGCOMM\u201819</li> </ul> <p>Both of them have a hardware primitive and a framework to express various packet scheduling algorithms on top of their primitive.</p> <p>PIFO\u2019s source code seems robust and has been used by later projects (e.g., PANIC OSDI\u201820). But PIFO\u2019s verilog implementation suffers from scalability issue. It solely uses LUTs to implement its storage and logic, no BRAM is used. I\u2019m not sure about PIEO.</p> <p>Q: Will a Softcore-based packet scheduler able to keep up the throughput? If not, can be customize the softcore to be packet scheduler friendly? The benefit is probably we can write scheduling algorithm in C (and change freely during runtime) while have hardware (line rate) performance.</p>"},{"location":"notes/packet-sched/#intel-barefoot-tofino2","title":"Intel Barefoot Tofino2","text":"<p>See here, especially the <code>Traffic Manager</code> slide:</p> <p></p>"},{"location":"notes/packet-sched/#intel-fm10000-multi-host-switch","title":"Intel FM10000 Multi-Host Switch","text":"<p>This is a shared-memory switch. This is from their spec. Only payload goes into the shared memory. Headers go into frame processing pipeline. </p> <p>This one shows how headers and payload are separated. Essentially, the <code>packet scheduler</code> only deals with HEADERS. This switch has 8 queues per TX port. If there is multicast, the headers will will duplicated multiple times. </p>"},{"location":"notes/packet-sched/#broadcom-trident","title":"Broadcom Trident","text":"<p>Resources:</p> <ul> <li>https://docs.broadcom.com/doc/12395356</li> </ul>"},{"location":"notes/packet-sched/#final-thoughts","title":"Final Thoughts","text":"<p>Although the shared memory based switch works for now, I\u2019m not sure whether it will continue working in the furture. For one, the network bandwidth is increasing, 200Gbps, 400Gbps. Will the memory still be able to sustain such high bandwidth? I doubt that.</p> <p>Also, share memory switch consumes a lot power. Not just the SRAM/DRAM, but also the SERDES transivers. Those guys consume A LOT energy. And this is exactly the reason people started looking into circuit switch.</p> <p>As for packet scheduling, I think there is definitely space for future work. For example, a better FPGA-friendly programmable framework, a dynamic framework shifting the packet scheduling task among CPU/NIC/Switch, a better p4-based algorithm etc. With the growing network bandwidth, all things should be revisted.</p>"},{"location":"notes/packet-sched/#references","title":"References","text":"<ol> <li>The iSLIP scheduling algorithm for input-queued switches, 1999</li> <li>Matching Output Queueing with a Combined Input Output Queued Switch, 1999<ul> <li>This paper proposed PIFO.</li> <li>It is trying to prove a CIOQ switch can be as good as a output queued switch.</li> </ul> </li> <li>Saturating the Transceiver Bandwidth: Switch Fabric Design on FPGAs, 2012<ul> <li>Use shared memory as switch.</li> </ul> </li> <li>Investigating the Feasibility of FPGA-based Network Switches, 2019</li> <li>High-Performance FPGA Network Switch Architecture, 2020</li> <li>Scheduling Algorithms for High Performance Network Switching on FPGAs: A Survey, 2018</li> </ol> <ol> <li>Intel\u00ae Ethernet Switch FM10000 Series</li> <li>Intel Barefoot Tofino2 has a 64MB Unified Packet Buffer </li> </ol> <ol> <li>PIFO, SIGCOMM\u201816</li> <li>PIEO, SIGCOMM\u201819</li> <li>Eiffel, NSDI\u201819</li> <li>Loom, NSDI\u201819</li> <li>Programmable Calendar Queue, NSDI\u201820</li> <li>Carousel, SIGCOMM\u201817</li> </ol>"},{"location":"notes/paper_fpga/","title":"An FPGA Reading List","text":"Version History Date Description Aug 26, 2020 Add those 2 ISCA\u201820 papers to Host Virtual Memory Section Nov 30, 2019 Add a lot security papers Oct 22, 2019 Shuffle scheduling section. More focused. Add two more recent fpga-virt papers Oct 5, 2019 More on scheduling. Add NoC. Add Security. Oct 4, 2019 Add more papers extracted from AmophOS Oct 3, 2019 Initial version from Github <p>A list of related papers I came across while doing FPGA-related research. If you\u2019d like to contribute, please comment below or create PR here.</p> <ul> <li>Virtualization<ul> <li>Scheduling</li> <li>NoC</li> <li>Memory Hierarchy</li> <li>Dynamic Memory Allocation</li> <li>Integrate with Host Virtual Memory</li> <li>Integrate with Host OSs</li> <li>Security</li> <li>Summary</li> </ul> </li> <li>Languages, Runtime, and Framework<ul> <li>Xilinx HLS</li> <li>Xilinx CAD</li> <li>High-Level Languages and Platforms</li> <li>Integrate with Frameworks</li> <li>Cloud Infrastructure</li> <li>Misc</li> </ul> </li> <li>Applications<ul> <li>Programmable Network</li> <li>Database</li> <li>Storage</li> <li>Machine Learning</li> <li>Graph</li> <li>Key-Value Store</li> <li>Bio</li> <li>Consensus</li> <li>Video Processing</li> <li>Blockchain</li> <li>Micro-services</li> </ul> </li> <li>FPGA Internal<ul> <li>General</li> <li>Partial Reconfiguration</li> <li>Logical Optimization and Technology Mapping</li> <li>Place and Route</li> <li>RTL2FPGA</li> </ul> </li> </ul>"},{"location":"notes/paper_fpga/#virtualization","title":"Virtualization","text":""},{"location":"notes/paper_fpga/#scheduling","title":"Scheduling","text":"<p>Scheduling is big topic for FPGA. Unlike the traditional CPU scheduling, there are more aspects to consider, e.g., 1) Partial reconfiguration (PR), 2) Dynamic self PR, 3) Preemptive scheduling, 4) Relocation, 5) Floorplanning, and so on.</p>"},{"location":"notes/paper_fpga/#preemptive-scheduling","title":"Preemptive Scheduling","text":"<ul> <li>Preemptive multitasking on FPGAs, 2000</li> <li>Multitasking on FPGA Coprocessors, 2000</li> <li>Context saving and restoring for multitasking in reconfigurable systems, 2005</li> <li>ReconOS Cooperative multithreading in dynamically reconfigurable systems, FPL\u201809</li> <li>Block, drop or roll(back): Alternative preemption methods for RH multi-tasking, FCCM\u201809</li> <li>Hardware Context-Switch Methodology for Dynamically Partially Reconfigurable Systems, 2010</li> <li>On-chip Context Save and Restore of Hardware Tasks on Partially Reconfigurable FPGAs, 2013</li> <li>HTR: on-chip Hardware Task Relocation For Partially Reconfigurable FPGAs, 2013</li> <li>Preemptive Hardware Multitasking in ReconOS, 2015</li> </ul>"},{"location":"notes/paper_fpga/#preemptive-reconfiguration","title":"Preemptive Reconfiguration","text":"<ul> <li>Preemption of the Partial Reconfiguration Process to Enable Real-Time Computing, 2018</li> </ul>"},{"location":"notes/paper_fpga/#bitstreams","title":"Bitstreams","text":"<ul> <li>Github 7-series bitmap reverse engineering</li> <li>PARBIT: A Tool to Transform Bitfiles to Implement Partial Reconfiguration of Field Programmable Gate Arrays (FPGAs), 2001</li> <li>BIL: A TOOL-CHAIN FOR BITSTREAM REVERSE-ENGINEERING, 2012</li> <li>BITMAN: A Tool and API for FPGA Bitstream Manipulations, 2017</li> </ul>"},{"location":"notes/paper_fpga/#relocation","title":"Relocation:","text":"<ul> <li>Context saving and restoring for multitasking in reconfigurable systems, 2005</li> <li>REPLICA2Pro: Task Relocation by Bitstream Manipulation in Virtex-II/Pro FPGAs, 2006</li> <li>Relocation and Automatic Floor-planning of FPGA Partial Configuration Bit-Streams, MSR 2008</li> <li>Internal and External Bitstream Relocation for Partial Dynamic Reconfiguration, 2009</li> <li>PRR-PRR Dynamic Relocation, 2009</li> <li>HTR: on-chip Hardware Task Relocation For Partially Reconfigurable FPGAs, 2003</li> <li>AutoReloc, 2016</li> <li>HTR: on-chip Hardware Task Relocation For Partially Reconfigurable FPGAs, 2013</li> </ul>"},{"location":"notes/paper_fpga/#others","title":"Others","text":"<ul> <li>hthreads: A hardware/software co-designed multithreaded RTOS kernel, 2005</li> <li>hthreads: Enabling a Uniform Programming Model Across the Software/Hardware Boundary, FCCM\u201816</li> <li>Tartan: Evaluating Spatial Computation for Whole Program Execution, ASPLOS\u201806</li> <li>A virtual hardware operating system for the Xilinx XC6200, 1996</li> <li>The Swappable Logic Unit: a Paradigm for Virtual Hardware, FCCM\u201897</li> <li>Run-time management of dynamically reconfigurable designs, 1998<ul> <li>All above ones are early work on FPGA scheduling.</li> <li>Worth a read, but don\u2019t take some of their assumptions. Some have been changed after SO many years.</li> </ul> </li> <li>S1. Reconfigurable Hardware Operating Systems: From Design Concepts to Realizations, 2003</li> <li>S2. Operating Systems for Reconfigurable Embedded Platforms: Online Scheduling of Real-Time Tasks, 2004<ul> <li>Very fruitful discussion. The paper schedules bitstreams inside FPGA,   following a Real-Time sched policy (deadline).</li> <li>Different from CPU sched, FPGA scheduling needs to consider \u201careas\u201d. The chip is a rectangle box, allocating areas needs great care to avoid fragmentation!</li> </ul> </li> <li>Context saving and restoring for multitasking in reconfigurable systems, FPL\u201805<ul> <li>Optimizing deschedule perf.</li> <li>This paper discusses ways to save and restore the state information of a hardware task.   There are generally three approachs: a) adding indirection. Let app use system API to read/write states.   b) yield-type API. c) use PR controller to read back bitstream.</li> <li>This paper used ICAP to read the bitstream back and extract necenssay state information that must be present at next bitstream resume.</li> </ul> </li> <li>Scheduling intervals for reconfigurable computing, FCCM\u201808</li> <li>Hardware context-switch methodology for dynamically partially reconfigurable systems, 2010</li> <li>Online Scheduling for Multi-core Shared Reconfigurable Fabric, DATE\u201812</li> <li>Multi-shape Tasks Scheduling for Online Multitasking on FPGAs, 2014</li> <li>AmophOS, OSDI\u201818</li> <li>Hardware context switching on FPGAs, 2014</li> <li>Efficient Hardware Context-Switch for Task Migration between Heterogeneous FPGAs, 2016</li> </ul>"},{"location":"notes/paper_fpga/#noc","title":"NoC","text":"<p>Network-on-Chip on FPGA.</p> <ul> <li>Interconnection Networks Enable Fine-Grain Dynamic Multi-Tasking on FPGAs, 2002<ul> <li>Like the idea of separating computation from communication.</li> <li>Also a lot discussions about possible NoC designs within FPGA.</li> </ul> </li> <li>LEAP Soft connections: Addressing the hardware-design modularity problem, DAC\u201809<ul> <li>Virtual channel concept. Time-insensitive.</li> </ul> </li> <li>Leveraging Latency-Insensitivity to Ease Multiple FPGA Design, FPGA\u201812</li> <li>CONNECT: re-examining conventional wisdom for designing nocs in the context of FPGAs, FPGA\u201812</li> <li>Your Programmable NIC Should be a Programmable Switch, HotNets\u201818</li> </ul>"},{"location":"notes/paper_fpga/#memory-hierarchy","title":"Memory Hierarchy","text":"<p>Papers deal with BRAM, registers, on-board DRAM, and host DRAM.</p> <ul> <li>LEAP Scratchpads: Automatic Memory and Cache Management for Reconfigurable Logic, FPGA\u201811<ul> <li>Main design hierarchy: Use BRAM as L1 cache, use on-board DRAM as L2 cache, and host memory as the backing store. Everthing is abstracted away through their interface (similar to load/store). Programming is pretty much the same as if you are writing for CPU.</li> <li>According to sec 2.2.2, its scratchpad controller, is using simple segment-based mapping scheme. Like AmorphOS\u2019s one.</li> </ul> </li> <li>LEAP Shared Memories: Automating the Construction of FPGA Coherent Memories, FCCM\u201814<ul> <li>Follow up work on LEAP Scratchpads, extends the work to have cache coherence between multiple FPGAs.</li> <li>Coherent Scatchpads with MOSI protocol.</li> </ul> </li> <li>MATCHUP: Memory Abstractions for Heap Manipulating Programs, FPGA\u201815</li> <li>CoRAM: An In-Fabric Memory Architecture for FPGA-Based Computing<ul> <li>CoRAM provides an interface for managing the on- and off-chip memory resource of an FPGA. It use \u201ccontrol threads\u201d enforce low-level control on data movement.</li> <li>Seriously, the CoRAM is just like Processor L1-L3 caches.</li> </ul> </li> <li>CoRAM Prototype and evaluation of the CoRAM memory architecture for FPGA-based computing, FPGA\u201812<ul> <li>Prototype on FPGA.</li> </ul> </li> <li>Sharing, Protection, and Compatibility for Reconfigurable Fabric with AMORPHOS, OSDI\u201818<ul> <li>Hull: provides memory protection for on-board DRAM using segment-based address translation.</li> </ul> </li> <li>Virtualized Execution Runtime for FPGA Accelerators in the Cloud, IEEE Access\u201817</li> </ul>"},{"location":"notes/paper_fpga/#dynamic-memory-allocation","title":"Dynamic Memory Allocation","text":"<p><code>malloc()</code> and <code>free()</code> for FPGA on-board DRAM.</p> <ul> <li>A High-Performance Memory Allocator for Object-Oriented Systems, IEEE\u201896</li> <li>SysAlloc: A Hardware Manager for Dynamic Memory Allocation in Heterogeneous Systems, FPL\u201815</li> <li>Hi-DMM: High-Performance Dynamic Memory Management in High-Level Synthesis, IEEE\u201818</li> </ul>"},{"location":"notes/paper_fpga/#integrate-with-host-virtual-memory","title":"Integrate with Host Virtual Memory","text":"<p>Papers deal with OS Virtual Memory System (VMS). Note that, all these papers introduce some form of MMU into the FPGA to let FPGA be able to work with host VMS. This added MMU is similar to CPU\u2019s MMU and RDMA NIC\u2019s internal cache. Note that the VMS still runs inside Linux (include pgfault, swapping, TLB shootdown and so on.), except one recent ISCA\u201820 paper.</p> <ul> <li>Virtual Memory Window for Application-Specific Reconfigurable Coprocessors, DAC\u201804<ul> <li>Early work that adds a new MMU to FPGA to let FPGA logic access <code>on-chip DRAM</code>. Note, it\u2019s not the system main memory. Thus the translation pgtable is different.</li> <li>Has some insights on prefetching and MMU CAM design.</li> </ul> </li> <li>Seamless Hardware Software Integration in Reconfigurable Computing Systems, 2005<ul> <li>Follow up summary on previous DAC\u201804 Virtual Memory Window.</li> </ul> </li> <li>A Reconfigurable Hardware Interface for a Modern Computing System, FCCM\u201807<ul> <li>This work adds a new MMU which includes a 16-entry TLB to FPGA. FPGA and CPU shares the same user virtual address space, use the same physical memory. FPGA and CPU share memory at cacheline granularity, FPGA is just another core in this sense. Upon a TLB miss at FPGA MMU, the FPGA sends interrupt to CPU, to let software to handle the TLB miss. Using software-managed TLB miss is not efficient. But they made cache coherence between FPGA and CPU easy.</li> </ul> </li> <li>Low-Latency High-Bandwidth HW/SW Communication in a Virtual Memory Environment, FPL\u201808<ul> <li>This work actually add a new MMU to FPGA, which works just like CPU MMU. It\u2019s similar to IOMMU, in some sense.</li> <li>But I think they missed one important aspect: cache coherence between CPU and FPGA. There is not too much information about this in the paper, it seems they do not have cache at FPGA. Anyhow, this is why recently CCIX and OpenCAPI are proposed.</li> </ul> </li> <li>Memory Virtualization for Multithreaded Reconfigurable Hardware, FPL\u201811<ul> <li>Part of the ReconOS project</li> <li>They implemented a simple MMU inside FPGA that includes a TLB. On protection violation or page invalid access cases, their MMU just hand over to CPU pgfault routines. How is this different from the FPL\u201808 one? Actually, IMO, they are the same.</li> </ul> </li> <li>S4 Virtualized Execution Runtime for FPGA Accelerators in the Cloud, IEEE Access\u201817<ul> <li>This paper also implemented a hardware MMU, but the virtual memory system still run on Linux.</li> <li>Also listed in <code>Cloud Infrastructure</code> part.</li> </ul> </li> <li>Lightweight Virtual Memory Support for Many-Core Accelerators in Heterogeneous Embedded SoCs, 2015</li> <li>Lightweight Virtual Memory Support for Zero-Copy Sharing of Pointer-Rich Data Structures in Heterogeneous Embedded SoCs, IEEE\u201817<ul> <li>Part of the PULP project.</li> <li>Essentially a software-managed IOMMU. The control path is running as a Linux kernel module. The datapath is a lightweight AXI transation translation.</li> </ul> </li> <li>Flick: Fast and Lightweight ISA-Crossing Call for Heterogeneous-ISA Environments, ISCA\u201820<ul> <li>This paper adds an MMU/TLB into FPGA-side RISC-V to fetch/translate host pgtable entries.   This paper\u2019s goal is to migrate threads between different ISAs, the key is VM.   But what\u2019s new?</li> </ul> </li> <li>A Case for Hardware-Based Demand Paging, ISCA\u201820<ul> <li>This paper is not FPGA-based, but does augments host MMU with pgfault handling capability.</li> <li>This paper targets file-backed pgfault, more specific, ultra-low-latency SSD backed files.   It adds several HW units to let CPU MMU able to handle and resolve such pgfaults   (essentially offload VFS-&gt;FS-&gt;BLK-&gt;NVMe Driver functionalties into HW. Some part is done via mmap() beforehand).</li> <li>It\u2019s async free page list, async LRU handling are used by our work as well.</li> </ul> </li> </ul>"},{"location":"notes/paper_fpga/#integrate-with-host-oss","title":"Integrate with Host OSs","text":"<ul> <li>A Virtual Hardware Operating System for the Xilinx XC6200, FPL\u201896</li> <li>Operating systems for reconfigurable embedded platforms: online scheduling of real-time tasks, IEEE\u201804</li> <li>hthreads: a hardware/software co-designed multithreaded RTOS kernel, 2005</li> <li>Reconfigurable computing: architectures and design methods, IEE\u201805</li> <li>BORPH: An Operating System for FPGA-Based Reconfigurable Computers. PhD Thesis.</li> <li>FUSE: Front-end user framework for O/S abstraction of hardware accelerators, FCCM\u201811</li> <li>ReconOS \u2013 an Operating System Approach for Reconfigurable Computing, IEEE Micro\u201814<ul> <li>Invoke kernel from FPGA. They built a shell in FPGA and delegation threads in CPU to achieve this.</li> <li>They implemented their own MMU (using pre-established pgtables) to let FPGA logic to access system memory. Ref.</li> <li>Read the \u201cOperating Systems for Reconfigurable Computing\u201d sidebar, nice summary.</li> </ul> </li> <li>LEAP Soft connections: Addressing the hardware-design modularity problem, DAC\u201809<ul> <li>Channel concept. Good.</li> </ul> </li> <li>LEAP Scratchpads: Automatic Memory and Cache Management for Reconfigurable Logic, FPGA\u201811<ul> <li>BRAM/on-board DRAM/host DRAM layering. Caching.</li> </ul> </li> <li>LEAP Shared Memories: Automating the Construction of FPGA Coherent Memories<ul> <li>Add cache-coherence on top of previous work.</li> <li>Also check out my note on Cache Coherence.</li> </ul> </li> <li>LEAP FPGA Operating System, FPL\u201814.</li> <li>A Survey on FPGA Virtualization, FPL\u201818</li> <li>ZUCL 2.0: Virtualised Memory and Communication for ZYNQ UltraScale+ FPGAs, FSP\u201819</li> </ul>"},{"location":"notes/paper_fpga/#security","title":"Security","text":"<p>If I were to recommend, I\u2019d suggest start from:</p> <ul> <li>Recent Attacks and Defenses on FPGA-based Systems, 2019</li> <li>Physical Side-Channel Attacks and Covert Communication on FPGAs: A Survey, 2019</li> <li>FPGA security: Motivations, features, and applications, 2014</li> </ul> <p>The whole list:</p> <ul> <li>FPGAhammer : Remote Voltage Fault Attacks on Shared FPGAs , suitable for DFA on AES</li> <li>FPGA-Based Remote Power Side-Channel Attacks</li> <li>Characterization of long wire data leakage in deep submicron FPGAS</li> <li>Protecting against cryptographic Trojans in FPGAS</li> <li>FPGA Side Channel Attacks without Physical Access</li> <li>FPGA security: Motivations, features, and applications</li> <li>FPGA side-channel receivers</li> <li>Security of FPGAs in data centers</li> <li>Secure Function Evaluation Using an FPGA Overlay Architecture</li> <li>Mitigating Electrical-level Attacks towards Secure Multi-Tenant FPGAs in the Cloud</li> <li>The Costs of Confidentiality in Virtualized FPGAs</li> <li>Temporal Thermal Covert Channels in Cloud FPGAs</li> <li>Characterizing Power Distribution Attacks in Multi-User FPGA Environments</li> <li>FASE: FPGA Acceleration of Secure Function Evaluation</li> <li>Securing Cryptographic Circuits by Exploiting Implementation Diversity and Partial Reconfiguration on FPGAs</li> <li>Measuring Long Wire Leakage with Ring Oscillators in Cloud FPGAs</li> <li>Physical Side-Channel Attacks and Covert Communication on FPGAs: A Survey</li> <li>Leaky Wires: Information Leakage and Covert Communication Between FPGA Long Wires</li> <li>Using the Power Side Channel of FPGAs for Communication</li> <li>An Inside Job: Remote Power Analysis Attacks on FPGAs</li> <li>Leakier Wires: Exploiting FPGA Long Wires for Covert- and Side-channel Attacks</li> <li>Voltage drop-based fault attacks on FPGAs using valid bitstreams</li> <li>Moats and Drawbridges: An Isolation Primitive for Reconfigurable Hardware Based Systems</li> <li>Sensing nanosecond-scale voltage attacks and natural transients in FPGAs</li> <li>Holistic Power Side-Channel Leakage Assessment:</li> <li>Hiding Intermittent Information Leakage with Architectural Support for Blinking</li> <li>Examining the consequences of high-level synthesis optimizations on power side-channel</li> <li>Register transfer level information flow tracking for provably secure hardware design</li> <li>A Protection and Pay-per-use Licensing Scheme for On-cloud FPGA Circuit IPs</li> <li>Recent Attacks and Defenses on FPGA-based Systems</li> <li>PFC: Privacy Preserving FPGA Cloud - A Case Study of MapReduce</li> <li>A Pay-per-Use Licensing Scheme for Hardware IP Cores in Recent SRAM-Based FPGAs</li> <li>FPGAs for trusted cloud computing</li> </ul>"},{"location":"notes/paper_fpga/#summary","title":"Summary","text":"<p>Summary on current FPGA Virtualization Status. Prior art mainly focus on: 1) How to virtualize on-chip BRAM (e.g., CoRAM, LEAP Scratchpad), 2) How to work with host, specifically, how to use the host DRAM, how to use host virtual memory. 3) How to schedule bitstreams inside a FPGA chip. 4) How to provide certain services to make FPGA programming easier (mostly work with host OS).</p>"},{"location":"notes/paper_fpga/#languages-runtime-and-framework","title":"Languages, Runtime, and Framework","text":"<p>Innovations in the toolchain space.</p>"},{"location":"notes/paper_fpga/#xilinx-hls","title":"Xilinx HLS","text":"<ul> <li>Design Patterns for Code Reuse in HLS Packet Processing Pipelines, FCCM\u201819<ul> <li>A very good HLS library from Mellanox folks.</li> </ul> </li> <li>Templatised Soft Floating-Point for High-Level Synthesis, FCCM\u201819</li> <li>ST-Accel: A High-Level Programming Platform for Streaming Applications on FPGA, FCCM\u201818</li> <li>HLScope+: Fast and Accurate Performance Estimation for FPGA HLS, ICCAD\u201817</li> <li>Separation Logic-Assisted Code Transformations for Efficient High-Level Synthesis, FCCM\u201814<ul> <li>An HLS design aids that analyze the original program at compile time and perform automated code transformations. The tool analysis pointer-manipulating programs and automatically splits heap-allocated data structures into disjoint, independent regions.</li> <li>The tool is for C++ heap operations.</li> <li>To put in another way: the tool looks at your BRAM usage, found any false-dependencies, and make multiple independent regions, then your II is improved.</li> </ul> </li> <li>MATCHUP: Memory Abstractions for Heap Manipulating Programs, FPGA\u201815<ul> <li>This is an HLS toolchain aid.</li> <li>Follow-up work of the above FCCM\u201814 one. This time they use LEAP scracchpads as the underlying caching block.</li> </ul> </li> </ul>"},{"location":"notes/paper_fpga/#xilinx-cad","title":"Xilinx CAD","text":"<ul> <li>Maverick: A Stand-alone CAD Flow for Partially Reconfigurable FPGA Modules, FCCM\u201819</li> </ul>"},{"location":"notes/paper_fpga/#high-level-languages-and-platforms","title":"High-Level Languages and Platforms","text":"<ul> <li>Just-in-Time Compilation for Verilog, ASPLOS\u201819</li> <li>Chisel: Constructing Hardware in a Scala Embedded Language, DAC\u201812<ul> <li>Chisel is being actively improved and used by UCB folks.</li> </ul> </li> <li>Rosetta: A Realistic High-Level Synthesis Benchmark Suite for Software Programmable FPGAs, FPGA\u201818</li> <li>From JVM to FPGA: Bridging Abstraction Hierarchy via Optimized Deep Pipelining, HotCloud\u201818</li> <li>HeteroCL: A Multi-Paradigm Programming Infrastructure for Software-Defined Reconfigurable Computing, FPGA\u201819</li> <li>LINQits: Big Data on Little Clients, ISCA\u201813<ul> <li>From Microsoft, used to express SQL-like functions (thus big data) and runs on ZYNQ (thus little client),</li> <li>You wrote C#, LINQits translate it to verilog, and run the whole thing at a ZYNQ (ARM+FPGA) board.</li> </ul> </li> <li>Lime: a Java-Compatible and Synthesizable Language for Heterogeneous Architectures, OOPSLA\u201810<ul> <li>Lime is a Java-based programming model and runtime from IBM which aims to provide a single unified   language to program heterogeneous architectures, from FPGAs to conventional CPUs</li> </ul> </li> <li>A line of work from Standord<ul> <li>Generating configurable hardware from parallel patterns, ASPLOS\u201816</li> <li>Plasticine: A Reconfigurable Architecture For Parallel Patterns, ISCA\u201817</li> <li>Spatial: A Language and Compiler for Application Accelerators, PLDI\u201818<ul> <li>Spatial generates Chisel code along with C++ code which can be used on a host CPU to control the execution of the accelerator on the target FPGA.</li> <li>This kind of academic papers must have a lot good ideas. But the truth is it will not be reliable because it\u2019s from academic labs.</li> </ul> </li> </ul> </li> </ul>"},{"location":"notes/paper_fpga/#integrate-with-frameworks","title":"Integrate with Frameworks","text":"<ul> <li>Map-reduce as a Programming Model for Custom Computing Machines, FCCM\u201808<ul> <li>This paper proposes a model to translate MapReduce code written in C to code that could run on FPGA and GPU. Many details are omitted, and they don\u2019t really have the compiler.</li> <li>Single-host framework, everything is in FPGA and GPU.</li> </ul> </li> <li>Axel: A Heterogeneous Cluster with FPGAs and GPUs, FPGA\u201810<ul> <li>A distributed MapReduce Framework, targets clusters with CPU, GPU, and FPGA. Mainly the idea of scheduling FPGA/GPU jobs.</li> <li>Distributed Framework.</li> </ul> </li> <li>FPMR: MapReduce Framework on FPGA, FPGA\u201810<ul> <li>A MapReduce framework on a single host\u2019s FPGA. You need to write Verilog/HLS for processing logic to hook with their framework. The framework mainly includes a data transfer controller, a simple schedule that enable certain blocks at certain time.</li> <li>Single-host framework, everything is in FPGA.</li> </ul> </li> <li>Melia: A MapReduce Framework on OpenCL-Based FPGAs, IEEE\u201816<ul> <li>Another framework, written in OpenCL, and users can use OpenCL to program as well. Similar to previous work, it\u2019s more about the framework design, not specific algorithms on FPGA.</li> <li>Single-host framework, everything is in FPGA. But they have a discussion on running on multiple FPGAs.</li> <li>Four MapReduce FPGA papers here, I believe there are more. The marriage between MapReduce and FPGA is not something hard to understand. FPGA can be viewed as another core with different capabilities. The thing is, given FPGA\u2019s reprogram-time and limited on-board memory, how to design a good scheduling algorithm and data moving/caching mechanisms. Those papers give some hints on this.</li> </ul> </li> <li>UCLA: When Apache Spark Meets FPGAs: A Case Study for Next-Generation DNA Sequencing Acceleration, HotCloud\u201816</li> <li>UCLA: Programming and Runtime Support to Blaze FPGA Accelerator Deployment at Datacenter Scale, SoCC\u201816<ul> <li>A system that hooks FPGA with Spark.</li> <li>There is a line of work that hook FPGA with big data processing framework (Spark), so the implementation of FPGA and the scale-out software can be separated. The Spark can schedule FPGA jobs to different machines, and take care of scale-out, failure handling etc. But, I personally think this line of work is really just an extension to ReconOS/FUSE/BORPH line of work. The main reason is: both these two lines of work try to integrate jobs run on CPU and jobs run on FPGA, so CPU and FPGA have an easier way to talk, or put in another way, CPU and FPGA have a better division of labor. Whether it\u2019s single-machine (like ReconOS, Melia), or distributed (like Blaze, Axel), they are essentially the same.</li> </ul> </li> <li>UCLA: Heterogeneous Datacenters: Options and Opportunities, DAC\u201816<ul> <li>Follow up work of Blaze. Nice comparison of big and wimpy cores.</li> </ul> </li> </ul>"},{"location":"notes/paper_fpga/#cloud-infrastructure","title":"Cloud Infrastructure","text":"<ul> <li>Huawei: FPGA as a Service in the Cloud</li> <li>UCLA: Customizable Computing: From Single Chip to Datacenters, IEEE\u201818</li> <li>UCLA: Accelerator-Rich Architectures: Opportunities and Progresses, DAC\u201814<ul> <li>Reminds me of OmniX. Disaggregation at a different scale.</li> <li>This paper actually targets single-machine case. But it can reflect a distributed setting.</li> </ul> </li> <li>Enabling FPGAs in the Cloud, CF\u201814<ul> <li>Paper raised four important aspects to enable FPGA in cloud: Abstraction, Sharing, Compatibility, and Security. FPGA itself requires a shell (paper calls it service logic) and being partitioned into multiple slots. Things discussed in the paper are straightforward, but worth reading. They did not solve the FPGA sharing issue, which, is solved by AmorphOS.</li> </ul> </li> <li>FPGAs in the Cloud: Booting Virtualized Hardware Accelerators with OpenStack, FCCM\u201814<ul> <li>Use OpenStack to manage FPGA resource. The FPGA is partitioned into multiple regions, each region can use PR. The FPGA shell includes: 1) basic MAC, and packet dispatcher, 2) memory controller, and segment-based partition scheme, 3) a soft processor used for runtime PR control. One very important aspect of this project is: they envision input to FPGA comes from Ethernet, which is very true nowadays. And this also makes their project quite similar to Catapult. It\u2019s a very solid paper, though the evaluation is a little bit weak. What could be added: migration, different-sized region.</li> <li>The above CF and FCCM papers are similar in the sense that they are both building SW framework and HW shell to provide a unified cloud management system. They differ in their shell design: CF one take inputs from DMA engine, which is local system DRAM, FCCM one take inputs from Ethernet. The things after DMA or MAC, are essentially similar.</li> <li>It seems all of them are using simple segment-based memory partition for user FPGA logic. What\u2019s the pros and cons of using paging here?</li> </ul> </li> <li>S1 DyRACT: A partial reconfiguration enabled accelerator and test platform, FPL\u201814</li> <li>S2 Virtualized FPGA Accelerators for Efficient Cloud Computing, CloudCom\u201815</li> <li>S3 Designing a Virtual Runtime for FPGA Accelerators in the Cloud, FPL\u201816</li> <li>S4 Virtualized Execution Runtime for FPGA Accelerators in the Cloud, IEEE Access\u201817<ul> <li>The above four papers came from the same group of folks. S1 developed a framework to use PCIe to do PR, okay. S2 is a follow-up on S1, read S2\u2019s chapter IV hardware architecture, many implementation details like internal FPGA switch, AXI stream interface. But no memory virtualization discussion. S3 is a two page short paper. S4 is the realization of S3. I was particularly interested if S4 has implemented their own virtual memory management. The answer is NO. S4 leveraged on-chip Linux, they just build a customized MMU (in the form of using BRAM to store page tables. This approach is similar to the papers listed in <code>Integrate with Virtual Memory</code>). Many things discussed in S4 have been proposed multiple times in previous cloud FPGA papers since 2014.</li> </ul> </li> <li>MS: A Reconfigurable Fabric for Accelerating Large-Scale Datacenter Services, ISCA\u201814</li> <li>MS: A Cloud-Scale Acceleration Architecture, Micro\u201816<ul> <li>Catapult is unique in its shell, which includes the Lightweight Transport Layer (LTL), and Elastic Router(ER). The cloud management part, which the paper just briefly mentioned, actually should include everything the above CF\u201814 and FCCM\u201814 have. The LTL has congestion control, packet loss detection/resend, ACK/NACK. The ER is a crossbar switch used by FPGA internal modules, which is essential to connect shell and roles.</li> <li>These two Catapult papers are simply a must read.</li> </ul> </li> <li>MS: A Configurable Cloud-Scale DNN Processor for Real-Time AI, Micro\u201818</li> <li>MS: Azure Accelerated Networking: SmartNICs in the Public Cloud, NSDI\u201818</li> <li>MS: Direct Universal Access : Making Data Center Resources Available to FPGA, NSDI\u201819<ul> <li>Catapult is just sweet, isn\u2019t it?</li> </ul> </li> <li>ASIC Clouds: Specializing the Datacenter, ISCA\u201816</li> <li>Virtualizating FPGAs in the Cloud, ASPLOS\u201820, to appear.</li> </ul>"},{"location":"notes/paper_fpga/#misc","title":"Misc","text":"<ul> <li>A Study of Pointer-Chasing Performance on Shared-Memory Processor-FPGA Systems, FPGA\u201816</li> </ul>"},{"location":"notes/paper_fpga/#applications","title":"Applications","text":""},{"location":"notes/paper_fpga/#programmable-network","title":"Programmable Network","text":"<ul> <li>MS: ClickNP: Highly Flexible and High Performance Network Processing with Reconfigurable Hardware, SIGCOMM\u201816</li> <li>MS: Multi-Path Transport for RDMA in Datacenters, NSDI\u201818</li> <li>MS: Azure Accelerated Networking: SmartNICs in the Public Cloud, NSDI\u201818</li> <li>Mellanox. NICA: An Infrastructure for Inline Acceleration of Network Applications, ATC\u201819</li> <li>The Case For In-Network Computing On Demand, EuroSys\u201819</li> <li>Fast, Scalable, and Programmable Packet Scheduler in Hardware, SIGCOMM\u201819</li> <li>HPCC: high precision congestion control, SIGCOMM\u201819</li> <li>Offloading Distributed Applications onto SmartNICs using iPipe, SIGCOMM\u201819<ul> <li>Not necessary FPGA, but SmartNICs. The actor programming model seems a good fit. There is another paper from ATC\u201819 that optimizes distributed actor runtime.</li> </ul> </li> </ul>"},{"location":"notes/paper_fpga/#database-and-sql","title":"Database and SQL","text":"<ul> <li>On-the-fly Composition of FPGA-Based SQL Query Accelerators Using A Partially Reconfigurable Module Library, 2012</li> <li>Accelerating database systems using FPGAs: A survey, FPL\u201818</li> </ul>"},{"location":"notes/paper_fpga/#storage","title":"Storage","text":"<ul> <li>Cognitive SSD: A Deep Learning Engine for In-Storage Data Retrieval, ATC\u201819</li> <li>INSIDER: Designing In-Storage Computing System for Emerging High-Performance Drive, ATC\u201819</li> <li>LightStore: Software-defined Network-attached Key-value Drives, ASPLOS\u201819</li> <li>FIDR: A Scalable Storage System for Fine-Grain Inline Data Reduction with Efficient Memory Handling, MICRO\u201819</li> <li>CIDR: A Cost-Effective In-line Data Reduction System for Terabit-per-Second Scale SSD Array, HPCA\u201819</li> </ul>"},{"location":"notes/paper_fpga/#machine-learning","title":"Machine Learning","text":"<ul> <li>TABLA: A Unified Template-based Framework for Accelerating Statistical Machine Learning, HPCA\u201816</li> <li>Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks, FPGA\u201815</li> <li>From High-Level Deep Neural Models to FPGAs, ISCA\u201816</li> <li>Deep Learning on FPGAs: Past, Present, and Future, arXiv\u201816</li> <li>Accelerating binarized neural networks: Comparison of FPGA, CPU, GPU, and ASIC, FPT\u201816</li> <li>FINN: A Framework for Fast, Scalable Binarized Neural Network Inference, FPGA\u201817</li> <li>In-Datacenter Performance Analysis of a Tensor Processing Unit, ISCA\u201817</li> <li>Accelerating Binarized Convolutional Neural Networks with Software-Programmable FPGAs, FPGA\u201817</li> <li>A Configurable Cloud-Scale DNN Processor for Real-Time AI, ISCA\u201818<ul> <li>Microsoft Project Brainware. Built on Catapult.</li> </ul> </li> <li>A Network-Centric Hardware/Algorithm Co-Design to Accelerate Distributed Training of Deep Neural Networks, MICRO\u201818</li> <li>DNNBuilder: an Automated Tool for Building High-Performance DNN Hardware Accelerators for FPGAs, ICCAD\u201818</li> <li>FA3C : FPGA-Accelerated Deep Reinforcement Learning\uff0c ASPLOS\u201919</li> <li>Cognitive SSD: A Deep Learning Engine for In-Storage Data Retrieval, ATC\u201819</li> </ul>"},{"location":"notes/paper_fpga/#graph","title":"Graph","text":"<ul> <li>A Scalable Processing-in-Memory Accelerator for Parallel Graph Processing, ISCA\u201815</li> <li>Energy Efficient Architecture for Graph Analytics Accelerators, ISCA\u201816</li> <li>Boosting the Performance of FPGA-based Graph Processor using Hybrid Memory Cube: A Case for Breadth First Search, FPGA\u201817</li> <li>FPGA-Accelerated Transactional Execution of Graph Workloads, FPGA\u201817</li> <li>An FPGA Framework for Edge-Centric Graph Processing, CF\u201818</li> </ul>"},{"location":"notes/paper_fpga/#key-value-store","title":"Key-Value Store","text":"<ul> <li>Achieving 10Gbps line-rate key-value stores with FPGAs, HotCloud\u201813</li> <li>Thin Servers with Smart Pipes: Designing SoC Accelerators for Memcached, ISCA\u201813</li> <li>An FPGA Memcached Appliance, FPGA\u201813</li> <li>Scaling out to a Single-Node 80Gbps Memcached Server with 40Terabytes of Memory, HotStorage\u201815</li> <li>KV-Direct: High-Performance In-Memory Key-Value Store with Programmable NIC, SOSP\u201817<ul> <li>This link is also useful for better understading Morning Paper</li> </ul> </li> <li>Ultra-Low-Latency and Flexible In-Memory Key-Value Store System Design on CPU-FPGA, FPT\u201818</li> </ul>"},{"location":"notes/paper_fpga/#bio","title":"Bio","text":"<ul> <li>When Apache Spark Meets FPGAs: A Case Study for Next-Generation DNA Sequencing Acceleration, HotCloud\u201816</li> <li>FPGA Accelerated INDEL Realignment in the Cloud, HPCA\u201819</li> </ul>"},{"location":"notes/paper_fpga/#consensus","title":"Consensus","text":"<ul> <li>Consensus in a Box: Inexpensive Coordination in Hardware, NSDI\u201816</li> </ul>"},{"location":"notes/paper_fpga/#video-processing","title":"Video Processing","text":"<ul> <li>Quantifying the Benefits of Dynamic Partial Reconfiguration for Embedded Vision Applications (FPL 2019)</li> <li>Time-Shared Execution of Realtime Computer Vision Pipelines by Dynamic Partial Reconfiguration (FPL 2018)</li> </ul>"},{"location":"notes/paper_fpga/#fpga-internal","title":"FPGA Internal","text":"<p>FPGA20: Highlighting Significant Contributions from 20 Years of the International Symposium on Field-Programmable Gate Arrays (1992\u20132011)</p>"},{"location":"notes/paper_fpga/#general","title":"General","text":"<ul> <li>FPGA and CPLD architectures: a tutorial, 1996</li> <li>Reconfigurable computing: a survey of systems and software, 2002</li> <li>Reconfigurable computing: architectures and design methods</li> <li>FPGA Architecture: Survey and Challenges, 2007<ul> <li>Read the first two paragraphs of each section and then come back to read all of that if needed.</li> </ul> </li> <li>RAMP: Research Accelerator For Multiple Processors, 2007</li> <li>Three Ages of FPGAs: A Retrospective on the First Thirty Years of FPGA Technology, IEEE\u201815</li> </ul>"},{"location":"notes/paper_fpga/#partial-reconfiguration","title":"Partial Reconfiguration","text":"<ul> <li>FPGA Dynamic and Partial Reconfiguration: A Survey of Architectures, Methods, and Applications, CSUR\u201818<ul> <li>Must read.</li> </ul> </li> <li>DyRACT: A partial reconfiguration enabled accelerator and test platform, FPL\u201814</li> <li>A high speed open source controller for FPGA partial reconfiguration</li> <li>Hardware context-switch methodology for dynamically partially reconfigurable systems, 2010</li> </ul>"},{"location":"notes/paper_fpga/#logical-optimization-and-technology-mapping","title":"Logical Optimization and Technology Mapping","text":"<ul> <li>FlowMap: An Optimal Technology Mapping Algorithm for Delay Optimization in Lookup-Table Based FPGA Designs, 1994</li> <li>Combinational Logic Synthesis for LUT Based Field Programmable Gate Arrays, 1996</li> <li>DAOmap: A Depth-optimal Area Optimization Mapping Algorithm for FPGA Designs, 2004</li> </ul>"},{"location":"notes/paper_fpga/#place-and-route","title":"Place and Route","text":"<ul> <li>VPR: A New Packing, Placement and Routing Tool for FPGA Research, 1997</li> <li>VTR 7.0: Next Generation Architecture and CAD System for FPGAs, 2014</li> </ul>"},{"location":"notes/paper_fpga/#rtl2fpga","title":"RTL2FPGA","text":"<ul> <li>A Case for FAME: FPGA Architecture Model Execution, 2010</li> <li>Strober: Fast and Accurate Sample-Based Energy Simulation for Arbitrary RTL, 2016</li> <li>Evaluation of RISC-V RTL with FPGA-Accelerated Simulation, 2017</li> <li>FireSim: FPGA-Accelerated Cycle-Exact Scale-Out System Simulation in the Public Cloud, 2018</li> </ul>"},{"location":"notes/paper_perf_shadows/","title":"Hiding In The Shadows","text":"Version History Date Description Jul 11, 2019 Initial draft <p>There are shadows under the sun. There are shadows in your life. There are shadows in your computer.  </p> <p>This note is about latency tolerance techniques. This note is about how to get the most out of the otherwise-wasted resource.</p>"},{"location":"notes/paper_perf_shadows/#nanoseconds","title":"Nanoseconds","text":"<p>Architecture solutions to attack nanosecond-level performance shadows that are mostly created by lower level data and instruction cache misses. OoO and SMT are the base to hide these latencies, but they fall short when ROB is full (or some other reasons). When that happens, these academic ideas come in rescue.</p>"},{"location":"notes/paper_perf_shadows/#runahead","title":"Runahead","text":"<p>Quote</p> <p>In runahead, once the processor stalls, it uses the instruction window to continue to fetch and execute operations. The goal of runahead is to generate new cache misses, thereby turning subsequent demand requests into cache hits instead of cache misses.[5]</p> <p>Papers</p> <ol> <li>Improving Data Cache Performance by Pre-executing Instructions Under a Cache Miss, ICS\u201997</li> <li>Runahead Execution: An Alternative to Very Large Instruction Windows for Out-of-order Processors, HPCA\u201903</li> <li>Efficient Runahead Execution: Power-Efficient Memory Latency Tolerance, IEEE Micro\u201906<ul> <li>Good timeline graphs show the benefit of Runahead.</li> </ul> </li> <li>Runahead Threads to Improve SMT Performance, HPCA\u201908<ul> <li>QoS control policy.</li> </ul> </li> <li>Continuous Runahead: Transparent Hardware Acceleration for Memory Intensive Workloads, MICRO\u201916<ul> <li>Nice idea to tackle the issue that runahead does not get enough time to run.</li> <li>Also has the notion of ideal runahead coverage.</li> </ul> </li> </ol> <p>Comments</p> <ul> <li>We should separate mechanism and policy.</li> <li>Runahead is the mechanism. It includes:<ul> <li>Enter runahead</li> <li>Execution in runahead context (most important thing is to maintain those INV bits and pseudo-retires)</li> <li>Exit runahead</li> </ul> </li> <li>Prefetch is one of the policy, a major one. It\u2019s the side effect of running instructions in the execution phase of runahead mode.</li> <li>QoS control is another policy. This means adding specific rules to the execution phase. More specifically: limit the core resource usage of the runahead thread, thus reduce the impact on the co-running HW thread.</li> </ul>"},{"location":"notes/paper_perf_shadows/#helper-threads-or-precomputation","title":"Helper Threads (or Precomputation)","text":"<p>Quote</p> <p>A helper thread is a stripped down version of the main thread that only includes the necessary instructions to generate memory accesses, including control flow instructions [10].</p> <p>Quote</p> <p>Precomputation uses idle thread contexts in a multithreaded architecture to improve performance of single-threaded applications. It attacks program stalls from data cache misses by pre-computing future memory accesses in available thread contexts, and prefetching these data.[1]</p> <p>Quote</p> <p>Such pre-execution threads are purely speculative, and their instructions are never committed into the main computation. Instead, the pre-execution threads run code designed to trigger cache misses. As long as the pre-execution threads execute far enough in front of the main thread, they effectively hide the latency of the cache misses so that the main thread experiences signicantly fewer memory stalls.[5]</p> <p>Papers</p> <ol> <li>Speculative Precomputation: Long-range Prefetching of Delinquent Loads, ISCA\u201801</li> <li>Dynamic Speculative Precomputation, Micro\u201801<ul> <li>Take a step further by using HW to construct the offloaded code slice automatically.</li> </ul> </li> <li>Execution-based Prediction Using Speculative Slices, ISCA\u201801</li> <li>Tolerating Memory Latency through Software-Controlled Pre-Execution in Simultaneous Multithreading Processors, ISCA\u201801<ul> <li>What\u2019s up with ISCA\u201801? This paper proposed to use software to control when to start running precomputation and when to exit. It uses compiler\u2019s help to generate those code slices, and insert special start/end instructions. On the contrast, hardware-controller precomputation relies on hints such as cache misses.</li> </ul> </li> <li>Design and Evaluation of Compiler Algorithms for PreExecution, ASPLOS\u201802<ul> <li>5.1 A Study of Source-Level Compiler Algorithms for Automatic Construction of Pre-Execution Code, TOCS\u201804</li> </ul> </li> <li>Dynamic Helper Threaded Prefetching on the Sun UltraSPARC\u00ae CMP Processor, Micro\u201805<ul> <li>The function table at helper thread seems nice and useful.</li> </ul> </li> <li>Accelerating and Adapting Precomputation Threads for Effcient Prefetching, HPCA\u201807<ul> <li>Dynamically construct precomputation code, called p-slices. They can adapt the same program differently depending on the program\u2019s data input and the underlying hardware architecture.</li> </ul> </li> <li>Inter-core Prefetching for Multicore Processors Using Migrating Helper Threads, ASPLOS\u201811<ul> <li>Pure software solution. I like the idea. But I don\u2019t think it will work for realistic applications.</li> <li>Learned <code>setcontext(), getcontext(), and swapcontext()</code>.</li> </ul> </li> <li>Bootstrapping: Using SMT Hardware to Improve Single-Thread Performance, ASPLOS\u201819</li> <li>Freeway: Maximizing MLP for slice-out-of-order execution, HPCA\u201819<ul> <li>Strictly speaking this is not in this catogory. But it is this paper   that lead me to Runahead and Helper thread topic. I was doing   something similar so those techniques caught my eye.</li> </ul> </li> </ol> <p>Comments</p> <ul> <li>The catch about precomputation is that it must create lightweight threads   that can actually proceed faster than the main thread, so that they   stay out in front.</li> <li>Other catch is: you also need to create the code slice that will   run on another core context. First of all, how is this code slice different   from the original code? The extracted code will be simplified in the sense   that it will only access memory without doing other computations.   The second question is how this code slice is extracted and then constructed?   There are many ways. You can handwrite, or use a static compiler to pre-generate   them (by using techniques in above papers), or use hardware to dynamically   generate them during runtime, or use software to dynamically generate them during runtime.   There are ways to it, but I don\u2019t think this is the core of precomputation.</li> <li>Also, same thing here, we should separate mechanism and policies.   Helper thread (or precomputation) is mainly used as a vehicle   for speculatively generating data addresses and prefetching.</li> </ul>"},{"location":"notes/paper_perf_shadows/#thread-level-speculation","title":"Thread-Level Speculation","text":"<p>Fill me in.</p>"},{"location":"notes/paper_perf_shadows/#locks","title":"Locks","text":"<p>Applying the insight of \u201cget the most out of the otherwise-wasted resource\u201d to the lock area. I will wait for Sanidhya\u2019s SOSP\u201819 paper. :-)</p>"},{"location":"notes/paper_perf_shadows/#misc","title":"Misc","text":"<ul> <li>Stretch: Balancing QoS and throughput for colocated server workloads on SMT cores (Best Paper), HPCA\u201819<ul> <li>Keyword: <code>ROB</code>, <code>Co-location QoS</code>.</li> <li>This paper tackles the perf interference when running co-running two SMT threads   on a single physical core, which is the common case in datacenters.   However co-running latency-sensitive jobs and batch jobs will   have huge impact on the perf of both.</li> <li>This paper found: \u201cLatency-sensitive workloads show little benefit   from large ROB capacities in modern server processors .. because frequent   cache misses and data-dependent computation limit both instruction   and memory-level parallelisms (ILP and MLP). In contrast, many batch   workloads benefit from a large ROB that helps unlock higher ILP and MLP.\u201d</li> <li>So they propose to have a ROB partition scheme rather than static equal   partition. Of course they also did some very extensive studies before   deciding to scale ROB. They first found shared ROB has the biggest   impact on perf interference than any other resources such as branch   predictor, cache, and so on. They further found that latency-sensitive   workload can tolerate some perf slack, which means they will not   violate their QoS even with a smaller ROB.</li> <li>Anyway, I think this is a very nice paper. Good reasoning, simple solution,   but works effectively.</li> </ul> </li> </ul>"},{"location":"notes/paper_perf_shadows/#put-it-all-together","title":"Put it all together","text":"<ul> <li>Both runahead and helper thread were proposed to do prefetch.   But they have a key difference. Runahead is invoked in the same core,   and is invoked when ROB is full (not always though). Helper thread is   invoked at another core. Besides, runahead can just fetch the   instructions and run, no need to cook another code slice. But for   helper thread, it needs to extract a code slice that will run on another core.</li> <li>I think the most important thing is to realize their insight.   In the most straightforward and plain way: they are trying to   get the most out of the otherwise-wasted resource. For example,   in runahead, they realize that with some help, the CPU is still   able to generate cache misses even if the instruction table is full.   For precomputation, obviously it is using the other idle cores.   The simple insight itself is not interesting enough, usually   where it\u2019s applied make things quite interesting.</li> </ul>"},{"location":"notes/paper_perf_shadows/#microseconds","title":"Microseconds","text":"<p>Fill me in</p>"},{"location":"notes/paper_perf_shadows/#milliseconds","title":"Milliseconds","text":"<p>Sleep. And wake me up when september ends. And this seems to be enough. ;-) This is true for OS to handle slow HDD and slow network.</p>"},{"location":"notes/proc/","title":"Special Files","text":"<ul> <li><code>/sys/devices/system/&lt;name&gt;</code><ul> <li>Creation: <code>subsys_system_register()</code>, @ drivers/base/bus.c</li> <li>Note that this subdirectory is a legacy. Newer stuffer are added into other folders inside <code>/sys</code>.</li> <li><code>/sys/devices/system/cpu/*</code>, @ drivers/base/cpu.c<ul> <li>Root Object is cpu_root_attrs. The <code>online</code> file belongs to another sub-object</li> <li>And this register_cpu() function is used to setup the directories for each cpu.</li> </ul> </li> </ul> </li> </ul> <p>Many applications use <code>/sys/devices/system/cpu/online</code> to get the number of available CPUs. And it\u2019s hard to change this behavior because it\u2019s usually encoded inside glibc. Thus, if you want to \u201chide\u201d certain CPUs from applications for some reason, you can write a kernel module that use <code>set_cpu_active(cpu, false)</code>, and then use the following small patch. (Note that using <code>set_cpu_online(cpu, false)</code> will confuse CPU idle routine and panic.) <pre><code>diff --git a/drivers/base/cpu.c b/drivers/base/cpu.c\n--- a/drivers/base/cpu.c\n+++ b/drivers/base/cpu.c\n@@ -220,7 +220,8 @@ static ssize_t show_cpus_attr(struct device *dev,\n\n /* Keep in sync with cpu_subsys_attrs */\n static struct cpu_attr cpu_attrs[] = {\n-       _CPU_ATTR(online, &amp;__cpu_online_mask),\n+       _CPU_ATTR(online, &amp;__cpu_active_mask),\n        _CPU_ATTR(possible, &amp;__cpu_possible_mask),\n        _CPU_ATTR(present, &amp;__cpu_present_mask),\n };\n</code></pre></p> <ul> <li><code>/proc/pressure</code><ul> <li>https://lwn.net/Articles/759658/</li> </ul> </li> </ul> <p>\u2013 Yizhou Shan Created: Jul 26, 2019 Last Updated: Aug 03, 2019</p>"},{"location":"notes/program_advice/","title":"Programming and Writing Advice","text":"Version History Date Description Mar 28, 2020 Started."},{"location":"notes/program_advice/#freebsd","title":"FreeBSD","text":"<p>Quote</p> <p>Source. Our ideology can be described by the following guidelines:</p> <ul> <li>Do not add new functionality unless an implementor cannot complete a real application without it.</li> <li>It is as important to decide what a system is not as to decide what it is. Do not serve all the world\u2019s needs; rather, make the system extensible so that additional needs can be met in an upwardly compatible fashion.</li> <li>The only thing worse than generalizing from one example is generalizing from no examples at all.</li> <li>If a problem is not completely understood, it is probably best to provide no solution at all.</li> <li>If you can get 90 percent of the desired effect for 10 percent of the work, use the simpler solution.</li> <li>Isolate complexity as much as possible.</li> <li>Provide mechanism, rather than policy. In particular, place user interface policy in the client\u2019s hands.</li> </ul> <p>From Scheifler &amp; Gettys: \u201cX Window System\u201d</p>"},{"location":"notes/program_advice/#prof-john-ousterhouts-favorite-sayings","title":"Prof. John Ousterhout\u2019s Favorite Sayings","text":"<p>Quote</p> <p>Source:</p> <ul> <li>The greatest performance improvement of all is when a system goes from not-working to working</li> <li>Use your intuition to ask questions, not to answer them</li> <li>The most important component of evolution is death</li> <li>Facts precede concepts</li> <li>If you don\u2019t know what the problem was, you haven\u2019t fixed it</li> <li>If it hasn\u2019t been used, it doesn\u2019t work</li> <li>The only thing worse than a problem that happens all the time is a problem that doesn\u2019t happen all the time</li> <li>The three most powerful words for building credibility are \u201cI don\u2019t know\u201d</li> <li>Coherent systems are inherently unstable</li> </ul>"},{"location":"notes/program_advice/#butler-w-lampsons-hints-for-computer-system-design","title":"Butler W. Lampson\u2019s Hints for Computer System Design","text":"<p>https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/acrobat-17.pdf</p>"},{"location":"notes/program_advice/#performance-evaluation","title":"Performance Evaluation","text":"<ul> <li>Systems Benchmarking Crimes</li> <li>Tim Harris: designing experiments for understanding performance<ul> <li>Very practical and useful suggestions.</li> </ul> </li> </ul>"},{"location":"notes/program_advice/#writing-tips","title":"Writing Tips","text":"<ul> <li>Plain Writing Act of 2010, Federal Plain Language Guidelines..</li> <li>Dash Writing Tips</li> </ul>"},{"location":"notes/resource-disaggregation-spectrum/","title":"Data Center Resource Disaggregation","text":"Version History Date Description Mar 7, 2022 Initial <p>This note discusses Resource Disaggregation\u2019s Design Spectrum.</p> <p>In our categorization, the traditional distributed systems approach is logical resource disaggregation. The newly emerged hardware resource disaggregation is physical resource disaggregation. The main difference lies in whether an indirection layer is required to achieve the conceptual resource pool view. Combined, they are two extreme design points of the resource disaggregation idea.</p> <p>All images below are from my recent defense slides. This note is part of my defense\u2019s intro.</p> <p>The full defense slide is here.</p>"},{"location":"notes/resource-disaggregation-spectrum/#intro","title":"Intro","text":"<p>Resource Disaggregation is a really general idea with a wide design spectrum that covers many designs and systems in data centers. The essense of resource disaggregation is to decouple resources so as to achieve independent resource scaling and failing. It has been applied in different granularities and to many different domains.</p> <p>The traditional resource disaggregation is usually built on top of monolithic servers using conventional distributed systems. It has been applied everywhere in data centers, just in different granularities. For example, in the classical storage disaggregation deployment, storage pools are disaggregated from compute pools; in machine learning deployment, paramemter servers are disaggregated from workers; in typical SDN deployment, control plane servers are disaggregated from data plane servers/switches. All these examples are instantiations of the resource disaggregation idea.</p> <p></p> <p>Hardware Resource Disaggregation is a super HOT research proposal that breaks the physical monolithic servers into segregated, network-attached hardware resource pools, each of which can be built, managed, and scaled independently. The disaggregated approach largely increases the management flexibility of a data center.</p> <p></p> <p>Hardware resource disaggregation is a drastic depature from the traditional computing paradigm and it calls for a top-down redesign on hardware, system software, networking, and applications.</p>"},{"location":"notes/resource-disaggregation-spectrum/#design-formula","title":"Design Formula","text":"<p>Is hardware resource disaggregation just a buzzword? Is it just another old wine in the new bottle kind of idea?</p> <p>I argue that the traditional resource disaggregation design approach using distributed systems and the newly emerged hardware resource disaggregation are not exclusive to each other and in fact can be unified within one design spectrum, with each being one end of the spectrum.</p> <p>Before we dig into the design spectrum. I want to spent a few words on the Resource Disaggregation Formula: one would take a set of system software and a set of disaggregated hardware devices or servers, then use whatever approach, to produce the same ultimate goal, which is the conceptual resource pool view. The pool can be a CPU pool, a memory pool, a Parameter Server pool. Basically every standalone \u201cconceptual\u201d resource. Think about the examples we mentioned earlier, all systems follow this formula, just produce different \u201cresource pools\u201d. </p>"},{"location":"notes/resource-disaggregation-spectrum/#design-spectrum","title":"Design Spectrum","text":"<p>Now, the categorization.</p> <p>On the far left, we have the logical resource disaggregation, which represents the traditional resource disaggregation model. This model builds on top of monolithic servers. A server would contribute part or all its resource to a certain resource pool. A server can be a part of multiple pools. Usually, an indirection layer at each server is required to achieve this goal. Essentially, the ultimate resource pool just logically maps back to the actual servers. This is the common-wisdon on building distributed systems.</p> <p>On the far right, we have the physical resource disaggregation, which represents the emerging hardware resource disaggregation model. This model builds on top of disaggregated hardware devices. Usually, no indirection layer is required. So essentially, the ultimate resource pool could physically maps back to the actual physical devices.</p> <p>In the middle, we have the Hybrid Disaggregation which has the best of both worlds. It has both normal servers and disaggregated devices.</p> <p>The following image shows the design spectrum. </p>"},{"location":"notes/resource-disaggregation-spectrum/#my-work","title":"My Work","text":"<p>So far, my work in this space has covered all grounds. (DUH! I defined the specturm to fit my work! :-) )</p> <p></p>"},{"location":"notes/rmap/","title":"Linux Reverse Mapping (<code>rmap</code>)","text":"Version History Date Description Jan 6, 2021 minor update Jun 16, 2019 add sanitizers section <p>Reserve map, or rmap, is a linux data structure used by the memory-management system. It is a reverse mapping from the physical page back to the PTEs. More specically, from the <code>struct page</code> back to the list of PTEs that point to the page.</p> <p>The <code>rmap</code> data structure is used heavily by memory related system calls, such as <code>mmap</code>, <code>munmap</code>, <code>madvise</code>, <code>brk</code>, and so on. And it is used by both anonmouys and file-backed pages. With the help of <code>rmap</code>, kernel is able to identify all the PTEs that point a certain page. Therefore, when kernel is trying to, say evict the page, it will be able to clear all the PTEs point to the page.</p> <p>The <code>rmap</code> data structured is used by both user and kernel pages. It makes the tracking of page sharing easier.</p> <p>The <code>rmap</code> concept seems simple and straightforward to implement, but it is very challenging to design a space- and performance-efficient one. The linux kernel uses quite a lot of tricks to optimize the <code>rmap</code>.</p> <p>You will understand how linux rmap works if you read the following articles carefully:</p> <ul> <li>PDF: Object-based Reverse Mapping</li> <li>LWN: Virtual Memory II: the return of objrmap</li> <li>LWN: The object-based reverse-mapping VM</li> </ul> <p> </p>"},{"location":"notes/rmap/#old-notes","title":"Old Notes","text":"<p>I implemente the basic PTE-chain based rmap for LegoOS. I can see the downsides of it. I tried to understand the linux rmap before, somehow gave up because I couldn\u2019t fully understand one thing: for a page that is shared among multiple processes\u2019 VMAs, the source code suggests it will always have same offset from the beginning of all VMA (i.e., <code>vm_start</code>). But does it actually works like this for ALL cases? I just think it\u2019s possible that a page is mapped by an VMA which has a slightly different starting address.</p> <p>I still have doubt about it. But after accepting this assumption, it\u2019s just easy to understand. I will check later on.</p> <p>The code suggests:</p> <ul> <li>The offset of a page is saved in <code>page-&gt;index</code>.</li> <li>For anonmouys pages, the <code>page-&gt;index</code> is saved by page_set_anon_rmap().</li> <li>When doing rmap walk over multiple VMAs:</li> <li>For anon: <code>unsigned long address = vma_address(page, vma);</code></li> <li>For file: <code>unsigned long address = vma_address(page, vma);</code></li> <li>And  <code>vma_address()</code> is basically <code>page-&gt;index</code></li> </ul> <pre><code>    static inline unsigned long\n    __vma_address(struct page *page, struct vm_area_struct *vma)\n    {\n        pgoff_t pgoff = page_to_pgoff(page);\n        return vma-&gt;vm_start + ((pgoff - vma-&gt;vm_pgoff) &lt;&lt; PAGE_SHIFT);\n    }\n</code></pre> <p>Compared to basic PTE-chain based solution, object-based rmap:</p> <p>The real benefit</p> <ul> <li>During page fault, we only need to set <code>page-&gt;mapping</code> to point to <code>struct anon_vma</code>,   rather than allocating a new structure and insert.</li> </ul> <p>The downside</p> <ul> <li>During rmap walk, we need extra computation to walk each VMA\u2019s page table   to make sure that the page is actually mapped within this specific VMA.</li> </ul> <p>Adding <code>struct anon_vma</code> is really similar to the idea of reusing <code>address_space</code>, i.e., having a data structure trampoline.</p> <p>Some more boring details:</p> <ul> <li>All pages within a single VMA share just one <code>anon_vma</code>.   <code>vma-&gt;anon_vma</code> indicates if a VMA has attached or note.   Related function is <code>anon_vma_prepare()</code> within <code>do_anonymous_fault()</code> link.</li> </ul>"},{"location":"notes/ssd/","title":"SSD 101","text":"Version History Date Description Nov 20, 2022 polish a bit, just a bit. Nov 15, 2022 Initial <p>Grab-and-go SSD 101 bullet points for newbies.</p>"},{"location":"notes/ssd/#basics","title":"Basics","text":""},{"location":"notes/ssd/#cell-bits-slc-mlc-tlc","title":"Cell Bits (SLC, MLC, TLC)","text":"<ul> <li>A cell can have 1-bit, 2-bit, 3-bit, or 4-bit saved. There is a trade-off among these. SLC has lower-latency and longer lifespan, but is more expensive. Enterprise &amp; Datacenter may prefer SLC for its longer lifespan cena better perf. Consumers may prefer MLC/TLC/QLC.</li> <li>A flash cell is a floating gate or a charge trap transistor to represent data by storing certain amount of charges, which determines the threshold voltage (Vth) of the cell.</li> <li>Reads<ul> <li>How Flash Memory Works | HowStuffWorks</li> <li>Understanding Flash: SLC, MLC and TLC | flashdba </li> <li>Sentinel Cells Enabled Fast Read for NAND Flash HotStorage\u201919 </li> </ul> </li> </ul>"},{"location":"notes/ssd/#parallelism-and-packaging","title":"Parallelism and Packaging","text":"<ul> <li>A NAND package is organized into a hierarchy of dies,  planes,  blocks, and pages.</li> <li>There may be one or several dies within a single physical package.</li> <li>A die allows a single I/O command to be executed at a time.</li> <li>A plane allows similar flash commands to be executed in parallel within a die.</li> <li>A page is usally 2K, 4K, etc. A block has thousands of pages, could be couple MBs.</li> </ul>"},{"location":"notes/ssd/#nand-has-3-programming-constraints","title":"NAND has 3 programming constraints","text":"<ol> <li>A write command must always contain enough data to program one (or several) full flash page(s)</li> <li>Writes must be sequential within a block</li> <li>An erase must be performed before a page within a block can be (re)written. The number of program/erase (PE) cycles is limited</li> </ol>"},{"location":"notes/ssd/#ftl-flash-translation-layer","title":"FTL Flash Translation Layer","text":"<ul> <li>For historical reasons, the SSDs first appeared with block interfaces.</li> <li>But this block interface conflicts with the underlying NAND flash addressing model.</li> <li>Hence, a FTL layer is introduced to bridge this gap.</li> <li>This abstraction stays.</li> <li>But this abstraction has many downsides, especially considering NAND flash\u2019s 3 fundamental programming constaints. Many background tasks are needed such as GC. It turns out those activities are the main culprit of SSD performance degradation under intensive workload.</li> <li>Why does SSD only support block-level erase rather than page-level erase?<ul> <li>Per-page FTL costs more memory than per-block FTL.</li> <li>The electricity/wires required are also less, I guess.</li> </ul> </li> <li>Reads<ul> <li>The ZNS ATC paper has an excellent historical pespective.</li> <li>Design Tradeoffs for SSD Performance, ATC\u201808</li> <li>http://www.csc.lsu.edu/~fchen/publications/papers/hpca11.pdf </li> </ul> </li> </ul>"},{"location":"notes/ssd/#garbage-collection-gc","title":"Garbage Collection (GC)","text":"<ul> <li>Why GC? Because SSD cells cannot be overwritten once programmed, it must be erased before it can be written again. Every SSD write would write into another block\u2019s page other than the one you originally read data from. The original page is marked as \u201cStale\u201d subsequently. It is apparent that many pages/blocks become stale gradually, and if no action is taken, the SSD will run out of space. GC mostly runs in the background to recycle such blocks (NOTE: erase happens in block-level granularity). If GC fails to catch up, foreground performance will be bottlenecked by Erase.</li> </ul>"},{"location":"notes/ssd/#write-amplification-factor","title":"Write Amplification Factor","text":"<ul> <li>The amount of data written by the SSD controller into the NAND flash compared the amount of data written from the host OS.</li> <li>The larger the WA, the faster the SSD ages and the worse performance.</li> </ul>"},{"location":"notes/ssd/#trim","title":"TRIM","text":"<ul> <li>Once you write something into an SSD block, SSD has no way to know whether a block is freed from FS/OS\u2019s perspective. During GC, SSD would still move such \u201cinvalid\u201d blocks around to make space. This is wasted effort.</li> <li>The TRIM command allows OS/FS to notify SSD that certain blocks are freed, hence SSD can erase them and no longer need to maintain them. It is a simple co-design.</li> </ul>"},{"location":"notes/ssd/#over-provisioning-op","title":"Over-Provisioning (OP)","text":"<ul> <li>I saw: OP 10-15% for normal light workload. OP 25% for write-intensive workloads. Not confirmed</li> <li>OP basically allows you to absorb more transient traffic and allows FTL to balance writes across more blocks hence prolong the overall lifespan</li> </ul>"},{"location":"notes/ssd/#wear-leveling","title":"Wear  Leveling","text":"<ul> <li>Wear = Last \u6301\u4e45</li> <li>Leveling = \u6c34\u5e73</li> <li>FTL controller tries to balance the number of P/E cycles made to all SSD blocks, so that most of them age at the same pace. </li> </ul>"},{"location":"notes/ssd/#queue-depth","title":"Queue Depth","text":"<ul> <li>TODO</li> </ul> <p>NVMe Namespaces</p> <ul> <li>a namespace is a collection of logical block addresses (LBA) accessible to host software. A namespace ID (NSID) is an identifier used by a controller to provide access to a namespace.</li> <li>There are many reasons why host software would want to break up an NVMe SSD into multiple namespaces: for logical isolation, multi-tenancy, security isolation (encryption per namespace), write protecting a namespace for recovery purposes, overprovisioning to improve write performance and endurance and so on.</li> <li>Namespaces =&gt; Zoned Namespaces. Its not a huge leap. The ZNS SSD is much simplified.</li> </ul>"},{"location":"notes/ssd/#seq-vs-random-ssd-writes","title":"Seq v.s. Random SSD Writes","text":"<ul> <li>From the FTL\u2019s point of view, seq/random NVMe accesses both translate to random blocks accesses.   As you know, it\u2019s an append-only program in SSD with no write-in-place.</li> <li>Whether it is random or sequential, it usually shows during the background operations (i.e. GC).   When more blocks within the Superblock get trimmed simultaneously   (which means the host file size is relatively big or you have an SW to arrange a similar type of data as a group),   this is considered sequential.   If a few blocks are being trimmed sporadically in the Superblock (which means the host is dealing with small files), then it is considered a random behavior, which brings up the WAF since more LBAs need to get rotated during GC or WL. The performance difference between random and sequential is pretty much coming from these background activities. In addition, if the OP size is small, it gets worse.  </li> </ul>"},{"location":"notes/ssd/#open-channel-ssd","title":"Open Channel SSD","text":"<ul> <li>Open-Channel SSDs allow host and SSD to collaborate through a set of contiguous LBA chunks</li> <li>This eliminates in-device garbage collection overhead and reduces the cost of media over-provisioning and DRAM.</li> <li>With OCSSDs, the host is responsible for data placement. This includes underlying media reliability management such as wear-leveling, and specific media failure characteristics.</li> <li>This has the potential to improve SSD performance and media lifetime over_ Stream SSDs_, but the host must manage differences across SSD implementations to guarantee durability, making the interface hard to adopt and requiring continual software upkeep.</li> <li>Reads<ul> <li>ZNS: Avoiding the Block Interface Tax for Flash-based SSDs, ATC\u201821</li> <li>https://openchannelssd.readthedocs.io/en/latest/ </li> </ul> </li> </ul>"},{"location":"notes/ssd/#zoned-namespace-zns","title":"Zoned Namespace (ZNS)","text":"<ul> <li>ZNS: Avoiding the Block Interface Tax for Flash-based SSDs, ATC\u201821 &amp; slide</li> <li>The SSD is partitioned into a set of zones.</li> <li>Each zone represents a region of the logical address space of the SSD that can be read arbitrarily but must be written sequentially, and to enable new writes, must be explicitly reset.</li> <li>Compared to OpenChannel: OC is shifting all management responsibilities to the host, which is burdensome to software. ZNS is different, ZNS disallows random writes but the SSD controller still needs to expose the Zone abstraction and manages the Zone to underlying block/page mapping. The benefit is that SSD can now do coarse-grained mapping. The host does fine-grained mapping and GC. </li> <li>The SSD controller is simpler in response to ZNS. Check The ZNS paper for the HW&amp;SW changes</li> <li>This implies that write amplification on the device is eliminated, which eliminates the need for capacity over-provisioning</li> </ul>"},{"location":"notes/ssd/#flexible-data-placement-fdp-vs-zns","title":"Flexible Data Placement (FDP) v.s. ZNS","text":"<ul> <li>https://nvmexpress.org/wp-content/uploads/Hyperscale-Innovation-Flexible-Data-Placement-Mode-FDP.pdf </li> <li>https://www.youtube.com/watch?v=R0GHuKwi3Fc </li> <li>https://www.youtube.com/watch?v=ZEISXHcNmSk </li> </ul>"},{"location":"notes/ssd/#aws-nitro-ssd","title":"AWS Nitro SSD","text":"<p>AWS re:Invent 2021 introduced their AWS Nitro SSD. There is only limited information about it.</p> <ul> <li>They onload part of the traditional SSD FTL to a Nitro chip. Which parts are onloaded? I think it should be modules related to GC, wear-leveling etc. </li> <li>Their approach is different from the ZNS/FDP approach although they are doing some sort of data placement in the onloaded FTL.</li> <li>They\u2019ve been boasting about their SW upgrades (instead of HW) with nearly zero downtime.</li> <li>End to End control requires us to break the strict abstraction/protocol boundaries. And in the SSD world, the FTL is the layer guarding the underlying flash. E2E opt should break this boundary, but the question is how much and to what extent. Following this principle, t does not make sense for them to onload the entire FTL to the Nitro SSD - some part of it for E2E opt should be sufficient (the parts like GC, like wear-leveling, i presume). This approach is similar to one taken by Google Aquila. They break the strict protocol boundaries among the network\u2019s physical/link/net/transport, allowing the transport to directly instruct link layer packets. And by breaking the protocol boundaries, Google Aquila achieves stable tail latency</li> </ul>"},{"location":"notes/ssd/#cxl-ssd-and-smart-ssd","title":"CXL SSD and Smart SSD","text":"<ul> <li>Samsung released their CXL SSD on Aug 2022. From the architecture diagram, we can see that the SSD supports both CXL.io for LBA access and CXL.mem for load/store.</li> <li>Samsung also partered with Xilinx to produce SmartSSD, bringing an FPGA into their SSD. The news show the FPGA is used for NDP, encryption etc. Makes sense for them to produce such a combined technology. But noted, this still exposes an traditional NVMe interface, no deep co-design with cloud workloads. </li> </ul>"},{"location":"notes/ssd/#readings","title":"Readings","text":"<ul> <li>This is my starting point. This is a 6-blog series and contains almost every detail we\u2019d care about. I recommend reading this. Coding for SSDs \u2013 Part 6: A Summary \u2013 What every programmer should know about solid-state drives </li> <li>Many recommend this paper as the one which proposed the log-based remapping mechanism. A Reconfigurable FTL (Flash Translation Layer) Architecture for NAND Flash-Based Applications </li> <li>Classical reads recommended by everyone<ul> <li>Design Tradeoffs for SSD Performance, ATC\u201808</li> <li>http://www.csc.lsu.edu/~fchen/publications/papers/hpca11.pdf </li> <li>WiscKey: Separating Keys from Values in SSD-conscious Storage, FAST\u201816 </li> </ul> </li> <li>Jian Huang\u2019s paper 1 &amp; 2 </li> </ul>"},{"location":"notes/sysml/","title":"System for ML","text":"Version History Date Description Jul 7, 2021 new <p>I\u2019m learning SysML and DNN, from the very beginning. As always, I will document and share my learning process. Let me know if you have reading recommendations, always welcomed!</p> <p>I mostly focus on the system aspects, in particular, how to design efficient large-scale machine learning frameworks. I care about operating system, network, storage, new hardware, and any other system related stuff. ML workload has its unique traits.</p>"},{"location":"notes/trace/","title":"Linux Tracing","text":"Version History Date Description Jan 18, 2021 Minor update Sep 6, 2020 Add more eBPF Jun 10, 2019 Initial version <p>This blog tries to explain how various linux tracers work, especially their core low-level mechanisms and relationships with each other.</p>"},{"location":"notes/trace/#intro","title":"Intro","text":"<p>In Linux, we have:</p> <ul> <li>ftrace</li> <li>kprobe</li> <li>uprobe</li> <li>perf_event</li> <li>tracepoints</li> <li>eBPF</li> </ul> <p>For all these tools, we can think this way:</p> <ul> <li>Tracing needs two parts, <code>1)</code> Mechanims to get data and do callback. This means we need a way to     let our tracing/profiling code got invoked on a running system. This can be static     or dynamic. Static means we added our tracing code to source code, like tracepoints.     Dynamic means we added our tracing code when system is running, like ftrace and kprobe.     <code>2)</code> Do our stuff within callback. All of them provide some sort of handling. But eBPF is the     most extensive one.</li> <li>For example, <code>ftrace</code>, <code>kprobe</code>, and <code>perf_event</code> include the callback facilities,     although they are not just limited to this.     <code>ftrace</code> has the <code>call mount</code> way to do callback on every single function invocation.     <code>kprobe</code> dynamically patch instructions and to do callback within exception handlers.     <code>perf_event</code> can let CPU fire NMI interrupt. Those are all mechanisms to catch perf data.</li> <li>In all, ftrace, kprobe, uprobe, perf_event, tracepoints all have mechanisms to get data and do callback.     ftrace is not programmable by normal users, it only prints the info.     kprobe allows us to attach customized pre-/post-handlers.     perf_event is not programmable, it only reports numbers.     Unlike all above subsystems, eBPF itself cannot intercept any programs,     but it can be attached to any of the above probes and run customized programs. That\u2019s why eBPF looks so versatile!</li> </ul> <p>The BPF Performance Tools book section 2 also takes a deep dive into this topic, and it links all subsystems together with a bit of history as well. Also see the blog from Julia: Linux tracing systems &amp; how they fit together.</p>"},{"location":"notes/trace/#ftrace","title":"<code>ftrace</code>","text":"<ul> <li>Mechanism<ul> <li>For each un-inlined function, gcc inserts a <code>call mcount</code>, or a <code>call fentry</code> instruction at the very beginning. This means whenever a function is called, the <code>mcount()</code> or the <code>fentry()</code> callback will be invoked.</li> <li>Having these <code>call</code> instructions introduce a lot overheads. So by default kernel replace <code>call</code> with <code>nop</code>. Only after we <code>echo something &gt; setup_filter_functions</code> will the ftrace code replace <code>nop</code> with <code>call</code>. Do note, Linux uses the linker magic again here, check Steven\u2019s slides.</li> <li>You can do a <code>objdump vmlinux -d</code>, and able to see the following instructions for almost all functions: <code>callq  ffffffff81a01560 &lt;__fentry__&gt;</code>.</li> <li>x86 related code: <code>arch/x86/kernel/ftrace_64.S</code>, <code>arch/x86/kernel/ftrace.c</code></li> <li>Questions: it seems we can know when a function got called by using fentry, but how can we know the function has returned? The trick is: the returning address is pushed to stack when a function got called. So ftrace, again, can replace that return address, so it can catch the exit time, and calculate the latency of a function. Neat!!</li> </ul> </li> <li>Resources<ul> <li>ftrace internal from Steven</li> </ul> </li> <li>Usage<ul> <li><code>Files under /sys/kernel/debug/tracing/*</code></li> <li><code>perf help ftrace</code></li> </ul> </li> </ul>"},{"location":"notes/trace/#kprobe","title":"<code>kprobe</code>","text":"<ul> <li>Mechanism<ul> <li>Kprobe replaces the original assembly instruction with an <code>int3</code> trap instruction.   So when we ran into the PC of the original instruction, an int3 CPU exception will happen.   Within <code>do_in3()</code>, kernel will callback to core kprobe layer to do <code>pre-handler</code>.   After singlestep, CPU have debug exception. Kernel walks into <code>do_debug()</code>,   where kprobe run <code>post-handler</code>.</li> <li>Kprobe is powerful, because it\u2019s able to trace almost everything at instruction level.</li> <li>Kprobe can NOT touch things inside <code>entry.S</code>. It needs a valid <code>pt_regs</code> to operate.</li> </ul> </li> <li>Resources<ul> <li>An introduction to kprobes (LWN)</li> </ul> </li> </ul>"},{"location":"notes/trace/#ebpf","title":"<code>eBPF</code>","text":"<ul> <li>Mechanism<ul> <li>I think one of the most important things is to understand what\u2019s the relationship between eBPF and the others.</li> <li>Part I: Hook. eBPF attach its program to kprobe/uprobe/ftrace/perf_event. You can think eBPF of a generic callback layer for kprobe/uprobe/ftrace/perf_event. It\u2019s essentially the second part of tracing we mentioned above. (see <code>include/uapi/linux/bpf.h</code>, you can find <code>BPF_PROG_TYPE_KPROBE</code>, <code>BPF_PROG_TYPE_PERF_EVENT</code>)</li> <li>Part II: Run. eBPF runs user supplied programs when the above hooks are invoked. eBPF is event-driven. </li> </ul> </li> <li>Usually as a user, we do not need to write and load eBPF programs directly. That process is quite intense,   you need to compile programs into eBPF bytecode, and then use eBPF SYSCALL to load into kernel.   Quite a lot higher-level frameworks have been introduced. For example, bcc a layer on top of raw eBPF   and smooth the process. bpftrace is even a layer higher than bcc, where users can write scripts to control eBPF.   There are more frameworks on this space. Once you understand how it works below, it is not hard to understand   and use high-level frameworks.</li> <li>Resources<ul> <li>Brendan D. Gregg Blog</li> <li>Github: Awesome-eBPF</li> <li>Cilium: BPF and XDP Reference Guide</li> <li>Blog: An eBPF overview</li> <li>bcc</li> <li>bpftrace</li> </ul> </li> </ul>"},{"location":"notes/trace/#perf","title":"<code>perf</code>","text":"<ul> <li>perf tool is simply amazing. It not only use CPU PMU, but also integrated with ftrace/kprobe/eBPF.</li> <li>perf is a tool to present data, but also a tool to collect data.</li> <li>Good references<ul> <li>http://www.brendangregg.com/perf.html</li> <li>https://developers.redhat.com/blog/2019/04/23/how-to-use-the-linux-perf-tool-to-count-software-events/</li> <li>https://opensource.com/article/18/7/fun-perf-and-python</li> </ul> </li> </ul> <p>Trace in real time:</p> <p>Print the number of page faults happen in every one second: <pre><code>perf stat -e \"page-faults\" -I 1000 -a -- sleep 10\n</code></pre></p> <p>Print the numberf of <code>mmap</code> syscall happen in every one second: <pre><code>perf stat -e \"syscalls:sys_enter_mmap\" -I 1000 -a -- sleep 10\n</code></pre></p> <p>Dynamically trace kernel functions: <pre><code>perf probe --add do_anonymous_page\nperf stat -I 5000 -e \"page-faults,probe:do_anonymous_page\" -- sleep 10\nperf probe --del=probe:do_anonymous_page\n</code></pre></p>"},{"location":"notes/trace/#references","title":"References","text":"<p>I have built the LegoOS profilers, and profile points before.</p> <p>Kernel maintains a top-level trace index file here.</p>"},{"location":"notes/userfaultfd/","title":"Linux Userfaultfd","text":"Version History Date Description Jan 6, 2021 Minor update Jun 4, 2019 Initial version"},{"location":"notes/userfaultfd/#code-study","title":"Code Study","text":"<p>(Notes based on linux 5.2-rc3)</p> <ul> <li>Code Layout<ul> <li>Major file: <code>fs/userfaultfd.c</code>, which has all the functions and callbacks.</li> <li>Callers spread across: <code>mm/memory.c</code>, <code>mm/mremap.c</code>, <code>mm/mmap.c</code>, and some others.</li> <li>The userfaultfd code is not that hard to understand if you already know how waitqueue etc work. It\u2019s built center around the <code>file_ops</code>, and couple callbacks for mm.</li> </ul> </li> <li><code>handle_userfault()</code>, called by <code>mm/memory.c</code>:<ul> <li>Userfaultfd callback only happens for anonymous pgfault</li> <li>Userfaultfd skip all the LRU, rmap, cgroup</li> <li>Userfaultfd does not use the shared global zero page</li> </ul> </li> <li><code>userfaultfd_unmap_prep(), userfaultfd_unmap_complete()</code>, called by <code>mm/mmap.c</code>, and <code>mm/mremap.c</code>:<ul> <li>Userfaultfd got notified if there are remap and unmap</li> <li>Userfaultfd deliver events via <code>userfaultfd_event_wait_completion()</code></li> <li>I found code in mmap.c and mremap.c is NOT skipping rmap/lru code. Since userfaultfd related pages don\u2019t have these setup during pgfault, I think those rmap/lru cleanup code will notice this and handle it well. In conclusion, userfault skip the expansive rmap/lru setup/teardown.</li> </ul> </li> </ul>"},{"location":"notes/userfaultfd/#why-userfaultfd","title":"Why userfaultfd?","text":"<p>It was at first developed to enhance VM migration: after migration, the destination QEMU can handle pgfault and bring pages from remote via network.</p> <p>Some databases also use it to have customized feature: http://tech.adroll.com/blog/data/2016/11/29/traildb-mmap-s3.html. Some academic papers are also using it to do customized processing in user space (e.g., remote regions). But I don\u2019t think this is going to be practical for performance-critical systems.</p> <p>My thought? The use case is very similar to what we did in Hotpot: get the faulting user address, and fetch it from remote. Due to kernel limitations and security constraints, the userfaultfd has to go through many layers and multiple kernel/user crossing. It would be interesting to inject <code>eBPF code</code> from user to kernel to handle pgfault (any research value?)</p>"},{"location":"notes/virt/","title":"Modern Virtualization Technology","text":"Version History Date Description Jul 17, 2022 Update deliverables Nov 19, 2021 Add slides Nov 19, 2021 Add slides Jun 22, 2021 add steps and bare-metal virt Dec 31, 2020 minor update Feb 4, 2020 Add VFIO stuff Jan 26, 2020 Minor adjustment Jan 25, 2020 Initial Document"},{"location":"notes/virt/#deliverables","title":"Deliverables","text":"<p>I have created two documents about virtualization. Hope they will be useful to you.</p> <ol> <li>Knowledge - Virtualization<ul> <li>List of resources about virtualization</li> <li>Light QEMU /KVM code study</li> <li>IO virtualization such as QEMU device emulation, virtio, IOMMU, etc.</li> </ul> </li> <li>Introduction of Cloud Virtualization Cards<ul> <li>A gentle introduction to cloud virtualization cards</li> <li>E.g., AWS Nitro, NVIDIA BlueField DPU, Microsoft FPGA</li> </ul> </li> </ol>"},{"location":"notes/virt/#introduction","title":"Introduction","text":"<p>This blog tries to cover a short history on virtualization, the practices used by cloud vendors, the specialized virtualization cards (e.g., AWS Nitro), and some detailed notes on QEMU/KVM.</p> <p>I started this doc when I was trying to understand how virtualization actually works. I was just reading QEMU/KVM and taking notes, but I end up exploring more.</p> <p>Favorite quote about QEMU (in fact, about virtualization in general):</p> <p>Quote</p> <p>And at the end of the day, all virtualization really means is running a particular set of assembly instructions (the guest OS) to manipulate locations within a giant memory map for causing a particular set of side effects, where QEMU is just a user-space application providing a memory map and mimicking the same side effects you would get when executing those guest instructions on the appropriate bare metal hardware</p> <p>Also check out Awesome-Virtualization.</p>"},{"location":"notes/virt/#a-short-history-of-virtualization","title":"A Short History of Virtualization","text":"<ol> <li>Software-based Virtualization. This is where VMware started. No hardware support but just smart software tricks. You should read their papers.</li> <li>Para-virtualization. This is what Xen invented. They changed the guest OS for a better emulation. No hardware support still. But the guest OS is changed.</li> <li>Hardware-assited Virtualization. This is what AMD and Intel Vt-d + IOMMU for. The CPU would support virtualization mode and non-virtualization mode (in x86, each mode has Ring 0-3). However, the hardware change alone cannot work. They must work a virtual machine monitor for at least device emulation and other things. This is where KVM and QEMU came in. KVM enables Linux to use those CPU features and turns Linux into a type-2 hypervisor. Userspace QEMU, acting as a VMM, helps setup KVM and emulates devices (QEMU can also do passthrough via VFIO).</li> <li>Offload virtualization to dedicated hardware. This is what big cloud vendors are doing. For example, AWS Nitro cards, Mirosoft FPGA based SmartNIC cards. Emulation is costly. Especially for I/O data path. This problem got worse since hardware is faster and faster (e.g., 100G networking). So rather than relying on QEMU (or vendor kernel) to emulate storage/network/misc devices, these vendors build customized cards that would handle the \u201cdevice emulation\u201d part in hardware! Other than that, vendors offload quite a lot hypervisor functionalaties as well. E.g., Microsoft offload OpenVSwitch alike modules to their FPGA (called GFT in the NSDI\u201818 paper). Guest VMs, of course, are not aware any of these. They see the same MMIO spaces. This approach greatly saves host CPU usage, hence reduces Datacenter Virtualization Tax.</li> <li>Bare-metal Virtualization. Going back to where we started! Even with those great virtulization cards, the CPU still has virtualization modes enabled, and this has a cost! In particular, the 2-level page table (EPT) is still in play and guest VMs will exit on certain instructions (e.g., CPUID). All these take a toll on performance even if the VM does no I/O. Since vendors usually have 1-to-1 pCPU and vCPU mapping, this virtualization overhead is simply annoying and should be avoided. Hence bare-metal virtualization, as in no hypervisors and no virtualization modes, yet we are still able to pack untrusted tenant VMs on one physical machine. Isn\u2019t this amazing?</li> </ol>"},{"location":"notes/virt/#details","title":"Details","text":"<p>Images below come from this slide I made: Slides on Cloud Virtualization Cards.</p>"},{"location":"notes/virt/#kvm-and-qemufirecraker-workflow","title":"KVM and QEMU/Firecraker Workflow","text":"<p>The following image shows the typical workflow when a VM tries to access I/O devices. It will VM exit to the KVM module, which then dispatch (essentially return the ioctl call) the events to the userspace hypervisor (e.g., QEMU, Firecracker). Inside those hypervisors, there would be many implementation choices. Say the VM is tring to send out a packet via the emualted NIC, QEMU at this point will send out that packet using normal sockets (via host Linux).</p> <p>This is the basic flow: VM -&gt; KVM -&gt; QEMU/Firecracker -&gt; host Linux. Internally, it could have many variantions.</p> <p>The green line represents SR-IOV enabled passthrough path. The VM can skip all hypervisor modules. SR-IOV is an all-or-nothing solution, so, once enabled, a cloud vendor / sysadmin has no way to control VM\u2019s usage on I/O devices.</p> <p></p>"},{"location":"notes/virt/#cloud-vendors-reserve-cores-to-run-hypervisor","title":"Cloud Vendors Reserve Cores to Run Hypervisor","text":"<p>Vendors would reserve cores to run the hypervisor. For several important reasons. First, they want to have separate processing provisioning. Second, to reduce switches on user core. This is a common practice for some cloud vendors. But they try to move away from it by using speciazed hardware and save the cores for users.</p> <p></p>"},{"location":"notes/virt/#modern-virtualization-hardware","title":"Modern Virtualization Hardware","text":"<p>Cloud vendors have been using specialized virtualization cards to speed up virtualization and to reduce datacenter infrastructue tax. Those cards are particularly useful for high-speed I/O devices (recall the workflow we presented earlier, it has huge perf cost). Examples include AWS Nitro cards, Microsoft FPGA based SmartNIC cards (NSDI\u201818). You can use NVIDIA DPU or Intel IPU to build a similar one as well.</p> <p>Those cards, essentially move the hypervisor modules into the hardware. At a high-level, they are \u201cSR-IOV + Hardware-based QEMU\u201d.</p> <p></p> <p>For storage + NIC, they can have two discrete cards or a unified one. The latter avoids the PCIe crossing. You can have NVMe-over-Fabric really easily.</p> <p></p>"},{"location":"notes/virt/#knowledge-virtualization","title":"Knowledge - Virtualization","text":"<p>Below is the note I took when I was reading QEMU/KVM source code. The questions I\u2019ve focused on are:</p> <ul> <li>1) how QEMU emulates all the devices.</li> <li>2) how KVM uses CPU features to switch between VMs, catch faults, return to QEMU etc.</li> <li>3) how KVM and QEMU work together.</li> <li>4) how virto works and how device-passthrough works (via VFIO).</li> <li> <p>5) Finally, if I want to write a new virtual machine monitor like QEMU, what should I build. Several recent projects (e.g., rust-vmm, firecracker) have hints on this.</p> </li> <li> <p>Google Doc Version</p> </li> <li>PDF Version</li> </ul>"},{"location":"notes/xperf/","title":"x86 Ring Switch Overhead (Page Fault version)","text":"Version History Date Description Feb 2, 2020 Move github content to here Aug 7, 2019 Initial draft <p>This page describes the mechanisms to measure the pure x86 ring switch overhead, i.e., from ring 3 to ring 0 and back.</p> <p>It is not straightforward to measure this in Linux kernel. Because when a user program traps from user space to kernel space, kernel will first run some assembly instructions to save the registers and load some new ones for kernel usage (i.e., syscall,  common IDT,  and some directly registered). And only then, the kernel will run the C code. Thus if we place the measurement code in the first C function that will run (e.g., <code>do_syscall_64</code>), it will be much larger than the actual ring switch overhead.</p> <p>My proposed solutions hacks the <code>entry_64.S</code> and tries to save a timestamp as soon as possible. The first version centers around page fault handler, whose trapping mechanism is different from syscalls. However, I think it could be easily ported. The code is here.</p> <p>Takeaways:</p> <ul> <li>It ain\u2019t cheap! It usually take ~400 cycles to trap from user to kernel space.</li> <li>User-to-kernel crossing is more expansive than kernel-to-user crossing!</li> <li>Virtilization adds more overhead</li> </ul> <p>The following content is adopted from the Github repo.</p>"},{"location":"notes/xperf/#numbers","title":"Numbers","text":"<p>The numbers reported by this repo are slightly larger than the real crossing overhead because some instructions are needed in between to do bookkeeping. Check below for details.</p> <p>Some preliminary numbers measured on top of Intel Xeon E5-v3 2.4GHz</p> Platform User to Kernel (Cycles) Kernel to User (Cycles) VM ~600 ~370 Bare-metal ~440 ~270"},{"location":"notes/xperf/#mechanisms","title":"Mechanisms","text":""},{"location":"notes/xperf/#files-changed","title":"Files changed","text":"<p>The whole patch is <code>xperf.patch</code></p> <ul> <li><code>arch/x86/entry/entry_64.S</code></li> <li><code>arch/x86/mm/fault.c</code>: save u2k_k to user stack</li> <li><code>xperf/xperf.c</code>: userspace test code</li> </ul>"},{"location":"notes/xperf/#user-to-kernel-u2k","title":"User to kernel (u2k)","text":"<p>At a high-level, the flow is:</p> <ul> <li>User save TSC into stack</li> <li>User pgfault</li> <li>Cross to kernel, get TSC, and save to user stack</li> </ul> <p>But devil is in the details, especially this low-level assembly code. There are several difficulties:</p> <ul> <li>Once in kernel, we need to save TSC without corrupting any other       registers and memory content. Any corruption leads to panic etc.       The challenge is to find somewhere to save stuff.       Options are: kernel stack, user stack, per-cpu. Using user stack       is dangerous, because we can\u2019t use safe probe in this assembly (i.e., copy_from/to_user()).       Using kernel stack is not flexible because we need to manually       find a spot above pt_regs, and this subject to number of <code>call</code> invoked.</li> <li>We need to ensure the measuring only applied to measure program,       but not all user program. We let user save a MAGIC on user stack.</li> </ul> <p>The approach:</p> <ul> <li><code>entry_64.S</code>: Save rax/rdx into kernel stack, because they are known to be good       if the exceptions came from user space.</li> <li><code>entry_64.S</code>: Save TSC into a per-cpu area. With swapgs surrounded.</li> <li><code>entry_64.S</code>: Restore rax/rdx</li> <li><code>fault.c</code>: use <code>copy_to_user</code> to save <code>u2k_k</code> in user stack.</li> </ul> <p>Enable/Disable:</p> <ul> <li><code>entry_64.S</code>: Change <code>xperf_idtentry</code> back to <code>idtentry</code> for both <code>page_fault</code> and <code>async_page_fault</code>.</li> </ul> <p>Note: u2k hack is safe because we don\u2019t probe user virtual address directly in assembly. Userspace accessing is done via <code>copy_from_user()</code>.</p>"},{"location":"notes/xperf/#kernel-to-user-k2u","title":"Kernel to user (k2u)","text":"<p>At a high-level, the flow is:</p> <ul> <li>Kernel save TSC into user stack</li> <li>Kernel IRET</li> <li>Cross to user, get TSC, and calculate latency</li> </ul> <p>This is relatively simpiler than measuring u2k because we can safely use kernel stack. The approach:</p> <ul> <li>Save scratch %rax, %rdx, %rcx into kernel stack</li> <li>Check if MAGIC match</li> <li>rdtsc</li> <li>save to user stack</li> <li>restore scratch registers</li> </ul> <p>Enable/Disable:</p> <ul> <li><code>entry_64.S:</code> There is a <code>xperf_return_kernel_tsc</code> code block.</li> </ul> <p>Note: k2u hack is NOT SAFE because we probe user virtual address directly in assembly, i.e., <code>movq    %rax, (%rcx)</code> in our hack. During my experiments, sometimes it will crash, but not always.</p>"},{"location":"notes/xperf/#xperfxperfc","title":"xperf/xperf.c","text":"<p>This user program will report both u2k and k2u crossing numbers. After compilation, use <code>objdump xperf.o -d</code> to check assembly, <pre><code>  mfence \n  rdtsc                 &lt;- u2k_u\n\n  shl    $0x20,%rdx\n  or     %rdx,%rax\n  mov    %rax,(%rdi)            &lt;- save to user stack\n\n  movl   $0x12345678,(%rsi)     &lt;- pgfault\n\n  rdtsc                 &lt;- k2u_u\n  mfence \n</code></pre></p> <p>The user stack layout upon pgfault is: <pre><code>  | ..       |\n  | 8B magic | (filled by user)   +24\n  | 8B u2k_u | (filled by user)   +16\n  | 8B u2k_k | (filled by kernel) +8\n  | 8B k2u_k | (filled by kernel) &lt;-- %rsp\n</code></pre></p>"},{"location":"notes/xperf/#tsc-measurement","title":"TSC Measurement","text":"<p>TSC will be reodered if no actions are taken. We use <code>mfence</code> to mimize runtime errors.</p> <p>Ideally, we want a test sequence like this: <pre><code>/*\n * User to Kernel \n *\n *          mfence\n *          rdtsc   &lt;- u2k_u\n * (user)\n * -------  pgfault  --------\n * (kernel)\n *          rdtsc   &lt;- u2k_k\n *          mfence\n */\n\n/*\n * Kernel to User\n *\n *          mfence\n *          rdtsc   &lt;- k2u_k\n * (kernel)\n * -------  IRET --------\n * (user)\n *          rdtsc   &lt;- k2u_k\n *          mfence\n */\n</code></pre></p> <p>But we need some instructions in between to do essential setup. So the real instruction flow is:</p> <p>U2K <pre><code>(User)\n    mfence \n    rdtsc                   &lt;- u2k_u\n\n    shl    $0x20,%rdx\n    or     %rdx,%rax\n    mov    %rax,(%rdi)\n\n    movl   $0x12345678,(%rsi)\n       --------------------------------         Crossing\n(Kernel)\n    testb   $3, CS-ORIG_RAX(%rsp)\n    jz  1f\n\n    movq    %rax, -8(%rsp)\n    movq    %rdx, -16(%rsp)\n\n    rdtsc                   &lt;- u2k_k\n    mfence\n</code></pre></p> <p>K2U <pre><code>(Kernel)\n    mfence\n    rdtsc                   &lt;- k2u_k\n\n    shl $32, %rdx\n    or  %rdx, %rax\n\n    movq    %rax, (%rcx)\n    popq    %rcx\n    popq    %rdx\n    popq    %rax\n\n    INTERRUPT_RETURN\n       --------------------------------         Crossing\n(User)\n    rdtsc                   &lt;- k2u_u\n    mfence\n</code></pre></p>"},{"location":"notes/xperf/#misc","title":"Misc","text":"<ul> <li>For VM scenario, the page fault entry point is <code>async_page_fault</code>, not the <code>page_fault</code>.</li> </ul>"},{"location":"notes/xperf/#howto-run","title":"HOWTO Run","text":"<p>FAT NOTE:</p> <ul> <li>Enabling k2u code might bring crash</li> <li>It\u2019s not safe to disable KPTI</li> <li>Switch back to normal kernel after testing</li> <li>Make sure if you have a way to reboot your machine!</li> </ul> <p>Steps:</p> <ul> <li>Copy your current kernel\u2019s .config into this repo</li> <li>make oldconfig</li> <li>Disable <code>CONFIG_PAGE_TABLE_ISOLATION</code></li> <li>Compile kernel and install.</li> <li>Reboot into new kernel</li> <li>Disable hugepage</li> <li><code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</code></li> <li>Run <code>xperf/xperf.c</code>, you will get a report.</li> </ul>"},{"location":"notes/go/golang/","title":"Go","text":"Version History Date Description Nov 5, 2021 Initial <p>I decided to learn Go and use it build some sample projects. I may just start from a simple webserver. Since Go is used a lot in virtualization part (e.g., Docker, gVisor) and databases (mangoDB?), I\u2019m thinking of doing along that line as well.</p> <p>The learning code will be pushed into https://github.com/lastweek/learn-go.</p>"},{"location":"notes/go/golang/#resources","title":"Resources","text":"<ul> <li>awesome-go</li> <li>gVisor</li> </ul>"},{"location":"notes/go/golang/#notes","title":"Notes","text":"<p>Function call pass by value or reference</p> <p>For function call, the following are passed by value: a) struct b) basic data type (e.g., int). So the function receives a copy of each argument; modifications to the copy do not affect the caller. However, the following are pointer like: pointers (to struct, int), slice, map, function, or channel. The caller may be affected by any modifications the function makes to variable indirectly referred to by the argument. (Some testing code here https://github.com/lastweek/learn-go/blob/master/playground/datatypes.go)</p> <p>Defer</p> <p>Defer is one of my favorite featues of Go. I have bad memories on maintaining the error handling code in C, especially in kernel: I have to carefully order the error handling code at the end of function, have proper labels and write proper goto. Here, <code>defer</code> elegantly solves this complex error handling issue.</p> <p>Goroutine</p> <p>Stack: a goroutine usually has a small stack typically 2KB. But unlike an OS thread, a goroutine\u2019s stack is not fixed; it grows and shrinks as needed. It could beas much as 1GB.</p> <p>Scheduling: what\u2019s the policy there? Does the runtime use some sort of timer if user code is not giving up control? It is an M:N scheduler. Some internal documentation: https://github.com/golang/go/blob/master/src/runtime/HACKING.md</p>"},{"location":"notes/go/golang/#go-runtime","title":"Go Runtime","text":"<p>The source code is here under this directory src/runtime. A huge directory with a lot of files. Why not create more subdirectories to better organize all these files?</p>"},{"location":"notes/go/gvisor/","title":"gVisor Case Study","text":"<p>gVisor is an application kernel to run container jobs. It is like a library OS. It intercept syscalls made into Linux kernel and implement almost everything in userspace. Of course, since gVisor itself is still running as a user program in Linux, gVisor will interact with Linux kernel. In other words, gVisor interact with Linux kernel on application\u2019s behalf.</p> <p>Why gVisor? It is result of the perf &amp; security trade-off between VM and container. To use VM, we have native perf and limited security exposure, most things are protected by hardware. But the downside is the slow start time and simply too heavy. Container is lightweight, you can deploy code directly. However, all containers share the underlying Linux kernel. So the security exposure space is much much large, it is the whole Linux kernel! And in fact, kernel does have a lot of security issues. That\u2019s why gVisor wants to take things into their own hand. By using gVisor and sandboxing apps using their library/app kernel, most of the OS functionalties are built into app\u2019s own domain, will not affect others. So the shared surface is smaller.</p> <p>It is interesting that gVisor comes out from May 2018. And the MIT Biscuit go-based OS comes out around Oct 2018. Both are using Go to write OS functionalties.</p>"},{"location":"notes/go/gvisor/#resources","title":"Resources","text":"<p>They have a good explanation on their architecture here.</p> <p>Papers:</p> <ul> <li>The True Cost of Containing: A gVisor Case Study, HotCloud\u201819.</li> <li>Blending Containers and Virtual Machines: A Study of Firecracker and gVisor, VEE\u201920</li> </ul>"},{"location":"notes/go/gvisor/#note","title":"Note","text":"<p>Source code is https://github.com/google/gvisor. I actually not particular sure where should I start. We don\u2019t really need to understand gVisor in order to use it though. I did a quick go through. The major kernel can be found in <code>pkg/</code> and <code>pkg/sentry</code>. The sentry is their core kernel.</p> <p>I decided to run it. I followed the docker+gVisor quick start guide. So apparently, docker can use gVisor instead of Linux to launch the container. We explicitly use the <code>runsc</code> runtime from gVisor. After the container is started, I run dmesg. It looks interesting. Same for files under <code>/proc</code>. Everything is emualted by gVisor. <pre><code>docker run --runtime=runsc --rm -it ubuntu /bin/bash\n</code></pre></p> <pre><code>root@59e9ca6d20a2:/proc# dmesg\n[    0.000000] Starting gVisor...\n[    0.461512] Waiting for children...\n[    0.882428] Searching for socket adapter...\n[    1.224004] Gathering forks...\n[    1.310421] Consulting tar man page...\n[    1.542386] Committing treasure map to memory...\n[    1.648830] Feeding the init monster...\n[    1.910484] Letting the watchdogs out...\n[    2.316306] Mounting deweydecimalfs...\n[    2.734728] Creating process schedule...\n[    3.013152] Generating random numbers by fair dice roll...\n[    3.351471] Setting up VFS2...\n[    3.508762] Ready!\n</code></pre>"},{"location":"notes/languages/rust/","title":"Note on Rust","text":"Version History Date Description Jan 9, 2021 Initial Version"},{"location":"notes/languages/rust/#learn","title":"Learn","text":"<p>Jan 9, 2020 As the first step, I\u2019m reading https://doc.rust-lang.org/book/.</p> <p>The documentation part is really really nice. Run <code>cargo doc --open</code>.</p>"},{"location":"notes/linux/","title":"on Linux","text":""},{"location":"notes/linux/#resources","title":"Resources","text":"<ol> <li>https://www.kernel.org/doc/html/latest/</li> <li>https://makelinux.github.io/kernel/map/</li> <li>https://0xax.gitbooks.io/linux-insides/content/index.html</li> </ol>"},{"location":"notes/linux/fork/","title":"Misc on Linux fork, switch_to, and scheduling","text":"Version History Date Description Oct 23, 2021 Initial <p>So I had some whiskey and chips last night. Sitting there watching TV, browsing random blogs. Then I came across a blog I saved long time ago about linux switch_to history. Then I recalled the moment I reliazed how switch_to/fork etc works, it was amazing. So I decide to read the source code again and do some documentation. I\u2019m mostly reading my LegoOS code. This note is quite uncomplete though. I won\u2019t have time going through the obvious.</p>"},{"location":"notes/linux/fork/#prepare-kernel-stack-and-function-pointers","title":"Prepare Kernel Stack and Function Pointers","text":"<p>copy_process() -&gt; copy_thread().</p> <p>This is the stack layout after <code>copy_thread()</code>. Also the rough layout when the newly created thread is enqueued into runqueue. </p> <p>The <code>copy_thread()</code> is architecture specific, I\u2019m using x86 as an example. This is a magic function as it plays with the stack, which is implicitly used by simply returning. And this is confusing to a lot people, including myself when I got started.</p> <p>Some facts about the kernel stack. The kernel stack is allocated during fork() before we run into <code>copy_thread()</code>. We can reference it by calling <code>task_stack_page(p)</code>. The stack has a fixed size (maybe the latest version has changed this?), a configurable value called <code>THREAD_SIZE</code>, default is 2 pages I remember. So the end (top) of the stack is simply <code>task_stack_page(p) + THREAD_SIZE</code>. Stack grows from top to bottom. Hence, kernel uses a simple trick. It leverages the bottom of the kernel stack to save a struct called <code>thread_info</code>. Quite an important data structure. The assumption is that kernel will not actually grow to the bottom.  They do have a method to detect kernel stack corruption, I will not cover it here.</p> <p>Alright, during <code>copy_thread()</code>, we basically have a \u201cfresh\u201d stack. We have copied everything from the old stack to the new stack (done before calling into <code>copy_thread</code>). The core job here is to setup the top of the stack, so that when this newly created thread can run into certain predefined functions.</p> <p>Top of the kernel stack is the <code>struct pt_regs</code>, this is true across the whole kernel. So it is fairly easy to grab the pointer to it by using a simple macro called <code>task_pt_regs(p)</code>, which just has simple pointer calculation. Here, <code>copy_thread()</code> used a structure called <code>struct fork_frame</code>, which contains a <code>struct inactive_task_frame</code> and a <code>struct pt_regs</code>. Again, leveraging the memory layout, we can easily calculate the pointers to either structures. Note, the <code>struct fork_frame</code> layout is crucial to understanding how fork\u2019ed process gets running and how kernel thread runs into passed functions.</p> <p>The bottom of the <code>struct fork_frame</code> is a field called <code>ret_addr</code>. This is essentially the first function gets run when this newly created thread gets running (scheduled by runqueue). Here it is assigned to a function called <code>ret_from_fork()</code>, which should be straightforward to understand. We will look into that later. Alright, if this fork() is actually creating a kernel thread, we will save the kernel function pointer and argument pointer to the <code>struct fork_frame</code> as well! All these info saved here will be used later on in the assembly (<code>entry_64.S</code>). <pre><code>        childregs = task_pt_regs(p);\n        fork_frame = container_of(childregs, struct fork_frame, regs);\n        frame-&gt;ret_addr = (unsigned long) ret_from_fork;\n        ...\n        ... \n        /*\n         * Save the kernel function pointer\n         * and argument pointer to the `struct fork_frame`\n         */\n        if (unlikely(p-&gt;flags &amp; PF_KTHREAD)) {     \n                p-&gt;thread.pkru = pkru_get_init_value();     \n                memset(childregs, 0, sizeof(struct pt_regs));     \n                kthread_frame_init(frame, sp, arg);     \n                return 0;     \n        }     \n</code></pre></p> <p>Then the newly created thread will be enqueued into the runqueue. Eventually it will gets running.</p>"},{"location":"notes/linux/fork/#running-for-the-first-time-after-fork","title":"Running For the first time after fork()","text":"<p>When the scheduler decides to run a thread, it will at least call <code>context_switch()</code>, which internally calls <code>switch_to()</code>, which is just a macro around <code>__switch_to_asm</code>. <pre><code>#define switch_to(prev, next, last)                                     \\    \ndo {                                                                    \\    \n        ((last) = __switch_to_asm((prev), (next)));                     \\    \n} while (0) \n</code></pre></p> <p><code>__switch_to_asm</code> is simply playing around the <code>struct fork_frame</code> we discussed above. It first the current thread\u2019s state, switch stack (to the newly created thread\u2019s stack), then starts popping out regs, eventually, only the <code>ret_addr</code> field remains in the stack!!</p> <p>This is very important: we <code>jump</code> to the <code>__switch_to()</code> function. Hence no return address will be pushed into the stack. Later on, when <code>__switch_to()</code> finishes and returns, the hardware will use the last field in the stack, which is the <code>ret_addr</code> field we placed there during <code>copy_thread()</code>! Elegant, isn\u2019t it? </p> <p>So, for a newly created process, the control flow is as follows <pre><code>context_switch (c)\n__switch_to_asm (asm)\n__switch_to (c)\nret_from_fork (asm)\n   ==&gt; return system call\n   ==&gt; run kernel function\n</code></pre></p> <p>Note the two lines switching stack. The <code>TASK_threadsp</code> is actually referring to <code>p-&gt;thread.sp</code>. For a newly created thread, <code>p-&gt;thread.sp</code> was set during <code>copy_thread()</code> and it directly points to the starting address of <code>struct fork_frame</code>.</p> <p>Note that there is a key difference with regard to normal threads scheduling, i.e., threading got de-scheduled and scheduled again. For the normal case, threads either willingly give up control or got preempted. Either way, the kernel stack will have all the calling trace (different from a newly forked thread\u2019s stack, which is clean), and the <code>p-&gt;thread.sp</code> points there. Assume we have 2 threads A and B. A is originally running. A willingly goes to sleep by calling schedule(), inside which, it eventually calls <code>context_switch()-&gt;__switch_to_asm()</code>. This saves a return address to <code>context_switch()</code> into the bottom of the kernel stack (and this is the <code>ret_field</code> position for <code>struct fork_frame</code>)! When A got re-scheduled again, it runs into <code>__switch_to_asm</code> again. Unlike the fork case, here the ret_field points to where A gave up control, essentially the original <code>context_switch()</code>. So A will resume to <code>context_switch()</code> and run into <code>finish_task_switch()</code>.</p> <pre><code>/*\n * %rdi: prev task\n * %rsi: next task\n */\nENTRY(__switch_to_asm)\n        pushq   %rbp    \n        pushq   %rbx    \n        pushq   %r12    \n        pushq   %r13    \n        pushq   %r14    \n        pushq   %r15    \n\n        /* Switch stack */    \n        movq    %rsp, TASK_threadsp(%rdi)    \n        movq    TASK_threadsp(%rsi), %rsp    \n\n        /* restore callee-saved registers */    \n        popq    %r15    \n        popq    %r14    \n        popq    %r13    \n        popq    %r12    \n        popq    %rbx    \n        popq    %rbp    \n\n        /*\n         * Note:\n         * After popping out the above fields, now we only have\n         * the `ret_field` left in the stack, which was pushed\n         * into the stack by `copy_thread()`!\n         * This is a *JUMP* to __switch_to() function!\n         */\n        jmp     __switch_to\nEND(__switch_to_asm)\n</code></pre> <p>I want to spend a few words on <code>ret_from_fork</code> as well. It is a quite interesting function. As we discussed above, a newly created thread will first run <code>ret_from_fork()</code>. And it got into this function by simply return from <code>__switch_to()</code>.</p> <p>As you can see, it will check whether we are creating a new kernel thread. If it is, we will invoke the kernel function directly (this is how kthread create new kernel thread). And this kernel thread is allowed to return to userspace by calling exec and its friends!</p> <pre><code>/*                                                                                           \n * A newly forked process directly context switches into this address.                                                                                           \n *                                                                                           \n * rax: prev task we switched from                                                                                           \n * rbx: kernel thread func (NULL for user thread)                                                                                           \n * r12: kernel thread arg                                                                                           \n */                                                                                           \nENTRY(ret_from_fork)                                                                                           \n        movq    %rax, %rdi\n        call    schedule_tail           /* rdi: 'prev' task parameter */\n\n        testq   %rbx, %rbx              /* from kernel_thread? */\n        jnz     1f                      /* kernel threads are uncommon */\n\n2:                                                                                           \n        movq    %rsp, %rdi\n        call    syscall_return_slowpath /* return with IRQs disabled */\n        SWAPGS                          /* switch to user gs.base */\n        jmp     restore_regs_and_iret\n\n1:                                                                                           \n        /* kernel thread */\n        movq    %r12, %rdi\n        call    *%rbx\n        /*    \n         * A kernel thread is allowed to return here after successfully    \n         * calling do_execve().  Exit to userspace to complete the execve()    \n         * syscall:    \n         */\n        movq    $0, RAX(%rsp)\n        jmp     2b\nEND(ret_from_fork)\n</code></pre>"},{"location":"notes/linux/fork/#misc","title":"Misc","text":""},{"location":"notes/linux/fork/#linux-current","title":"Linux <code>current</code>","text":"<p>The <code>current</code> macro refers to the current running thread. It is very convient variable and it works like magic before. Long time ago, <code>current</code> is a macro that has a set of assmebly instructions calculating the pointer to <code>task_struct</code> based on the current <code>kernel stack pointer</code>. Since the kernel stack has a fixed size, so it is easy to derive the bottom of the kernel stack by masking the current sp pointer. Then, kernel saved some extra info there to make a connection to the task_struct. Simple and works well.</p> <p>Nowadays, in x86, the current becomes a per-cpu variable. IMO, it is actually much cleaner. The variable is called <code>current_task</code>. It got updated inside <code>__switch_to</code>. <code>current</code> becomes a function reading the <code>current_task</code>, should is much lightweigh than old solutions.</p>"},{"location":"notes/linux/fork/#linux-pt_regs","title":"Linux <code>pt_regs</code>","text":"<p>PT stands for program trace. <code>pt_regs</code> includes the whole register status, very arch-specific. They live at the top of the kernel stack. When a program trap from user to kernel space, the first thing kernel would do is to construct such pt_regs (check <code>entry_64.S</code>).</p> <p>However, things might got tricky though. Threads in kernel can be interrupted as well. So we could have multiple <code>pt_regs</code> instances inside kernel stack frame. So logically, there is a stack of <code>pt_regs</code>, and kernel code should use the right <code>pt_regs</code> rather than blindly use the top of the kernel stack!</p>"},{"location":"notes/linux/fork/#leveraging-ret-and-iret","title":"Leveraging <code>ret</code> and <code>iret</code>","text":"<p>Kernel uses this trick a lot. At its core, <code>ret</code> and <code>iret</code> transfer control to the addresses saved in the stack. So if we change the saved addresses, C\u2019s <code>return XX</code>  becomes very magical. It can return to unexpected places. This trick is used by <code>__switch_to_asm</code> and <code>ret_from_fork</code>.</p>"},{"location":"notes/linux/fork/#kernel-exception-handling","title":"Kernel Exception Handling","text":"<p>Kernel can handle exceptions from kernel itself, or fixup exceptions. Some of the exceptions are okay. Say <code>copy_from_user()</code>, there might be page fault during this call. And kernel should be able to recognize that in the page fault handler and resume execution.</p>"},{"location":"notes/linux/linux-boot/","title":"Linux boot sequence after GRUB","text":"Version History Date Description Jan 6, 2021 minor update Dec 23, 2020 initial version <p>This note is aboue the linux/grub boot protocol and a walk through of the low-level booting code.</p> <p>This is adopted from my previous note. I was looking into this while I was building the LegoOS boot process. I was trying to find out how GRUB2 loads the kernel image and how it prepares all the boot environment.</p>"},{"location":"notes/linux/linux-boot/#linux-boot-protocol-and-code-sequence","title":"Linux Boot Protocol and Code Sequence","text":"<p>Linux (x86) has a boot protocol between the bootloader and kernel image itself, described here.</p> <p>Essentially, there is a contiguous memory region passing information between these two entities. This big region just like a big C <code>struct</code>: some fields are filled by kernel duing compile time (<code>arch/x86/boot/tools/build.c</code> and some in code), some fields are filled by GRUB2 during boot time to tell kernel some important addresses, e.g., kernel parameters, ramdisk locations etc.</p> <p>GRUB2 code follows the protocol, and you can partially tell from the <code>grub_cmd_linux()</code> function.</p> <p>Last time I working on this was late 2016, I truly spent a lot investigating how GRUB and linux boot works. I will try to document a bit, if my memory serves:</p> <ol> <li> <p>In the Linux kernel, file <code>arch/x86/boot/header.S</code> is the first file got run after GRUB2. This file is a bit complicated but not hard to understand! It has 3 parts. For the first part, it detects if it was loaded by a bootloader, if not, just by printing an error message and reboot. It the kernel was loaded by a bootloader like GRUB2, the first part will never execute. The bootload will directly jump to the second part. This is part of the boot protocol. For the second part, it lists all the fields described by the boot protocol. And finally the third part is real-mode instructions that got run after the GRUB2 jumo. The starting function is called <code>start_of_setup</code>, which will do some stack checking, and then jump to C code in <code>arch/x86/boot/main.c</code>.</p> </li> <li> <p><code>arch/x86/boot/main.c</code> runs on real-mode, it will do some setup and jump to protected-mode (32-bit). It is running after BIOS but before the actual Linux kernel. Thus this piece of code must rely on BIOS to do stuff, which makes it very unique. The major task of the setup code is to prepare the <code>struct boot_params</code>, which has all the boot information, some of them were extracted from the <code>header.S</code>. The <code>struct boot_params</code> will be passed down and used by many kernel subsystems later on. The final jump happens in <code>arch/x86/boot/pmjump.S</code> <pre><code>        #\n        # Jump to protected-mode kernel, 0x100000\n        # which is the compressed/head_$(BITS).o\n        #\n        jmp     *%eax\n</code></pre></p> </li> <li> <p>Then, we are in <code>arch/x86/boot/compressed/head_64.S</code>. Above pmjump jumps to <code>startup_32</code>, it will enable paging, tweak GDT table etc, setup pagetable, and transition to 64-bit entry point <code>startup_64</code>.  And finally, we are in 64-bit. The final jump will go to <code>arch/x86/kernel/head_64.S</code>. We are close!</p> </li> <li> <p>Now we are in <code>arch/x86/kernel/head_64.S</code>. We are in 64-bit. But some further setup is needed. This part is really low-level and engaging. I would never know I how managed to understand and port all this shit. It setup a lot GDT, IDT stuff, and some pgfault handlers. It turns out those early pgfault handlers are NECESSARY and I remember they played an very interesting role! Finally, this assembly will jump to <code>arch/x86/kernel/head64.c</code>, the C code!</p> <ul> <li>I guess an interesting part is <code>secondary_startup_64</code>. This code is actually run by non-booting CPUs, or secondary CPUs.   After the major boot CPU is up and running (already within <code>start_kernel()</code>), I believe its the <code>smp_init()</code> that will send IPI wakeup interrupts to all present secondary CPUs.   The secondary CPUs will start from real-mode, obviously. Then they will transition from 16bit to 32bit, from 32bit to 64bit. That code is in <code>arch/x86/realmode/rm/trampoline.S</code>!</li> <li><code>arch/x86/realmode</code> is interesting. It uses piggyback technique. All the real-mode and 32bit code are in <code>arch/x86/realmode/rm/*</code>, a special linker script is used to construct the code in a specific way! Think about mix 16bit, 32bit, 64bit code together, nasty!</li> </ul> </li> <li> <p>Hooray, C world. We are in <code>arch/x86/kernel/head64.c</code>. The starting function is <code>x86_64_start_kernel</code>! And the end is the <code>start_kernel</code>, the one in <code>init/main.c</code>.</p> </li> </ol> <p>In all, there are a lot jumps after GRUB2 loads the kernel image, and it\u2019s really a long road before we can reach <code>start_kernel()</code>. It probably should not be this complex, but the x86 architecture is just making it worse.</p>"},{"location":"notes/linux/linux-boot/#grub2-linux-vs-linux16","title":"GRUB2: linux v.s. linux16","text":"<p>An interesting thing is that there are two ways to load an kernel image in <code>/boot/grub2/grub.cfg</code>, either using <code>linux vmlinuz-3.10.0</code> or <code>linux16 vmlinuz-3.10.0</code>. They have different effects. I remember only the <code>linux16</code> one works for me, but not remembering why. At least on CentOS 7, it\u2019s all <code>linux16</code>. Different distro may have different preferences?</p> <p>The <code>linux16</code> and <code>initrd16</code> in <code>grub-core/loader/i386/pc/linux.c</code>: <pre><code>GRUB_MOD_INIT(linux16)\n{\n  cmd_linux =\n    grub_register_command (\"linux16\", grub_cmd_linux,\n               0, N_(\"Load Linux.\"));\n  cmd_initrd =\n    grub_register_command (\"initrd16\", grub_cmd_initrd,\n               0, N_(\"Load initrd.\"));\n  my_mod = mod;\n}\n</code></pre></p> <p>The <code>linux</code> and <code>initrd</code> in <code>grub-core/loader/i386/linux.c</code>: <pre><code>static grub_command_t cmd_linux, cmd_initrd;\n\nGRUB_MOD_INIT(linux)\n{\n  cmd_linux = grub_register_command (\"linux\", grub_cmd_linux,\n                     0, N_(\"Load Linux.\"));\n  cmd_initrd = grub_register_command (\"initrd\", grub_cmd_initrd,\n                      0, N_(\"Load initrd.\"));\n  my_mod = mod;\n}\n</code></pre></p>"},{"location":"notes/linux/linux-completion/","title":"wait, swait, completion","text":"Version History Date Description Oct 28, 2021 created <p>Completion, swait, and wait are kernel APIs. They provide barrier-like semantics. They are easy to use and simple to understand as well.</p> <p>The <code>swait</code> (simple waitqueue) was added to the kernel around 2016 by Peter Zijlstra. As the email (<code>git log -p kernel/sched/swait.c</code>) and comments in the file point out, they just want to have a simpler version  for this frequently used data structure. The <code>waitqueue</code> has unnecessary overhead for simple use cases.</p> <ul> <li><code>waitqueue</code> can be found in <code>kernel/sched/wait.c</code></li> <li><code>swait</code> can be found in <code>kernel/sched/swait.c</code>.</li> <li><code>completion</code> can be found in <code>kernel/sched/completion.c</code></li> </ul> <p>The <code>swait</code> and <code>waiqueue_t</code> are essentially the same: they are a queue of sleeping threads. They provide APIs for you to insert (sleep) and delete (wakeup) threads within the queue. I recommend start from swait, it is simple enough as long as you are familiar with kernel list ops.</p> <p>The <code>completion</code> API essentially builds itself on top of <code>swait</code>. The <code>complete()</code> call directly call <code>swake_up_locked()</code>. I guess the only interesting thing is <code>wait_for_completion()</code>.</p> <pre><code>static long __sched\nwait_for_common(struct completion *x, long timeout, int state)\n{\n    return __wait_for_common(x, schedule_timeout, timeout, state);\n}\n</code></pre> <p>All different flavors of wait eventually fall into the following func. It adds the current thread into the <code>swait</code> queue, change the thread state, then simply calls <code>action()</code> function pointer, which, in normal cases, is <code>schedule_timeout()</code>. So this is the place a thread goes to sleep and wait for the other thread to call <code>complete()</code>. <pre><code>static inline long __sched\ndo_wait_for_common(struct completion *x,\n           long (*action)(long), long timeout, int state)\n{\n    if (!x-&gt;done) {\n        DECLARE_SWAITQUEUE(wait);\n\n        do {\n            if (signal_pending_state(state, current)) {\n                timeout = -ERESTARTSYS;\n                break;\n            }\n            __prepare_to_swait(&amp;x-&gt;wait, &amp;wait);\n            __set_current_state(state);\n            raw_spin_unlock_irq(&amp;x-&gt;wait.lock);\n            timeout = action(timeout);\n            raw_spin_lock_irq(&amp;x-&gt;wait.lock);\n        } while (!x-&gt;done &amp;&amp; timeout);\n        __finish_swait(&amp;x-&gt;wait, &amp;wait);\n        if (!x-&gt;done)\n            return timeout;\n    }\n    if (x-&gt;done != UINT_MAX)\n        x-&gt;done--;\n    return timeout ?: 1;\n}\n</code></pre></p>"},{"location":"notes/linux/linux-completion/#references","title":"References","text":"<ul> <li>Documentation/scheduler/completion.rst</li> </ul>"},{"location":"notes/linux/linux-function-trace/","title":"How to Dump Function Call Graph in Linux","text":"Version History Date Description Nov 1, 2021 new <p>I want to share the method I use to dump the function call graph in a live Linux machine. This is particularly useful when you are studying the source code and try to understand the call flow. This is not the only way to do so, but I found it convenient in my own reading flow.</p> <p>The approach I took is fairly simple, I use ftrace. It has a feature to monitor the call graph AND dump the latency. I wrote a very simple script for this purpose.</p> <p>The whole scripts are uploaded to this repo https://github.com/lastweek/linux-ftrace. These are the steps I\u2019d take</p> <ol> <li>Modify the <code>set_graph_function.sh</code>, add the functions I want to dump.</li> <li>Run <code>set_graph_function.sh</code> directly.</li> <li>Dump the trace by running <code>cat_trace_file.sh</code>.</li> <li>Disable tracing by running <code>disable.sh</code>.</li> </ol> <p>The nice thing about ftrace is that it also measures the latency. If you want to understand how ftrace is able to dynamically measure the latency and has such a great flexibility, please check out my other blog here: http://lastweek.io/notes/trace/#ftrace.</p>"},{"location":"notes/linux/linux-function-trace/#examples","title":"Examples","text":"<p>Say I want to check <code>handle_mm_fault()</code>\u2019s runtime call graph. I would first modify the scipts to include this func. <pre><code>set -e\n\nDIR=/sys/kernel/debug/tracing\n\n# Presetup if any\n# ./prepare.sh\n\n# Disable tracing and clear trace\necho 0 &gt; $DIR/tracing_on\necho &gt; $DIR/trace\necho &gt; $DIR/set_ftrace_filter\necho &gt; $DIR/set_graph_function\n\n# Setup tracer type\necho function_graph &gt; $DIR/current_tracer\n\n#\n# The functions we'd trace\n#\necho handle_mm_fault &gt;&gt; $DIR/set_graph_function\n\necho \"Enabled graph functions:\"\ncat $DIR/set_graph_function\n\necho 1 &gt; $DIR/tracing_on\n</code></pre></p> <p>Run the scripts, and look into the trace file, it would give us something like the following. Though, keep in mind that functions like <code>handle_mm_fault()</code> is very dynamic, there are many call graph combos. <pre><code># tracer: function_graph                            \n#                                                            \n# CPU  DURATION                  FUNCTION CALLS       \n# |     |   |                     |   |   |   |       \n 39)               |  handle_mm_fault() {           \n 39)   0.677 us    |    mem_cgroup_from_task();       \n 39)   0.918 us    |    __count_memcg_events();         \n 39)               |    __handle_mm_fault() {                 \n 39)               |      do_huge_pmd_numa_page() {             \n 39)   0.682 us    |        _raw_spin_lock();       \n 39)   0.570 us    |        pmd_trans_migrating();                 \n 39)               |        mpol_misplaced() {                 \n 39)   0.471 us    |          __get_vma_policy();       \n 39)               |          get_vma_policy.part.0() {       \n 39)   0.387 us    |            get_task_policy.part.0();       \n 39)   1.091 us    |          }                            \n 39)               |          should_numa_migrate_memory() {       \n 39)   0.374 us    |            page_cpupid_xchg_last();       \n 39)   1.095 us    |          }       \n 39)   4.410 us    |        }       \n 39)   0.389 us    |        unlock_page();       \n 39)               |        task_numa_fault() {       \n 39)               |          __kmalloc() {           \n 39)   0.382 us    |            kmalloc_slab();       \n 39)               |            _cond_resched() {            \n 39)   0.391 us    |              rcu_all_qs();       \n 39)   1.115 us    |            }                   \n 39)   0.391 us    |            should_failslab();       \n 39)   0.461 us    |            memcg_kmem_put_cache();       \n 39)   4.628 us    |          }                         \n 39)   0.529 us    |          task_numa_placement();          \n 39)   6.481 us    |        }                                   \n 39) + 15.130 us   |      }           \n 39) + 16.854 us   |    }                                          \n 39) + 21.198 us   |  }\n</code></pre></p>"},{"location":"notes/linux/linux-iouring/","title":"Linux io_uring","text":"Version History Date Description Jan 8, 2021 Initial <p>It has been two years since io_uring was added into mainline kernel. Over this short course, io_uring has grown a lot. The idea of using kernel, or even building kernel in an async way, ryhthms with a research idea I had, that\u2019s why I have always kept an eye on the development of io_uring.</p> <p>Nonetheless, I\u2019m not sure how real world softwares are picking it up. The io_uring introduced a set of new APIs and we have to rewrite applications to take advantage of its benefits. Although it may have performance benefits, this may prevent a wider adoption.</p> <p>Some argue there is nothing new about io_uring. I partially agree. It is a common practice to use rings to bridge multiple communicating parties, or to realize async ops. But actually implement the feature for syscalls is challenging.</p> <p>There are not too many stuff out there, you will mostly come across the following writeups: 1) Ringing in a new asynchronous I/O API 2) The rapid growth of io_uring</p> <p>There is user library called liburing to ease the use of io_ring.</p> <p>The kernel code is <code>fs/io_uring.c</code>. Such a big file. Bad practice.</p> <p>I think the whole io_uring thing is worth checking out. And you should think about what you can further do about it. I think it has great potentials.</p>"},{"location":"notes/linux/linux-linker-script/","title":"Linux Linker Script Framework","text":"Version History Date Description Oct 30, 2021 Initial <p>Has nothing better to do, so to write some random note on linker script.</p>"},{"location":"notes/linux/linux-linker-script/#intro","title":"Intro","text":"<p>The kernel is complied in a very controlled way. It has a linker script to control exactly what sections are generated and where they are. The linker script is architecture specific. I will examine <code>arch/x86/kernel/vmliniux.ld.S</code>. Yes, it is an assembly file. The build framework will compile it into <code>vmlinux.ld</code>.  The reason that it is in assembly format is simple. We need to use a lot of macros, that are shared with C code. Assembly files allow us to do that, linker script does not.</p> <p>When I wrote LegoOS, I used the exact framework. The whole thing was very confusing to me in the beginning. The kernel code interacts with the linker script quite a lot, actually. The most common use, is to annnotate C code (say put into a special section), and then the linker script will aggregate them. Let me summarize the common flow:</p> <ol> <li>Create a new section name. And use it to annotate your function and data. For example, I can create <code>__section(\"test\")</code>, and mark <code>int foo __section(\"test\")</code>. </li> <li>Then look into <code>vmlinux.lds.S</code>, add a new section. Also, add begin and end marcos before and after the section. You can use these macros in your C code. <pre><code>    . = ALIGN(8);\n    .test_section : AT(ADDR(.test_section) - LOAD_OFFSET) {\n        __test_section_start = .;\n        *(.test);\n        __test_section_end = .;\n    }\n</code></pre></li> <li>And in your C code, you can declare <code>__test_section_start</code> and <code>__test_section_end</code>, and use them. Kernel uses this trick a lot. If everything in this section is the same type of data structures, you can simply walk through it as if it is an array.</li> </ol> <p>Let\u2019s look at an example, say the x86 apicdrivers.</p> <p>They defined a macro to annotate apic drivers. <pre><code>#define apic_driver(sym)                                        \\    \n        static const struct apic *__apicdrivers_##sym __used            \\    \n        __aligned(sizeof(struct apic *))                        \\    \n        __section(\".apicdrivers\") = { &amp;sym }\n\n\nstatic const struct apic testAPICdriver = { ... };\napic_driver(testAPICdriver)\n</code></pre></p> <p>And inside linker script, they define: <pre><code>    . = ALIGN(8);\n    .apicdrivers : AT(ADDR(.apicdrivers) - LOAD_OFFSET) {\n        __apicdrivers = .;\n        *(.apicdrivers);\n        __apicdrivers_end = .;\n    }\n</code></pre></p> <p>Finally, define them in C and use it. <pre><code>extern struct apic *__apicdrivers[], *__apicdrivers_end[];\n\nstruct apic **drv;\nfor (drv = __apicdrivers; drv &lt; __apicdrivers_end; drv++) {\n...\n}\n</code></pre></p> <p>The kernel scheduler code the trick to define various scheduler drivers too.</p>"},{"location":"notes/linux/linux-linker-script/#kernel","title":"Kernel","text":"<p>Various things that use linker script to organize their data and functions.</p> <ol> <li>per-cpu data</li> <li>ftrace</li> <li>init and exit functions</li> <li>ACPI, APIC</li> <li>IRQCHIP</li> <li>Exception handlers</li> <li>cacheline aligned</li> </ol>"},{"location":"notes/linux/linux-linker-script/#boring-details","title":"Boring Details","text":"<p>In the <code>vmlinux.lds.S</code>, those header files are included. The most important one is <code>vmlinux.lds.h</code>. <pre><code>#include &lt;asm-generic/vmlinux.lds.h&gt;\n#include &lt;asm/asm-offsets.h&gt;\n#include &lt;asm/thread_info.h&gt;\n#include &lt;asm/page_types.h&gt;\n#include &lt;asm/orc_lookup.h&gt;\n#include &lt;asm/cache.h&gt;\n#include &lt;asm/boot.h&gt;\n</code></pre></p> <p>And be sure to checkout the <code>vmlinux.lds.h</code>. The top comments. It lays out the basic structrue of a linker script in linux. And it defines all the macros used in the assembly linker file. <pre><code>/*\n * Helper macros to support writing architecture specific\n * linker scripts.\n *\n * A minimal linker scripts has following content:\n * [This is a sample, architectures may have special requiriements]\n *\n * OUTPUT_FORMAT(...)\n * OUTPUT_ARCH(...)\n * ENTRY(...)\n * SECTIONS\n * {\n *  . = START;\n *  __init_begin = .;\n *  HEAD_TEXT_SECTION\n *  INIT_TEXT_SECTION(PAGE_SIZE)\n *  INIT_DATA_SECTION(...)\n *  PERCPU_SECTION(CACHELINE_SIZE)\n *  __init_end = .;\n *\n *  _stext = .;\n *  TEXT_SECTION = 0\n *  _etext = .;\n *\n *      _sdata = .;\n *  RO_DATA(PAGE_SIZE)\n *  RW_DATA(...)\n *  _edata = .;\n *\n *  EXCEPTION_TABLE(...)\n *\n *  BSS_SECTION(0, 0, 0)\n *  _end = .;\n *\n *  STABS_DEBUG\n *  DWARF_DEBUG\n *  ELF_DETAILS\n *\n *  DISCARDS        // must be the last\n * }\n *\n * [__init_begin, __init_end] is the init section that may be freed after init\n *  // __init_begin and __init_end should be page aligned, so that we can\n *  // free the whole .init memory\n * [_stext, _etext] is the text section\n * [_sdata, _edata] is the data section\n *\n * Some of the included output section have their own set of constants.\n * Examples are: [__initramfs_start, __initramfs_end] for initramfs and\n *               [__nosave_begin, __nosave_end] for the nosave data\n */\n</code></pre></p>"},{"location":"notes/linux/linux-rcu/","title":"Linux RCU","text":"Version History Date Description Oct 24, 2021 Add code reading section Oct 23, 2021 Initial"},{"location":"notes/linux/linux-rcu/#references","title":"References","text":"<ol> <li>What is RCU, Fundamentally?<ul> <li>This is a great article.</li> <li>You should really understand the example cases in this article. It could give a better understanding on why RCU works and how to modify your code to use it.</li> </ul> </li> <li>RCU Usage In the Linux Kernel: One Decade Later</li> <li>http://blog.foool.net/wp-content/uploads/linuxdocs/RCU.pdf</li> </ol> <p>I write this note as I read the related blog and the code. So my understanding expressed in this note is sequential. After reading various blogs and the kernel source code, I did reach a good conclusion and have a good understanding in the end.</p>"},{"location":"notes/linux/linux-rcu/#notes","title":"Notes","text":"<p>RCU is just brilliant but also painfully hard to understand in the first place. I want to walk through how RCU is actually implemented in the kernel and take some notes (Oct 23, 2021).</p> <p>The <code>synchronize_rcu()</code> is the most interesting function. By definition, it will only return after making sure no other CPUs are still in the reader side critical section. In a non-preemptive kernel, it can simply wait all other CPUs to have a context switch. But in a preemptive kernel, it becomes more complicated.</p> <p>Just a naive thought, one can use some sort of per-cpu variable to track whether a CPU has a context switch during the  <code>synchronize_rcu()</code> call.</p> <p>In the latest code (v5.9), this is the impl. So it appears <code>synchronize_rcu_expedited()</code> will speedup the grace period by forcefully send IPI to other CPUs to enforce context switch. The normal wait is the <code>wait_rcu_gp()</code> function. Very complicated function. It has several callback etc. But I guess it has to has a way to check other CPUs\u2019 status, right? To know whether other CPUs have context switched or so on. Anymore, I didn\u2019t expect to understand RCU impl in just few hours. I should use this a bit more and read a bit more.</p> <pre><code>void synchronize_rcu(void)\n{\n    if (rcu_blocking_is_gp())\n        return;  // Context allows vacuous grace periods.\n    if (rcu_gp_is_expedited())\n        synchronize_rcu_expedited();\n    else\n        wait_rcu_gp(call_rcu);\n}\n</code></pre> <p>Ah, I think the RCU usage paper gives a nice high-level summary on Linux\u2019s implementaiton:</p> <ul> <li>In practice Linux implements <code>synchronize_rcu</code> by waiting for all CPUs in the system to pass through a context switch, instead of scheduling a thread on each CPU. This design optimizes the Linux RCU implementation for low-cost RCU critical sections, but at the cost of delaying synchronize_rcu callers longer than necessary. In principle, a writer waiting for a particular reader need only wait for that reader to complete an RCU critical section. The reader, however, must communicate to the writer that the RCU critical section is complete. The Linux RCU implementation essentially batches reader-to-writer communication by waiting for context switches. When possible, writers can use an asynchronous version of <code>synchronize_rcu</code>, <code>call_rcu</code>, that will asynchronously invokes a specified callback after all CPUs have passed through at least one context switch.</li> <li>The Linux RCU implementation tries to amortize the cost of detecting context switches over many <code>synchronize_rcu</code> and <code>call_rcu</code> operations. Detecting context switches requires maintaining state shared between CPUs. A CPU must update state, which other CPUs read, that indicate it executed a context switch. Updating shared state can be costly, because it causes other CPUs to cache miss. RCU reduces this cost by reporting per-CPU state roughly once per scheduling clock tick. If the kernel calls <code>synchronize_rcu</code> and <code>call_rcu</code> many times in that period, RCU will have reduced the average cost of each call to <code>synchronize_rcu</code> and <code>call_rcu</code> at the cost of higher latency. Linux can satisfy more than 1,000 calls to <code>synchronize_rcu</code> and <code>call_rcu</code> in a single batch [22]. For latency sensitive kernel subsystems, RCU provides expedited synchronization functions that execute without waiting for all CPUs to execute multiple context switches.</li> </ul>"},{"location":"notes/linux/linux-rcu/#how-to-use-rcu","title":"How to use RCU?","text":"<p>After reading several RCU code snippets, it is not hard to notice that they have a common theme. Especicially for the List related operations, there is no final atomic modification in the updater thread. This atomic update serves as a barrier. The reaeders rely on this pointer to grab info pointed by this pointer. This is very important trick to leverage RCU. If you code is not like, you should add this level of indirection, package your data behind a pointer and modify the reader to follow the pointer.</p> <p>Also, the List RCU related operations may seem confusing in the start, because, naturally, we\u2019d think there are so many operations inside list walk, insert and removal, how come they are safe? The catch is that, usually for readers who are doing list-walk, they only use the <code>next</code> pointer. So for <code>insert</code> and <code>removal</code>, they only need to gurantee the of <code>next</code>, meaning, they need to make sure that the list/data is correct (no NULL pointer) for both before and after updaing <code>next</code> pointer. And this is sufficient for readers!</p> <p>In all, changing to RCU requires a good understanding on your own logic. If your data structrue is not packaged, package it behind some pointers. And make sure the readers integrity can be ensured by relying on this single pointer.</p> <p>One more thing is Reader Retry. It is obvious that the readers might see stale data. So it is up to the designers to retry. The designer can rely on the Sequence Lock for this purpose for example.</p> <p>You can read the RCU usage paper for more suggestions.</p>"},{"location":"notes/linux/linux-rcu/#code-reading","title":"Code Reading","text":"<p>This section is my note on the actual codes. There are two possible implementations: tiny and tree. Tiny is for UP system. Tree is the most standard one. So I will be looking into <code>kernel/rcu/tree.c</code> first</p> <p>My general approach to new code: 1) look top and bottom of the file. Top usually defines some importnat global variables. Bottom usually has the init functions, which could tell us what\u2019s going on, what threads are created etc. Then I scroll up from bottom.</p> <ul> <li><code>gp</code> stands for Grace Period</li> </ul> <p>Important Data Structrues and Threads</p> <ul> <li>One global <code>struct rcu_state</code>. Init by <code>rcu_init_one()</code>. See <code>include/linux/rcu/tree.h</code> for detailed comments.</li> <li>Per CPU <code>struct rcu_data</code>.</li> <li><code>struct rcu_node</code></li> <li>There is thread called <code>rcu_gp_kthread()</code>, comment says this is a kthread that handles grace period. Shouldn\u2019t there be one per CPU? Why there is just one though?</li> </ul> <p>Initialization</p> <ul> <li><code>rcu_init()</code></li> <li>I saw <code>rcutree_online_cpu()</code> and <code>rcutree_offline_cpu()</code>. The core seems to be the <code>rnp-&gt;ffmask</code>, the <code>ffmask</code>.   It appears this mask represent the cpu status in RCU subsystem. Pay attention to it later.</li> <li><code>rcutree_prepare_cpu()</code>: init per-CPU RCU data (<code>rcu_data</code>). I have no idea what those fields in rcu_data are doing. And it is re-loading quite some info from the global <code>rcu_state</code>.</li> </ul> <p>Core</p> <p>It seems <code>rnp-&gt;gp_seq</code> != <code>rdp-&gt;gp_seq</code> means a grace period is started? Based on various functions, it appears that if they need a grace period, they will invoke the <code>rcu_gp_kthread()</code>!</p> <p>Inside <code>rcu_gp_kthread()</code> it is just a big loop. It constantly sleeps. Once waken up, it will use <code>rcu_gp_init()</code> to actuallt start a grace period! Quite heavy. The core seems to be <code>rcu_seq_start(&amp;rcu_state.gp_seq);</code>: update the <code>gp_seq</code>, the VERY variable that others use to check grace period. Think this is it. Now I still need to figure out how grace period got integrated into <code>synchronize_rcu</code>.</p> <p>So inside <code>synchronize_rcu()</code>, the main thing is <code>wait_rcu_gp()</code>, seems waiting for the grace period to finish. Ah we are getting close. The <code>wait_rcu_gp()</code> takes the <code>call_rcu()</code> function as a parameter. The <code>call_rcu()</code> queues an RCU callback for invocation AFTER a grace period (YES! Makes sense. So now, we know who is creating grace period - that above kthread and where we are waiting).</p> <p>For <code>__wait_rcu_gp()</code>, I don\u2019t understand much other than this complicated function callback. <pre><code>(crcu_array[i])(&amp;rs_array[i].head, wakeme_after_rcu);\n</code></pre></p> <p>Note, if we are calling from <code>synchronize_rcu</code>, this <code>crcu_array[i]</code> is essentially <code>call_rcu()</code> function. So the above callback essentially becomes: <pre><code>call_rcu(&amp;rs_array[i].head, wakeme_after_rcu);\n</code></pre></p> <p>In <code>__call_rcu</code>, I think the core is the following couple lines. It packages the incoming function callback and enqueue into the rcu segcblist. Not only <code>synchronize_rcu()</code> calls <code>call_rcu()</code>, any kernel code can call this to register a function to, say, free an object! Nice. Since callbacks MUST be called after it is safe to do so, meaning all CPUs have context switched. So we should find the place where callbacks are run. <pre><code>__call_rcu()\n    ...\n    head-&gt;func = func;\n    head-&gt;next = NULL;\n    ...\n    rcu_segcblist_enqueue(&amp;rdp-&gt;cblist, head);\n    ..\n</code></pre></p> <p>Now try to find the place run callbacks. First up, examine the enqueue function. ThenIn the following func, the <code>rsclp-&gt;tails</code> caught my eye. Follow this. <pre><code>void rcu_segcblist_enqueue(struct rcu_segcblist *rsclp,\n               struct rcu_head *rhp)\n{\n    rcu_segcblist_inc_len(rsclp);\n    rcu_segcblist_inc_seglen(rsclp, RCU_NEXT_TAIL);\n    rhp-&gt;next = NULL;\n    WRITE_ONCE(*rsclp-&gt;tails[RCU_NEXT_TAIL], rhp);\n    WRITE_ONCE(rsclp-&gt;tails[RCU_NEXT_TAIL], &amp;rhp-&gt;next);\n}\n</code></pre></p> <p>Since someone MUST call these callbacks after grace period. If we found that place, we will know which code represent the end of grace period. So I search for <code>func</code> and <code>tails</code>. Bang, we are in <code>rcu_do_batch()</code>. As you can see, it will walk through the callback list and run one by one. Note this callbacks come from either other kernel code or rcu itself. This callback is short, usually free the object or complete sth. <pre><code>/*\n * Invoke any RCU callbacks that have made it to the end of their grace\n * period.  Throttle as specified by rdp-&gt;blimit.\n */\nstatic void rcu_do_batch(struct rcu_data *rdp)\n{\n    ...\n\n    /* Invoke callbacks. */\n    tick_dep_set_task(current, TICK_DEP_BIT_RCU);\n    rhp = rcu_cblist_dequeue(&amp;rcl);\n\n    for (; rhp; rhp = rcu_cblist_dequeue(&amp;rcl)) {\n        ...\n        f = rhp-&gt;func;\n        WRITE_ONCE(rhp-&gt;func, (rcu_callback_t)0L);\n        f(rhp);\n        ...\n    }\n    ...\n}\n</code></pre></p> <p>Now we should find who calls <code>rcu_do_batch</code>. It is called by <code>rcu_core()</code> only, which is called by <code>rcu_cpu_kthread()</code>.</p> <p>This <code>rcu_cpu_kthread()</code> is different from the <code>rcu_gp_thread</code> (the one who START grace period). This function is registered via the <code>smpboot_regsiter_percpu_thread()</code> framework. This framework creates an internal thread repeatly calling the registered callbacks. So <code>rcu_cpu_kthread()</code> is actually running in a loop! It is just that the Loop logic is within the smpbook framework. It runs if <code>rcu_data.rcu_cpu_has_work</code> is 1, which is only set by <code>invoke_rcu_core_kthread()</code>. <pre><code>/*\n * Wake up this CPU's rcuc kthread to do RCU core processing.\n */\nstatic void invoke_rcu_core(void)\n{\n    if (!cpu_online(smp_processor_id()))\n        return;\n    if (use_softirq)\n        raise_softirq(RCU_SOFTIRQ);\n    else\n        invoke_rcu_core_kthread();\n}\n</code></pre></p> <p>So, WHOEVER calls <code>invoke_rcu_core()</code> should be the one checking whether a grace period has expired!!</p> <p>The cloest caller I found is this. The description is inline with what the RCU usage paper said. They do batch processing every scheduling-tick. Pay attention to  <code>rcu_pending()</code>. So <code>rcu_pending()</code> checks if there is any RCU-related work to be done. If so, call <code>invoke_rcu_core()</code> to do all the callbacks. I mean, <code>rcu_pending()</code> should mean a grace period has ended, right? <pre><code>/*\n * This function is invoked from each scheduling-clock interrupt,\n * and checks to see if this CPU is in a non-context-switch quiescent\n * state, for example, user mode or idle loop.  It also schedules RCU\n * core processing.  If the current grace period has gone on too long,\n * it will ask the scheduler to manufacture a context switch for the sole\n * purpose of providing the needed quiescent state.\n */\nvoid rcu_sched_clock_irq(int user)\n{\n    ...\n    if (rcu_pending(user))\n        invoke_rcu_core();\n    ...\n}\n</code></pre></p> <p>Go for <code>rcu_pending()</code>. Though it checks grace period but it appears it does not check whether it ended or not. Maybe my fundamental understanding about the grace period impl is not correct. <pre><code>/*\n * Check to see if there is any immediate RCU-related work to be done by\n * the current CPU, returning 1 if so and zero otherwise.  The checks are\n * in order of increasing expense: checks that can be carried out against\n * CPU-local state are performed first.  However, we must check for CPU\n * stalls first, else we might not get a chance.\n */\nstatic int rcu_pending(int user)\n{\n    ...\n    gp_in_progress = rcu_gp_in_progress();\n    ..\n}\n\n/*\n * Return true if an RCU grace period is in progress.  The READ_ONCE()s\n * permit this function to be invoked without holding the root rcu_node\n * structure's -&gt;lock, but of course results can be subject to change.\n */\nstatic int rcu_gp_in_progress(void)\n{\n    return rcu_seq_state(rcu_seq_current(&amp;rcu_state.gp_seq));\n}\n</code></pre></p> <p>I must have missed a lot important connections, most importantly,  how they ensure all CPUs have experienced a context switch  and how exactly grace period is used here, meaning how it enforce things? I do see a lot of callback registerd and those callbacks usually are very simple, mostly do the <code>complete()</code> call.</p> <p>And the whole RCU subsystem has several data structures, <code>rcu_data</code>, <code>rcu_node</code> etc. And several threads, <code>rcu_gp_kthread()</code>, who advances grace period. <code>rcu_cpu_kthread()</code>  who actually run the registered callbacks from call_rcu/synchronize_rcu.</p> <p>Anyway this is conclusion for me, for now (Oct 24, 2021). I might look into the userspace impl later. Nonetheless the core of <code>synchronize_rcu()</code> is fairly simple: make sure a grace period has gone (e.g., all other CPUs have context switched). But a real efficient implementation is quite complicated, esp in Linux kernel.</p>"},{"location":"notes/linux/linux-rcu/#after-thought","title":"After Thought","text":"<p>Finished code reading.</p> <p>So it appears that for normal kernel code, use <code>call_rcu()</code> to register a callback is better than <code>synchronize_rcu()</code>. The former simply register the callback (e.g., free an object) and returns. The callback will be invoked once a grace period has expired. On the other hand, <code>synchronize_rcu()</code> is synchronize, it waits a grace period has actually passed. For most code, this is not necessary, as most code just want to do some cleanup code, as long as it is done.</p>"},{"location":"notes/linux/linux-resource/","title":"Linux Kernel Resource","text":"Version History Date Description Mar 13, 2020 add lkt, nice Oct 7, 2019 Feels like I need to start thi"},{"location":"notes/linux/linux-resource/#high-level","title":"High-level","text":"<ul> <li>Linux Kernel Teaching</li> <li>The Linux Storage Stack Diagram</li> <li>Linux kernel map</li> </ul>"},{"location":"notes/linux/linux-resource/#sched","title":"Sched","text":"<ul> <li>Evolution of the x86 context switch in Linux</li> </ul>"},{"location":"notes/linux/linux-resource/#memory-management","title":"Memory Management","text":"<ul> <li>Memory: the flat, the discontiguous, and the sparse</li> <li>Reducing page structures for huge pages</li> </ul>"},{"location":"notes/linux/linux-resource/#misc","title":"Misc","text":"<ul> <li>Why printk() is so complicated (and how to fix it)<ul> <li>Slide.</li> </ul> </li> <li>Special sections in Linux binaries, 2013</li> </ul>"},{"location":"notes/linux/linux-resource/#storage","title":"Storage","text":"<ul> <li>i10, good NVMe code</li> </ul>"},{"location":"notes/linux/linux-rust/","title":"Rust in Linux","text":"Version History Date Description Nov 1, 2021 new <p>Nov 1, 2021. I know very little about Rust, only has read its documentation. But I\u2019m curious as hell on how to develop a kernel module in Rust. There was a lot buzz last year. I will try to take a look some time soon.</p>"},{"location":"notes/linux/linux-workqueue/","title":"Linux Work Queue","text":"Version History Date Description Oct 29, 2021 Initial <p>NOTE: like a lot of my other notes. This is written for myself. The note is not a high-level summary. It documents my journery on reading the source code and gradually understand the workqueue subsystem. I wrote it sequentially and I ask questions. Most of the questions are answered in a later section.</p> <p>My simple testing code is here: https://github.com/lastweek/linux-sample-modules/tree/master/workqueue.</p>"},{"location":"notes/linux/linux-workqueue/#intro","title":"Intro","text":"<p>Work queue is a generic async execution with shared worker pool in linux kernel. It does what is designed to do, it runs \u201cyour function\u201d across a set of worker threads. The subsystem is huge. As of v5.9, the <code>workqueue.c</code> has more than 6K lines of code.</p> <p>The internal documentation is at <code>Documentation/core-api/workqueue.rst</code>.</p> <p>Think about how would you design the thread pool and interfaces to submit work to it. I have designed one in LegoOS. The basic infrastructure is not hard, basically playing around various queues. The tricky part is to get the concurrency right, and various corner cases. Also, NUMA affinity, multiple thread pools etc features add more complexity. But the important thing is to understand the core!</p> <p>Public APIs</p> <ul> <li><code>alloc_workqueue()</code></li> <li><code>queue_work()</code></li> </ul>"},{"location":"notes/linux/linux-workqueue/#key-data-structures-and-functions","title":"Key Data Structures and Functions","text":"<p>Data Structures</p> <ul> <li><code>struct work_struct</code>, the work item, including the func</li> <li><code>struct worker</code>, the actual worker thread<ul> <li>has a <code>struct task_struct *task</code></li> </ul> </li> <li> <p><code>struct worker_pool</code>, multiple workers can form a pool</p> </li> <li> <p>So it looks like there 2 worker pools per cpu, and it is accessed by macro. But can we create more pools? <pre><code>NR_STD_WORKER_POOLS = 2\n/* the per-cpu worker pools */\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct worker_pool [NR_STD_WORKER_POOLS], cpu_worker_pools);\n\n\n#define for_each_cpu_worker_pool(pool, cpu)             \\\n    for ((pool) = &amp;per_cpu(cpu_worker_pools, cpu)[0];       \\\n         (pool) &lt; &amp;per_cpu(cpu_worker_pools, cpu)[NR_STD_WORKER_POOLS]; \\\n         (pool)++)\n</code></pre></p> </li> <li> <p><code>workqueues</code> is a list of all workqueues <pre><code>static LIST_HEAD(workqueues);       /* PR: list of all workqueues */\n</code></pre></p> </li> </ul>"},{"location":"notes/linux/linux-workqueue/#create-workers","title":"Create workers","text":"<p>The first is I want to understand is how workers are created, and how many of them are created. I think I will do a bottom-up fashion instead of top-down. So I started from the function to create a single worker, then I check who calls it.</p> <p>The <code>create_worker()</code> - creates a worker thread. The steps are straightforward. Calling into <code>kthread_create</code>, attach it to a <code>worker_pool</code>. So this is how worker and pool got connected. <pre><code>static struct worker *create_worker(struct worker_pool *pool)\n{\n...\n\n    worker-&gt;task = kthread_create_on_node(worker_thread, worker, pool-&gt;node,\n                          \"kworker/%s\", id_buf);\n\n\n    /* successful, attach the worker to the pool */\n    worker_attach_to_pool(worker, pool);\n\n\n    /* start the newly created worker */\n    raw_spin_lock_irq(&amp;pool-&gt;lock);\n    worker-&gt;pool-&gt;nr_workers++;\n    worker_enter_idle(worker);\n    wake_up_process(worker-&gt;task);\n    raw_spin_unlock_irq(&amp;pool-&gt;lock);\n...\n}\n</code></pre></p> <p>The <code>worker_attach_to_pool()</code> is quite simple, just some list op. <pre><code>    list_add_tail(&amp;worker-&gt;node, &amp;pool-&gt;workers);\n    worker-&gt;pool = pool;\n</code></pre></p> <p>Okay, now I want to see who calls <code>create_worker()</code>. It is a static function, so only called within this file. Cool.</p> <p>First off, it is called by <code>workqueue_init()</code>, during startup. So here looks like it is creating a worker for the per-cpu pools (2 pools per cpu). What are those workers for though? <pre><code>void __init workqueue_init(void)\n{\n...\n    /* create the initial workers */\n    for_each_online_cpu(cpu) {\n        for_each_cpu_worker_pool(pool, cpu) {\n            pool-&gt;flags &amp;= ~POOL_DISASSOCIATED;\n            BUG_ON(!create_worker(pool));\n        }\n    }\n\n    hash_for_each(unbound_pool_hash, bkt, pool, hash_node)\n        BUG_ON(!create_worker(pool));\n...\n}\n</code></pre></p> <p>Anyways, it is also called within <code>workqueue_prepare_cpu()</code>, which is a callback for cpu hotplug. Skip. Also called by <code>maybe_create_worker()</code>, which seems to be called within worker thread itself to create another worker within a pool. I\u2019m not sure whether the initial workers we created in <code>workqueue_init()</code> will create those during runtime..</p> <p>Anyways, the final caller is <code>get_unbound_pool()</code>. Looks promising. It does says <code>start the initial worker</code>. So follows the caller of <code>get_unbound_pool()</code>. <pre><code>/**\n * get_unbound_pool - get a worker_pool with the specified attributes\n * @attrs: the attributes of the worker_pool to get\n ..\n */\nstatic struct worker_pool *get_unbound_pool(const struct workqueue_attrs *attrs)\n{\n    ...\n    /* create and start the initial worker */\n    if (wq_online &amp;&amp; !create_worker(pool))\n        goto fail;\n    ...\n}\n</code></pre></p> <p>The <code>get_unbound_pool()</code> is called by <code>alloc_unbound_pwq()</code> only. It seems to be creating <code>struct pool_workqueue</code>. This structure, seems a wrapper around <code>struct worker_pool</code>?</p> <p>Okay, seem this is it. I\u2019m going to do top-down. Start from the public API. <code>apply_workqueue_attrs()</code> is easy to understand. It gots the workqueue entry and some attributes and then do some work based on that.</p> <p>I just want to understand what will be created if one calls <code>alloc_workqueue</code>. Well, it looks like inside <code>apply_wqattrs_prepare()</code>, it is looping over nodes. So it appears end of the day, it is one create_worker per node? I thought it is per cpu? Well, I could try it out and see.</p> <pre><code>alloc_workqueue()               - Public API\n  -&gt; alloc_and_link_pwqs(struct workqueue_struct *wq)\n    -&gt; apply_workqueue_attrs(workqueue_struct, workqueue_attrs)\n        -&gt; apply_workqueue_attrs_locked(workqueue_struct, workqueue_attrs)\n            -&gt; apply_wqattrs_prepare() *****\n                -&gt; alloc_unbound_pwq()\n                    -&gt; get_unbound_pool()\n                        -&gt; create_worker()\n</code></pre> <p>Actually, look closely into <code>get_unbound_pool()</code>. It actually has quite some logic before calling into <code>create_worker()</code>. This logic is checking whether we already have a matching pool and return early. And this is why our <code>alloc_workqueue()</code> won\u2019t create kworker right away. But I\u2019m wondering whether it creates later on.. Any way, I\u2019m done!</p>"},{"location":"notes/linux/linux-workqueue/#the-worker","title":"The worker","text":"<p>The worker is created by the function <code>create_worker()</code>. Duh. The worker thread is fairly straightforward, it repeatly sleep, wakeup, check if there are any pending work, do it, sleep. It appears that workers get work from the <code>struct worker_pool</code>. So now I understand what the pool concept is used here. And, it sorts of also answered my earlier question: the workers are generic and it appears <code>alloc_workqueue</code> actually will not create new threads. New users reuse the old worker threads. Though the worker may create more depends on load (that func is simple too..).</p> <pre><code>/**\n * worker_thread - the worker thread function\n * @__worker: self\n *\n * The worker thread function.  All workers belong to a worker_pool -\n * either a per-cpu one or dynamic unbound one.  These workers process all\n * work items regardless of their specific target workqueue.  The only\n * exception is work items which belong to workqueues with a rescuer which\n * will be explained in rescuer_thread().\n *\n * Return: 0\n */\nstatic int worker_thread(void *__worker)\n{\n    struct worker *worker = __worker;\n    struct worker_pool *pool = worker-&gt;pool;\n\n    ...\n\n    do {\n        //\n        // Yizhou:\n        // See, we are dequeuing work from the pool\n        // So, we can check who/when enqueue into worklist\n        //\n        struct work_struct *work =\n            list_first_entry(&amp;pool-&gt;worklist,\n                     struct work_struct, entry);\n\n        pool-&gt;watchdog_ts = jiffies;\n\n        if (likely(!(*work_data_bits(work) &amp; WORK_STRUCT_LINKED))) {\n            /* optimization path, not strictly necessary */\n            process_one_work(worker, work);\n            if (unlikely(!list_empty(&amp;worker-&gt;scheduled)))\n                process_scheduled_works(worker);\n        } else {\n            move_linked_works(work, &amp;worker-&gt;scheduled, NULL);\n            process_scheduled_works(worker);\n        }\n    } while (keep_working(pool));\n}\n</code></pre> <p>So, checking out <code>worklist</code>. It is simply modified by <code>__queue_work()</code>. Now the last question, I guess, is to figure out how <code>__queue_work()</code> decide which pool to insert the new work into.</p> <p>The <code>__queue_work()</code> only gets the <code>wq</code> returned by <code>alloc_workqueue()</code>. Let\u2019s see. Ok, looks like there are quite a lot flags controlling these. <code>WQ_UNBOUND</code>, <code>WORK_CPU_UNBOUND</code> and so on. These flags control, sort of, which pool to use.</p>"},{"location":"notes/linux/linux-workqueue/#todo","title":"TODO","text":"<p>I need to try it out.</p>"},{"location":"notes/linux/linux-workqueue/#references","title":"References","text":"<ul> <li>https://events.static.linuxfound.org/sites/events/files/slides/Async%20execution%20with%20wqs.pdf </li> </ul>"},{"location":"notes/linux/linux-x86-fpu/","title":"Linux/LegoOS x86 Floating Point Unit","text":"Version History Date Description Jan 9, 2021 repolished after reading the why mmap is faster syscall post. Indeed, the difference is that mmap is using user-level AVX-aided memmove while kernel cannot. This reminded me of this post so I decided to move it to here. Feb 22, 2018 Initial Version <p>This blog documents how kernel is dealing with x86 FPU at a high level.</p> <p>FPU is heavily used by user level code, but not kernel. You may not use it directly, but glibc is using it all over the place, e.g. the <code>strcmp</code>, <code>memcpy</code>. x86 FPU is really a super complex technology designed by Intel. Of course its performance is good and also widely used, but the legacy compatible feature? Hmm, not so yummy.</p> <p>Without Ingo Molnar\u2019s x86 FPU code rewrite, there is no way for me to easily understand it. In 2019, the FPU code received another huge improvement (patch).</p> <p>The current x86 FPU code is well-written. Even though I don\u2019t understand some of the low-level code, I do enjoy reading it. The naming convention, the code organization, the file organization, the header files, it is a nice piece of art.</p> <p>Below I will briefly list kernel subsystems that use FPU. My understanding is based on code before the 2019 FPU patch, so some facts may have changed already.</p>"},{"location":"notes/linux/linux-x86-fpu/#boot","title":"Boot","text":"<p>FPU detection and init happen during early boot. The <code>struct fpu</code> is a dynamically-sized structure. Its size depends on what features the underlying CPU support. Since <code>struct fpu</code> is part of <code>struct task_struct</code>, that implies <code>task_struct</code> is dynamically-sized as well (<code>task_struct -&gt; thread_struct -&gt; fpu</code>). The <code>cpu_init()</code> will also callback to init its local FPU.</p>"},{"location":"notes/linux/linux-x86-fpu/#context-switch","title":"Context Switch","text":"<p>FPU consists of a huge amount of registers. Each thread will have its own FPU context. However, the CPU itself will not save or restore any FPU registers automatically, it is software\u2019s duty to save and restore FPU context properly. And FPU context/registers are saved into <code>struct fpu</code>.</p> <p>Thus whenever we switch task, we also need to switch FPU context (note: not always, it is optional, kernel is using a lazy switching trick). Code: <pre><code>__visible struct task_struct *\n__switch_to(struct task_struct *prev_p, struct task_struct *next_p)\n{\n        ..\n        fpu_switch = switch_fpu_prepare(prev_fpu, next_fpu, cpu);\n        ..\n        switch_fpu_finish(next_fpu, fpu_switch);\n        ..\n}\n</code></pre></p>"},{"location":"notes/linux/linux-x86-fpu/#syscall","title":"SYSCALL","text":"<ul> <li>fork() and clone(): When a new thread or process is created, the FPU context is copied from the calling thread.</li> <li>execve(): during this syscall, the FPU context will be cleared.</li> <li>exit(): When a thread exit, FPU will do cleanup based on whether <code>eagerfpu</code> or <code>lazyfpu</code> is used.</li> </ul>"},{"location":"notes/linux/linux-x86-fpu/#exceptions","title":"Exceptions","text":"<p>Like the <code>device not available</code> exception, which may be triggered if lazyfpu is used. The <code>do_simd_exception()</code> and <code>do_coprocessor_error()</code> are some math related exceptions.</p>"},{"location":"notes/linux/linux-x86-fpu/#signal","title":"Signal","text":"<p>Kernel needs to setup a <code>sigframe</code> for user level signal handlers. <code>sigframe</code> is a contiguous stack memory consists of the general purpose registers AND FPU registers. So signal handling part has to call back to FPU code to setup and copy the FPU registers to the in stack <code>sigframe</code>.</p> <p>Signal handling is another beast.</p>"},{"location":"notes/linux/linux-x86-fpu/#thoughts","title":"Thoughts","text":"<p>Compatibility is a heavy thing to carry. But it is also a nice thing for marketing. No one can deny the success of Intel on its backward compatibility. Bad for low-level system developers.</p>"},{"location":"notes/linux/linux-x86-fpu/#references","title":"References","text":"<ol> <li>https://unix.stackexchange.com/questions/475956/why-can-the-kernel-not-use-sse-avx-registers-and-instructions</li> <li>2019 FPU patch: https://lkml.org/lkml/2019/4/3/877</li> </ol>"},{"location":"notes/rust/rust/","title":"Rust","text":"Version History Date Description Nov 5, 2021 Initial <p>I starting to learn Rust again lol. I\u2019m learing Rust and Go at the same time.</p>"},{"location":"notes/source_code/20200501-on-graphic-softwares/","title":"On Unix Graphic Softwares","text":"Version History Date Description Dec 4, 2020 Add high level libaries May 1, 2020 Initial Version"},{"location":"notes/source_code/20200501-on-graphic-softwares/#part-i","title":"Part I","text":"<p>For work reason, I use VNC a lot recently. I need to login into our lab\u2019s servers and perform intensive graphic operations. Somehow I\u2019m not a fan of GUI-based systems, but it really got me wonder: how VNC works? Or, how graphics/GUI works in general?</p> <p>So I decided to look it up. The whole thing was very complex to me at the beginning. There are numerous layers of systems, and it not clear who is doing what. After getting a better understanding, I realize it is \u201cdo one thing and do it well\u201d works at its best: Each layer of the graphic stack is doing what it is supposed to do, nothing more and nothing less. Even though the line blurred over the years (i think), the principle persists. I like it.</p> <p>I\u2019m no where near explaing the whole thing well (still a bit confused myself :)). But you can find awesome references at:</p> <p>1) Wiki Display Server, 2) Wayland Architecture 3) StackExchange Difference between Xorg and Gnome/KDE/Xfce 4) https://en.wikipedia.org/wiki/Free_and_open-source_graphics_device_driver</p> <p>Following are some figures I drew to show the architecture of all these softwares. In the graphic world, kernel\u2019s involvement is minimal, but a critical one. Kernel mainly need to deliver mouse/keyboard events, render frames via graphic cards, handle network. In other words, kernel provides a mechanism. The policy is left to userspace stacks.</p> <p>At the lowest level, we have Display Manager, or Display Server. Downstream, this layer interact with kernel, i.e., getting keyboard/mouse events from kernel evdev framework, rendering frames via DRM interfaces. Upstream, this layer accepts request from their clients (i.e., the widget layer) and make them happen in real displays. Typical systems at this layer are X.org server and Wayland. They follow the client-server model, communication has a certain protocol and is via socket (I guess?). </p> <p>Next up, is the widget toolkit, or UX library layer. The famous GTK/Qt belong to this layer. What this layer is doing? So this one is a collection of widgets, like buttons, menu, dropdown, i.e., GUI elements. Both GTK/Qt offer a lot such stuff (if you are using GNOME desktop, try run <code>gtk3-widget-factory</code>). This layer ask the display manager layer (e.g. X.org server) to display stuff.</p> <p>GNOME/KDE are desktop envionment, they present the whole desktop experience, it includes many applications built based on GTK and Qt, respectively. You probably have seen <code>gnome-shell</code>, yup, this is GNOME\u2019s main program.</p> <p>The highest layer is user applications, like Chrome (which by default uses GTK on linux, code on <code>ui/gtk</code>). All these linux GUI applications, they are usually built on top of either GTK or Qt\u2019s libraries. That being said, if you want to develop GUI-based apps on Linux, chances are, you will use either of the libraries.</p> <p>This is a landscape overview: </p> <p>But how VNC fits into the big picture? In short, VNC sits in the middle between X and GTK/Qt. On one hand, VNC appears as a client of X. On the other, VNC appears as an X server to GTK/Qt. Middleman works at its best lol. There are, however, many different implementation choices. If you have used TigerVNC, which in turn uses Xvnc, its man page says: Xvnc is the X VNC (Virtual Network Computing) server. It is based on a standard X server, but it has a \u201cvirtual\u201d screen rather than a physical one. X applications display themselves on it as if it were a normal X display, but they can only be accessed via a VNC viewer - see vncviewer(1). So Xvnc is really two servers in one. To the applications it is an X server, and to the remote VNC users it is a VNC server.</p> <p>Thus it looks like this with VNC: </p> <p>A machine have multiple such instances, thus multiple virtual and physical display can coexist. And for that, I think it\u2019s all because of the clear separation of layers and good engineering (man, those graphic framebuffer code is monstrous): </p> <p>This post remind me of \u201cWhat happens when you type google.com into your browser and press enter?\u201d?</p> <p>As always, hope you enjoyed this blog.</p>"},{"location":"notes/source_code/20200501-on-graphic-softwares/#part-ii","title":"Part II","text":"<p>This part wants to look at those high-level libaries used by developers every day. I somewhat got interested when I started playing Steam games and saw \u201cVulkan Shaders\u201d.</p> <p>Vulkan is an alternative system to OpenCL/Direct3D. Instead of hiding details, Vulkan expose quite a lot low-level details and let programmers do the tuning.</p> <p>So, what\u2019s the difference between Vulkan/OpenCL/Direct3D with gtk/Qt? I guess the former is for graphic development, any shape. While the latter is some predefined gadgets and a framework for developing standadrd GUI apps?</p>"},{"location":"notes/source_code/compilers/","title":"Compilers","text":"Version History Date Description Oct 16, 2021 Move compilers section from the summary file <p>The general ones:</p> <ul> <li>Clang, LLVM, in C++<ul> <li>This is a collection of projects. Clang is the frontend, compiles C/C++ code into LLVM\u2019s own IR format. The the backend LLVM will take multiple Passes to optimize the IR and the finally generate the assembly.</li> <li>The beauty of Clang and LLVM is that they can be used as libraries, and we could invoke them to manipulate the compilation results, to do source-to-source transforms, modify Pass\u2019s IR etc. I found this super interesting!</li> <li>To get started, I strongly recommend LLVM for Grad Students</li> </ul> </li> <li>OpenJDK</li> <li>CPython</li> <li>GNU GCC</li> <li>Rustc, in Rust</li> <li>PHP, in C</li> <li>Google V8, in C++</li> <li>Apple Swift, in C++</li> <li>TCL, in C</li> <li>Perl 5, in C</li> <li>Lua, in C</li> <li>Ruby, in C</li> <li>Scala</li> <li>SpinalHDL</li> </ul>"},{"location":"notes/source_code/compilers/#cpython","title":"CPython","text":"<p>Today (Oct 14, 201) I was reading Hacker News and came across this post A viable solution for Python concurrency. It was about removing the Global Interpreter Lock (GIL) in the cpython compilers. Quite interesting. The technique is to use Biased Atomic Reference Accounting. Basically, it uses non-atomic operation if it is single-thread so to avoid the cost of atomic instructions. But for multiple thread case, it will normal atomic instructions (which will be much better the original GIL implementation).</p> <p>So I decide to take another look at the cpython source code, which I have cloned (repo)quite a while ago when I had a broken leg. Once I decided to read the code, I google some cpython internals and these links pop up quite nicely. There are A LOT good contents out there, I probably don\u2019t have time reading that now.</p> <p>I briefly read the code, a lot typedefs for sure. The <code>PyStatus</code> structure is interesting. And the way they organize the repo is also interesting. For a common python library, say csv, there will a python library file under <code>Lib/csv.py</code>, then optionally a C accelerated version in <code>Modules/_csv.c</code>. Essentially the whole thing is built like a Exokernel, the base is written in C for performance and portability among OSes. Then a more rich python wrapper on top of that, which will be the default built-in python libraries we use day-to-day.</p> <p>For those common built-in functions, they are organized here</p> <ol> <li>Your Guide to the CPython Source Code</li> <li>Exploring CPython\u2019s Internals</li> <li>Design of CPython\u2019s Compiler</li> <li>Yet another guided tour of CPython</li> </ol>"},{"location":"notes/source_code/compilers/#java","title":"Java","text":"<ul> <li> <p>OpenJDK</p> <ul> <li>JRE = JVM + Runtime Classes =&gt; JVM is the one parsing the bytecode, along with some extra classes/libraries, they form JRE.</li> <li>JDK = JRE + Development Tools =&gt; JDK as in Development Kit therefore consists of some tools in addition to JRE.</li> <li>JDK is a monster collection of resources in one place.   The JVM here is called <code>HotSpot</code>, a reference JVM implementation written in C++,   Since JDK also has so many runtime support, it has a lot Java code.</li> <li>Personally I haven\u2019t written Java since 2013 or so.   Although I\u2019m not using it anytime soon, I\u2019m curious how it performs nowadays.</li> <li>The repo is VERY WELL organized. see <code>src/</code></li> </ul> </li> <li> <p>HotSpot JVM</p> <ul> <li>This one is included in the OpenJDK Repo, written in C++.</li> <li>e.g., the GC code is under <code>src/hotspot/share/gc</code>.</li> </ul> </li> <li> <p>Eclipse Openj9 JVM</p> <ul> <li>A JVM for OpenJDK that\u2019s optimized for small footprint, fast start-up, and high throughput</li> </ul> </li> <li> <p>ASM</p> <ul> <li>ASM is an all purpose Java bytecode manipulation and analysis framework.</li> <li>It can be used to modify existing classes or to dynamically generate classes, directly in binary form.</li> </ul> </li> </ul> <p>All these OpenJDK components follow the Java Language Spec and JVM Spec.</p> <p>An important note: Java is NOT the only language that can run on a JVM. A lot of other languages are using JVM as well! Such as Kotlin, Scala, Clojure etc. I think the reason is that JVM is production-ready and proven to be stable across platforms. If a new language compiles into JVM bytecode, then this new language can instantly run all architectures. Without it, the new language\u2019s compiler needs to emit different ISA\u2019s assembly, which is difficult and quite an effort.</p>"},{"location":"notes/source_code/compilers/#jvm-based-languages","title":"JVM-based Languages","text":"<p>There is a List of JVM languages: This list of JVM Languages comprises notable computer programming languages that are used to produce computer software that runs on the Java virtual machine (JVM). Some of these languages are interpreted by a Java program, and some are compiled to Java bytecode and JIT-compiled during execution as regular Java programs to improve performance. The most popurlar ones are: 1) Java, 2) Groovy, 3) Scala, 4) Clojure, 5) Kotlin.</p> <p>So follow up on the Java section, I want to spend some time on JVM-based languages, the rationale and benefits behind it, and how should one create a new language on JVM. Great explanation here.</p> <p>JVM is a virtual MACHINE, with its own machine model and ISA. Hence it has assembly instructions and assmeblers (e.g., Jasmin) compiling annoted assembly into Java class file / bytecode (or binary for the JVM, in some sense). Some people seem to use Java ASM tool to generate bytecode as well.</p> <p>Several blogs I found via google that try to build a new language on top of JVM. There must be more. 1) https://github.com/ftomassetti/LangSandbox, 2) http://jakubdziworski.github.io/categories.html#Enkel-ref</p>"},{"location":"notes/source_code/dotconfigs/","title":"Dot Configs","text":"Version History Date Description Dec 17, 2020 started <p>Like many others, I maintain my own dot-file repo: https://github.com/lastweek/dot-home. It helps me setup the terminal whenever I start using a new machine.</p> <p>I\u2019m a heavy terminal user. For whatever coding task (e.g., kernel, RDMA, FPGA, scala, C), I use terminal. I sometimes use terminal to write paper as well.</p> <p>There are several important tools I rely on: zsh, git, neovim, and tmux. And I\u2019m grateful for folks working on these tools and their plugins.</p> <ul> <li>For zsh, I use oh-my-zsh.</li> <li>For git, I use git alias.</li> <li>For tmux, I use tpm. I used to cook status line myself, but I have switched to powerline.</li> <li>For nvim, I use vundle. And I have several cooked keys.</li> </ul>"},{"location":"notes/source_code/dotconfigs/#vim","title":"VIM","text":"<p>I\u2019m using several popular tools: NERD Tree, NERD commenter, GitGutter, and Tagbar.</p> <p>I created the following mapped keys so that I could invoke them quite easily. Basically I press <code>\\</code> first, and then press <code>t</code>, or <code>f</code>, or <code>g</code>. <pre><code>map \\l :TagbarToggle&lt;Enter&gt;    =&gt; to toggle tagbar list\nmap \\f :NERDTreeToggle&lt;CR&gt;     =&gt; to toggle nerd file tree\nmap \\g :GitGutterLineHighlightsToggle&lt;Enter&gt; :GitGutterSignsToggle&lt;Enter&gt;   =&gt; to highlight git difference\n</code></pre></p> <p>Besides, I have several extra syntax files, for C, ASM, scala, and verilog. I started this when I was hacking linux kernel. It has so many new awesome macros (e.g., <code>BUG_ON</code>, <code>for_each_cpu</code>) and I want to diffrentiate them from normal functions. So I added those <code>after/syntax</code> files.</p>"},{"location":"notes/source_code/dotconfigs/#colorful-man-pages","title":"Colorful Man Pages","text":"<p>This is one thing I highly recommend. It was always a pain reading man pages, not until I found this trick. We can, in fact, redirect man outputs into vim, which in turn can present the text in a colorway.</p> <p>Add these to your shell dotconfig: <pre><code>vman() { man $* | col -b | vim -c 'set ft=man nomod nolist' -; }    \nalias man=\"vman\"\n</code></pre></p>"},{"location":"notes/source_code/dotconfigs/#git","title":"Git","text":"<p>For git, I\u2019m using git alias and a tool call tig.</p> <p>The <code>git alias</code> project has quite a lot shortcuts. Those are my most used ones: <pre><code>g s\n\ng l\ng ll\ng lll\n\ng d\ng dc\ng ds\n</code></pre></p>"},{"location":"notes/source_code/firmware-softwares/","title":"Open-source Firmware and Bootloaders","text":"Version History Date Description Jun 17, 2021 some reorg Dec 7, 2020 add iPXE May 6, 2020 Initial Version <p>In this blog post, I will review the current firmware and bootloader ecosystem. Note that this is very x86-centric.</p>"},{"location":"notes/source_code/firmware-softwares/#landscape","title":"Landscape","text":"<p> (Arrow from A to B means A can run after B. The combination and flow is very flexible.)</p> <p>There are a lot open-source firmware projects. I was trying to understand their relationship. After some research, I drew the above figure. This figure is very x86-centric. Other architecture have other firmwares.</p> <p>Bottom-up:</p> <ol> <li>Coreboot/Libreboot/UEFI: for motherboard init, e.g., init memory controller.</li> <li>UEFI/BIOS</li> <li>GRUB2/u-boot/iPXE: Bootloader<ul> <li>u-boot implements some UEFI spec as well.</li> </ul> </li> <li>OS</li> </ol>"},{"location":"notes/source_code/firmware-softwares/#stages","title":"Stages","text":"<p>Stage 0:</p> <ul> <li>For some boards, some ROM code gets run first no matter what.</li> </ul> <p>Stage 1:</p> <ul> <li>coreboot/libreboot/UEFI.</li> <li>One of their major job is to initialize DRAM, processor, and other low level things,   prepare HW so that later software can run.   Their early stage code must ran from on-chip SRAM/Cache! They will init DRAM so that   later firmware/bootloader/OS can use it.</li> <li>Once that is done, they will pass control to later stage software.</li> </ul> <p>Stage 2:</p> <ul> <li>UEFI/SeaBIOS for x86/OpenSBI for risc-v</li> <li>Those are the firmware in general sense. They will discover hardware, prepare   the memory map, prepare device tree, and so on. Essentially, they gather info.</li> <li>Note that, some of them live even after they pass control to OS.</li> <li>E.g., UEFI is also a service that OS can use.</li> </ul> <p>Stage 3:</p> <ul> <li>U-boot/GRUB/iPXE</li> <li>This is the normal bootloader. Their responsibility is to load the OS kernel.</li> <li>They understand filesystem, network, and other stuff. They are a small OS in some sense.</li> </ul> <p>Stage 4:</p> <ul> <li>OS</li> </ul> <p>You can generally test all these firmware and bootloaders using QEMU. Different distro may choose different bootloaders.</p>"},{"location":"notes/source_code/firmware-softwares/#project-details","title":"Project Details","text":"<ul> <li> <p>Coreboot and Libreboot</p> <ul> <li>Coreboot seems very interesting. It\u2019s only doing one job, which is initialize the very low-level memory controller and on-board resources. It uses cache as memory.</li> <li>We don\u2019t need it on QEMU.</li> <li>Image from here. It shows the Cache-as-RAM v.s. DRAM timeline, the coreboot timline, and where it hands over to next stage.</li> <li></li> </ul> </li> <li> <p>SeaBIOS: the default BIOS used by QEMU</p> <ul> <li>This is good code to learn from.</li> <li>SeaBIOS also works on physical machines.</li> </ul> </li> <li>qboot: an alternative and lightweight BIOS for QEMU<ul> <li>Those are massive hackers, respect.</li> <li>My experience about BIOS is calling them while the kernel (LegoOS) is running at 16-bit.   BIOS is the OS for a just-booted kernel. I remember the lower 1MB is never cleared,   maybe we could invoke the BIOS at 32 or 64-bit mode?</li> </ul> </li> <li>u-boot<ul> <li>Generally u-boot is used as the primary bootloader after BIOS.</li> <li>But u-boot is much more. Based on its description, it can init HW just like coreboot.   Besides, it also provides some UEFI interfaces. So a mix of different things.</li> <li>u-boot is used by Chromebook.</li> </ul> </li> <li>UEFI<ul> <li>UEFI EDK II <ul> <li>\u201cEDK II is a firmware development environment for the UEFI and UEFI Platform Initialization (PI) specifications\u201d</li> <li>Part of the TianoCore project, an open-source UEFI platform</li> <li>The Unified Extensible Firmware Interface (UEFI) is a specification that   defines a software interface between an operating system and platform firmware.   UEFI is designed to replace the Basic Input/Output System (BIOS) firmware interface.</li> <li>OVMF: OVMF is an EDK II based project to enable UEFI support for Virtual Machines. OVMF contains sample UEFI firmware for QEMU and KVM.</li> </ul> </li> <li>Microsoft Project Mu, a separate fork of EDK II<ul> <li>\u201cProject Mu is a modular adaptation of TianoCore\u2019s edk2 tuned for building modern devices using a scalable, maintainable, and reusable pattern\u201d</li> <li>It\u2019s homepage explains the motivation behind it. Microsoft Surface is using it.</li> </ul> </li> <li>A book: <code>Beyond BIOS Developing with the Unified Extensible Firmware Interface</code>.</li> </ul> </li> <li>Then boot loaders such as GRUB and U-Boot</li> <li>iPXE, network bootloader, this is an open-source version. As their website says, iPXE allows you to:     <pre><code>boot from a web server via HTTP\nboot from an iSCSI SAN\nboot from a Fibre Channel SAN via FCoE\nboot from an AoE SAN\nboot from a wireless network\nboot from a wide-area network\nboot from an Infiniband network\ncontrol the boot process with a script\n</code></pre></li> <li>LinuxBoot<ul> <li>Use Linux as the firmware, directly runs after HW is initialized (e.g., after coreboot).</li> </ul> </li> </ul> <p>If you are using a normal laptop or desktop, chances are, none of those firmware is used. Normally machines are shipped with commercial firmwares.</p> <p>To me, I like SeaBIOS project the most. It\u2019s simple and can boot everything we need. (For example, Linux, LegoOS as well).</p>"},{"location":"notes/source_code/firmware-softwares/#thoughts","title":"Thoughts","text":"<p>I\u2019ve read most of the project source code. I do find a lot redundant code/steps. A lot of them will do some initial setup, do hardware probe etc.</p>"},{"location":"notes/source_code/firmware-softwares/#device-tree","title":"Device Tree","text":"<p>There is a device tree specification.</p> <p>Quote</p> <p>A DTSpec-compliant devicetree describes device information in a system that cannot necessarily be dynamically detected by a client program. For example, the architecture of PCI enables a client to probe and detect attached devices, and thus devicetree nodes describing PCI devices might not be required. However, a device node is required to describe a PCI host bridge device in the system if it cannot be detected by probing.</p> <p>==&gt; So it is intended for devices that cannot be dynamically probed.     Devices like PCIe that could be probed shouldn\u2019t be included in a device tree.</p>"},{"location":"notes/source_code/fpga/","title":"FPGA","text":"<p>What is HDL? Hard and Difficult Language. :)</p> <p>This page reflects on various FPGA projects I came across.</p>"},{"location":"notes/source_code/fpga/#code","title":"Code","text":""},{"location":"notes/source_code/fpga/#tools","title":"Tools","text":"<ul> <li>Languages<ul> <li>SpinalHDL</li> <li>Chisel</li> <li>Google XLS</li> </ul> </li> <li>Simulators<ul> <li>Verilator</li> <li>iVerilog</li> </ul> </li> <li>Misc<ul> <li>cocotb</li> <li>MyHDL</li> </ul> </li> <li>gtkwave</li> </ul>"},{"location":"notes/source_code/fpga/#network","title":"Network","text":"<ul> <li>Alex Forencich\u2019s Verilog Ethernet<ul> <li>This repo includes Ethernet PHY, MAC, IP, and UDP layer IPs.</li> <li>It works on various boards.</li> <li>THE BEST choice if you are trying to connect your board to network.</li> <li>Written in Verilog</li> </ul> </li> <li>Alex Forencich\u2019s Corundum NIC<ul> <li>This repo is a full-fledged NIC implementation including the above   Verilog-Ethernet part, DMA engines, PCIe controller, interrupts,   and so on.</li> <li>A NIC has more features than a basic FPGA Ethenet solution.   You need a NIC if you are working with host softwares,   otherwise you should consider using the verilog-ethernet version.</li> <li>Written in Verilog</li> </ul> </li> <li>TCP/IP, RoCEv2 from ETH<ul> <li>There are several papers published using this repo.   It provides the basic TCP/IP and RoCE v2 stack (StRom, EuroSys\u201819).</li> <li>Personally I haven\u2019t used this repo so I don\u2019t have any comments.</li> <li>Written in Xilinx HLS.</li> </ul> </li> </ul>"},{"location":"notes/source_code/fpga/#memory","title":"Memory","text":"<p>TODO.</p>"},{"location":"notes/source_code/fpga/#partial-reconfiguration","title":"Partial Reconfiguration","text":"<p>TODO.</p>"},{"location":"notes/source_code/fpga/#soft-cores","title":"Soft Cores","text":"<ul> <li>VexRiscv, based on SpinalHDL</li> <li>ZipCPU, RISC CPU, written in Verilog</li> <li>OpenPOWER a2i and a2o</li> </ul>"},{"location":"notes/source_code/fpga/#misc","title":"MISC","text":"<ul> <li>OpenWIFI</li> <li>NyuziProcessor, a GPGPU Processor</li> <li>HDMI</li> <li>FPGACosmacELF, based on SpinalHDL</li> </ul>"},{"location":"notes/source_code/fpga/#my-story-with-fpga","title":"My Story with FPGA","text":"<p>Back at late 2018, I started using FPGA to do datacenter research. More specific, we used FPGA to build a disaggregated memory component, which was intended as a follow-up to our prior work LegoOS, OSDI\u201818.</p> <p>Along the way, our idea spin-off a bit. I started looking into building an real OS into FPGA: we tried to build <code>sched</code> (temporal and spacial), <code>mm</code>, <code>net</code>, and various OS functionalties into FPGA (more than a traditional FPGA shell, and other FPGA OSs that a lot of acadamic papers claim!). This experiences enriched me with all sorts of low-level FPGA knowledge. I spent quit a lot of time digging into partial reconfiguration and various hacks to avoid its limitations (see Bitstream Explained, Morphous PR, Ultrascale SSI). This FPGA OS project did not go well and we decided to suspend it.</p>"},{"location":"notes/source_code/gpu/","title":"GPU","text":"<p>For research purpose, I started digging into GPU for the first time. Spent some time just learning the basics. And for now just want to know how large systems are using GPUs, esp. CUDA. Just get a basic sense.</p>"},{"location":"notes/source_code/gpu/#systems","title":"Systems","text":"<ul> <li>tensorflow<ul> <li>CUDA: <code>tensorflow/core/common_runtime/gpu</code></li> <li>quite complicated.</li> </ul> </li> <li>tvm<ul> <li>CUDA: <code>src/runtime/cuda</code></li> <li>OpenCL: <code>src/runtime/opencl</code></li> <li>both seem quite small. And they have documentation: https://tvm.apache.org/docs/dev/codebase_walkthrough.html?highlight=cuda. Hooray!</li> </ul> </li> <li>pytorch and caffee2<ul> <li>CUDA: over all the places. well.</li> </ul> </li> <li>nvidia cuda samples</li> </ul>"},{"location":"notes/source_code/misc/","title":"Misc","text":""},{"location":"notes/source_code/misc/#edb-debugger","title":"EDB Debugger","text":"<p>https://github.com/eteran/edb-debugger</p>"},{"location":"notes/source_code/misc/#blender","title":"Blender","text":"<p>The 3D creation suit. https://github.com/blender/blender</p>"},{"location":"notes/source_code/os/","title":"Operating Systems","text":"Version History Date Description Oct 26, 2021 Add the Mach family references Dec 18, 2020 extracted from the summary doc <p>My personal interest in CS starts from OS. I started by writing my own OS, it was such a rewarding and joyful journey. Since then, I\u2019m hooked with any OS related projects. This page, is my attempt to document the well-known and less well-known OSes. This list is not meant to be complete, a lot of acedemic OS papers are not mentioned here.</p> <p>This awsome-os has a more complete list.</p>"},{"location":"notes/source_code/os/#mainstream","title":"Mainstream","text":"<ul> <li>Linux 0.0.1<ul> <li>This is the first linux source code released by Linus.   Despite several designs are static   or obsolete from today\u2019s point of view, it showcases a simple and elegant solution.</li> </ul> </li> <li>Plan 9 OS<ul> <li>Legendary OS.</li> <li>So many systems are influended by Plan 9 (e.g., Go, gVisor)</li> </ul> </li> <li>illumos, a fork of the Oracle Solaris OS.</li> <li>seL4 Microkernel</li> <li>Mach Family<ul> <li>Mach 3.0 the last version from CMU. Code in Github.</li> <li>GNU Mach and GNU Hurd<ul> <li>MacOS Darwin XNU</li> </ul> </li> </ul> </li> <li>BSD Family<ul> <li>BSD releases all the companion software packages along with the kernel.   So there is a tighter relation between them.   If you ever wondered how XXX is done, or how to get YYY from OS, this is where you can look into.</li> <li>FreeBSD</li> <li>OpenBSD</li> <li>NetBSD</li> <li>TrueOS</li> </ul> </li> <li>Unikernel<ul> <li>OSv. A lightweight unikernel.</li> <li>IncludeOS</li> <li>Rumprun</li> <li>Solo5. Unikernel as processes!</li> </ul> </li> <li>Google Fuchsia<ul> <li>TODO.</li> </ul> </li> </ul> <p> (Image source: https://commons.wikimedia.org/wiki/File:Unix_timeline.en.svg)</p>"},{"location":"notes/source_code/os/#hobby","title":"Hobby","text":"<ul> <li>Visopsys<ul> <li>\u201cIt features a simple but functional graphical interface, pre-emptive multitasking, and virtual memory\u201d</li> </ul> </li> <li>BootOS</li> </ul>"},{"location":"notes/source_code/os/#academic","title":"Academic","text":"<ul> <li>Singularity.<ul> <li>A research OS from MSR. Very interesting one.   It leverages certain PL features to write secure and dependable OS.   It also allows verification. It never landed as a commercial one,   but it does inspire certain follow-up works.</li> <li>Several old research OSes have also used certain language features to carry out security measures (e.g., V++).</li> </ul> </li> <li>MIT Corey<ul> <li>I think the code itself is based on jos.</li> </ul> </li> </ul>"},{"location":"notes/source_code/os/#linux-distribution","title":"Linux Distribution","text":"<p>Ever thought about how to go from Linux Kernel to a full Linux Distribution?</p> <ul> <li>Read: Linux From Scratch</li> <li>systemd</li> </ul>"},{"location":"notes/source_code/rdma/","title":"On DPDK and RDMA Related Software","text":"Version History Date Description Feb 16, 2021 Some updates on Mellanox RDMA NICs Dec 14, 2020 More on DPDK May 28, 2020 Copied from summary <p>This note mainly talks about how DPDK interacts with RDMA (libibverbs), and how libibverbs communicates with the kernel. I document some misc things about RDMA as well.</p>"},{"location":"notes/source_code/rdma/#rdma-nic-latest-updates","title":"RDMA NIC Latest Updates","text":"<p>I sometimes read the <code>MLNX_OFED</code> to track the latest changes introduced in RDMA NICs. They are not sorted chronologically.</p> <ol> <li>Advanced Transport<ul> <li>This section talks about XRC and Dynamically Connected Transport (DCT).   Those are not new, they have been around for some time.   I\u2019m really not sure whether anyone is using them.</li> <li>The RDMA scalability issue stems from the stateful RDMA QP/MR and limited on-chip SRAM cache.   Many prior work tried to address them.   The latest work in this space are: FLOCK, SOSP\u201821 that multiplex QPs in SW; LITE, SOSP\u201817; FaRM/FaSST/etc.</li> </ul> </li> <li>Mellanox Zero Touch RoCE.<ul> <li>Came across a thing called Zero Touch RoCE, looks like it essentially is RoCE w/o PFC.</li> <li>Based on the description, ConnectX-6 is actually using Selective Transmission to handle lossy RoCE!</li> <li>Wow, a lot of changes made to the CC algorithm. Apparently, they must be.</li> <li>So in all, they changed the retranmission mechanism and CC (the whole transport) to make   RDMA NIC work with lossy links (i.e., no PFC). This seems a milestone to me.</li> </ul> </li> <li>Out-of-Order (OOO) Data Placement<ul> <li>Interesting. So they now will not drop out-of-sequence/order packets.   This of course is not their original Go-Back-N retranmission protocol,   but this mechanism works well with data center multi-path routing (e.g., ECMP) and helps improve network utilization.</li> <li>Looks like that this technique, along with the above Zero Touch RoCE, essentially   transforms the original Go-Back-N based RDMA transport that best to work with PFC,   into one that is Selective Retransmission-based and can work w/o lossless link layer.</li> <li>This is of course not impossible and not difficult.   In their OOO placement scheme, they can directly move OoO packets into host DRAM   without even caching them in on-chip memory/cache (not possible!).   So the cost is really minimal, maybe a set of bitmaps.   They probably use techniques in the IRN, SIGCOMM\u201819 paper to track the not-fully-received msgs.</li> <li>The end result is nice.   The RDMA NIC can now get rid of its reliance on lossless link layer (IB or PFC-based Ethernet).   So many PFC issues can be avoided if you are using RoCE.   Just like the IRN paper mentioned, eventually, the iWRAP choice wins.</li> </ul> </li> <li>Device Memory Programming<ul> <li>(Thank you Stew for pointing me to this feature. It is used in the Sherman, SIGMOD\u201822 paper)</li> <li>The RDMA NIC on-device memory is exposed to user applications. RDMA verbs can directly access them.   This avoids the PCIe trips to main memory. Great performance indeed. But I\u2019m not sure how large it is and how to properly manage it.</li> <li>Do note that it is quite easy for any FPGA-based SmartNICs to have this sort of feature implemented.</li> </ul> </li> </ol>"},{"location":"notes/source_code/rdma/#dpdk-and-rdma","title":"DPDK and RDMA","text":"<p>DPDK leverages VFIO to be able to directly access physical devices in the user space. Note that QEMU/Firecracker also use VFIO to directly assign devices to guest OSes (i.e., device passthrough mode).</p> <p>Although both DPDK and RDMA\u2019s data path bypass kernel, their control path are very different from each other. For most NIC drivers in DPDK, there are completely self-contained device drivers in the user space, and these drivers can directly communicate with the hardware device via MMIO (all possible thanks to VFIO). Specifically, once DPDK has done some VFIO ioctls, all data and control path can bypass kernel. Nice, right\uff1f</p> <p>However, for the <code>rdma-core</code>, a lot of the control-path IB verbs (e.g., <code>create_pd</code>, <code>create_cq</code>) still communicate with the kernel via ioctl calls on Infiniband related device files. On the kernel side, the in-kernel uverb hanlders are located in <code>drivers/infiniband/core/uverbs.c</code>. Do note that this is a quite complicated way to build communicatation channels between user and kernel space, although it is quite efficient. This simple framework is used by several other kernel subsystems, such as <code>io_uring</code>. In details, the control verbs mmap some pages between user and kernel, then all the following data path IB verbs (e.g., <code>post_send</code>) could just bypass kernel and talk to the device via MMIO directly. Though <code>rdma-core</code> also has some vendor-specific \u201cdrivers\u201d, this is really different from the above DPDK\u2019s userspace PCIe driver. Userspace \u201crdma-core\u201d vendor-driver deals with the kernel devel vendor-level driver details (same for the ones inside DPDK).</p> <p>FWIW, if you are using a Mellanox VPI card in Ethernet mode (e.g. CX3-5),   DPDK will use its built-in mlx driver, which further use libibverbs,   which further relies on kernel IB stack. It\u2019s not a complete user solution somehow.   Note that DPDK built-in mlx driver uses RAW_PACKET QPs.</p>"},{"location":"notes/source_code/rdma/#dpdk-internal","title":"DPDK Internal","text":"<p>Top-down:</p> <ul> <li>The user-facing part is called Envionmemt Abstraction Layer (EAL), which provides a set of portable interfaces among many OSes. We can think it of as a \u201cPOSIX\u201d interface. This EAL has quite a lot useful and handy APIs, e.g., multicore support where you can call a function on arbitray cores (like the linux <code>on_each_cpu</code> core), timers, atomic operations, memory management APIs. I have built all these components myself, still very pleased to see this.</li> <li>Poll Mode Driver - we cover the mlx ones above</li> <li>Various other drivers</li> </ul>"},{"location":"notes/source_code/rdma/#rdma","title":"RDMA","text":"<p>Below is a list of RDMA-based systems I have used or the ones I think are useful.</p> <p>For RDMA programming tricks, see this seminal work: Design Guidelines for High Performance RDMA Systems, ATC\u201816</p> <ul> <li>Mellanox libvma<ul> <li>An userspace IB verbs based layer providing POSIX socket APIs.   (The SocketDirect, SIGCOMM\u201819 paper was building a similar thing).</li> </ul> </li> <li>verbs perftest<ul> <li>The collection contains a set of bandwidth and latency benchmark such as:</li> <li>Send        - <code>ib_send_bw</code> and <code>ib_send_lat</code></li> <li>RDMA Read   - <code>ib_read_bw</code> and <code>ib_read_lat</code></li> <li>RDMA Write  - <code>ib_write_bw</code> and <code>ib_wriet_lat</code></li> <li>RDMA Atomic - <code>ib_atomic_bw</code> and <code>ib_atomic_lat</code></li> <li>Native Ethernet (when working with MOFED2) - <code>raw_ethernet_bw</code>, <code>raw_ethernet_lat</code></li> </ul> </li> <li>rdma-core<ul> <li>This is the core userspace IB verbs library (e.g., libibverbs). Whenever you are writing userspace RDMA applications, you are using this library.</li> <li>It is interesting to learn how userspace IB layer communicates with kernel.   It is using <code>ioctl()</code> and <code>mmap()</code> to do the trick, quite standard.       Not sure how io_uring would help here.   The ABI interface (i.e., data structures) are quite complex and has several versions.</li> <li><code>libibverbs/example</code><ul> <li>asyncwatch.c</li> <li>device_list.c</li> <li>devinfo.c</li> <li>pingpong.c</li> <li>rc_pingpong.c</li> <li>srq_pingpong.c</li> <li>uc_pingpong.c</li> <li>ud_pingpong.c</li> <li>xsrq_pingpong.c</li> </ul> </li> <li><code>infiniband-diags</code><ul> <li>ibv_devinfo    </li> <li>iblinkinfo    </li> <li>ibping    </li> <li>ibaddr</li> </ul> </li> <li>Kernel Infiniband stack</li> </ul> </li> <li>RPC<ul> <li>gRPC</li> <li>eRPC, NSDI\u201819</li> </ul> </li> </ul>"},{"location":"notes/source_code/risc-v/","title":"Explore RISC-V","text":"Version History Date Description Jun 17, 2021 Initial"},{"location":"notes/source_code/risc-v/#architecture","title":"Architecture","text":"<p>First of all, explore its architecture designs, such as ISA, virtual memory, virtualization support, devices, and so on. At the time of writing, RISC-V\u2019s hypervisor extension has not been defined yet (hence not IOMMU as well).</p> <ul> <li>ISA</li> <li>VM</li> <li>Virtualization</li> <li>I/O, I/O MMU</li> </ul>"},{"location":"notes/source_code/risc-v/#firmwarebootloader","title":"Firmware/Bootloader","text":"<p>This section discuss the boot flow and the firmware status. RISC-V has been ported to most of the major firmware and bootloaders, e.g., coreboot (first-stage-bootloader, prepare RAM), UEFI, U-Boot.</p> <p>RISC-V has a cleaner design compared to X86. Rather than relying on messed up ACPI interfaces, it relys on a layer defined by SBI (an open-source implementation called OpenSBI). The OpenSBI layer sits in Machine-Mode, i.e., the most priviledged mode. It directly manages hardware and exposes standard APIs to upperlayer OS. For example, it exposed <code>send_IPI</code>, <code>reset</code> APIs. Hence, in Linux, it could simply call SBI to send IPI rather than implementing on its own and concerns about hardware details. I like this separation of concerns. </p>"},{"location":"notes/source_code/risc-v/#opensbi","title":"OpenSBI","text":"<p>OpenSBI. This is the default firmware in QEMU for RISC-V. It replaces the old BBL. This one runs after ROM and coreboot (if any). This one will discover/probe hardware (I suppose). After that, it passes control to normal bootloaders like u-boot or GRUB, or just to linux kernel.</p>"},{"location":"notes/source_code/risc-v/#code-study","title":"Code Study","text":"<ul> <li><code>firmware/fw_base.S</code> is the entry point.</li> <li>mostly doing the usual, setting up envionment for C functions. It will save some critical information into a struct passed to C.</li> <li>In the end, it will call into C <code>sbi_init(struct sbi_scratch *)</code>. Note the <code>sbi_scratch</code> structure is filled with crutial info by fw_base.S.</li> <li>It seems every hart will do the same?</li> <li><code>lib/sbi/sbi_init.c</code> is the C entry point after assembly.</li> </ul> <p>Reset: - See <code>sbi_system.c</code> and <code>sbi_ipi.c</code>. It looks like the reset is: send an IPI to target HART, which will then ran a sbi_ipi_process_halt handler to halt. - Is this warm or cold reboot? Or neither?</p>"},{"location":"notes/source_code/risc-v/#scripts","title":"Scripts","text":"<pre><code>make V=1 CROSS_COMPILE=riscv64-linux-gnu- PLATFORM=generic FW_PAYLOAD_PATH=../linux/arch/riscv/boot/Image\n</code></pre>"},{"location":"notes/source_code/risc-v/#qemu","title":"QEMU","text":"<p>Code in <code>hw/riscv/</code>, <code>hw/intc/*_clint_*</code>.</p>"},{"location":"notes/source_code/risc-v/#kernel","title":"Kernel","text":""},{"location":"notes/source_code/risc-v/#toolchain","title":"Toolchain","text":""},{"location":"notes/source_code/spdk/","title":"SPDK","text":"Version History Date Description Dec 14, 2020 More on DPDK May 28, 2020 Copied from summary <p>The source code is here: https://github.com/spdk/spdk.</p>"},{"location":"notes/source_code/summary/","title":"Index","text":""},{"location":"notes/source_code/summary/#source-code-study","title":"Source Code Study","text":"Version History Date Description Oct 16, 2021 Move compilers section to a separate file Dec 7, 2020 add sanitizers section Sep 13, 2020 some notes for python; add tcpstat Jul 26, 2020 Add OpenJDK! Hinted by Hacker News :) Jun 2, 2020 Add librcu Apr 26, 2020 Add wayland, X, gnome, gtk etc Apr 10, 2020 add graphics section Apr 6, 2020 add verbs perftes Mar 3, 2020 add FreeBSD, some fpga stuff Feb 4, 2020 add io_uring, firecracker Jan 31, 2020 Add some good stuff Jan 18, 2020 Initial <p>Beautiful code is art. This page documents all the interesting &amp; practical software/hardware/firmware I came across during my work.</p> <ul> <li>Nutrition</li> <li>Operating Systems</li> <li>Network</li> <li>Virtualization</li> <li>Compilers</li> <li>Bootloader and Firmware</li> <li>Web Servers</li> <li>KVS</li> <li>Databases</li> <li>RDMA and More</li> <li>Graphics</li> <li>FPGA</li> <li>Sanitizers</li> </ul>"},{"location":"notes/source_code/summary/#nutrition","title":"Nutrition","text":"<p>Projects supporting our day-to-day work.</p> <ul> <li>GNU glibc: libc, elf, and dynamic linker<ul> <li>It is the default C library used by almost everyone</li> <li>It includes <code>ld.so</code>, the dynamic linker</li> <li>I wrote some notes about GOT/PLT and explains what has happend before main() is called.</li> </ul> </li> <li>GNU binutils: gas, static linker, and more<ul> <li>This repo has a lot commands like <code>as</code>, <code>ld</code>, <code>objdump</code>, <code>nm</code> and so on</li> <li><code>ld</code> is static linker and I like the magic of its linker script</li> <li>I guess another useful repo is <code>elfutils</code></li> </ul> </li> <li>C Library<ul> <li>GNU glibc used by major Linux distributions</li> <li>musl libc is a small libc impl used by Alpine Linux. Clean code.</li> <li>uClibc is a small libc targeting embedded cases</li> <li>bionic is Android\u2019s C library, math library, and dynamic linker</li> </ul> </li> <li>[C++ Library]<ul> <li>NVIDIA libcu++ </li> </ul> </li> <li>strace<ul> <li>System call tracer at userspace</li> <li>I\u2019ve designed one for LegoOS in kernel space</li> </ul> </li> <li>Unix Commands<ul> <li>Of course almost all other listed repos in this section have some sort of commands.   But they are not essential. The following repos have the essential UNIX commands like ls, cat.   It\u2019s not possible to go through all of them. But rather, I think they serve as references   when we want to know how certain things are implemented (e.g., how dmesg get kernel log).</li> <li>BusyBox</li> <li>GNU Coreutils</li> <li>util-linux</li> <li>FreeBSD and its friends</li> </ul> </li> <li>Tools<ul> <li>tmux</li> <li>git</li> </ul> </li> <li>Editors<ul> <li>vim</li> <li>neovim</li> </ul> </li> <li>C for life<ul> <li>Some small and useful C projects</li> <li>cJSON: A lightweight JSON parser in C.</li> <li>userspace-rcu: A userspace RCU implementation library.</li> </ul> </li> <li>Outliers<ul> <li>CRIU: Checkpoint and Restore in Userspace<ul> <li>The reason I love this repo is because it has so many interesting pieces   on how to interact with kernel, save states, and restore them. In addition,   it shows how to properly use many less well known syscalls.</li> </ul> </li> <li>GRUB2: bootloader<ul> <li>Learn how modern bootloader works.</li> <li>Detailed analysis of Linux booting sequence (how it transit from   real-mode to protected mode, and finally to 64-bit mode,   how to navigate Linux source code etc.)</li> </ul> </li> <li>FFmpeg<ul> <li>FFmpeg project is famous for its clean and neat C code.</li> <li>Besides, this project is used by a lot online video service companies</li> </ul> </li> <li>io uring<ul> <li>user liburing</li> <li>kernel io_uring.c</li> </ul> </li> </ul> </li> </ul>"},{"location":"notes/source_code/summary/#operating-systems","title":"Operating Systems","text":"<p>See here.</p>"},{"location":"notes/source_code/summary/#network","title":"Network","text":"<ul> <li>iperf3 is a TCP, UDP, and SCTP network bandwidth measurement tool</li> <li>tcpdump</li> <li>iputils (arping, ping, etc)</li> <li>scapy: Python-based interactive packet manipulation program &amp; library. Very neat</li> <li>tcpstat: C-based simple tool that could dump network traffic. Seems using pcap interface, the one used by tcpdump?</li> <li>Also checkout FreeBSD as it has tools like <code>ifconfig</code>, <code>if</code>. </li> <li>OpenSSH is our ssh!</li> <li>OpenSSL</li> </ul>"},{"location":"notes/source_code/summary/#virtualization","title":"Virtualization","text":"<p>Also see: http://lastweek.io/notes/source_code/virt/.</p> <ul> <li>libvirt: virsh and more</li> <li>QEMU</li> <li>Firecracker</li> <li>rust-vmm</li> <li>cloud-hypervisor</li> <li>Containers<ul> <li>runc in go.</li> <li>containerd in go.</li> <li>docker in go.</li> <li>k8s in go.</li> </ul> </li> </ul>"},{"location":"notes/source_code/summary/#compilers","title":"Compilers","text":"<p>See here.</p>"},{"location":"notes/source_code/summary/#bootloader-and-firmware","title":"Bootloader and Firmware","text":"<p>See here.</p> <p>The open-source firmware landscape: </p>"},{"location":"notes/source_code/summary/#fpga","title":"FPGA","text":"<ul> <li>My own Collection</li> <li>My own Paper Readings</li> <li>Partial Reconfiguration<ul> <li>Partial Reconfiguration Building Framework</li> <li>Intepret Xilinx Bitstream</li> <li>HLS-based ICAP Controller</li> </ul> </li> <li>Network<ul> <li>Corundum: an FPGA-based NIC<ul> <li>This is THE BEST network stack out there.</li> <li>This is not simply a network stack, it is a NIC.</li> <li>So what makes a NIC? First, PHY and MAC are basic. Second, PCIe connection between host and board. Third, DMA using PCIe, for TX and RX packets between host and board. Fourth, a host NIC driver; Fifth, some opt modules at NIC.</li> <li>This project has it all. Most amazingly, it works on so many boards.</li> <li>They have an FCCM\u201820 paper (finally!) describing the small modules inside.</li> </ul> </li> <li>Verilog-Ethernet<ul> <li>Self-made PHY, MAC IPs, ARP, IP, UDP stack</li> <li>This is also used by the Corundum project.</li> </ul> </li> <li>Limago, HLS-based 100 GbE TCP/IP</li> <li>FPGA Network Stack<ul> <li>This one came from ETH as well.</li> <li>This one is used by many papers, as far as i know, StRoM, EuroSys\u201820.</li> <li>It\u2019s mostly HLS-based. And has ETH/IP/UDP/TCP, RoCE v2 stack.</li> </ul> </li> </ul> </li> <li>Simulation, Synthesis, and P&amp;R<ul> <li>Icarus iverilog.   iverilog is a compiler that translates Verilog source code into   executable programs for simulation, or other netlist formats for further processing man page.</li> <li>VMware Cascade.   Just-in-time compilation for Verilog, what a brilliant idea.</li> <li>Verilog-to-routing.<ul> <li>Synthesis (<code>ODIN II</code>)</li> <li>Logic Optimization &amp; Technology Mapping (<code>ABC</code>)</li> <li>Placement and Route (<code>VPR</code>)</li> </ul> </li> </ul> </li> </ul>"},{"location":"notes/source_code/summary/#web-servers","title":"Web Servers","text":"<ul> <li>Apache httpd</li> <li>nginx</li> </ul>"},{"location":"notes/source_code/summary/#key-value-stores","title":"Key Value Stores","text":"<p>Point of interests: 1) in-memory, and can it extend to use disk/ssd? 2) persistence support 3) network support</p> <ul> <li>RocksDB: A persistent KVS for Flash and RAM Storage. C++</li> <li>LevelDB. C++</li> <li>Memcached. C</li> <li>Redis. C</li> <li>etcd: Distributed reliable KVS. Go</li> </ul>"},{"location":"notes/source_code/summary/#databases","title":"Databases","text":"<ul> <li>MySQL</li> <li>PostgresSQL</li> <li>Yugabyte, distributed SQL</li> </ul>"},{"location":"notes/source_code/summary/#rdma-and-more","title":"RDMA and More","text":"<p>See here</p>"},{"location":"notes/source_code/summary/#graphics","title":"Graphics","text":"<p>More here</p> <ul> <li>X Server and Wayland<ul> <li>X is being replaced by Wayland now..</li> <li>Wayland code seems clean</li> </ul> </li> <li>xvnc<ul> <li>xvnc and its friends, are sitting on top of display manager (i.e., X/Wayland).   They are clients of X/Wayland, but they act as X/Wayland servers for upper layer   application such as GTK/Qt.</li> <li>It\u2019s a middleman, bringing network between X and GTK.</li> <li>TigerVNC, TurboVNC and so on.</li> </ul> </li> <li>GNOME Shell and GTK<ul> <li>GTK\u2019s default backend is X.</li> <li>GNOME shell is a layer on top of GTK+. Similar for KDE/Qt.</li> </ul> </li> <li>xRDP, an RDP server. In C</li> <li>FreeRDP, client and server. In C<ul> <li>Took a brief read of the code, it\u2019s super neat. Should take a serious look sometime.</li> </ul> </li> <li>Vulkan/OpenCL</li> <li>Proton</li> </ul> <p>The landscape:  </p>"},{"location":"notes/source_code/summary/#sanitizers","title":"Sanitizers","text":"<p>There are many tools in both user and kernel space helping programmers identify various issues early on. Those issues including memory safty issue, threading issue, and others.</p> <p>Personally I have not used these tools a lot. But I am very interested in them. I think they could greatly improve productivity.</p> <p>TODO: https://github.com/google/sanitizers</p>"},{"location":"notes/source_code/unix-tools/","title":"Unix Tools","text":"Version History Date Description Jun 21, 2021 Update Dec 23, 2020 extracted from the summary doc"},{"location":"notes/source_code/unix-tools/#alternative-unix-commands","title":"Alternative UNIX commands","text":"<p>Old wine in new bottles. Those are moden rewrite of common commands.</p> <ul> <li>https://github.com/ibraheemdev/modern-unix</li> </ul>"},{"location":"notes/source_code/unix-tools/#essential-commands","title":"Essential Commands","text":"<p>The following repos have the essential UNIX commands like ls, cat, demsg. I don\u2019t think it is a good idea to blindly read the source code. Rather, I think they should be used as references whenever we need to check how something is implemented.</p> <p>Large Collections</p> <ul> <li>BusyBox<ul> <li>This is a software suite that provides several Unix utilities in a single executable file.</li> <li>It has a large collection of commands. It probably has everything that GNU coreutils has.   BuysBox is targeting embedded environment.</li> </ul> </li> <li>GNU Coreutils<ul> <li>This repo has the most used commands such as <code>cp</code>, <code>dd</code>, <code>cat</code>.</li> <li>See the full list here.</li> </ul> </li> <li>GNU binutils: gas, static linker, and more<ul> <li>This one has a set of programming tools for creating and   managing binary programs, object files, libraries, profile data, and assembly source code.</li> <li>See the full list here</li> </ul> </li> <li>util-linux<ul> <li>This is a standard package distributed by the Linux Kernel Organization   for use as part of the Linux operating system.</li> <li>See the full list here.</li> </ul> </li> <li>FreeBSD</li> </ul>"},{"location":"notes/source_code/unix-tools/#network-commands","title":"Network Commands","text":"<ul> <li>iperf3 is a TCP, UDP, and SCTP network bandwidth measurement tool</li> <li>arping</li> <li>tcpdump</li> <li>OpenSSH is our ssh!</li> <li>scapy: Python-based interactive packet manipulation program &amp; library. Very neat</li> <li>tcpstat: C-based simple tool that could dump network traffic. Seems using pcap interface, the one used by tcpdump?</li> <li>Also checkout FreeBSD as it has tools like <code>ifconfig</code>, <code>if</code> and many more</li> </ul>"},{"location":"notes/source_code/unix-tools/#misc","title":"Misc","text":"<ul> <li> <p>Tools</p> <ul> <li>tmux</li> <li>git</li> <li>FFmpeg<ul> <li>FFmpeg project is famous for its clean and neat C code.</li> <li>This project is used by a lot online video service companies</li> </ul> </li> <li>CRIU: Checkpoint and Restore in Userspace<ul> <li>The reason I love this repo is because it has so many interesting pieces   on how to interact with kernel, save states, and restore them. In addition,   it shows how to properly use many less well known syscalls.</li> </ul> </li> <li>GRUB2: bootloader<ul> <li>Learn how modern bootloader works.</li> <li>Detailed analysis of Linux booting sequence (how it transit from   real-mode to protected mode, and finally to 64-bit mode,   how to navigate Linux source code etc.)</li> </ul> </li> <li>strace<ul> <li>System call tracer at userspace</li> <li>I\u2019ve designed one for LegoOS in kernel space</li> </ul> </li> </ul> </li> <li> <p>Editors</p> <ul> <li>vim</li> <li>neovim</li> </ul> </li> </ul>"},{"location":"notes/source_code/unix-tools/#libraries","title":"Libraries","text":"<ul> <li>GNU glibc: libc, elf, and dynamic linker<ul> <li>It is the default C library used by almost everyone</li> <li>It includes <code>ld.so</code>, the dynamic linker</li> <li>I wrote some notes about GOT/PLT and explains what has happend before main() is called.</li> </ul> </li> <li>GNU binutils: gas, static linker, and more<ul> <li>This repo has a lot commands like <code>as</code>, <code>ld</code>, <code>objdump</code>, <code>nm</code> and so on</li> <li><code>ld</code> is static linker and I like the magic of its linker script</li> <li>I guess another useful repo is <code>elfutils</code></li> </ul> </li> <li>C Library<ul> <li>GNU glibc used by major Linux distributions</li> <li>musl libc is a small libc impl used by Alpine Linux. Clean code.</li> <li>uClibc is a small libc targeting embedded cases</li> <li>bionic is Android\u2019s C library, math library, and dynamic linker</li> </ul> </li> <li>C++ Library<ul> <li>NVIDIA libcu++ </li> </ul> </li> </ul>"},{"location":"notes/source_code/virt/","title":"Virtualization","text":"<p>Moved to here: http://lastweek.io/notes/virt/.</p>"},{"location":"rdma/rdma/","title":"Restless Dumb Memory Assassinate (RDMA)","text":""},{"location":"rdma/rdma/#q","title":"Q","text":"<ul> <li>Atomic Operations: what exactly does the atomic mean in this context?</li> <li>RPC: SEND or RDMA Write with Immediate, which is better and why?</li> </ul>"},{"location":"rdma/rdma/#except","title":"Except","text":"<ul> <li><code>One-sided v.s. Two sided</code><ul> <li>SEND and RECV are two sided as the CPU at the responder needs to post a RECV in order for an incoming SEND to be processed. Unlike memory verbs, the responder\u2019s CPU is involved. One thing I do like to note is: the actual data transfer will not bother responder\u2019s CPU, the generated CQE will not bother it as well, only the pre-post action need CPU involvement. (HERD)</li> </ul> </li> <li><code>CQE Generation</code><ul> <li>Requester side: On completing a verb, the requester\u2019s NIC optionally signals completion by DMA-ing a completion entry (CQE) to a completion queue (CQ) associated with the QP. Of course, some WQE can be un-signaled.</li> <li>Responder side: NIC must DMA a CQE for completed RECV. (So I think this will not involve responder\u2019s CPU, right?)</li> </ul> </li> </ul>"},{"location":"rdma/rdma/#ib-specification","title":"IB Specification","text":"<ul> <li> <p>The QP is the virtual interface that the hardware provides to an IBA consumer; it serves as a virtual communication port for the consumer.</p> </li> <li> <p>Memory Region, L_Key, R_Key (sec 3.5.3/3.5.4)</p> <ul> <li>Used in RDMA requests.</li> <li>This is key in many design choices.</li> </ul> </li> <li> <p>Addressing (sec 3.5.10 and sec 4)</p> <ul> <li>Each QP has as queue pair number (QPN) assigned by the channel adapter which uniquely identifies the QP within the channel adapter.</li> <li>QPN GID, LID stuff</li> </ul> </li> <li> <p>IBA Semantic (sec 3.6)</p> <ul> <li>Channel (Send/Receive), classical I/O channel<ul> <li>The message transmitted on the wire only names the destination\u2019s QP, the message does not describe where in the destination consumer\u2019s memory space the message content will be written. Instead, the destination QP contains addressing information used to deliver the message to the appropriate memory location.</li> <li>Pre-Post Receive Buffer (a channel semantic operation for SEND from remote.)</li> </ul> </li> <li>Memory (RDMA)<ul> <li>With memory semantics the initiating party directly reads or writes the virtual address space of a remote node. The remote party needs only communicate the location of the buffer; it is not involved with the actual transfer of the data. Hence, this style is sometimes referred to as single-ended communications.</li> </ul> </li> <li>L_Key and R_Key used to validate access permission.</li> </ul> </li> <li> <p>Immediate Data</p> <ul> <li>RDMA Write and SEND can carry 4 bytes of Immediate data.</li> <li>sec 3.6 SEND can carry Immediate data for each send message. If included, the Immediate data is contained within an additional header field on the last packet of the SEND Operation (sec 9.4.1 SEND Operation).</li> <li>sec 3.7.4 An RDMA Write with immediate data will consume a receive WQE even though the QP did not place any data into the receive buffer since the IMMDT is placed in a CQE that references the receive WQE and indicates that the WQE has completed.</li> <li>sec 9.4.3 If specified by the verbs layer, Immediate data is included in the last packet of an RDMA WRITE message. The Immediate data is not written to the target virtual address range, but is passed to the client after the last RDMA WRITE packet is successfully processed.</li> <li>sec 10.7.2.2 C10-86: The responder\u2019s Receive Queue shall consume a Work Request when Immediate Data is specified in a successfully completed incoming RDMA Write.</li> </ul> </li> <li> <p>QP transport services</p> <ul> <li>RC</li> <li>RD</li> <li>UC</li> <li>UD</li> </ul> </li> <li> <p>IB Layers</p> <ul> <li>The network and link protocols deliver a packet to the desired destination. The transport portion of the packet delivers the packet to the proper QP and instructs the QP how to process the packet\u2019s data.</li> <li>Upper Layers (Consumer Operations). This is the layer most people focus on and try to optimize, right?</li> </ul> </li> <li> <p>IB Transaction Flow (sec 3.8)</p> <ul> <li>Describe the general flow. A nice read.</li> <li>So the WQE of RDMA Write/Read, the sender side\u2019s driver will create a CQE when sender get ACK from receiver? And that marks the end of a RDMA Read/Write? For RC, I think so. According to: When the originator receives an acknowledgment, it creates a CQE on the CQ and retires the WQE from the send queue.</li> <li>sec 3.2.1 Each time the remote consumer successfully executes a SEND operation, the hardware takes the next entry from the receive queue, places the received data in the memory location specified in that receive WQE, and places a CQE on the completion queue indicating to the consumer that the receive operation has completed. Thus the execution of a SEND operation causes a receive queue operation at the remote consumer. That is one important claim, the receiver side can poll the CQ to know if it has received a SEND or not.</li> </ul> </li> <li> <p>IB I/O Operations (sec 3.9)</p> <ul> <li>Interesting. So, instead of a Host Channel Adapter (HCA), we have Target Channel Adapter (TCA), which is attached to a IO device such as SSD. If we look from the IB layered architecture, everything below upper level protocols remain the same. In upper level protocols, which used to be Consumer, now is I/O controller.</li> <li>Do we have this kind of hardware on market? Fabric over NVMe?</li> </ul> </li> <li> <p>Transport Layer (sec 9)</p> <ul> <li>The transport header contains the information required by the endnode to complete the specified operation, e.g. delivery of data payload to the appropriate entity within the endnode such as a thread or IO controller.</li> <li>For a host platform, the client of the transport layer is the Verbs software layer. The client posts buffers or commands to these queues and hardware transfers data from or into the buffers.</li> <li>Reliable transport has response (acknowledge). Unreliable transport does not use acknowledgment messages.</li> <li>SEND can carry 4 bytes of Immediate data for each send message. If included, the Immediate data is contained within an additional header field on the last packet of the SEND Operation (sec 9.4.1 SEND Operation).</li> <li>WQ Packet Ordering Stuff (sec 9.5 Transaction Ordering): A requester shall transmit request messages in the order that the Work Queue Elements (WQEs) were posted.</li> <li>Reliable Service (sec 9.7)<ul> <li>Before it can consider a WQE completed, the requester must wait for the necessary response(s) to arrive. If the requester requires an explicit response such that it can complete a given WQE, then the requester shall be responsible to take the necessary steps to ensure that the needed response is forthcoming.</li> </ul> </li> <li>This section is still too much details on hardware behavior. But Mel must have more detailed stuff in house.</li> </ul> </li> <li> <p>Software Transport interface (sec 10)</p> <ul> <li>I think this section is trying to describe the various software concepts, such as HCA, Protection domain, and so on. The actual manipulations are carried out by Verbs, which are described in sec 11.</li> <li>A QP, which is a component of the channel interface, is NOT directly accessible by the Verbs consumer and can only be manipulated through the use of Verbs.</li> <li>A CQ can be used to multiplex work completions from multiple work queues across queue pairs on the same HCA.</li> <li>Shared Receive Queue (sec 10.2.9) (Is it used in Lego?)</li> <li>Memory Management (sec 10.6)<ul> <li>Memory Region</li> </ul> </li> <li>Able to register a virtually contiguous address range, even though the physical pages are not contiguous.</li> <li>Able to register a physically contiguous address range.</li> <li>Prior to invoking a Register Physical Memory Region or Reregister Physical Memory Region Verb, the Consumer should pin down in physical memory every physical buffer within the Memory Region. (But now Mellanox supports pgfault in their products, right?)</li> <li>Work Request (sec 10.7 and sec 10.8)<ul> <li>Signaled Completion and Unsignaled Completion (sec 10.7.3.1) Finally meet these two description in tech documents. In Lego, we used to use unsignaled (polling), and then we change that to signaled handler.</li> </ul> </li> <li>Submitting a list of Work Requests.. (10.8.2.1)</li> <li>.. the HCA is notified that one or more WQEs are ready to be processed. What is the mechanism of this notification? How does HCA got notified? HCA polling, or driver write something into HCA?</li> <li>Completion Queue Operations: poll a specified CQ for a Work Completion, that is <code>ib_poll_cq()</code>! (sec 11.4.2)</li> </ul> </li> <li> <p>SG list</p> <ul> <li>Based on discussion with Shin-Yeh and Yiying.</li> <li>x3: if a sender uses one-sided RDMA write/read to send a sg-list to remote, the receiver side can only receive a consecutive memory buffer.</li> <li>x3: if a sender uses two-sided RDMA to SEND a sg-list to remote, the receiver can get a sg-list of buffers by pre-post RECV to receive queue.</li> <li>x4 and x5: looks like the User-Mode Memory Registration (UMR) can help to solve the one-sided RDMA issue (not verified).</li> </ul> </li> </ul>"}]}